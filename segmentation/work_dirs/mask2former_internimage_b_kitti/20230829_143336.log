2023-08-29 14:33:36,961 - mmseg - INFO - Multi-processing start method is `None`
2023-08-29 14:33:36,961 - mmseg - INFO - OpenCV num_threads is `12
2023-08-29 14:33:36,961 - mmseg - INFO - OMP num threads is 1
2023-08-29 14:33:36,989 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce GTX 1080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 12.1, V12.1.66
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+cefb275
------------------------------------------------------------

2023-08-29 14:33:36,989 - mmseg - INFO - Distributed training: True
2023-08-29 14:33:37,921 - mmseg - INFO - Config:
num_things_classes = 0
num_stuff_classes = 2
num_classes = 2
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoderMask2Former',
    pretrained=None,
    backbone=dict(
        type='InternImage',
        core_op='DCNv3',
        channels=112,
        depths=[4, 4, 21, 4],
        groups=[7, 14, 28, 56],
        mlp_ratio=4.0,
        drop_path_rate=0.4,
        norm_layer='LN',
        layer_scale=1.0,
        offset_scale=1.0,
        post_norm=True,
        with_cp=False,
        out_indices=(0, 1, 2, 3),
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
        )),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[112, 224, 448, 896],
        feat_channels=256,
        out_channels=256,
        in_index=[0, 1, 2, 3],
        num_things_classes=0,
        num_stuff_classes=2,
        num_queries=100,
        num_transformer_feat_level=3,
        pixel_decoder=dict(
            type='MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        num_heads=8,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=False,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True),
                        with_cp=True),
                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),
                init_cfg=None),
            positional_encoding=dict(
                type='SinePositionalEncoding', num_feats=128, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(
            type='SinePositionalEncoding', num_feats=128, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=256,
                    num_heads=8,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=256,
                    feedforward_channels=2048,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True,
                    with_cp=True),
                feedforward_channels=2048,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[1.0, 1.0, 0.1]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0)),
    train_cfg=dict(
        num_points=12544,
        oversample_ratio=3.0,
        importance_sample_ratio=0.75,
        assigner=dict(
            type='MaskHungarianAssigner',
            cls_cost=dict(type='ClassificationCost', weight=2.0),
            mask_cost=dict(
                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
            dice_cost=dict(
                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
        sampler=dict(type='MaskPseudoSampler')),
    test_cfg=dict(
        panoptic_on=True,
        semantic_on=False,
        instance_on=True,
        max_per_image=100,
        iou_thr=0.8,
        filter_low_score=True,
        mode='slide',
        crop_size=(200, 664),
        stride=(341, 341)),
    init_cfg=None)
dataset_type = 'UPBDataset'
data_root = '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation'
img_norm_cfg = dict(
    mean=[89.497, 93.675, 92.645], std=[76.422, 78.611, 80.487], to_rgb=True)
crop_size = (200, 664)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=False),
    dict(type='LoadCategory'),
    dict(type='Resize', img_scale=(664, 200), ratio_range=None),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[89.497, 93.675, 92.645],
        std=[76.422, 78.611, 80.487],
        to_rgb=True),
    dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
    dict(type='ToMask'),
    dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels', 'category'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(200, 664),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir='self_supervised_labels_30',
        split='splits/val_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=False),
            dict(type='LoadCategory'),
            dict(type='Resize', img_scale=(664, 200), ratio_range=None),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
            dict(type='ToMask'),
            dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=[
                    'img', 'gt_semantic_seg', 'gt_masks', 'gt_labels',
                    'category'
                ])
        ]),
    val=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    constructor='CustomLayerDecayOptimizerConstructor',
    paramwise_cfg=dict(
        num_layers=39,
        layer_decay_rate=0.94,
        depths=[5, 5, 24, 5],
        offset_lr_scale=1.0))
optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
evaluation = dict(
    interval=16000, metric='mIoU', pre_eval=True, save_best='mIoU')
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
work_dir = 'work_dirs/mask2former_internimage_b_kitti'
gpu_ids = range(0, 2)
auto_resume = False

2023-08-29 14:33:39,818 - mmseg - INFO - Set random seed to 1501383380, deterministic: False
2023-08-29 14:33:39,819 - mmseg - INFO - using core type: DCNv3
2023-08-29 14:33:39,819 - mmseg - INFO - using activation layer: GELU
2023-08-29 14:33:39,819 - mmseg - INFO - using main norm layer: LN
2023-08-29 14:33:39,819 - mmseg - INFO - using dpr: linear, 0.4
2023-08-29 14:33:39,819 - mmseg - INFO - level2_post_norm: False
2023-08-29 14:33:39,819 - mmseg - INFO - level2_post_norm_block_ids: None
2023-08-29 14:33:39,819 - mmseg - INFO - res_post_norm: False
2023-08-29 14:33:41,109 - mmseg - INFO - load checkpoint from http path: https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth
2023-08-29 14:33:41,372 - mmseg - INFO - _IncompatibleKeys(missing_keys=[], unexpected_keys=['conv_head.0.weight', 'conv_head.1.0.weight', 'conv_head.1.0.bias', 'conv_head.1.0.running_mean', 'conv_head.1.0.running_var', 'conv_head.1.0.num_batches_tracked', 'head.weight', 'head.bias'])
Name of parameter - Initialization information

backbone.patch_embed.conv1.weight - torch.Size([56, 3, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.weight - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.weight - torch.Size([112, 56, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.conv.weight - torch.Size([224, 112, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.conv.weight - torch.Size([448, 224, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.conv.weight - torch.Size([896, 448, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 896, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 448, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 224, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 112, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  
2023-08-29 14:33:41,612 - mmseg - INFO - Loaded 20598 images
2023-08-29 14:33:52,818 - mmseg - INFO - {'num_layers': 39, 'layer_decay_rate': 0.94, 'depths': [5, 5, 24, 5], 'offset_lr_scale': 1.0}
2023-08-29 14:33:52,818 - mmseg - INFO - Build CustomLayerDecayOptimizerConstructor 0.940000 - 41
2023-08-29 14:33:52,823 - mmseg - INFO - Param groups = {
  "layer_0_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.weight",
      "backbone.patch_embed.conv2.weight",
      "decode_head.query_embed.weight",
      "decode_head.query_feat.weight",
      "decode_head.level_embed.weight",
      "decode_head.cls_embed.weight",
      "decode_head.mask_embed.0.weight",
      "decode_head.mask_embed.2.weight",
      "decode_head.mask_embed.4.weight"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.05
  },
  "layer_0_no_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.bias",
      "backbone.patch_embed.norm1.1.weight",
      "backbone.patch_embed.norm1.1.bias",
      "backbone.patch_embed.conv2.bias",
      "backbone.patch_embed.norm2.1.weight",
      "backbone.patch_embed.norm2.1.bias",
      "decode_head.cls_embed.bias",
      "decode_head.mask_embed.0.bias",
      "decode_head.mask_embed.2.bias",
      "decode_head.mask_embed.4.bias"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.0
  },
  "layer_1_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.gamma1",
      "backbone.levels.0.blocks.0.gamma2",
      "backbone.levels.0.blocks.0.norm1.0.weight",
      "backbone.levels.0.blocks.0.norm1.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.0.dcn.offset.bias",
      "backbone.levels.0.blocks.0.dcn.mask.bias",
      "backbone.levels.0.blocks.0.dcn.input_proj.bias",
      "backbone.levels.0.blocks.0.dcn.output_proj.bias",
      "backbone.levels.0.blocks.0.norm2.0.weight",
      "backbone.levels.0.blocks.0.norm2.0.bias",
      "backbone.levels.0.blocks.0.mlp.fc1.bias",
      "backbone.levels.0.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.0
  },
  "layer_1_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.0.dcn.offset.weight",
      "backbone.levels.0.blocks.0.dcn.mask.weight",
      "backbone.levels.0.blocks.0.dcn.input_proj.weight",
      "backbone.levels.0.blocks.0.dcn.output_proj.weight",
      "backbone.levels.0.blocks.0.mlp.fc1.weight",
      "backbone.levels.0.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.05
  },
  "layer_2_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.gamma1",
      "backbone.levels.0.blocks.1.gamma2",
      "backbone.levels.0.blocks.1.norm1.0.weight",
      "backbone.levels.0.blocks.1.norm1.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.1.dcn.offset.bias",
      "backbone.levels.0.blocks.1.dcn.mask.bias",
      "backbone.levels.0.blocks.1.dcn.input_proj.bias",
      "backbone.levels.0.blocks.1.dcn.output_proj.bias",
      "backbone.levels.0.blocks.1.norm2.0.weight",
      "backbone.levels.0.blocks.1.norm2.0.bias",
      "backbone.levels.0.blocks.1.mlp.fc1.bias",
      "backbone.levels.0.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.0
  },
  "layer_2_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.1.dcn.offset.weight",
      "backbone.levels.0.blocks.1.dcn.mask.weight",
      "backbone.levels.0.blocks.1.dcn.input_proj.weight",
      "backbone.levels.0.blocks.1.dcn.output_proj.weight",
      "backbone.levels.0.blocks.1.mlp.fc1.weight",
      "backbone.levels.0.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.05
  },
  "layer_3_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.gamma1",
      "backbone.levels.0.blocks.2.gamma2",
      "backbone.levels.0.blocks.2.norm1.0.weight",
      "backbone.levels.0.blocks.2.norm1.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.2.dcn.offset.bias",
      "backbone.levels.0.blocks.2.dcn.mask.bias",
      "backbone.levels.0.blocks.2.dcn.input_proj.bias",
      "backbone.levels.0.blocks.2.dcn.output_proj.bias",
      "backbone.levels.0.blocks.2.norm2.0.weight",
      "backbone.levels.0.blocks.2.norm2.0.bias",
      "backbone.levels.0.blocks.2.mlp.fc1.bias",
      "backbone.levels.0.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.0
  },
  "layer_3_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.2.dcn.offset.weight",
      "backbone.levels.0.blocks.2.dcn.mask.weight",
      "backbone.levels.0.blocks.2.dcn.input_proj.weight",
      "backbone.levels.0.blocks.2.dcn.output_proj.weight",
      "backbone.levels.0.blocks.2.mlp.fc1.weight",
      "backbone.levels.0.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.05
  },
  "layer_4_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.gamma1",
      "backbone.levels.0.blocks.3.gamma2",
      "backbone.levels.0.blocks.3.norm1.0.weight",
      "backbone.levels.0.blocks.3.norm1.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.3.dcn.offset.bias",
      "backbone.levels.0.blocks.3.dcn.mask.bias",
      "backbone.levels.0.blocks.3.dcn.input_proj.bias",
      "backbone.levels.0.blocks.3.dcn.output_proj.bias",
      "backbone.levels.0.blocks.3.norm2.0.weight",
      "backbone.levels.0.blocks.3.norm2.0.bias",
      "backbone.levels.0.blocks.3.mlp.fc1.bias",
      "backbone.levels.0.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.0
  },
  "layer_4_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.3.dcn.offset.weight",
      "backbone.levels.0.blocks.3.dcn.mask.weight",
      "backbone.levels.0.blocks.3.dcn.input_proj.weight",
      "backbone.levels.0.blocks.3.dcn.output_proj.weight",
      "backbone.levels.0.blocks.3.mlp.fc1.weight",
      "backbone.levels.0.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.05
  },
  "layer_6_decay": {
    "param_names": [
      "backbone.levels.0.downsample.conv.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.0.dcn.offset.weight",
      "backbone.levels.1.blocks.0.dcn.mask.weight",
      "backbone.levels.1.blocks.0.dcn.input_proj.weight",
      "backbone.levels.1.blocks.0.dcn.output_proj.weight",
      "backbone.levels.1.blocks.0.mlp.fc1.weight",
      "backbone.levels.1.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.05
  },
  "layer_6_no_decay": {
    "param_names": [
      "backbone.levels.0.downsample.norm.1.weight",
      "backbone.levels.0.downsample.norm.1.bias",
      "backbone.levels.1.blocks.0.gamma1",
      "backbone.levels.1.blocks.0.gamma2",
      "backbone.levels.1.blocks.0.norm1.0.weight",
      "backbone.levels.1.blocks.0.norm1.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.0.dcn.offset.bias",
      "backbone.levels.1.blocks.0.dcn.mask.bias",
      "backbone.levels.1.blocks.0.dcn.input_proj.bias",
      "backbone.levels.1.blocks.0.dcn.output_proj.bias",
      "backbone.levels.1.blocks.0.norm2.0.weight",
      "backbone.levels.1.blocks.0.norm2.0.bias",
      "backbone.levels.1.blocks.0.mlp.fc1.bias",
      "backbone.levels.1.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.0
  },
  "layer_7_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.gamma1",
      "backbone.levels.1.blocks.1.gamma2",
      "backbone.levels.1.blocks.1.norm1.0.weight",
      "backbone.levels.1.blocks.1.norm1.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.1.dcn.offset.bias",
      "backbone.levels.1.blocks.1.dcn.mask.bias",
      "backbone.levels.1.blocks.1.dcn.input_proj.bias",
      "backbone.levels.1.blocks.1.dcn.output_proj.bias",
      "backbone.levels.1.blocks.1.norm2.0.weight",
      "backbone.levels.1.blocks.1.norm2.0.bias",
      "backbone.levels.1.blocks.1.mlp.fc1.bias",
      "backbone.levels.1.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.0
  },
  "layer_7_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.1.dcn.offset.weight",
      "backbone.levels.1.blocks.1.dcn.mask.weight",
      "backbone.levels.1.blocks.1.dcn.input_proj.weight",
      "backbone.levels.1.blocks.1.dcn.output_proj.weight",
      "backbone.levels.1.blocks.1.mlp.fc1.weight",
      "backbone.levels.1.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.05
  },
  "layer_8_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.gamma1",
      "backbone.levels.1.blocks.2.gamma2",
      "backbone.levels.1.blocks.2.norm1.0.weight",
      "backbone.levels.1.blocks.2.norm1.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.2.dcn.offset.bias",
      "backbone.levels.1.blocks.2.dcn.mask.bias",
      "backbone.levels.1.blocks.2.dcn.input_proj.bias",
      "backbone.levels.1.blocks.2.dcn.output_proj.bias",
      "backbone.levels.1.blocks.2.norm2.0.weight",
      "backbone.levels.1.blocks.2.norm2.0.bias",
      "backbone.levels.1.blocks.2.mlp.fc1.bias",
      "backbone.levels.1.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.0
  },
  "layer_8_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.2.dcn.offset.weight",
      "backbone.levels.1.blocks.2.dcn.mask.weight",
      "backbone.levels.1.blocks.2.dcn.input_proj.weight",
      "backbone.levels.1.blocks.2.dcn.output_proj.weight",
      "backbone.levels.1.blocks.2.mlp.fc1.weight",
      "backbone.levels.1.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.05
  },
  "layer_9_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.gamma1",
      "backbone.levels.1.blocks.3.gamma2",
      "backbone.levels.1.blocks.3.norm1.0.weight",
      "backbone.levels.1.blocks.3.norm1.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.3.dcn.offset.bias",
      "backbone.levels.1.blocks.3.dcn.mask.bias",
      "backbone.levels.1.blocks.3.dcn.input_proj.bias",
      "backbone.levels.1.blocks.3.dcn.output_proj.bias",
      "backbone.levels.1.blocks.3.norm2.0.weight",
      "backbone.levels.1.blocks.3.norm2.0.bias",
      "backbone.levels.1.blocks.3.mlp.fc1.bias",
      "backbone.levels.1.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.0
  },
  "layer_9_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.3.dcn.offset.weight",
      "backbone.levels.1.blocks.3.dcn.mask.weight",
      "backbone.levels.1.blocks.3.dcn.input_proj.weight",
      "backbone.levels.1.blocks.3.dcn.output_proj.weight",
      "backbone.levels.1.blocks.3.mlp.fc1.weight",
      "backbone.levels.1.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.05
  },
  "layer_11_decay": {
    "param_names": [
      "backbone.levels.1.downsample.conv.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.0.dcn.offset.weight",
      "backbone.levels.2.blocks.0.dcn.mask.weight",
      "backbone.levels.2.blocks.0.dcn.input_proj.weight",
      "backbone.levels.2.blocks.0.dcn.output_proj.weight",
      "backbone.levels.2.blocks.0.mlp.fc1.weight",
      "backbone.levels.2.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.05
  },
  "layer_11_no_decay": {
    "param_names": [
      "backbone.levels.1.downsample.norm.1.weight",
      "backbone.levels.1.downsample.norm.1.bias",
      "backbone.levels.2.blocks.0.gamma1",
      "backbone.levels.2.blocks.0.gamma2",
      "backbone.levels.2.blocks.0.norm1.0.weight",
      "backbone.levels.2.blocks.0.norm1.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.0.dcn.offset.bias",
      "backbone.levels.2.blocks.0.dcn.mask.bias",
      "backbone.levels.2.blocks.0.dcn.input_proj.bias",
      "backbone.levels.2.blocks.0.dcn.output_proj.bias",
      "backbone.levels.2.blocks.0.norm2.0.weight",
      "backbone.levels.2.blocks.0.norm2.0.bias",
      "backbone.levels.2.blocks.0.mlp.fc1.bias",
      "backbone.levels.2.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.0
  },
  "layer_12_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.gamma1",
      "backbone.levels.2.blocks.1.gamma2",
      "backbone.levels.2.blocks.1.norm1.0.weight",
      "backbone.levels.2.blocks.1.norm1.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.1.dcn.offset.bias",
      "backbone.levels.2.blocks.1.dcn.mask.bias",
      "backbone.levels.2.blocks.1.dcn.input_proj.bias",
      "backbone.levels.2.blocks.1.dcn.output_proj.bias",
      "backbone.levels.2.blocks.1.norm2.0.weight",
      "backbone.levels.2.blocks.1.norm2.0.bias",
      "backbone.levels.2.blocks.1.mlp.fc1.bias",
      "backbone.levels.2.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.0
  },
  "layer_12_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.1.dcn.offset.weight",
      "backbone.levels.2.blocks.1.dcn.mask.weight",
      "backbone.levels.2.blocks.1.dcn.input_proj.weight",
      "backbone.levels.2.blocks.1.dcn.output_proj.weight",
      "backbone.levels.2.blocks.1.mlp.fc1.weight",
      "backbone.levels.2.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.05
  },
  "layer_13_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.gamma1",
      "backbone.levels.2.blocks.2.gamma2",
      "backbone.levels.2.blocks.2.norm1.0.weight",
      "backbone.levels.2.blocks.2.norm1.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.2.dcn.offset.bias",
      "backbone.levels.2.blocks.2.dcn.mask.bias",
      "backbone.levels.2.blocks.2.dcn.input_proj.bias",
      "backbone.levels.2.blocks.2.dcn.output_proj.bias",
      "backbone.levels.2.blocks.2.norm2.0.weight",
      "backbone.levels.2.blocks.2.norm2.0.bias",
      "backbone.levels.2.blocks.2.mlp.fc1.bias",
      "backbone.levels.2.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.0
  },
  "layer_13_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.2.dcn.offset.weight",
      "backbone.levels.2.blocks.2.dcn.mask.weight",
      "backbone.levels.2.blocks.2.dcn.input_proj.weight",
      "backbone.levels.2.blocks.2.dcn.output_proj.weight",
      "backbone.levels.2.blocks.2.mlp.fc1.weight",
      "backbone.levels.2.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.05
  },
  "layer_14_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.gamma1",
      "backbone.levels.2.blocks.3.gamma2",
      "backbone.levels.2.blocks.3.norm1.0.weight",
      "backbone.levels.2.blocks.3.norm1.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.3.dcn.offset.bias",
      "backbone.levels.2.blocks.3.dcn.mask.bias",
      "backbone.levels.2.blocks.3.dcn.input_proj.bias",
      "backbone.levels.2.blocks.3.dcn.output_proj.bias",
      "backbone.levels.2.blocks.3.norm2.0.weight",
      "backbone.levels.2.blocks.3.norm2.0.bias",
      "backbone.levels.2.blocks.3.mlp.fc1.bias",
      "backbone.levels.2.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.0
  },
  "layer_14_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.3.dcn.offset.weight",
      "backbone.levels.2.blocks.3.dcn.mask.weight",
      "backbone.levels.2.blocks.3.dcn.input_proj.weight",
      "backbone.levels.2.blocks.3.dcn.output_proj.weight",
      "backbone.levels.2.blocks.3.mlp.fc1.weight",
      "backbone.levels.2.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.05
  },
  "layer_15_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.gamma1",
      "backbone.levels.2.blocks.4.gamma2",
      "backbone.levels.2.blocks.4.norm1.0.weight",
      "backbone.levels.2.blocks.4.norm1.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.4.dcn.offset.bias",
      "backbone.levels.2.blocks.4.dcn.mask.bias",
      "backbone.levels.2.blocks.4.dcn.input_proj.bias",
      "backbone.levels.2.blocks.4.dcn.output_proj.bias",
      "backbone.levels.2.blocks.4.norm2.0.weight",
      "backbone.levels.2.blocks.4.norm2.0.bias",
      "backbone.levels.2.blocks.4.mlp.fc1.bias",
      "backbone.levels.2.blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.0
  },
  "layer_15_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.4.dcn.offset.weight",
      "backbone.levels.2.blocks.4.dcn.mask.weight",
      "backbone.levels.2.blocks.4.dcn.input_proj.weight",
      "backbone.levels.2.blocks.4.dcn.output_proj.weight",
      "backbone.levels.2.blocks.4.mlp.fc1.weight",
      "backbone.levels.2.blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.05
  },
  "layer_16_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.gamma1",
      "backbone.levels.2.blocks.5.gamma2",
      "backbone.levels.2.blocks.5.norm1.0.weight",
      "backbone.levels.2.blocks.5.norm1.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.5.dcn.offset.bias",
      "backbone.levels.2.blocks.5.dcn.mask.bias",
      "backbone.levels.2.blocks.5.dcn.input_proj.bias",
      "backbone.levels.2.blocks.5.dcn.output_proj.bias",
      "backbone.levels.2.blocks.5.norm2.0.weight",
      "backbone.levels.2.blocks.5.norm2.0.bias",
      "backbone.levels.2.blocks.5.mlp.fc1.bias",
      "backbone.levels.2.blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.0
  },
  "layer_16_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.5.dcn.offset.weight",
      "backbone.levels.2.blocks.5.dcn.mask.weight",
      "backbone.levels.2.blocks.5.dcn.input_proj.weight",
      "backbone.levels.2.blocks.5.dcn.output_proj.weight",
      "backbone.levels.2.blocks.5.mlp.fc1.weight",
      "backbone.levels.2.blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.05
  },
  "layer_17_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.gamma1",
      "backbone.levels.2.blocks.6.gamma2",
      "backbone.levels.2.blocks.6.norm1.0.weight",
      "backbone.levels.2.blocks.6.norm1.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.6.dcn.offset.bias",
      "backbone.levels.2.blocks.6.dcn.mask.bias",
      "backbone.levels.2.blocks.6.dcn.input_proj.bias",
      "backbone.levels.2.blocks.6.dcn.output_proj.bias",
      "backbone.levels.2.blocks.6.norm2.0.weight",
      "backbone.levels.2.blocks.6.norm2.0.bias",
      "backbone.levels.2.blocks.6.mlp.fc1.bias",
      "backbone.levels.2.blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.0
  },
  "layer_17_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.6.dcn.offset.weight",
      "backbone.levels.2.blocks.6.dcn.mask.weight",
      "backbone.levels.2.blocks.6.dcn.input_proj.weight",
      "backbone.levels.2.blocks.6.dcn.output_proj.weight",
      "backbone.levels.2.blocks.6.mlp.fc1.weight",
      "backbone.levels.2.blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.05
  },
  "layer_18_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.gamma1",
      "backbone.levels.2.blocks.7.gamma2",
      "backbone.levels.2.blocks.7.norm1.0.weight",
      "backbone.levels.2.blocks.7.norm1.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.7.dcn.offset.bias",
      "backbone.levels.2.blocks.7.dcn.mask.bias",
      "backbone.levels.2.blocks.7.dcn.input_proj.bias",
      "backbone.levels.2.blocks.7.dcn.output_proj.bias",
      "backbone.levels.2.blocks.7.norm2.0.weight",
      "backbone.levels.2.blocks.7.norm2.0.bias",
      "backbone.levels.2.blocks.7.mlp.fc1.bias",
      "backbone.levels.2.blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.0
  },
  "layer_18_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.7.dcn.offset.weight",
      "backbone.levels.2.blocks.7.dcn.mask.weight",
      "backbone.levels.2.blocks.7.dcn.input_proj.weight",
      "backbone.levels.2.blocks.7.dcn.output_proj.weight",
      "backbone.levels.2.blocks.7.mlp.fc1.weight",
      "backbone.levels.2.blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.05
  },
  "layer_19_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.gamma1",
      "backbone.levels.2.blocks.8.gamma2",
      "backbone.levels.2.blocks.8.norm1.0.weight",
      "backbone.levels.2.blocks.8.norm1.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.8.dcn.offset.bias",
      "backbone.levels.2.blocks.8.dcn.mask.bias",
      "backbone.levels.2.blocks.8.dcn.input_proj.bias",
      "backbone.levels.2.blocks.8.dcn.output_proj.bias",
      "backbone.levels.2.blocks.8.norm2.0.weight",
      "backbone.levels.2.blocks.8.norm2.0.bias",
      "backbone.levels.2.blocks.8.mlp.fc1.bias",
      "backbone.levels.2.blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.0
  },
  "layer_19_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.8.dcn.offset.weight",
      "backbone.levels.2.blocks.8.dcn.mask.weight",
      "backbone.levels.2.blocks.8.dcn.input_proj.weight",
      "backbone.levels.2.blocks.8.dcn.output_proj.weight",
      "backbone.levels.2.blocks.8.mlp.fc1.weight",
      "backbone.levels.2.blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.05
  },
  "layer_20_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.gamma1",
      "backbone.levels.2.blocks.9.gamma2",
      "backbone.levels.2.blocks.9.norm1.0.weight",
      "backbone.levels.2.blocks.9.norm1.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.9.dcn.offset.bias",
      "backbone.levels.2.blocks.9.dcn.mask.bias",
      "backbone.levels.2.blocks.9.dcn.input_proj.bias",
      "backbone.levels.2.blocks.9.dcn.output_proj.bias",
      "backbone.levels.2.blocks.9.norm2.0.weight",
      "backbone.levels.2.blocks.9.norm2.0.bias",
      "backbone.levels.2.blocks.9.mlp.fc1.bias",
      "backbone.levels.2.blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.0
  },
  "layer_20_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.9.dcn.offset.weight",
      "backbone.levels.2.blocks.9.dcn.mask.weight",
      "backbone.levels.2.blocks.9.dcn.input_proj.weight",
      "backbone.levels.2.blocks.9.dcn.output_proj.weight",
      "backbone.levels.2.blocks.9.mlp.fc1.weight",
      "backbone.levels.2.blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.05
  },
  "layer_21_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.gamma1",
      "backbone.levels.2.blocks.10.gamma2",
      "backbone.levels.2.blocks.10.norm1.0.weight",
      "backbone.levels.2.blocks.10.norm1.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.10.dcn.offset.bias",
      "backbone.levels.2.blocks.10.dcn.mask.bias",
      "backbone.levels.2.blocks.10.dcn.input_proj.bias",
      "backbone.levels.2.blocks.10.dcn.output_proj.bias",
      "backbone.levels.2.blocks.10.norm2.0.weight",
      "backbone.levels.2.blocks.10.norm2.0.bias",
      "backbone.levels.2.blocks.10.mlp.fc1.bias",
      "backbone.levels.2.blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.0
  },
  "layer_21_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.10.dcn.offset.weight",
      "backbone.levels.2.blocks.10.dcn.mask.weight",
      "backbone.levels.2.blocks.10.dcn.input_proj.weight",
      "backbone.levels.2.blocks.10.dcn.output_proj.weight",
      "backbone.levels.2.blocks.10.mlp.fc1.weight",
      "backbone.levels.2.blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.05
  },
  "layer_22_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.gamma1",
      "backbone.levels.2.blocks.11.gamma2",
      "backbone.levels.2.blocks.11.norm1.0.weight",
      "backbone.levels.2.blocks.11.norm1.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.11.dcn.offset.bias",
      "backbone.levels.2.blocks.11.dcn.mask.bias",
      "backbone.levels.2.blocks.11.dcn.input_proj.bias",
      "backbone.levels.2.blocks.11.dcn.output_proj.bias",
      "backbone.levels.2.blocks.11.norm2.0.weight",
      "backbone.levels.2.blocks.11.norm2.0.bias",
      "backbone.levels.2.blocks.11.mlp.fc1.bias",
      "backbone.levels.2.blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.0
  },
  "layer_22_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.11.dcn.offset.weight",
      "backbone.levels.2.blocks.11.dcn.mask.weight",
      "backbone.levels.2.blocks.11.dcn.input_proj.weight",
      "backbone.levels.2.blocks.11.dcn.output_proj.weight",
      "backbone.levels.2.blocks.11.mlp.fc1.weight",
      "backbone.levels.2.blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.05
  },
  "layer_23_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.gamma1",
      "backbone.levels.2.blocks.12.gamma2",
      "backbone.levels.2.blocks.12.norm1.0.weight",
      "backbone.levels.2.blocks.12.norm1.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.12.dcn.offset.bias",
      "backbone.levels.2.blocks.12.dcn.mask.bias",
      "backbone.levels.2.blocks.12.dcn.input_proj.bias",
      "backbone.levels.2.blocks.12.dcn.output_proj.bias",
      "backbone.levels.2.blocks.12.norm2.0.weight",
      "backbone.levels.2.blocks.12.norm2.0.bias",
      "backbone.levels.2.blocks.12.mlp.fc1.bias",
      "backbone.levels.2.blocks.12.mlp.fc2.bias"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.0
  },
  "layer_23_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.12.dcn.offset.weight",
      "backbone.levels.2.blocks.12.dcn.mask.weight",
      "backbone.levels.2.blocks.12.dcn.input_proj.weight",
      "backbone.levels.2.blocks.12.dcn.output_proj.weight",
      "backbone.levels.2.blocks.12.mlp.fc1.weight",
      "backbone.levels.2.blocks.12.mlp.fc2.weight"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.05
  },
  "layer_24_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.gamma1",
      "backbone.levels.2.blocks.13.gamma2",
      "backbone.levels.2.blocks.13.norm1.0.weight",
      "backbone.levels.2.blocks.13.norm1.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.13.dcn.offset.bias",
      "backbone.levels.2.blocks.13.dcn.mask.bias",
      "backbone.levels.2.blocks.13.dcn.input_proj.bias",
      "backbone.levels.2.blocks.13.dcn.output_proj.bias",
      "backbone.levels.2.blocks.13.norm2.0.weight",
      "backbone.levels.2.blocks.13.norm2.0.bias",
      "backbone.levels.2.blocks.13.mlp.fc1.bias",
      "backbone.levels.2.blocks.13.mlp.fc2.bias"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.0
  },
  "layer_24_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.13.dcn.offset.weight",
      "backbone.levels.2.blocks.13.dcn.mask.weight",
      "backbone.levels.2.blocks.13.dcn.input_proj.weight",
      "backbone.levels.2.blocks.13.dcn.output_proj.weight",
      "backbone.levels.2.blocks.13.mlp.fc1.weight",
      "backbone.levels.2.blocks.13.mlp.fc2.weight"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.05
  },
  "layer_25_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.gamma1",
      "backbone.levels.2.blocks.14.gamma2",
      "backbone.levels.2.blocks.14.norm1.0.weight",
      "backbone.levels.2.blocks.14.norm1.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.14.dcn.offset.bias",
      "backbone.levels.2.blocks.14.dcn.mask.bias",
      "backbone.levels.2.blocks.14.dcn.input_proj.bias",
      "backbone.levels.2.blocks.14.dcn.output_proj.bias",
      "backbone.levels.2.blocks.14.norm2.0.weight",
      "backbone.levels.2.blocks.14.norm2.0.bias",
      "backbone.levels.2.blocks.14.mlp.fc1.bias",
      "backbone.levels.2.blocks.14.mlp.fc2.bias"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.0
  },
  "layer_25_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.14.dcn.offset.weight",
      "backbone.levels.2.blocks.14.dcn.mask.weight",
      "backbone.levels.2.blocks.14.dcn.input_proj.weight",
      "backbone.levels.2.blocks.14.dcn.output_proj.weight",
      "backbone.levels.2.blocks.14.mlp.fc1.weight",
      "backbone.levels.2.blocks.14.mlp.fc2.weight"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.05
  },
  "layer_26_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.gamma1",
      "backbone.levels.2.blocks.15.gamma2",
      "backbone.levels.2.blocks.15.norm1.0.weight",
      "backbone.levels.2.blocks.15.norm1.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.15.dcn.offset.bias",
      "backbone.levels.2.blocks.15.dcn.mask.bias",
      "backbone.levels.2.blocks.15.dcn.input_proj.bias",
      "backbone.levels.2.blocks.15.dcn.output_proj.bias",
      "backbone.levels.2.blocks.15.norm2.0.weight",
      "backbone.levels.2.blocks.15.norm2.0.bias",
      "backbone.levels.2.blocks.15.mlp.fc1.bias",
      "backbone.levels.2.blocks.15.mlp.fc2.bias"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.0
  },
  "layer_26_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.15.dcn.offset.weight",
      "backbone.levels.2.blocks.15.dcn.mask.weight",
      "backbone.levels.2.blocks.15.dcn.input_proj.weight",
      "backbone.levels.2.blocks.15.dcn.output_proj.weight",
      "backbone.levels.2.blocks.15.mlp.fc1.weight",
      "backbone.levels.2.blocks.15.mlp.fc2.weight"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.05
  },
  "layer_27_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.gamma1",
      "backbone.levels.2.blocks.16.gamma2",
      "backbone.levels.2.blocks.16.norm1.0.weight",
      "backbone.levels.2.blocks.16.norm1.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.16.dcn.offset.bias",
      "backbone.levels.2.blocks.16.dcn.mask.bias",
      "backbone.levels.2.blocks.16.dcn.input_proj.bias",
      "backbone.levels.2.blocks.16.dcn.output_proj.bias",
      "backbone.levels.2.blocks.16.norm2.0.weight",
      "backbone.levels.2.blocks.16.norm2.0.bias",
      "backbone.levels.2.blocks.16.mlp.fc1.bias",
      "backbone.levels.2.blocks.16.mlp.fc2.bias"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.0
  },
  "layer_27_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.16.dcn.offset.weight",
      "backbone.levels.2.blocks.16.dcn.mask.weight",
      "backbone.levels.2.blocks.16.dcn.input_proj.weight",
      "backbone.levels.2.blocks.16.dcn.output_proj.weight",
      "backbone.levels.2.blocks.16.mlp.fc1.weight",
      "backbone.levels.2.blocks.16.mlp.fc2.weight"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.05
  },
  "layer_28_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.gamma1",
      "backbone.levels.2.blocks.17.gamma2",
      "backbone.levels.2.blocks.17.norm1.0.weight",
      "backbone.levels.2.blocks.17.norm1.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.17.dcn.offset.bias",
      "backbone.levels.2.blocks.17.dcn.mask.bias",
      "backbone.levels.2.blocks.17.dcn.input_proj.bias",
      "backbone.levels.2.blocks.17.dcn.output_proj.bias",
      "backbone.levels.2.blocks.17.norm2.0.weight",
      "backbone.levels.2.blocks.17.norm2.0.bias",
      "backbone.levels.2.blocks.17.mlp.fc1.bias",
      "backbone.levels.2.blocks.17.mlp.fc2.bias"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.0
  },
  "layer_28_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.17.dcn.offset.weight",
      "backbone.levels.2.blocks.17.dcn.mask.weight",
      "backbone.levels.2.blocks.17.dcn.input_proj.weight",
      "backbone.levels.2.blocks.17.dcn.output_proj.weight",
      "backbone.levels.2.blocks.17.mlp.fc1.weight",
      "backbone.levels.2.blocks.17.mlp.fc2.weight"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.05
  },
  "layer_29_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.gamma1",
      "backbone.levels.2.blocks.18.gamma2",
      "backbone.levels.2.blocks.18.norm1.0.weight",
      "backbone.levels.2.blocks.18.norm1.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.18.dcn.offset.bias",
      "backbone.levels.2.blocks.18.dcn.mask.bias",
      "backbone.levels.2.blocks.18.dcn.input_proj.bias",
      "backbone.levels.2.blocks.18.dcn.output_proj.bias",
      "backbone.levels.2.blocks.18.norm2.0.weight",
      "backbone.levels.2.blocks.18.norm2.0.bias",
      "backbone.levels.2.blocks.18.mlp.fc1.bias",
      "backbone.levels.2.blocks.18.mlp.fc2.bias"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.0
  },
  "layer_29_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.18.dcn.offset.weight",
      "backbone.levels.2.blocks.18.dcn.mask.weight",
      "backbone.levels.2.blocks.18.dcn.input_proj.weight",
      "backbone.levels.2.blocks.18.dcn.output_proj.weight",
      "backbone.levels.2.blocks.18.mlp.fc1.weight",
      "backbone.levels.2.blocks.18.mlp.fc2.weight"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.05
  },
  "layer_30_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.gamma1",
      "backbone.levels.2.blocks.19.gamma2",
      "backbone.levels.2.blocks.19.norm1.0.weight",
      "backbone.levels.2.blocks.19.norm1.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.19.dcn.offset.bias",
      "backbone.levels.2.blocks.19.dcn.mask.bias",
      "backbone.levels.2.blocks.19.dcn.input_proj.bias",
      "backbone.levels.2.blocks.19.dcn.output_proj.bias",
      "backbone.levels.2.blocks.19.norm2.0.weight",
      "backbone.levels.2.blocks.19.norm2.0.bias",
      "backbone.levels.2.blocks.19.mlp.fc1.bias",
      "backbone.levels.2.blocks.19.mlp.fc2.bias"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.0
  },
  "layer_30_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.19.dcn.offset.weight",
      "backbone.levels.2.blocks.19.dcn.mask.weight",
      "backbone.levels.2.blocks.19.dcn.input_proj.weight",
      "backbone.levels.2.blocks.19.dcn.output_proj.weight",
      "backbone.levels.2.blocks.19.mlp.fc1.weight",
      "backbone.levels.2.blocks.19.mlp.fc2.weight"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.05
  },
  "layer_31_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.gamma1",
      "backbone.levels.2.blocks.20.gamma2",
      "backbone.levels.2.blocks.20.norm1.0.weight",
      "backbone.levels.2.blocks.20.norm1.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.20.dcn.offset.bias",
      "backbone.levels.2.blocks.20.dcn.mask.bias",
      "backbone.levels.2.blocks.20.dcn.input_proj.bias",
      "backbone.levels.2.blocks.20.dcn.output_proj.bias",
      "backbone.levels.2.blocks.20.norm2.0.weight",
      "backbone.levels.2.blocks.20.norm2.0.bias",
      "backbone.levels.2.blocks.20.mlp.fc1.bias",
      "backbone.levels.2.blocks.20.mlp.fc2.bias"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.0
  },
  "layer_31_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.20.dcn.offset.weight",
      "backbone.levels.2.blocks.20.dcn.mask.weight",
      "backbone.levels.2.blocks.20.dcn.input_proj.weight",
      "backbone.levels.2.blocks.20.dcn.output_proj.weight",
      "backbone.levels.2.blocks.20.mlp.fc1.weight",
      "backbone.levels.2.blocks.20.mlp.fc2.weight"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.05
  },
  "layer_35_decay": {
    "param_names": [
      "backbone.levels.2.downsample.conv.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.0.dcn.offset.weight",
      "backbone.levels.3.blocks.0.dcn.mask.weight",
      "backbone.levels.3.blocks.0.dcn.input_proj.weight",
      "backbone.levels.3.blocks.0.dcn.output_proj.weight",
      "backbone.levels.3.blocks.0.mlp.fc1.weight",
      "backbone.levels.3.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.05
  },
  "layer_35_no_decay": {
    "param_names": [
      "backbone.levels.2.downsample.norm.1.weight",
      "backbone.levels.2.downsample.norm.1.bias",
      "backbone.levels.3.blocks.0.gamma1",
      "backbone.levels.3.blocks.0.gamma2",
      "backbone.levels.3.blocks.0.norm1.0.weight",
      "backbone.levels.3.blocks.0.norm1.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.0.dcn.offset.bias",
      "backbone.levels.3.blocks.0.dcn.mask.bias",
      "backbone.levels.3.blocks.0.dcn.input_proj.bias",
      "backbone.levels.3.blocks.0.dcn.output_proj.bias",
      "backbone.levels.3.blocks.0.norm2.0.weight",
      "backbone.levels.3.blocks.0.norm2.0.bias",
      "backbone.levels.3.blocks.0.mlp.fc1.bias",
      "backbone.levels.3.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.0
  },
  "layer_36_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.gamma1",
      "backbone.levels.3.blocks.1.gamma2",
      "backbone.levels.3.blocks.1.norm1.0.weight",
      "backbone.levels.3.blocks.1.norm1.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.1.dcn.offset.bias",
      "backbone.levels.3.blocks.1.dcn.mask.bias",
      "backbone.levels.3.blocks.1.dcn.input_proj.bias",
      "backbone.levels.3.blocks.1.dcn.output_proj.bias",
      "backbone.levels.3.blocks.1.norm2.0.weight",
      "backbone.levels.3.blocks.1.norm2.0.bias",
      "backbone.levels.3.blocks.1.mlp.fc1.bias",
      "backbone.levels.3.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.0
  },
  "layer_36_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.1.dcn.offset.weight",
      "backbone.levels.3.blocks.1.dcn.mask.weight",
      "backbone.levels.3.blocks.1.dcn.input_proj.weight",
      "backbone.levels.3.blocks.1.dcn.output_proj.weight",
      "backbone.levels.3.blocks.1.mlp.fc1.weight",
      "backbone.levels.3.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.05
  },
  "layer_37_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.gamma1",
      "backbone.levels.3.blocks.2.gamma2",
      "backbone.levels.3.blocks.2.norm1.0.weight",
      "backbone.levels.3.blocks.2.norm1.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.2.dcn.offset.bias",
      "backbone.levels.3.blocks.2.dcn.mask.bias",
      "backbone.levels.3.blocks.2.dcn.input_proj.bias",
      "backbone.levels.3.blocks.2.dcn.output_proj.bias",
      "backbone.levels.3.blocks.2.norm2.0.weight",
      "backbone.levels.3.blocks.2.norm2.0.bias",
      "backbone.levels.3.blocks.2.mlp.fc1.bias",
      "backbone.levels.3.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.0
  },
  "layer_37_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.2.dcn.offset.weight",
      "backbone.levels.3.blocks.2.dcn.mask.weight",
      "backbone.levels.3.blocks.2.dcn.input_proj.weight",
      "backbone.levels.3.blocks.2.dcn.output_proj.weight",
      "backbone.levels.3.blocks.2.mlp.fc1.weight",
      "backbone.levels.3.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.05
  },
  "layer_38_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.gamma1",
      "backbone.levels.3.blocks.3.gamma2",
      "backbone.levels.3.blocks.3.norm1.0.weight",
      "backbone.levels.3.blocks.3.norm1.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.3.dcn.offset.bias",
      "backbone.levels.3.blocks.3.dcn.mask.bias",
      "backbone.levels.3.blocks.3.dcn.input_proj.bias",
      "backbone.levels.3.blocks.3.dcn.output_proj.bias",
      "backbone.levels.3.blocks.3.norm2.0.weight",
      "backbone.levels.3.blocks.3.norm2.0.bias",
      "backbone.levels.3.blocks.3.mlp.fc1.bias",
      "backbone.levels.3.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.0
  },
  "layer_38_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.3.dcn.offset.weight",
      "backbone.levels.3.blocks.3.dcn.mask.weight",
      "backbone.levels.3.blocks.3.dcn.input_proj.weight",
      "backbone.levels.3.blocks.3.dcn.output_proj.weight",
      "backbone.levels.3.blocks.3.mlp.fc1.weight",
      "backbone.levels.3.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.05
  },
  "layer_40_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.weight",
      "decode_head.pixel_decoder.input_convs.1.conv.weight",
      "decode_head.pixel_decoder.input_convs.2.conv.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.level_encoding.weight",
      "decode_head.pixel_decoder.lateral_convs.0.conv.weight",
      "decode_head.pixel_decoder.output_convs.0.conv.weight",
      "decode_head.pixel_decoder.mask_feature.weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.05
  },
  "layer_40_no_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.bias",
      "decode_head.pixel_decoder.input_convs.0.gn.weight",
      "decode_head.pixel_decoder.input_convs.0.gn.bias",
      "decode_head.pixel_decoder.input_convs.1.conv.bias",
      "decode_head.pixel_decoder.input_convs.1.gn.weight",
      "decode_head.pixel_decoder.input_convs.1.gn.bias",
      "decode_head.pixel_decoder.input_convs.2.conv.bias",
      "decode_head.pixel_decoder.input_convs.2.gn.weight",
      "decode_head.pixel_decoder.input_convs.2.gn.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.bias",
      "decode_head.pixel_decoder.lateral_convs.0.gn.weight",
      "decode_head.pixel_decoder.lateral_convs.0.gn.bias",
      "decode_head.pixel_decoder.output_convs.0.gn.weight",
      "decode_head.pixel_decoder.output_convs.0.gn.bias",
      "decode_head.pixel_decoder.mask_feature.bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.0.weight",
      "decode_head.transformer_decoder.layers.0.norms.0.bias",
      "decode_head.transformer_decoder.layers.0.norms.1.weight",
      "decode_head.transformer_decoder.layers.0.norms.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.2.weight",
      "decode_head.transformer_decoder.layers.0.norms.2.bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.0.weight",
      "decode_head.transformer_decoder.layers.1.norms.0.bias",
      "decode_head.transformer_decoder.layers.1.norms.1.weight",
      "decode_head.transformer_decoder.layers.1.norms.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.2.weight",
      "decode_head.transformer_decoder.layers.1.norms.2.bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.0.weight",
      "decode_head.transformer_decoder.layers.2.norms.0.bias",
      "decode_head.transformer_decoder.layers.2.norms.1.weight",
      "decode_head.transformer_decoder.layers.2.norms.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.2.weight",
      "decode_head.transformer_decoder.layers.2.norms.2.bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.0.weight",
      "decode_head.transformer_decoder.layers.3.norms.0.bias",
      "decode_head.transformer_decoder.layers.3.norms.1.weight",
      "decode_head.transformer_decoder.layers.3.norms.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.2.weight",
      "decode_head.transformer_decoder.layers.3.norms.2.bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.0.weight",
      "decode_head.transformer_decoder.layers.4.norms.0.bias",
      "decode_head.transformer_decoder.layers.4.norms.1.weight",
      "decode_head.transformer_decoder.layers.4.norms.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.2.weight",
      "decode_head.transformer_decoder.layers.4.norms.2.bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.0.weight",
      "decode_head.transformer_decoder.layers.5.norms.0.bias",
      "decode_head.transformer_decoder.layers.5.norms.1.weight",
      "decode_head.transformer_decoder.layers.5.norms.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.2.weight",
      "decode_head.transformer_decoder.layers.5.norms.2.bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.0.weight",
      "decode_head.transformer_decoder.layers.6.norms.0.bias",
      "decode_head.transformer_decoder.layers.6.norms.1.weight",
      "decode_head.transformer_decoder.layers.6.norms.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.2.weight",
      "decode_head.transformer_decoder.layers.6.norms.2.bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.0.weight",
      "decode_head.transformer_decoder.layers.7.norms.0.bias",
      "decode_head.transformer_decoder.layers.7.norms.1.weight",
      "decode_head.transformer_decoder.layers.7.norms.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.2.weight",
      "decode_head.transformer_decoder.layers.7.norms.2.bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.0.weight",
      "decode_head.transformer_decoder.layers.8.norms.0.bias",
      "decode_head.transformer_decoder.layers.8.norms.1.weight",
      "decode_head.transformer_decoder.layers.8.norms.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.2.weight",
      "decode_head.transformer_decoder.layers.8.norms.2.bias",
      "decode_head.transformer_decoder.post_norm.weight",
      "decode_head.transformer_decoder.post_norm.bias"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.0
  }
}
2023-08-29 14:33:52,844 - mmseg - INFO - Loaded 6861 images
2023-08-29 14:33:52,878 - mmseg - INFO - Start running, host: nemodrive@nemodrive0, work_dir: /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti
2023-08-29 14:33:52,878 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-08-29 14:33:52,878 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-08-29 14:33:52,878 - mmseg - INFO - Checkpoints will be saved to /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti by HardDiskBackend.
2023-08-29 14:34:26,875 - mmseg - INFO - Iter [50/160000]	lr: 5.497e-08, eta: 1 day, 6:12:06, time: 0.680, data_time: 0.007, memory: 6584, decode.loss_cls: 1.7560, decode.loss_mask: 3.5326, decode.loss_dice: 3.1865, decode.d0.loss_cls: 2.2869, decode.d0.loss_mask: 2.3091, decode.d0.loss_dice: 3.1300, decode.d1.loss_cls: 2.6377, decode.d1.loss_mask: 2.6893, decode.d1.loss_dice: 3.1434, decode.d2.loss_cls: 2.5994, decode.d2.loss_mask: 2.9730, decode.d2.loss_dice: 3.3075, decode.d3.loss_cls: 2.1266, decode.d3.loss_mask: 3.2116, decode.d3.loss_dice: 3.3586, decode.d4.loss_cls: 1.9765, decode.d4.loss_mask: 3.3876, decode.d4.loss_dice: 3.1245, decode.d5.loss_cls: 1.3705, decode.d5.loss_mask: 3.4436, decode.d5.loss_dice: 3.0720, decode.d6.loss_cls: 2.3618, decode.d6.loss_mask: 3.4504, decode.d6.loss_dice: 3.1652, decode.d7.loss_cls: 1.5141, decode.d7.loss_mask: 3.5332, decode.d7.loss_dice: 3.0678, decode.d8.loss_cls: 2.0989, decode.d8.loss_mask: 3.5309, decode.d8.loss_dice: 3.1344, loss: 84.4793, grad_norm: 375.4324
2023-08-29 14:35:02,280 - mmseg - INFO - Iter [100/160000]	lr: 1.110e-07, eta: 1 day, 6:49:20, time: 0.708, data_time: 0.047, memory: 6584, decode.loss_cls: 1.2883, decode.loss_mask: 3.5807, decode.loss_dice: 3.0480, decode.d0.loss_cls: 2.2898, decode.d0.loss_mask: 1.9564, decode.d0.loss_dice: 2.9196, decode.d1.loss_cls: 2.3272, decode.d1.loss_mask: 2.3399, decode.d1.loss_dice: 2.8468, decode.d2.loss_cls: 2.0799, decode.d2.loss_mask: 2.8449, decode.d2.loss_dice: 3.0700, decode.d3.loss_cls: 1.6372, decode.d3.loss_mask: 3.1449, decode.d3.loss_dice: 3.1043, decode.d4.loss_cls: 1.4671, decode.d4.loss_mask: 3.2826, decode.d4.loss_dice: 2.8817, decode.d5.loss_cls: 1.1767, decode.d5.loss_mask: 3.4210, decode.d5.loss_dice: 2.9513, decode.d6.loss_cls: 1.6183, decode.d6.loss_mask: 3.4289, decode.d6.loss_dice: 3.0079, decode.d7.loss_cls: 1.2228, decode.d7.loss_mask: 3.7130, decode.d7.loss_dice: 2.8585, decode.d8.loss_cls: 1.4365, decode.d8.loss_mask: 3.6281, decode.d8.loss_dice: 2.9299, loss: 77.5021, grad_norm: 230.0055
2023-08-29 14:35:38,137 - mmseg - INFO - Iter [150/160000]	lr: 1.670e-07, eta: 1 day, 7:09:18, time: 0.717, data_time: 0.046, memory: 6584, decode.loss_cls: 1.1453, decode.loss_mask: 3.5106, decode.loss_dice: 3.0008, decode.d0.loss_cls: 2.2935, decode.d0.loss_mask: 1.4300, decode.d0.loss_dice: 2.6053, decode.d1.loss_cls: 1.8472, decode.d1.loss_mask: 1.3878, decode.d1.loss_dice: 2.4778, decode.d2.loss_cls: 1.4888, decode.d2.loss_mask: 1.8036, decode.d2.loss_dice: 2.5523, decode.d3.loss_cls: 1.2847, decode.d3.loss_mask: 2.1323, decode.d3.loss_dice: 2.6251, decode.d4.loss_cls: 1.1947, decode.d4.loss_mask: 2.7071, decode.d4.loss_dice: 2.7378, decode.d5.loss_cls: 1.1392, decode.d5.loss_mask: 2.9093, decode.d5.loss_dice: 2.8263, decode.d6.loss_cls: 1.2417, decode.d6.loss_mask: 3.0595, decode.d6.loss_dice: 2.9025, decode.d7.loss_cls: 1.1348, decode.d7.loss_mask: 3.4101, decode.d7.loss_dice: 2.8886, decode.d8.loss_cls: 1.1524, decode.d8.loss_mask: 3.3922, decode.d8.loss_dice: 2.9352, loss: 67.2164, grad_norm: 173.4271
2023-08-29 14:36:14,273 - mmseg - INFO - Iter [200/160000]	lr: 2.230e-07, eta: 1 day, 7:22:46, time: 0.723, data_time: 0.046, memory: 6584, decode.loss_cls: 1.1359, decode.loss_mask: 2.9029, decode.loss_dice: 2.8217, decode.d0.loss_cls: 2.2938, decode.d0.loss_mask: 1.3454, decode.d0.loss_dice: 2.4167, decode.d1.loss_cls: 1.4471, decode.d1.loss_mask: 1.2962, decode.d1.loss_dice: 2.3377, decode.d2.loss_cls: 1.1867, decode.d2.loss_mask: 1.3567, decode.d2.loss_dice: 2.3280, decode.d3.loss_cls: 1.1511, decode.d3.loss_mask: 1.3923, decode.d3.loss_dice: 2.3409, decode.d4.loss_cls: 1.1432, decode.d4.loss_mask: 1.4955, decode.d4.loss_dice: 2.4033, decode.d5.loss_cls: 1.0963, decode.d5.loss_mask: 1.5168, decode.d5.loss_dice: 2.3891, decode.d6.loss_cls: 1.1759, decode.d6.loss_mask: 1.7172, decode.d6.loss_dice: 2.4471, decode.d7.loss_cls: 1.0971, decode.d7.loss_mask: 2.2768, decode.d7.loss_dice: 2.5889, decode.d8.loss_cls: 1.1152, decode.d8.loss_mask: 2.4697, decode.d8.loss_dice: 2.7156, loss: 55.4009, grad_norm: 174.6179
2023-08-29 14:36:48,401 - mmseg - INFO - Iter [250/160000]	lr: 2.790e-07, eta: 1 day, 7:09:12, time: 0.683, data_time: 0.004, memory: 6584, decode.loss_cls: 0.9849, decode.loss_mask: 1.5328, decode.loss_dice: 2.2574, decode.d0.loss_cls: 2.2905, decode.d0.loss_mask: 1.4266, decode.d0.loss_dice: 2.1970, decode.d1.loss_cls: 1.1481, decode.d1.loss_mask: 1.5667, decode.d1.loss_dice: 2.1806, decode.d2.loss_cls: 0.9079, decode.d2.loss_mask: 1.5718, decode.d2.loss_dice: 2.1924, decode.d3.loss_cls: 0.7863, decode.d3.loss_mask: 1.5370, decode.d3.loss_dice: 2.2048, decode.d4.loss_cls: 0.8005, decode.d4.loss_mask: 1.4768, decode.d4.loss_dice: 2.2078, decode.d5.loss_cls: 0.7981, decode.d5.loss_mask: 1.5064, decode.d5.loss_dice: 2.1814, decode.d6.loss_cls: 0.8060, decode.d6.loss_mask: 1.4820, decode.d6.loss_dice: 2.1733, decode.d7.loss_cls: 0.8385, decode.d7.loss_mask: 1.5145, decode.d7.loss_dice: 2.2325, decode.d8.loss_cls: 0.9311, decode.d8.loss_mask: 1.4752, decode.d8.loss_dice: 2.2909, loss: 47.4999, grad_norm: 137.4502
2023-08-29 14:37:24,087 - mmseg - INFO - Iter [300/160000]	lr: 3.349e-07, eta: 1 day, 7:13:48, time: 0.714, data_time: 0.048, memory: 6584, decode.loss_cls: 0.6730, decode.loss_mask: 1.5615, decode.loss_dice: 2.1578, decode.d0.loss_cls: 2.2870, decode.d0.loss_mask: 1.5542, decode.d0.loss_dice: 2.1531, decode.d1.loss_cls: 0.9873, decode.d1.loss_mask: 1.5873, decode.d1.loss_dice: 2.1685, decode.d2.loss_cls: 0.6785, decode.d2.loss_mask: 1.6184, decode.d2.loss_dice: 2.1336, decode.d3.loss_cls: 0.4499, decode.d3.loss_mask: 1.5953, decode.d3.loss_dice: 2.1453, decode.d4.loss_cls: 0.3976, decode.d4.loss_mask: 1.5962, decode.d4.loss_dice: 2.1432, decode.d5.loss_cls: 0.3878, decode.d5.loss_mask: 1.5891, decode.d5.loss_dice: 2.1448, decode.d6.loss_cls: 0.3783, decode.d6.loss_mask: 1.5899, decode.d6.loss_dice: 2.1287, decode.d7.loss_cls: 0.4403, decode.d7.loss_mask: 1.5777, decode.d7.loss_dice: 2.1726, decode.d8.loss_cls: 0.5700, decode.d8.loss_mask: 1.5659, decode.d8.loss_dice: 2.1958, loss: 44.6285, grad_norm: 155.9740
2023-08-29 14:38:00,525 - mmseg - INFO - Iter [350/160000]	lr: 3.908e-07, eta: 1 day, 7:22:37, time: 0.729, data_time: 0.046, memory: 6584, decode.loss_cls: 0.3155, decode.loss_mask: 1.5937, decode.loss_dice: 2.0768, decode.d0.loss_cls: 2.2867, decode.d0.loss_mask: 1.5560, decode.d0.loss_dice: 2.1061, decode.d1.loss_cls: 0.8789, decode.d1.loss_mask: 1.5911, decode.d1.loss_dice: 2.1153, decode.d2.loss_cls: 0.4361, decode.d2.loss_mask: 1.6106, decode.d2.loss_dice: 2.1050, decode.d3.loss_cls: 0.2569, decode.d3.loss_mask: 1.6108, decode.d3.loss_dice: 2.0649, decode.d4.loss_cls: 0.1892, decode.d4.loss_mask: 1.6076, decode.d4.loss_dice: 2.0559, decode.d5.loss_cls: 0.1705, decode.d5.loss_mask: 1.5908, decode.d5.loss_dice: 2.0756, decode.d6.loss_cls: 0.1508, decode.d6.loss_mask: 1.6068, decode.d6.loss_dice: 2.0567, decode.d7.loss_cls: 0.1749, decode.d7.loss_mask: 1.5833, decode.d7.loss_dice: 2.0852, decode.d8.loss_cls: 0.2450, decode.d8.loss_mask: 1.5843, decode.d8.loss_dice: 2.1064, loss: 41.8873, grad_norm: 199.8325
2023-08-29 14:38:37,058 - mmseg - INFO - Iter [400/160000]	lr: 4.466e-07, eta: 1 day, 7:29:43, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.1779, decode.loss_mask: 1.6027, decode.loss_dice: 2.0170, decode.d0.loss_cls: 2.2842, decode.d0.loss_mask: 1.5709, decode.d0.loss_dice: 2.0878, decode.d1.loss_cls: 0.7987, decode.d1.loss_mask: 1.5931, decode.d1.loss_dice: 2.0789, decode.d2.loss_cls: 0.3167, decode.d2.loss_mask: 1.5994, decode.d2.loss_dice: 2.0341, decode.d3.loss_cls: 0.1712, decode.d3.loss_mask: 1.5982, decode.d3.loss_dice: 2.0238, decode.d4.loss_cls: 0.1189, decode.d4.loss_mask: 1.5983, decode.d4.loss_dice: 2.0234, decode.d5.loss_cls: 0.1054, decode.d5.loss_mask: 1.5906, decode.d5.loss_dice: 2.0281, decode.d6.loss_cls: 0.0914, decode.d6.loss_mask: 1.5985, decode.d6.loss_dice: 2.0094, decode.d7.loss_cls: 0.1028, decode.d7.loss_mask: 1.5853, decode.d7.loss_dice: 2.0198, decode.d8.loss_cls: 0.1387, decode.d8.loss_mask: 1.5847, decode.d8.loss_dice: 2.0315, loss: 40.5813, grad_norm: 239.6251
2023-08-29 14:39:11,435 - mmseg - INFO - Iter [450/160000]	lr: 5.024e-07, eta: 1 day, 7:22:20, time: 0.687, data_time: 0.004, memory: 6584, decode.loss_cls: 0.1097, decode.loss_mask: 1.6064, decode.loss_dice: 1.9678, decode.d0.loss_cls: 2.2851, decode.d0.loss_mask: 1.5784, decode.d0.loss_dice: 2.0502, decode.d1.loss_cls: 0.7316, decode.d1.loss_mask: 1.5759, decode.d1.loss_dice: 2.0395, decode.d2.loss_cls: 0.2470, decode.d2.loss_mask: 1.6020, decode.d2.loss_dice: 1.9892, decode.d3.loss_cls: 0.1239, decode.d3.loss_mask: 1.6005, decode.d3.loss_dice: 1.9720, decode.d4.loss_cls: 0.0792, decode.d4.loss_mask: 1.5884, decode.d4.loss_dice: 1.9859, decode.d5.loss_cls: 0.0703, decode.d5.loss_mask: 1.5867, decode.d5.loss_dice: 1.9830, decode.d6.loss_cls: 0.0569, decode.d6.loss_mask: 1.6014, decode.d6.loss_dice: 1.9616, decode.d7.loss_cls: 0.0641, decode.d7.loss_mask: 1.5863, decode.d7.loss_dice: 1.9697, decode.d8.loss_cls: 0.0857, decode.d8.loss_mask: 1.5804, decode.d8.loss_dice: 1.9723, loss: 39.6510, grad_norm: 297.6501
2023-08-29 14:39:47,443 - mmseg - INFO - Iter [500/160000]	lr: 5.582e-07, eta: 1 day, 7:25:00, time: 0.720, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0889, decode.loss_mask: 1.5633, decode.loss_dice: 1.9019, decode.d0.loss_cls: 2.2815, decode.d0.loss_mask: 1.5844, decode.d0.loss_dice: 2.0141, decode.d1.loss_cls: 0.6735, decode.d1.loss_mask: 1.5541, decode.d1.loss_dice: 1.9781, decode.d2.loss_cls: 0.2102, decode.d2.loss_mask: 1.5767, decode.d2.loss_dice: 1.9236, decode.d3.loss_cls: 0.1110, decode.d3.loss_mask: 1.5684, decode.d3.loss_dice: 1.9043, decode.d4.loss_cls: 0.0708, decode.d4.loss_mask: 1.5564, decode.d4.loss_dice: 1.9118, decode.d5.loss_cls: 0.0613, decode.d5.loss_mask: 1.5573, decode.d5.loss_dice: 1.9073, decode.d6.loss_cls: 0.0546, decode.d6.loss_mask: 1.5581, decode.d6.loss_dice: 1.8907, decode.d7.loss_cls: 0.0583, decode.d7.loss_mask: 1.5449, decode.d7.loss_dice: 1.8943, decode.d8.loss_cls: 0.0732, decode.d8.loss_mask: 1.5501, decode.d8.loss_dice: 1.9008, loss: 38.5240, grad_norm: 313.2452
2023-08-29 14:40:24,083 - mmseg - INFO - Iter [550/160000]	lr: 6.140e-07, eta: 1 day, 7:30:09, time: 0.733, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0751, decode.loss_mask: 1.5891, decode.loss_dice: 1.8825, decode.d0.loss_cls: 2.2790, decode.d0.loss_mask: 1.6134, decode.d0.loss_dice: 1.9933, decode.d1.loss_cls: 0.6120, decode.d1.loss_mask: 1.5678, decode.d1.loss_dice: 1.9440, decode.d2.loss_cls: 0.1819, decode.d2.loss_mask: 1.5830, decode.d2.loss_dice: 1.8963, decode.d3.loss_cls: 0.0949, decode.d3.loss_mask: 1.5814, decode.d3.loss_dice: 1.8820, decode.d4.loss_cls: 0.0660, decode.d4.loss_mask: 1.5698, decode.d4.loss_dice: 1.8940, decode.d5.loss_cls: 0.0596, decode.d5.loss_mask: 1.5670, decode.d5.loss_dice: 1.8882, decode.d6.loss_cls: 0.0547, decode.d6.loss_mask: 1.5789, decode.d6.loss_dice: 1.8734, decode.d7.loss_cls: 0.0571, decode.d7.loss_mask: 1.5712, decode.d7.loss_dice: 1.8733, decode.d8.loss_cls: 0.0654, decode.d8.loss_mask: 1.5699, decode.d8.loss_dice: 1.8756, loss: 38.3397, grad_norm: 357.0604
2023-08-29 14:41:00,974 - mmseg - INFO - Iter [600/160000]	lr: 6.697e-07, eta: 1 day, 7:35:27, time: 0.738, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0488, decode.loss_mask: 1.4359, decode.loss_dice: 1.7627, decode.d0.loss_cls: 2.2797, decode.d0.loss_mask: 1.5042, decode.d0.loss_dice: 1.9049, decode.d1.loss_cls: 0.5535, decode.d1.loss_mask: 1.4370, decode.d1.loss_dice: 1.8293, decode.d2.loss_cls: 0.1507, decode.d2.loss_mask: 1.4569, decode.d2.loss_dice: 1.7827, decode.d3.loss_cls: 0.0729, decode.d3.loss_mask: 1.4422, decode.d3.loss_dice: 1.7675, decode.d4.loss_cls: 0.0437, decode.d4.loss_mask: 1.4293, decode.d4.loss_dice: 1.7798, decode.d5.loss_cls: 0.0383, decode.d5.loss_mask: 1.4426, decode.d5.loss_dice: 1.7746, decode.d6.loss_cls: 0.0321, decode.d6.loss_mask: 1.4377, decode.d6.loss_dice: 1.7565, decode.d7.loss_cls: 0.0327, decode.d7.loss_mask: 1.4262, decode.d7.loss_dice: 1.7661, decode.d8.loss_cls: 0.0406, decode.d8.loss_mask: 1.4220, decode.d8.loss_dice: 1.7589, loss: 35.6098, grad_norm: 398.0216
2023-08-29 14:41:35,179 - mmseg - INFO - Iter [650/160000]	lr: 7.253e-07, eta: 1 day, 7:28:50, time: 0.684, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0344, decode.loss_mask: 1.5174, decode.loss_dice: 1.8390, decode.d0.loss_cls: 2.2779, decode.d0.loss_mask: 1.5647, decode.d0.loss_dice: 1.9595, decode.d1.loss_cls: 0.5060, decode.d1.loss_mask: 1.5227, decode.d1.loss_dice: 1.8910, decode.d2.loss_cls: 0.1323, decode.d2.loss_mask: 1.5499, decode.d2.loss_dice: 1.8638, decode.d3.loss_cls: 0.0613, decode.d3.loss_mask: 1.5407, decode.d3.loss_dice: 1.8512, decode.d4.loss_cls: 0.0352, decode.d4.loss_mask: 1.5264, decode.d4.loss_dice: 1.8547, decode.d5.loss_cls: 0.0300, decode.d5.loss_mask: 1.5341, decode.d5.loss_dice: 1.8536, decode.d6.loss_cls: 0.0247, decode.d6.loss_mask: 1.5348, decode.d6.loss_dice: 1.8413, decode.d7.loss_cls: 0.0238, decode.d7.loss_mask: 1.5184, decode.d7.loss_dice: 1.8360, decode.d8.loss_cls: 0.0284, decode.d8.loss_mask: 1.5157, decode.d8.loss_dice: 1.8330, loss: 37.1019, grad_norm: 426.4291
2023-08-29 14:42:11,200 - mmseg - INFO - Iter [700/160000]	lr: 7.810e-07, eta: 1 day, 7:30:00, time: 0.720, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0308, decode.loss_mask: 1.4001, decode.loss_dice: 1.7092, decode.d0.loss_cls: 2.2763, decode.d0.loss_mask: 1.4885, decode.d0.loss_dice: 1.8595, decode.d1.loss_cls: 0.4495, decode.d1.loss_mask: 1.4093, decode.d1.loss_dice: 1.7714, decode.d2.loss_cls: 0.1178, decode.d2.loss_mask: 1.4158, decode.d2.loss_dice: 1.7429, decode.d3.loss_cls: 0.0538, decode.d3.loss_mask: 1.4068, decode.d3.loss_dice: 1.7251, decode.d4.loss_cls: 0.0315, decode.d4.loss_mask: 1.3962, decode.d4.loss_dice: 1.7285, decode.d5.loss_cls: 0.0264, decode.d5.loss_mask: 1.3987, decode.d5.loss_dice: 1.7208, decode.d6.loss_cls: 0.0229, decode.d6.loss_mask: 1.4007, decode.d6.loss_dice: 1.7103, decode.d7.loss_cls: 0.0225, decode.d7.loss_mask: 1.3844, decode.d7.loss_dice: 1.7103, decode.d8.loss_cls: 0.0257, decode.d8.loss_mask: 1.3985, decode.d8.loss_dice: 1.6972, loss: 34.5312, grad_norm: 426.0199
2023-08-29 14:42:47,612 - mmseg - INFO - Iter [750/160000]	lr: 8.366e-07, eta: 1 day, 7:32:18, time: 0.728, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0276, decode.loss_mask: 1.4564, decode.loss_dice: 1.7575, decode.d0.loss_cls: 2.2741, decode.d0.loss_mask: 1.5145, decode.d0.loss_dice: 1.9009, decode.d1.loss_cls: 0.4063, decode.d1.loss_mask: 1.4555, decode.d1.loss_dice: 1.8073, decode.d2.loss_cls: 0.1078, decode.d2.loss_mask: 1.4785, decode.d2.loss_dice: 1.7817, decode.d3.loss_cls: 0.0500, decode.d3.loss_mask: 1.4725, decode.d3.loss_dice: 1.7634, decode.d4.loss_cls: 0.0299, decode.d4.loss_mask: 1.4549, decode.d4.loss_dice: 1.7723, decode.d5.loss_cls: 0.0249, decode.d5.loss_mask: 1.4623, decode.d5.loss_dice: 1.7600, decode.d6.loss_cls: 0.0207, decode.d6.loss_mask: 1.4544, decode.d6.loss_dice: 1.7593, decode.d7.loss_cls: 0.0209, decode.d7.loss_mask: 1.4477, decode.d7.loss_dice: 1.7531, decode.d8.loss_cls: 0.0238, decode.d8.loss_mask: 1.4605, decode.d8.loss_dice: 1.7509, loss: 35.4495, grad_norm: 491.9072
2023-08-29 14:43:24,304 - mmseg - INFO - Iter [800/160000]	lr: 8.921e-07, eta: 1 day, 7:35:11, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0227, decode.loss_mask: 1.4293, decode.loss_dice: 1.6919, decode.d0.loss_cls: 2.2732, decode.d0.loss_mask: 1.4756, decode.d0.loss_dice: 1.8334, decode.d1.loss_cls: 0.3624, decode.d1.loss_mask: 1.4403, decode.d1.loss_dice: 1.7420, decode.d2.loss_cls: 0.0963, decode.d2.loss_mask: 1.4607, decode.d2.loss_dice: 1.7185, decode.d3.loss_cls: 0.0442, decode.d3.loss_mask: 1.4488, decode.d3.loss_dice: 1.7049, decode.d4.loss_cls: 0.0262, decode.d4.loss_mask: 1.4204, decode.d4.loss_dice: 1.7073, decode.d5.loss_cls: 0.0221, decode.d5.loss_mask: 1.4360, decode.d5.loss_dice: 1.7015, decode.d6.loss_cls: 0.0184, decode.d6.loss_mask: 1.4349, decode.d6.loss_dice: 1.6974, decode.d7.loss_cls: 0.0184, decode.d7.loss_mask: 1.4207, decode.d7.loss_dice: 1.7069, decode.d8.loss_cls: 0.0197, decode.d8.loss_mask: 1.4271, decode.d8.loss_dice: 1.6964, loss: 34.4977, grad_norm: 466.5609
2023-08-29 14:43:58,978 - mmseg - INFO - Iter [850/160000]	lr: 9.477e-07, eta: 1 day, 7:31:20, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0229, decode.loss_mask: 1.3301, decode.loss_dice: 1.6209, decode.d0.loss_cls: 2.2713, decode.d0.loss_mask: 1.4251, decode.d0.loss_dice: 1.7837, decode.d1.loss_cls: 0.3260, decode.d1.loss_mask: 1.3481, decode.d1.loss_dice: 1.6726, decode.d2.loss_cls: 0.0900, decode.d2.loss_mask: 1.3429, decode.d2.loss_dice: 1.6530, decode.d3.loss_cls: 0.0404, decode.d3.loss_mask: 1.3346, decode.d3.loss_dice: 1.6292, decode.d4.loss_cls: 0.0246, decode.d4.loss_mask: 1.3221, decode.d4.loss_dice: 1.6342, decode.d5.loss_cls: 0.0201, decode.d5.loss_mask: 1.3318, decode.d5.loss_dice: 1.6281, decode.d6.loss_cls: 0.0174, decode.d6.loss_mask: 1.3318, decode.d6.loss_dice: 1.6206, decode.d7.loss_cls: 0.0173, decode.d7.loss_mask: 1.3297, decode.d7.loss_dice: 1.6184, decode.d8.loss_cls: 0.0194, decode.d8.loss_mask: 1.3294, decode.d8.loss_dice: 1.6098, loss: 32.7455, grad_norm: 473.7608
2023-08-29 14:44:35,188 - mmseg - INFO - Iter [900/160000]	lr: 1.003e-06, eta: 1 day, 7:32:23, time: 0.724, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0188, decode.loss_mask: 1.3951, decode.loss_dice: 1.6208, decode.d0.loss_cls: 2.2686, decode.d0.loss_mask: 1.4315, decode.d0.loss_dice: 1.7866, decode.d1.loss_cls: 0.2856, decode.d1.loss_mask: 1.4164, decode.d1.loss_dice: 1.6841, decode.d2.loss_cls: 0.0813, decode.d2.loss_mask: 1.4147, decode.d2.loss_dice: 1.6475, decode.d3.loss_cls: 0.0360, decode.d3.loss_mask: 1.4106, decode.d3.loss_dice: 1.6263, decode.d4.loss_cls: 0.0219, decode.d4.loss_mask: 1.3851, decode.d4.loss_dice: 1.6240, decode.d5.loss_cls: 0.0185, decode.d5.loss_mask: 1.3966, decode.d5.loss_dice: 1.6190, decode.d6.loss_cls: 0.0160, decode.d6.loss_mask: 1.3999, decode.d6.loss_dice: 1.6142, decode.d7.loss_cls: 0.0155, decode.d7.loss_mask: 1.3945, decode.d7.loss_dice: 1.6203, decode.d8.loss_cls: 0.0166, decode.d8.loss_mask: 1.4026, decode.d8.loss_dice: 1.6150, loss: 33.2837, grad_norm: 513.5055
2023-08-29 14:45:11,869 - mmseg - INFO - Iter [950/160000]	lr: 1.059e-06, eta: 1 day, 7:34:34, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0335, decode.loss_mask: 1.3418, decode.loss_dice: 1.6215, decode.d0.loss_cls: 2.2644, decode.d0.loss_mask: 1.3944, decode.d0.loss_dice: 1.7733, decode.d1.loss_cls: 0.2622, decode.d1.loss_mask: 1.3664, decode.d1.loss_dice: 1.6674, decode.d2.loss_cls: 0.0847, decode.d2.loss_mask: 1.3538, decode.d2.loss_dice: 1.6538, decode.d3.loss_cls: 0.0438, decode.d3.loss_mask: 1.3450, decode.d3.loss_dice: 1.6292, decode.d4.loss_cls: 0.0341, decode.d4.loss_mask: 1.3372, decode.d4.loss_dice: 1.6236, decode.d5.loss_cls: 0.0290, decode.d5.loss_mask: 1.3435, decode.d5.loss_dice: 1.6156, decode.d6.loss_cls: 0.0293, decode.d6.loss_mask: 1.3440, decode.d6.loss_dice: 1.6194, decode.d7.loss_cls: 0.0294, decode.d7.loss_mask: 1.3363, decode.d7.loss_dice: 1.6186, decode.d8.loss_cls: 0.0302, decode.d8.loss_mask: 1.3399, decode.d8.loss_dice: 1.6181, loss: 32.7833, grad_norm: 488.8609
2023-08-29 14:45:48,947 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-08-29 14:45:51,256 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 14:45:51,256 - mmseg - INFO - Iter [1000/160000]	lr: 1.114e-06, eta: 1 day, 7:43:40, time: 0.788, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0254, decode.loss_mask: 1.3340, decode.loss_dice: 1.5480, decode.d0.loss_cls: 2.2644, decode.d0.loss_mask: 1.3726, decode.d0.loss_dice: 1.7116, decode.d1.loss_cls: 0.2363, decode.d1.loss_mask: 1.3665, decode.d1.loss_dice: 1.6075, decode.d2.loss_cls: 0.0782, decode.d2.loss_mask: 1.3529, decode.d2.loss_dice: 1.5748, decode.d3.loss_cls: 0.0391, decode.d3.loss_mask: 1.3394, decode.d3.loss_dice: 1.5610, decode.d4.loss_cls: 0.0283, decode.d4.loss_mask: 1.3342, decode.d4.loss_dice: 1.5540, decode.d5.loss_cls: 0.0266, decode.d5.loss_mask: 1.3302, decode.d5.loss_dice: 1.5497, decode.d6.loss_cls: 0.0229, decode.d6.loss_mask: 1.3230, decode.d6.loss_dice: 1.5466, decode.d7.loss_cls: 0.0231, decode.d7.loss_mask: 1.3268, decode.d7.loss_dice: 1.5484, decode.d8.loss_cls: 0.0236, decode.d8.loss_mask: 1.3273, decode.d8.loss_dice: 1.5446, loss: 31.9212, grad_norm: 540.5349
2023-08-29 14:46:26,256 - mmseg - INFO - Iter [1050/160000]	lr: 1.169e-06, eta: 1 day, 7:40:44, time: 0.700, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0164, decode.loss_mask: 1.3093, decode.loss_dice: 1.5697, decode.d0.loss_cls: 2.2612, decode.d0.loss_mask: 1.3721, decode.d0.loss_dice: 1.7454, decode.d1.loss_cls: 0.2088, decode.d1.loss_mask: 1.3549, decode.d1.loss_dice: 1.6261, decode.d2.loss_cls: 0.0673, decode.d2.loss_mask: 1.3261, decode.d2.loss_dice: 1.6027, decode.d3.loss_cls: 0.0284, decode.d3.loss_mask: 1.3109, decode.d3.loss_dice: 1.5842, decode.d4.loss_cls: 0.0182, decode.d4.loss_mask: 1.3082, decode.d4.loss_dice: 1.5757, decode.d5.loss_cls: 0.0153, decode.d5.loss_mask: 1.3073, decode.d5.loss_dice: 1.5620, decode.d6.loss_cls: 0.0137, decode.d6.loss_mask: 1.3092, decode.d6.loss_dice: 1.5654, decode.d7.loss_cls: 0.0129, decode.d7.loss_mask: 1.3097, decode.d7.loss_dice: 1.5635, decode.d8.loss_cls: 0.0137, decode.d8.loss_mask: 1.3047, decode.d8.loss_dice: 1.5605, loss: 31.8235, grad_norm: 585.2926
2023-08-29 14:47:02,622 - mmseg - INFO - Iter [1100/160000]	lr: 1.225e-06, eta: 1 day, 7:41:18, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0168, decode.loss_mask: 1.2793, decode.loss_dice: 1.5060, decode.d0.loss_cls: 2.2578, decode.d0.loss_mask: 1.3338, decode.d0.loss_dice: 1.6488, decode.d1.loss_cls: 0.1820, decode.d1.loss_mask: 1.3145, decode.d1.loss_dice: 1.5494, decode.d2.loss_cls: 0.0617, decode.d2.loss_mask: 1.2914, decode.d2.loss_dice: 1.5249, decode.d3.loss_cls: 0.0267, decode.d3.loss_mask: 1.2814, decode.d3.loss_dice: 1.5046, decode.d4.loss_cls: 0.0174, decode.d4.loss_mask: 1.2735, decode.d4.loss_dice: 1.5028, decode.d5.loss_cls: 0.0146, decode.d5.loss_mask: 1.2710, decode.d5.loss_dice: 1.5042, decode.d6.loss_cls: 0.0135, decode.d6.loss_mask: 1.2804, decode.d6.loss_dice: 1.4980, decode.d7.loss_cls: 0.0138, decode.d7.loss_mask: 1.2662, decode.d7.loss_dice: 1.5086, decode.d8.loss_cls: 0.0140, decode.d8.loss_mask: 1.2729, decode.d8.loss_dice: 1.4978, loss: 30.7278, grad_norm: 578.0827
2023-08-29 14:47:39,038 - mmseg - INFO - Iter [1150/160000]	lr: 1.280e-06, eta: 1 day, 7:41:55, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0132, decode.loss_mask: 1.3221, decode.loss_dice: 1.5156, decode.d0.loss_cls: 2.2543, decode.d0.loss_mask: 1.3394, decode.d0.loss_dice: 1.6606, decode.d1.loss_cls: 0.1663, decode.d1.loss_mask: 1.3428, decode.d1.loss_dice: 1.5552, decode.d2.loss_cls: 0.0567, decode.d2.loss_mask: 1.3211, decode.d2.loss_dice: 1.5246, decode.d3.loss_cls: 0.0237, decode.d3.loss_mask: 1.3144, decode.d3.loss_dice: 1.5079, decode.d4.loss_cls: 0.0154, decode.d4.loss_mask: 1.3122, decode.d4.loss_dice: 1.5046, decode.d5.loss_cls: 0.0124, decode.d5.loss_mask: 1.3215, decode.d5.loss_dice: 1.5028, decode.d6.loss_cls: 0.0111, decode.d6.loss_mask: 1.3192, decode.d6.loss_dice: 1.4997, decode.d7.loss_cls: 0.0114, decode.d7.loss_mask: 1.3235, decode.d7.loss_dice: 1.5013, decode.d8.loss_cls: 0.0115, decode.d8.loss_mask: 1.3321, decode.d8.loss_dice: 1.5060, loss: 31.1028, grad_norm: 590.3554
2023-08-29 14:48:15,875 - mmseg - INFO - Iter [1200/160000]	lr: 1.335e-06, eta: 1 day, 7:43:21, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0151, decode.loss_mask: 1.2509, decode.loss_dice: 1.4862, decode.d0.loss_cls: 2.2517, decode.d0.loss_mask: 1.3029, decode.d0.loss_dice: 1.6597, decode.d1.loss_cls: 0.1581, decode.d1.loss_mask: 1.2892, decode.d1.loss_dice: 1.5500, decode.d2.loss_cls: 0.0562, decode.d2.loss_mask: 1.2583, decode.d2.loss_dice: 1.5140, decode.d3.loss_cls: 0.0237, decode.d3.loss_mask: 1.2544, decode.d3.loss_dice: 1.4914, decode.d4.loss_cls: 0.0162, decode.d4.loss_mask: 1.2479, decode.d4.loss_dice: 1.4940, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 1.2515, decode.d5.loss_dice: 1.4867, decode.d6.loss_cls: 0.0130, decode.d6.loss_mask: 1.2457, decode.d6.loss_dice: 1.4840, decode.d7.loss_cls: 0.0127, decode.d7.loss_mask: 1.2499, decode.d7.loss_dice: 1.4868, decode.d8.loss_cls: 0.0134, decode.d8.loss_mask: 1.2571, decode.d8.loss_dice: 1.4833, loss: 30.3180, grad_norm: 617.2352
2023-08-29 14:48:50,541 - mmseg - INFO - Iter [1250/160000]	lr: 1.391e-06, eta: 1 day, 7:40:01, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0260, decode.loss_mask: 1.2575, decode.loss_dice: 1.4580, decode.d0.loss_cls: 2.2467, decode.d0.loss_mask: 1.3083, decode.d0.loss_dice: 1.6164, decode.d1.loss_cls: 0.1479, decode.d1.loss_mask: 1.2948, decode.d1.loss_dice: 1.5198, decode.d2.loss_cls: 0.0596, decode.d2.loss_mask: 1.2594, decode.d2.loss_dice: 1.4721, decode.d3.loss_cls: 0.0315, decode.d3.loss_mask: 1.2465, decode.d3.loss_dice: 1.4618, decode.d4.loss_cls: 0.0261, decode.d4.loss_mask: 1.2579, decode.d4.loss_dice: 1.4564, decode.d5.loss_cls: 0.0251, decode.d5.loss_mask: 1.2587, decode.d5.loss_dice: 1.4498, decode.d6.loss_cls: 0.0231, decode.d6.loss_mask: 1.2610, decode.d6.loss_dice: 1.4490, decode.d7.loss_cls: 0.0237, decode.d7.loss_mask: 1.2648, decode.d7.loss_dice: 1.4522, decode.d8.loss_cls: 0.0240, decode.d8.loss_mask: 1.2605, decode.d8.loss_dice: 1.4511, loss: 30.0898, grad_norm: 713.3563
2023-08-29 14:49:27,032 - mmseg - INFO - Iter [1300/160000]	lr: 1.446e-06, eta: 1 day, 7:40:35, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0109, decode.loss_mask: 1.2876, decode.loss_dice: 1.4623, decode.d0.loss_cls: 2.2453, decode.d0.loss_mask: 1.3186, decode.d0.loss_dice: 1.6244, decode.d1.loss_cls: 0.1301, decode.d1.loss_mask: 1.3221, decode.d1.loss_dice: 1.5211, decode.d2.loss_cls: 0.0481, decode.d2.loss_mask: 1.2952, decode.d2.loss_dice: 1.4810, decode.d3.loss_cls: 0.0195, decode.d3.loss_mask: 1.2948, decode.d3.loss_dice: 1.4566, decode.d4.loss_cls: 0.0128, decode.d4.loss_mask: 1.2988, decode.d4.loss_dice: 1.4489, decode.d5.loss_cls: 0.0109, decode.d5.loss_mask: 1.2848, decode.d5.loss_dice: 1.4566, decode.d6.loss_cls: 0.0099, decode.d6.loss_mask: 1.2830, decode.d6.loss_dice: 1.4578, decode.d7.loss_cls: 0.0090, decode.d7.loss_mask: 1.2873, decode.d7.loss_dice: 1.4639, decode.d8.loss_cls: 0.0090, decode.d8.loss_mask: 1.2848, decode.d8.loss_dice: 1.4606, loss: 30.2958, grad_norm: 647.0304
2023-08-29 14:50:03,261 - mmseg - INFO - Iter [1350/160000]	lr: 1.501e-06, eta: 1 day, 7:40:36, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0118, decode.loss_mask: 1.1898, decode.loss_dice: 1.3812, decode.d0.loss_cls: 2.2403, decode.d0.loss_mask: 1.2188, decode.d0.loss_dice: 1.5340, decode.d1.loss_cls: 0.1169, decode.d1.loss_mask: 1.2022, decode.d1.loss_dice: 1.4312, decode.d2.loss_cls: 0.0444, decode.d2.loss_mask: 1.1819, decode.d2.loss_dice: 1.3891, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 1.1873, decode.d3.loss_dice: 1.3708, decode.d4.loss_cls: 0.0178, decode.d4.loss_mask: 1.1868, decode.d4.loss_dice: 1.3643, decode.d5.loss_cls: 0.0109, decode.d5.loss_mask: 1.1866, decode.d5.loss_dice: 1.3636, decode.d6.loss_cls: 0.0096, decode.d6.loss_mask: 1.1959, decode.d6.loss_dice: 1.3654, decode.d7.loss_cls: 0.0093, decode.d7.loss_mask: 1.1866, decode.d7.loss_dice: 1.3734, decode.d8.loss_cls: 0.0096, decode.d8.loss_mask: 1.1877, decode.d8.loss_dice: 1.3759, loss: 28.3605, grad_norm: 599.3983
2023-08-29 14:50:39,945 - mmseg - INFO - Iter [1400/160000]	lr: 1.556e-06, eta: 1 day, 7:41:24, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0109, decode.loss_mask: 1.2292, decode.loss_dice: 1.3869, decode.d0.loss_cls: 2.2379, decode.d0.loss_mask: 1.2515, decode.d0.loss_dice: 1.5313, decode.d1.loss_cls: 0.1083, decode.d1.loss_mask: 1.2464, decode.d1.loss_dice: 1.4283, decode.d2.loss_cls: 0.0445, decode.d2.loss_mask: 1.2214, decode.d2.loss_dice: 1.3989, decode.d3.loss_cls: 0.0175, decode.d3.loss_mask: 1.2168, decode.d3.loss_dice: 1.3874, decode.d4.loss_cls: 0.0123, decode.d4.loss_mask: 1.2171, decode.d4.loss_dice: 1.3825, decode.d5.loss_cls: 0.0105, decode.d5.loss_mask: 1.2160, decode.d5.loss_dice: 1.3856, decode.d6.loss_cls: 0.0093, decode.d6.loss_mask: 1.2197, decode.d6.loss_dice: 1.3870, decode.d7.loss_cls: 0.0093, decode.d7.loss_mask: 1.2134, decode.d7.loss_dice: 1.3862, decode.d8.loss_cls: 0.0093, decode.d8.loss_mask: 1.2291, decode.d8.loss_dice: 1.3852, loss: 28.7898, grad_norm: 672.9774
2023-08-29 14:51:14,765 - mmseg - INFO - Iter [1450/160000]	lr: 1.611e-06, eta: 1 day, 7:38:42, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0098, decode.loss_mask: 1.2252, decode.loss_dice: 1.3768, decode.d0.loss_cls: 2.2329, decode.d0.loss_mask: 1.2638, decode.d0.loss_dice: 1.5283, decode.d1.loss_cls: 0.1031, decode.d1.loss_mask: 1.2596, decode.d1.loss_dice: 1.4309, decode.d2.loss_cls: 0.0397, decode.d2.loss_mask: 1.2311, decode.d2.loss_dice: 1.3947, decode.d3.loss_cls: 0.0155, decode.d3.loss_mask: 1.2247, decode.d3.loss_dice: 1.3829, decode.d4.loss_cls: 0.0110, decode.d4.loss_mask: 1.2274, decode.d4.loss_dice: 1.3766, decode.d5.loss_cls: 0.0092, decode.d5.loss_mask: 1.2293, decode.d5.loss_dice: 1.3777, decode.d6.loss_cls: 0.0082, decode.d6.loss_mask: 1.2262, decode.d6.loss_dice: 1.3727, decode.d7.loss_cls: 0.0081, decode.d7.loss_mask: 1.2326, decode.d7.loss_dice: 1.3697, decode.d8.loss_cls: 0.0084, decode.d8.loss_mask: 1.2199, decode.d8.loss_dice: 1.3762, loss: 28.7721, grad_norm: 743.9818
2023-08-29 14:51:51,245 - mmseg - INFO - Iter [1500/160000]	lr: 1.666e-06, eta: 1 day, 7:39:04, time: 0.730, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0108, decode.loss_mask: 1.2174, decode.loss_dice: 1.3493, decode.d0.loss_cls: 2.2288, decode.d0.loss_mask: 1.2143, decode.d0.loss_dice: 1.4936, decode.d1.loss_cls: 0.0973, decode.d1.loss_mask: 1.2153, decode.d1.loss_dice: 1.3924, decode.d2.loss_cls: 0.0387, decode.d2.loss_mask: 1.1912, decode.d2.loss_dice: 1.3486, decode.d3.loss_cls: 0.0161, decode.d3.loss_mask: 1.1923, decode.d3.loss_dice: 1.3385, decode.d4.loss_cls: 0.0116, decode.d4.loss_mask: 1.1967, decode.d4.loss_dice: 1.3345, decode.d5.loss_cls: 0.0106, decode.d5.loss_mask: 1.2046, decode.d5.loss_dice: 1.3294, decode.d6.loss_cls: 0.0096, decode.d6.loss_mask: 1.2047, decode.d6.loss_dice: 1.3407, decode.d7.loss_cls: 0.0095, decode.d7.loss_mask: 1.2110, decode.d7.loss_dice: 1.3420, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 1.2121, decode.d8.loss_dice: 1.3470, loss: 28.1179, grad_norm: 749.6468
2023-08-29 14:52:27,674 - mmseg - INFO - Iter [1550/160000]	lr: 1.667e-06, eta: 1 day, 7:39:18, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0088, decode.loss_mask: 1.1714, decode.loss_dice: 1.3112, decode.d0.loss_cls: 2.2248, decode.d0.loss_mask: 1.2316, decode.d0.loss_dice: 1.4711, decode.d1.loss_cls: 0.0899, decode.d1.loss_mask: 1.1975, decode.d1.loss_dice: 1.3659, decode.d2.loss_cls: 0.0358, decode.d2.loss_mask: 1.1668, decode.d2.loss_dice: 1.3304, decode.d3.loss_cls: 0.0144, decode.d3.loss_mask: 1.1650, decode.d3.loss_dice: 1.3094, decode.d4.loss_cls: 0.0100, decode.d4.loss_mask: 1.1656, decode.d4.loss_dice: 1.3124, decode.d5.loss_cls: 0.0089, decode.d5.loss_mask: 1.1613, decode.d5.loss_dice: 1.3061, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 1.1651, decode.d6.loss_dice: 1.3051, decode.d7.loss_cls: 0.0077, decode.d7.loss_mask: 1.1592, decode.d7.loss_dice: 1.3052, decode.d8.loss_cls: 0.0076, decode.d8.loss_mask: 1.1730, decode.d8.loss_dice: 1.3073, loss: 27.4964, grad_norm: 631.6713
2023-08-29 14:53:04,580 - mmseg - INFO - Iter [1600/160000]	lr: 1.666e-06, eta: 1 day, 7:40:16, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0090, decode.loss_mask: 1.1470, decode.loss_dice: 1.2989, decode.d0.loss_cls: 2.2188, decode.d0.loss_mask: 1.2029, decode.d0.loss_dice: 1.4562, decode.d1.loss_cls: 0.0837, decode.d1.loss_mask: 1.1523, decode.d1.loss_dice: 1.3629, decode.d2.loss_cls: 0.0355, decode.d2.loss_mask: 1.1413, decode.d2.loss_dice: 1.3128, decode.d3.loss_cls: 0.0143, decode.d3.loss_mask: 1.1360, decode.d3.loss_dice: 1.3010, decode.d4.loss_cls: 0.0101, decode.d4.loss_mask: 1.1312, decode.d4.loss_dice: 1.2982, decode.d5.loss_cls: 0.0092, decode.d5.loss_mask: 1.1326, decode.d5.loss_dice: 1.3032, decode.d6.loss_cls: 0.0081, decode.d6.loss_mask: 1.1374, decode.d6.loss_dice: 1.3017, decode.d7.loss_cls: 0.0077, decode.d7.loss_mask: 1.1441, decode.d7.loss_dice: 1.3000, decode.d8.loss_cls: 0.0077, decode.d8.loss_mask: 1.1416, decode.d8.loss_dice: 1.3000, loss: 27.1055, grad_norm: 648.5224
2023-08-29 14:53:39,509 - mmseg - INFO - Iter [1650/160000]	lr: 1.666e-06, eta: 1 day, 7:37:58, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0095, decode.loss_mask: 1.1382, decode.loss_dice: 1.3246, decode.d0.loss_cls: 2.2153, decode.d0.loss_mask: 1.1887, decode.d0.loss_dice: 1.4830, decode.d1.loss_cls: 0.0802, decode.d1.loss_mask: 1.1482, decode.d1.loss_dice: 1.3770, decode.d2.loss_cls: 0.0327, decode.d2.loss_mask: 1.1276, decode.d2.loss_dice: 1.3394, decode.d3.loss_cls: 0.0133, decode.d3.loss_mask: 1.1291, decode.d3.loss_dice: 1.3228, decode.d4.loss_cls: 0.0101, decode.d4.loss_mask: 1.1200, decode.d4.loss_dice: 1.3245, decode.d5.loss_cls: 0.0088, decode.d5.loss_mask: 1.1328, decode.d5.loss_dice: 1.3239, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 1.1298, decode.d6.loss_dice: 1.3247, decode.d7.loss_cls: 0.0080, decode.d7.loss_mask: 1.1295, decode.d7.loss_dice: 1.3277, decode.d8.loss_cls: 0.0080, decode.d8.loss_mask: 1.1341, decode.d8.loss_dice: 1.3247, loss: 27.2440, grad_norm: 622.6133
2023-08-29 14:54:16,376 - mmseg - INFO - Iter [1700/160000]	lr: 1.665e-06, eta: 1 day, 7:38:47, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0105, decode.loss_mask: 1.1134, decode.loss_dice: 1.2928, decode.d0.loss_cls: 2.2103, decode.d0.loss_mask: 1.1599, decode.d0.loss_dice: 1.4601, decode.d1.loss_cls: 0.0778, decode.d1.loss_mask: 1.1333, decode.d1.loss_dice: 1.3483, decode.d2.loss_cls: 0.0341, decode.d2.loss_mask: 1.1068, decode.d2.loss_dice: 1.2959, decode.d3.loss_cls: 0.0143, decode.d3.loss_mask: 1.1092, decode.d3.loss_dice: 1.2877, decode.d4.loss_cls: 0.0111, decode.d4.loss_mask: 1.1085, decode.d4.loss_dice: 1.2817, decode.d5.loss_cls: 0.0102, decode.d5.loss_mask: 1.1115, decode.d5.loss_dice: 1.2859, decode.d6.loss_cls: 0.0095, decode.d6.loss_mask: 1.1074, decode.d6.loss_dice: 1.2815, decode.d7.loss_cls: 0.0093, decode.d7.loss_mask: 1.1153, decode.d7.loss_dice: 1.2847, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 1.1139, decode.d8.loss_dice: 1.2860, loss: 26.6803, grad_norm: 649.5811
2023-08-29 14:54:52,668 - mmseg - INFO - Iter [1750/160000]	lr: 1.665e-06, eta: 1 day, 7:38:39, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0087, decode.loss_mask: 1.0212, decode.loss_dice: 1.1797, decode.d0.loss_cls: 2.2032, decode.d0.loss_mask: 1.0434, decode.d0.loss_dice: 1.3404, decode.d1.loss_cls: 0.0715, decode.d1.loss_mask: 1.0241, decode.d1.loss_dice: 1.2317, decode.d2.loss_cls: 0.0303, decode.d2.loss_mask: 1.0223, decode.d2.loss_dice: 1.1965, decode.d3.loss_cls: 0.0122, decode.d3.loss_mask: 1.0286, decode.d3.loss_dice: 1.1813, decode.d4.loss_cls: 0.0104, decode.d4.loss_mask: 1.0220, decode.d4.loss_dice: 1.1717, decode.d5.loss_cls: 0.0096, decode.d5.loss_mask: 1.0201, decode.d5.loss_dice: 1.1798, decode.d6.loss_cls: 0.0085, decode.d6.loss_mask: 1.0216, decode.d6.loss_dice: 1.1794, decode.d7.loss_cls: 0.0082, decode.d7.loss_mask: 1.0209, decode.d7.loss_dice: 1.1760, decode.d8.loss_cls: 0.0082, decode.d8.loss_mask: 1.0168, decode.d8.loss_dice: 1.1851, loss: 24.6337, grad_norm: 590.1096
2023-08-29 14:55:29,550 - mmseg - INFO - Iter [1800/160000]	lr: 1.664e-06, eta: 1 day, 7:39:21, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0092, decode.loss_mask: 1.1297, decode.loss_dice: 1.2741, decode.d0.loss_cls: 2.1997, decode.d0.loss_mask: 1.2252, decode.d0.loss_dice: 1.4361, decode.d1.loss_cls: 0.0670, decode.d1.loss_mask: 1.1455, decode.d1.loss_dice: 1.3199, decode.d2.loss_cls: 0.0286, decode.d2.loss_mask: 1.1149, decode.d2.loss_dice: 1.2774, decode.d3.loss_cls: 0.0115, decode.d3.loss_mask: 1.1050, decode.d3.loss_dice: 1.2686, decode.d4.loss_cls: 0.0098, decode.d4.loss_mask: 1.1148, decode.d4.loss_dice: 1.2716, decode.d5.loss_cls: 0.0087, decode.d5.loss_mask: 1.1158, decode.d5.loss_dice: 1.2657, decode.d6.loss_cls: 0.0083, decode.d6.loss_mask: 1.1192, decode.d6.loss_dice: 1.2662, decode.d7.loss_cls: 0.0080, decode.d7.loss_mask: 1.1259, decode.d7.loss_dice: 1.2720, decode.d8.loss_cls: 0.0078, decode.d8.loss_mask: 1.1271, decode.d8.loss_dice: 1.2645, loss: 26.5980, grad_norm: 647.6381
2023-08-29 14:56:06,673 - mmseg - INFO - Iter [1850/160000]	lr: 1.664e-06, eta: 1 day, 7:40:19, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0069, decode.loss_mask: 1.0979, decode.loss_dice: 1.2124, decode.d0.loss_cls: 2.1926, decode.d0.loss_mask: 1.1366, decode.d0.loss_dice: 1.3640, decode.d1.loss_cls: 0.0622, decode.d1.loss_mask: 1.0929, decode.d1.loss_dice: 1.2563, decode.d2.loss_cls: 0.0271, decode.d2.loss_mask: 1.0994, decode.d2.loss_dice: 1.2188, decode.d3.loss_cls: 0.0106, decode.d3.loss_mask: 1.0998, decode.d3.loss_dice: 1.2061, decode.d4.loss_cls: 0.0083, decode.d4.loss_mask: 1.0995, decode.d4.loss_dice: 1.2047, decode.d5.loss_cls: 0.0073, decode.d5.loss_mask: 1.0982, decode.d5.loss_dice: 1.2066, decode.d6.loss_cls: 0.0068, decode.d6.loss_mask: 1.1025, decode.d6.loss_dice: 1.2108, decode.d7.loss_cls: 0.0069, decode.d7.loss_mask: 1.0992, decode.d7.loss_dice: 1.2066, decode.d8.loss_cls: 0.0065, decode.d8.loss_mask: 1.0996, decode.d8.loss_dice: 1.2119, loss: 25.6589, grad_norm: 613.4577
2023-08-29 14:56:41,156 - mmseg - INFO - Iter [1900/160000]	lr: 1.663e-06, eta: 1 day, 7:37:33, time: 0.690, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0058, decode.loss_mask: 1.0663, decode.loss_dice: 1.2897, decode.d0.loss_cls: 2.1871, decode.d0.loss_mask: 1.0672, decode.d0.loss_dice: 1.3980, decode.d1.loss_cls: 0.0589, decode.d1.loss_mask: 1.0549, decode.d1.loss_dice: 1.3074, decode.d2.loss_cls: 0.0247, decode.d2.loss_mask: 1.0584, decode.d2.loss_dice: 1.2823, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 1.0596, decode.d3.loss_dice: 1.2757, decode.d4.loss_cls: 0.0071, decode.d4.loss_mask: 1.0592, decode.d4.loss_dice: 1.2798, decode.d5.loss_cls: 0.0061, decode.d5.loss_mask: 1.0618, decode.d5.loss_dice: 1.2791, decode.d6.loss_cls: 0.0054, decode.d6.loss_mask: 1.0624, decode.d6.loss_dice: 1.2786, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 1.0601, decode.d7.loss_dice: 1.2872, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 1.0597, decode.d8.loss_dice: 1.2875, loss: 25.8896, grad_norm: 599.4458
2023-08-29 14:57:17,324 - mmseg - INFO - Iter [1950/160000]	lr: 1.663e-06, eta: 1 day, 7:37:10, time: 0.723, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0187, decode.loss_mask: 1.0106, decode.loss_dice: 1.1331, decode.d0.loss_cls: 2.1819, decode.d0.loss_mask: 1.0875, decode.d0.loss_dice: 1.2762, decode.d1.loss_cls: 0.0646, decode.d1.loss_mask: 1.0231, decode.d1.loss_dice: 1.1622, decode.d2.loss_cls: 0.0337, decode.d2.loss_mask: 1.0109, decode.d2.loss_dice: 1.1332, decode.d3.loss_cls: 0.0201, decode.d3.loss_mask: 1.0052, decode.d3.loss_dice: 1.1245, decode.d4.loss_cls: 0.0189, decode.d4.loss_mask: 1.0003, decode.d4.loss_dice: 1.1263, decode.d5.loss_cls: 0.0180, decode.d5.loss_mask: 1.0045, decode.d5.loss_dice: 1.1206, decode.d6.loss_cls: 0.0175, decode.d6.loss_mask: 1.0090, decode.d6.loss_dice: 1.1257, decode.d7.loss_cls: 0.0178, decode.d7.loss_mask: 1.0037, decode.d7.loss_dice: 1.1297, decode.d8.loss_cls: 0.0176, decode.d8.loss_mask: 1.0052, decode.d8.loss_dice: 1.1299, loss: 24.0300, grad_norm: 513.8616
2023-08-29 14:57:54,356 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-08-29 14:57:56,764 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 14:57:56,764 - mmseg - INFO - Iter [2000/160000]	lr: 1.662e-06, eta: 1 day, 7:41:05, time: 0.789, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0075, decode.loss_mask: 0.9761, decode.loss_dice: 1.1164, decode.d0.loss_cls: 2.1757, decode.d0.loss_mask: 1.0526, decode.d0.loss_dice: 1.2929, decode.d1.loss_cls: 0.0553, decode.d1.loss_mask: 0.9691, decode.d1.loss_dice: 1.1613, decode.d2.loss_cls: 0.0240, decode.d2.loss_mask: 0.9704, decode.d2.loss_dice: 1.1155, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.9682, decode.d3.loss_dice: 1.1095, decode.d4.loss_cls: 0.0081, decode.d4.loss_mask: 0.9752, decode.d4.loss_dice: 1.1113, decode.d5.loss_cls: 0.0077, decode.d5.loss_mask: 0.9733, decode.d5.loss_dice: 1.1060, decode.d6.loss_cls: 0.0068, decode.d6.loss_mask: 0.9740, decode.d6.loss_dice: 1.1095, decode.d7.loss_cls: 0.0074, decode.d7.loss_mask: 0.9733, decode.d7.loss_dice: 1.1123, decode.d8.loss_cls: 0.0067, decode.d8.loss_mask: 0.9775, decode.d8.loss_dice: 1.1133, loss: 23.4663, grad_norm: 663.2563
2023-08-29 14:58:34,104 - mmseg - INFO - Iter [2050/160000]	lr: 1.662e-06, eta: 1 day, 7:42:05, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0368, decode.loss_mask: 1.0965, decode.loss_dice: 1.2084, decode.d0.loss_cls: 2.1673, decode.d0.loss_mask: 1.1492, decode.d0.loss_dice: 1.3598, decode.d1.loss_cls: 0.0717, decode.d1.loss_mask: 1.0703, decode.d1.loss_dice: 1.2339, decode.d2.loss_cls: 0.0473, decode.d2.loss_mask: 1.0784, decode.d2.loss_dice: 1.2155, decode.d3.loss_cls: 0.0362, decode.d3.loss_mask: 1.0744, decode.d3.loss_dice: 1.2056, decode.d4.loss_cls: 0.0354, decode.d4.loss_mask: 1.0792, decode.d4.loss_dice: 1.2064, decode.d5.loss_cls: 0.0357, decode.d5.loss_mask: 1.0806, decode.d5.loss_dice: 1.2046, decode.d6.loss_cls: 0.0355, decode.d6.loss_mask: 1.0892, decode.d6.loss_dice: 1.2034, decode.d7.loss_cls: 0.0358, decode.d7.loss_mask: 1.0916, decode.d7.loss_dice: 1.2023, decode.d8.loss_cls: 0.0364, decode.d8.loss_mask: 1.0886, decode.d8.loss_dice: 1.2091, loss: 25.6851, grad_norm: 683.5420
2023-08-29 14:59:08,727 - mmseg - INFO - Iter [2100/160000]	lr: 1.661e-06, eta: 1 day, 7:39:35, time: 0.692, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0214, decode.loss_mask: 1.0481, decode.loss_dice: 1.1802, decode.d0.loss_cls: 2.1625, decode.d0.loss_mask: 1.1280, decode.d0.loss_dice: 1.3445, decode.d1.loss_cls: 0.0607, decode.d1.loss_mask: 1.0371, decode.d1.loss_dice: 1.1999, decode.d2.loss_cls: 0.0347, decode.d2.loss_mask: 1.0463, decode.d2.loss_dice: 1.1749, decode.d3.loss_cls: 0.0220, decode.d3.loss_mask: 1.0380, decode.d3.loss_dice: 1.1691, decode.d4.loss_cls: 0.0215, decode.d4.loss_mask: 1.0396, decode.d4.loss_dice: 1.1713, decode.d5.loss_cls: 0.0215, decode.d5.loss_mask: 1.0317, decode.d5.loss_dice: 1.1711, decode.d6.loss_cls: 0.0203, decode.d6.loss_mask: 1.0421, decode.d6.loss_dice: 1.1757, decode.d7.loss_cls: 0.0204, decode.d7.loss_mask: 1.0492, decode.d7.loss_dice: 1.1668, decode.d8.loss_cls: 0.0209, decode.d8.loss_mask: 1.0452, decode.d8.loss_dice: 1.1737, loss: 24.8386, grad_norm: 712.1350
2023-08-29 14:59:45,214 - mmseg - INFO - Iter [2150/160000]	lr: 1.661e-06, eta: 1 day, 7:39:28, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0152, decode.loss_mask: 1.0626, decode.loss_dice: 1.2114, decode.d0.loss_cls: 2.1582, decode.d0.loss_mask: 1.1615, decode.d0.loss_dice: 1.3937, decode.d1.loss_cls: 0.0550, decode.d1.loss_mask: 1.0531, decode.d1.loss_dice: 1.2344, decode.d2.loss_cls: 0.0286, decode.d2.loss_mask: 1.0427, decode.d2.loss_dice: 1.2013, decode.d3.loss_cls: 0.0159, decode.d3.loss_mask: 1.0510, decode.d3.loss_dice: 1.1905, decode.d4.loss_cls: 0.0155, decode.d4.loss_mask: 1.0436, decode.d4.loss_dice: 1.2006, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 1.0424, decode.d5.loss_dice: 1.2080, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 1.0433, decode.d6.loss_dice: 1.2030, decode.d7.loss_cls: 0.0144, decode.d7.loss_mask: 1.0510, decode.d7.loss_dice: 1.2064, decode.d8.loss_cls: 0.0139, decode.d8.loss_mask: 1.0506, decode.d8.loss_dice: 1.2069, loss: 25.2017, grad_norm: 703.8138
2023-08-29 15:00:21,991 - mmseg - INFO - Iter [2200/160000]	lr: 1.660e-06, eta: 1 day, 7:39:41, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0060, decode.loss_mask: 0.9548, decode.loss_dice: 1.0766, decode.d0.loss_cls: 2.1522, decode.d0.loss_mask: 0.9984, decode.d0.loss_dice: 1.2403, decode.d1.loss_cls: 0.0483, decode.d1.loss_mask: 0.9452, decode.d1.loss_dice: 1.0924, decode.d2.loss_cls: 0.0208, decode.d2.loss_mask: 0.9650, decode.d2.loss_dice: 1.0752, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 0.9648, decode.d3.loss_dice: 1.0710, decode.d4.loss_cls: 0.0078, decode.d4.loss_mask: 0.9550, decode.d4.loss_dice: 1.0688, decode.d5.loss_cls: 0.0071, decode.d5.loss_mask: 0.9586, decode.d5.loss_dice: 1.0670, decode.d6.loss_cls: 0.0064, decode.d6.loss_mask: 0.9571, decode.d6.loss_dice: 1.0648, decode.d7.loss_cls: 0.0064, decode.d7.loss_mask: 0.9496, decode.d7.loss_dice: 1.0777, decode.d8.loss_cls: 0.0058, decode.d8.loss_mask: 0.9542, decode.d8.loss_dice: 1.0718, loss: 22.7785, grad_norm: 623.8526
2023-08-29 15:00:59,126 - mmseg - INFO - Iter [2250/160000]	lr: 1.660e-06, eta: 1 day, 7:40:16, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0340, decode.loss_mask: 1.0427, decode.loss_dice: 1.1271, decode.d0.loss_cls: 2.1448, decode.d0.loss_mask: 1.1177, decode.d0.loss_dice: 1.2631, decode.d1.loss_cls: 0.0634, decode.d1.loss_mask: 1.0512, decode.d1.loss_dice: 1.1398, decode.d2.loss_cls: 0.0419, decode.d2.loss_mask: 1.0569, decode.d2.loss_dice: 1.1292, decode.d3.loss_cls: 0.0324, decode.d3.loss_mask: 1.0471, decode.d3.loss_dice: 1.1256, decode.d4.loss_cls: 0.0329, decode.d4.loss_mask: 1.0394, decode.d4.loss_dice: 1.1218, decode.d5.loss_cls: 0.0329, decode.d5.loss_mask: 1.0482, decode.d5.loss_dice: 1.1224, decode.d6.loss_cls: 0.0321, decode.d6.loss_mask: 1.0469, decode.d6.loss_dice: 1.1172, decode.d7.loss_cls: 0.0335, decode.d7.loss_mask: 1.0500, decode.d7.loss_dice: 1.1226, decode.d8.loss_cls: 0.0329, decode.d8.loss_mask: 1.0531, decode.d8.loss_dice: 1.1253, loss: 24.4279, grad_norm: 598.7100
2023-08-29 15:01:33,946 - mmseg - INFO - Iter [2300/160000]	lr: 1.659e-06, eta: 1 day, 7:38:09, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0079, decode.loss_mask: 0.9723, decode.loss_dice: 1.0985, decode.d0.loss_cls: 2.1404, decode.d0.loss_mask: 1.0230, decode.d0.loss_dice: 1.2685, decode.d1.loss_cls: 0.0442, decode.d1.loss_mask: 0.9611, decode.d1.loss_dice: 1.1213, decode.d2.loss_cls: 0.0202, decode.d2.loss_mask: 0.9668, decode.d2.loss_dice: 1.1046, decode.d3.loss_cls: 0.0089, decode.d3.loss_mask: 0.9660, decode.d3.loss_dice: 1.0900, decode.d4.loss_cls: 0.0079, decode.d4.loss_mask: 0.9688, decode.d4.loss_dice: 1.0917, decode.d5.loss_cls: 0.0075, decode.d5.loss_mask: 0.9695, decode.d5.loss_dice: 1.0895, decode.d6.loss_cls: 0.0073, decode.d6.loss_mask: 0.9645, decode.d6.loss_dice: 1.0873, decode.d7.loss_cls: 0.0074, decode.d7.loss_mask: 0.9687, decode.d7.loss_dice: 1.0866, decode.d8.loss_cls: 0.0069, decode.d8.loss_mask: 0.9694, decode.d8.loss_dice: 1.0899, loss: 23.1167, grad_norm: 668.9552
2023-08-29 15:02:10,403 - mmseg - INFO - Iter [2350/160000]	lr: 1.659e-06, eta: 1 day, 7:37:56, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0280, decode.loss_mask: 0.9967, decode.loss_dice: 1.0683, decode.d0.loss_cls: 2.1321, decode.d0.loss_mask: 1.0456, decode.d0.loss_dice: 1.2183, decode.d1.loss_cls: 0.0552, decode.d1.loss_mask: 0.9755, decode.d1.loss_dice: 1.0793, decode.d2.loss_cls: 0.0374, decode.d2.loss_mask: 0.9773, decode.d2.loss_dice: 1.0654, decode.d3.loss_cls: 0.0275, decode.d3.loss_mask: 0.9768, decode.d3.loss_dice: 1.0657, decode.d4.loss_cls: 0.0266, decode.d4.loss_mask: 0.9786, decode.d4.loss_dice: 1.0660, decode.d5.loss_cls: 0.0255, decode.d5.loss_mask: 0.9792, decode.d5.loss_dice: 1.0658, decode.d6.loss_cls: 0.0202, decode.d6.loss_mask: 0.9873, decode.d6.loss_dice: 1.0707, decode.d7.loss_cls: 0.0258, decode.d7.loss_mask: 1.0007, decode.d7.loss_dice: 1.0641, decode.d8.loss_cls: 0.0260, decode.d8.loss_mask: 0.9934, decode.d8.loss_dice: 1.0698, loss: 23.1490, grad_norm: 660.6874
2023-08-29 15:02:47,223 - mmseg - INFO - Iter [2400/160000]	lr: 1.658e-06, eta: 1 day, 7:38:07, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0070, decode.loss_mask: 0.9313, decode.loss_dice: 1.0394, decode.d0.loss_cls: 2.1276, decode.d0.loss_mask: 0.9846, decode.d0.loss_dice: 1.1918, decode.d1.loss_cls: 0.0397, decode.d1.loss_mask: 0.9251, decode.d1.loss_dice: 1.0686, decode.d2.loss_cls: 0.0199, decode.d2.loss_mask: 0.9280, decode.d2.loss_dice: 1.0458, decode.d3.loss_cls: 0.0090, decode.d3.loss_mask: 0.9206, decode.d3.loss_dice: 1.0379, decode.d4.loss_cls: 0.0077, decode.d4.loss_mask: 0.9218, decode.d4.loss_dice: 1.0400, decode.d5.loss_cls: 0.0069, decode.d5.loss_mask: 0.9220, decode.d5.loss_dice: 1.0375, decode.d6.loss_cls: 0.0067, decode.d6.loss_mask: 0.9259, decode.d6.loss_dice: 1.0392, decode.d7.loss_cls: 0.0067, decode.d7.loss_mask: 0.9261, decode.d7.loss_dice: 1.0401, decode.d8.loss_cls: 0.0063, decode.d8.loss_mask: 0.9356, decode.d8.loss_dice: 1.0380, loss: 22.1366, grad_norm: 589.6190
2023-08-29 15:03:24,311 - mmseg - INFO - Iter [2450/160000]	lr: 1.657e-06, eta: 1 day, 7:38:32, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0068, decode.loss_mask: 0.9802, decode.loss_dice: 1.0880, decode.d0.loss_cls: 2.1190, decode.d0.loss_mask: 1.0265, decode.d0.loss_dice: 1.2276, decode.d1.loss_cls: 0.0391, decode.d1.loss_mask: 0.9827, decode.d1.loss_dice: 1.1159, decode.d2.loss_cls: 0.0193, decode.d2.loss_mask: 0.9866, decode.d2.loss_dice: 1.0888, decode.d3.loss_cls: 0.0086, decode.d3.loss_mask: 0.9862, decode.d3.loss_dice: 1.0877, decode.d4.loss_cls: 0.0076, decode.d4.loss_mask: 0.9791, decode.d4.loss_dice: 1.0940, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.9722, decode.d5.loss_dice: 1.0898, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.9785, decode.d6.loss_dice: 1.0863, decode.d7.loss_cls: 0.0068, decode.d7.loss_mask: 0.9720, decode.d7.loss_dice: 1.0887, decode.d8.loss_cls: 0.0064, decode.d8.loss_mask: 0.9791, decode.d8.loss_dice: 1.0890, loss: 23.1262, grad_norm: 549.8894
2023-08-29 15:03:58,998 - mmseg - INFO - Iter [2500/160000]	lr: 1.657e-06, eta: 1 day, 7:36:24, time: 0.694, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0074, decode.loss_mask: 0.9648, decode.loss_dice: 1.1028, decode.d0.loss_cls: 2.1149, decode.d0.loss_mask: 1.0697, decode.d0.loss_dice: 1.2538, decode.d1.loss_cls: 0.0384, decode.d1.loss_mask: 0.9727, decode.d1.loss_dice: 1.1215, decode.d2.loss_cls: 0.0197, decode.d2.loss_mask: 0.9616, decode.d2.loss_dice: 1.0994, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 0.9587, decode.d3.loss_dice: 1.0995, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.9513, decode.d4.loss_dice: 1.0905, decode.d5.loss_cls: 0.0078, decode.d5.loss_mask: 0.9523, decode.d5.loss_dice: 1.0843, decode.d6.loss_cls: 0.0071, decode.d6.loss_mask: 0.9594, decode.d6.loss_dice: 1.0904, decode.d7.loss_cls: 0.0078, decode.d7.loss_mask: 0.9598, decode.d7.loss_dice: 1.0914, decode.d8.loss_cls: 0.0071, decode.d8.loss_mask: 0.9598, decode.d8.loss_dice: 1.0978, loss: 23.0689, grad_norm: 573.5664
2023-08-29 15:04:35,366 - mmseg - INFO - Iter [2550/160000]	lr: 1.656e-06, eta: 1 day, 7:36:02, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0187, decode.loss_mask: 0.9263, decode.loss_dice: 0.9882, decode.d0.loss_cls: 2.1064, decode.d0.loss_mask: 1.0143, decode.d0.loss_dice: 1.1658, decode.d1.loss_cls: 0.0456, decode.d1.loss_mask: 0.9051, decode.d1.loss_dice: 1.0136, decode.d2.loss_cls: 0.0283, decode.d2.loss_mask: 0.9177, decode.d2.loss_dice: 0.9910, decode.d3.loss_cls: 0.0198, decode.d3.loss_mask: 0.9197, decode.d3.loss_dice: 0.9932, decode.d4.loss_cls: 0.0192, decode.d4.loss_mask: 0.9269, decode.d4.loss_dice: 0.9817, decode.d5.loss_cls: 0.0197, decode.d5.loss_mask: 0.9251, decode.d5.loss_dice: 0.9877, decode.d6.loss_cls: 0.0185, decode.d6.loss_mask: 0.9328, decode.d6.loss_dice: 0.9844, decode.d7.loss_cls: 0.0191, decode.d7.loss_mask: 0.9272, decode.d7.loss_dice: 0.9888, decode.d8.loss_cls: 0.0188, decode.d8.loss_mask: 0.9251, decode.d8.loss_dice: 0.9916, loss: 21.7207, grad_norm: 553.6164
2023-08-29 15:05:12,515 - mmseg - INFO - Iter [2600/160000]	lr: 1.656e-06, eta: 1 day, 7:36:28, time: 0.743, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0066, decode.loss_mask: 0.9016, decode.loss_dice: 0.9751, decode.d0.loss_cls: 2.0992, decode.d0.loss_mask: 0.9600, decode.d0.loss_dice: 1.1346, decode.d1.loss_cls: 0.0342, decode.d1.loss_mask: 0.8999, decode.d1.loss_dice: 1.0021, decode.d2.loss_cls: 0.0168, decode.d2.loss_mask: 0.8948, decode.d2.loss_dice: 0.9818, decode.d3.loss_cls: 0.0077, decode.d3.loss_mask: 0.8947, decode.d3.loss_dice: 0.9777, decode.d4.loss_cls: 0.0067, decode.d4.loss_mask: 0.8954, decode.d4.loss_dice: 0.9740, decode.d5.loss_cls: 0.0065, decode.d5.loss_mask: 0.8968, decode.d5.loss_dice: 0.9741, decode.d6.loss_cls: 0.0061, decode.d6.loss_mask: 0.9018, decode.d6.loss_dice: 0.9714, decode.d7.loss_cls: 0.0070, decode.d7.loss_mask: 0.8994, decode.d7.loss_dice: 0.9727, decode.d8.loss_cls: 0.0064, decode.d8.loss_mask: 0.9025, decode.d8.loss_dice: 0.9807, loss: 21.1883, grad_norm: 553.3848
2023-08-29 15:05:49,542 - mmseg - INFO - Iter [2650/160000]	lr: 1.655e-06, eta: 1 day, 7:36:45, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0063, decode.loss_mask: 0.8748, decode.loss_dice: 0.9884, decode.d0.loss_cls: 2.0912, decode.d0.loss_mask: 0.9394, decode.d0.loss_dice: 1.1329, decode.d1.loss_cls: 0.0331, decode.d1.loss_mask: 0.8792, decode.d1.loss_dice: 1.0075, decode.d2.loss_cls: 0.0161, decode.d2.loss_mask: 0.8766, decode.d2.loss_dice: 0.9873, decode.d3.loss_cls: 0.0078, decode.d3.loss_mask: 0.8764, decode.d3.loss_dice: 0.9866, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.8690, decode.d4.loss_dice: 0.9827, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.8662, decode.d5.loss_dice: 0.9766, decode.d6.loss_cls: 0.0064, decode.d6.loss_mask: 0.8669, decode.d6.loss_dice: 0.9779, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.8749, decode.d7.loss_dice: 0.9861, decode.d8.loss_cls: 0.0060, decode.d8.loss_mask: 0.8734, decode.d8.loss_dice: 0.9885, loss: 20.9985, grad_norm: 619.6215
2023-08-29 15:06:24,321 - mmseg - INFO - Iter [2700/160000]	lr: 1.655e-06, eta: 1 day, 7:34:47, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0051, decode.loss_mask: 0.8454, decode.loss_dice: 0.9443, decode.d0.loss_cls: 2.0834, decode.d0.loss_mask: 0.9349, decode.d0.loss_dice: 1.1252, decode.d1.loss_cls: 0.0320, decode.d1.loss_mask: 0.8488, decode.d1.loss_dice: 0.9743, decode.d2.loss_cls: 0.0151, decode.d2.loss_mask: 0.8375, decode.d2.loss_dice: 0.9564, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.8363, decode.d3.loss_dice: 0.9482, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.8361, decode.d4.loss_dice: 0.9434, decode.d5.loss_cls: 0.0059, decode.d5.loss_mask: 0.8392, decode.d5.loss_dice: 0.9446, decode.d6.loss_cls: 0.0052, decode.d6.loss_mask: 0.8318, decode.d6.loss_dice: 0.9413, decode.d7.loss_cls: 0.0053, decode.d7.loss_mask: 0.8375, decode.d7.loss_dice: 0.9442, decode.d8.loss_cls: 0.0049, decode.d8.loss_mask: 0.8360, decode.d8.loss_dice: 0.9471, loss: 20.3221, grad_norm: 559.1307
2023-08-29 15:07:00,892 - mmseg - INFO - Iter [2750/160000]	lr: 1.654e-06, eta: 1 day, 7:34:36, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0054, decode.loss_mask: 0.8394, decode.loss_dice: 0.9468, decode.d0.loss_cls: 2.0757, decode.d0.loss_mask: 0.9223, decode.d0.loss_dice: 1.1196, decode.d1.loss_cls: 0.0310, decode.d1.loss_mask: 0.8568, decode.d1.loss_dice: 0.9743, decode.d2.loss_cls: 0.0155, decode.d2.loss_mask: 0.8433, decode.d2.loss_dice: 0.9482, decode.d3.loss_cls: 0.0069, decode.d3.loss_mask: 0.8420, decode.d3.loss_dice: 0.9478, decode.d4.loss_cls: 0.0063, decode.d4.loss_mask: 0.8394, decode.d4.loss_dice: 0.9459, decode.d5.loss_cls: 0.0059, decode.d5.loss_mask: 0.8421, decode.d5.loss_dice: 0.9444, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.8413, decode.d6.loss_dice: 0.9460, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.8432, decode.d7.loss_dice: 0.9464, decode.d8.loss_cls: 0.0053, decode.d8.loss_mask: 0.8385, decode.d8.loss_dice: 0.9474, loss: 20.3382, grad_norm: 657.7623
2023-08-29 15:07:37,315 - mmseg - INFO - Iter [2800/160000]	lr: 1.654e-06, eta: 1 day, 7:34:16, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0191, decode.loss_mask: 0.8252, decode.loss_dice: 0.9326, decode.d0.loss_cls: 2.0670, decode.d0.loss_mask: 0.8903, decode.d0.loss_dice: 1.0764, decode.d1.loss_cls: 0.0404, decode.d1.loss_mask: 0.8366, decode.d1.loss_dice: 0.9561, decode.d2.loss_cls: 0.0278, decode.d2.loss_mask: 0.8268, decode.d2.loss_dice: 0.9320, decode.d3.loss_cls: 0.0199, decode.d3.loss_mask: 0.8262, decode.d3.loss_dice: 0.9324, decode.d4.loss_cls: 0.0195, decode.d4.loss_mask: 0.8224, decode.d4.loss_dice: 0.9289, decode.d5.loss_cls: 0.0196, decode.d5.loss_mask: 0.8135, decode.d5.loss_dice: 0.9278, decode.d6.loss_cls: 0.0187, decode.d6.loss_mask: 0.8195, decode.d6.loss_dice: 0.9231, decode.d7.loss_cls: 0.0192, decode.d7.loss_mask: 0.8250, decode.d7.loss_dice: 0.9344, decode.d8.loss_cls: 0.0190, decode.d8.loss_mask: 0.8214, decode.d8.loss_dice: 0.9335, loss: 20.0543, grad_norm: 646.9829
2023-08-29 15:08:14,359 - mmseg - INFO - Iter [2850/160000]	lr: 1.653e-06, eta: 1 day, 7:34:29, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.8317, decode.loss_dice: 0.9479, decode.d0.loss_cls: 2.0616, decode.d0.loss_mask: 0.8964, decode.d0.loss_dice: 1.1057, decode.d1.loss_cls: 0.0287, decode.d1.loss_mask: 0.8349, decode.d1.loss_dice: 0.9781, decode.d2.loss_cls: 0.0147, decode.d2.loss_mask: 0.8370, decode.d2.loss_dice: 0.9619, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.8299, decode.d3.loss_dice: 0.9502, decode.d4.loss_cls: 0.0057, decode.d4.loss_mask: 0.8259, decode.d4.loss_dice: 0.9583, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.8306, decode.d5.loss_dice: 0.9510, decode.d6.loss_cls: 0.0047, decode.d6.loss_mask: 0.8315, decode.d6.loss_dice: 0.9496, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.8273, decode.d7.loss_dice: 0.9547, decode.d8.loss_cls: 0.0044, decode.d8.loss_mask: 0.8290, decode.d8.loss_dice: 0.9526, loss: 20.2251, grad_norm: 681.5738
2023-08-29 15:08:49,228 - mmseg - INFO - Iter [2900/160000]	lr: 1.653e-06, eta: 1 day, 7:32:42, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0187, decode.loss_mask: 0.9079, decode.loss_dice: 0.9452, decode.d0.loss_cls: 2.0522, decode.d0.loss_mask: 0.9339, decode.d0.loss_dice: 1.0702, decode.d1.loss_cls: 0.0370, decode.d1.loss_mask: 0.8921, decode.d1.loss_dice: 0.9589, decode.d2.loss_cls: 0.0253, decode.d2.loss_mask: 0.8925, decode.d2.loss_dice: 0.9515, decode.d3.loss_cls: 0.0182, decode.d3.loss_mask: 0.8876, decode.d3.loss_dice: 0.9490, decode.d4.loss_cls: 0.0178, decode.d4.loss_mask: 0.8806, decode.d4.loss_dice: 0.9502, decode.d5.loss_cls: 0.0183, decode.d5.loss_mask: 0.8871, decode.d5.loss_dice: 0.9469, decode.d6.loss_cls: 0.0181, decode.d6.loss_mask: 0.8952, decode.d6.loss_dice: 0.9442, decode.d7.loss_cls: 0.0186, decode.d7.loss_mask: 0.8945, decode.d7.loss_dice: 0.9450, decode.d8.loss_cls: 0.0181, decode.d8.loss_mask: 0.8944, decode.d8.loss_dice: 0.9499, loss: 20.8193, grad_norm: 599.9824
2023-08-29 15:09:25,814 - mmseg - INFO - Iter [2950/160000]	lr: 1.652e-06, eta: 1 day, 7:32:30, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0182, decode.loss_mask: 0.8672, decode.loss_dice: 0.9339, decode.d0.loss_cls: 1.9885, decode.d0.loss_mask: 1.0195, decode.d0.loss_dice: 1.1325, decode.d1.loss_cls: 0.0360, decode.d1.loss_mask: 0.8721, decode.d1.loss_dice: 0.9500, decode.d2.loss_cls: 0.0254, decode.d2.loss_mask: 0.8644, decode.d2.loss_dice: 0.9366, decode.d3.loss_cls: 0.0198, decode.d3.loss_mask: 0.8706, decode.d3.loss_dice: 0.9300, decode.d4.loss_cls: 0.0189, decode.d4.loss_mask: 0.8684, decode.d4.loss_dice: 0.9342, decode.d5.loss_cls: 0.0191, decode.d5.loss_mask: 0.8739, decode.d5.loss_dice: 0.9281, decode.d6.loss_cls: 0.0186, decode.d6.loss_mask: 0.8670, decode.d6.loss_dice: 0.9294, decode.d7.loss_cls: 0.0189, decode.d7.loss_mask: 0.8692, decode.d7.loss_dice: 0.9297, decode.d8.loss_cls: 0.0187, decode.d8.loss_mask: 0.8629, decode.d8.loss_dice: 0.9348, loss: 20.5566, grad_norm: 537.2651
2023-08-29 15:10:02,168 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-08-29 15:10:04,522 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 15:10:04,522 - mmseg - INFO - Iter [3000/160000]	lr: 1.652e-06, eta: 1 day, 7:34:08, time: 0.774, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0058, decode.loss_mask: 0.7868, decode.loss_dice: 0.8506, decode.d0.loss_cls: 1.9089, decode.d0.loss_mask: 0.8830, decode.d0.loss_dice: 1.0431, decode.d1.loss_cls: 0.0247, decode.d1.loss_mask: 0.7815, decode.d1.loss_dice: 0.8727, decode.d2.loss_cls: 0.0133, decode.d2.loss_mask: 0.7812, decode.d2.loss_dice: 0.8505, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.7784, decode.d3.loss_dice: 0.8442, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.7770, decode.d4.loss_dice: 0.8438, decode.d5.loss_cls: 0.0058, decode.d5.loss_mask: 0.7782, decode.d5.loss_dice: 0.8452, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.7826, decode.d6.loss_dice: 0.8390, decode.d7.loss_cls: 0.0054, decode.d7.loss_mask: 0.7842, decode.d7.loss_dice: 0.8414, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.7861, decode.d8.loss_dice: 0.8419, loss: 18.5775, grad_norm: 579.8755
2023-08-29 15:10:41,892 - mmseg - INFO - Iter [3050/160000]	lr: 1.651e-06, eta: 1 day, 7:34:32, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0055, decode.loss_mask: 0.7997, decode.loss_dice: 0.8830, decode.d0.loss_cls: 1.9022, decode.d0.loss_mask: 0.9400, decode.d0.loss_dice: 1.1112, decode.d1.loss_cls: 0.0238, decode.d1.loss_mask: 0.8097, decode.d1.loss_dice: 0.9150, decode.d2.loss_cls: 0.0136, decode.d2.loss_mask: 0.7939, decode.d2.loss_dice: 0.8913, decode.d3.loss_cls: 0.0059, decode.d3.loss_mask: 0.7961, decode.d3.loss_dice: 0.8835, decode.d4.loss_cls: 0.0054, decode.d4.loss_mask: 0.7960, decode.d4.loss_dice: 0.8853, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.7981, decode.d5.loss_dice: 0.8851, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.7985, decode.d6.loss_dice: 0.8815, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.7967, decode.d7.loss_dice: 0.8789, decode.d8.loss_cls: 0.0045, decode.d8.loss_mask: 0.8022, decode.d8.loss_dice: 0.8830, loss: 19.2049, grad_norm: 599.8729
2023-08-29 15:11:16,557 - mmseg - INFO - Iter [3100/160000]	lr: 1.651e-06, eta: 1 day, 7:32:37, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.7742, decode.loss_dice: 0.8427, decode.d0.loss_cls: 1.8950, decode.d0.loss_mask: 0.8618, decode.d0.loss_dice: 1.0321, decode.d1.loss_cls: 0.0229, decode.d1.loss_mask: 0.7657, decode.d1.loss_dice: 0.8740, decode.d2.loss_cls: 0.0133, decode.d2.loss_mask: 0.7630, decode.d2.loss_dice: 0.8523, decode.d3.loss_cls: 0.0059, decode.d3.loss_mask: 0.7668, decode.d3.loss_dice: 0.8454, decode.d4.loss_cls: 0.0054, decode.d4.loss_mask: 0.7688, decode.d4.loss_dice: 0.8386, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.7684, decode.d5.loss_dice: 0.8432, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.7689, decode.d6.loss_dice: 0.8444, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.7687, decode.d7.loss_dice: 0.8414, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.7771, decode.d8.loss_dice: 0.8396, loss: 18.4030, grad_norm: 635.7363
2023-08-29 15:11:53,388 - mmseg - INFO - Iter [3150/160000]	lr: 1.650e-06, eta: 1 day, 7:32:33, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0042, decode.loss_mask: 0.7762, decode.loss_dice: 0.8447, decode.d0.loss_cls: 1.8872, decode.d0.loss_mask: 0.8566, decode.d0.loss_dice: 1.0208, decode.d1.loss_cls: 0.0216, decode.d1.loss_mask: 0.7741, decode.d1.loss_dice: 0.8656, decode.d2.loss_cls: 0.0122, decode.d2.loss_mask: 0.7748, decode.d2.loss_dice: 0.8499, decode.d3.loss_cls: 0.0057, decode.d3.loss_mask: 0.7734, decode.d3.loss_dice: 0.8470, decode.d4.loss_cls: 0.0051, decode.d4.loss_mask: 0.7705, decode.d4.loss_dice: 0.8430, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.7717, decode.d5.loss_dice: 0.8416, decode.d6.loss_cls: 0.0045, decode.d6.loss_mask: 0.7766, decode.d6.loss_dice: 0.8473, decode.d7.loss_cls: 0.0046, decode.d7.loss_mask: 0.7782, decode.d7.loss_dice: 0.8508, decode.d8.loss_cls: 0.0041, decode.d8.loss_mask: 0.7817, decode.d8.loss_dice: 0.8429, loss: 18.4415, grad_norm: 595.8076
2023-08-29 15:12:29,705 - mmseg - INFO - Iter [3200/160000]	lr: 1.650e-06, eta: 1 day, 7:32:03, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0043, decode.loss_mask: 0.8084, decode.loss_dice: 0.9133, decode.d0.loss_cls: 1.8809, decode.d0.loss_mask: 0.9143, decode.d0.loss_dice: 1.0802, decode.d1.loss_cls: 0.0211, decode.d1.loss_mask: 0.8133, decode.d1.loss_dice: 0.9210, decode.d2.loss_cls: 0.0116, decode.d2.loss_mask: 0.8071, decode.d2.loss_dice: 0.9060, decode.d3.loss_cls: 0.0056, decode.d3.loss_mask: 0.8067, decode.d3.loss_dice: 0.9002, decode.d4.loss_cls: 0.0051, decode.d4.loss_mask: 0.8048, decode.d4.loss_dice: 0.9053, decode.d5.loss_cls: 0.0050, decode.d5.loss_mask: 0.8025, decode.d5.loss_dice: 0.9057, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.8060, decode.d6.loss_dice: 0.9004, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.8015, decode.d7.loss_dice: 0.9009, decode.d8.loss_cls: 0.0076, decode.d8.loss_mask: 0.8087, decode.d8.loss_dice: 0.9017, loss: 19.3589, grad_norm: 585.8969
2023-08-29 15:13:06,682 - mmseg - INFO - Iter [3250/160000]	lr: 1.649e-06, eta: 1 day, 7:32:04, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0169, decode.loss_mask: 0.7886, decode.loss_dice: 0.8241, decode.d0.loss_cls: 1.8742, decode.d0.loss_mask: 0.8948, decode.d0.loss_dice: 0.9943, decode.d1.loss_cls: 0.0286, decode.d1.loss_mask: 0.8016, decode.d1.loss_dice: 0.8406, decode.d2.loss_cls: 0.0233, decode.d2.loss_mask: 0.7927, decode.d2.loss_dice: 0.8281, decode.d3.loss_cls: 0.0181, decode.d3.loss_mask: 0.7903, decode.d3.loss_dice: 0.8178, decode.d4.loss_cls: 0.0179, decode.d4.loss_mask: 0.7944, decode.d4.loss_dice: 0.8244, decode.d5.loss_cls: 0.0177, decode.d5.loss_mask: 0.7913, decode.d5.loss_dice: 0.8248, decode.d6.loss_cls: 0.0168, decode.d6.loss_mask: 0.7945, decode.d6.loss_dice: 0.8195, decode.d7.loss_cls: 0.0178, decode.d7.loss_mask: 0.7917, decode.d7.loss_dice: 0.8201, decode.d8.loss_cls: 0.0167, decode.d8.loss_mask: 0.7917, decode.d8.loss_dice: 0.8230, loss: 18.4964, grad_norm: 631.9146
2023-08-29 15:13:41,805 - mmseg - INFO - Iter [3300/160000]	lr: 1.649e-06, eta: 1 day, 7:30:36, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0051, decode.loss_mask: 0.8029, decode.loss_dice: 0.8896, decode.d0.loss_cls: 1.8682, decode.d0.loss_mask: 0.9715, decode.d0.loss_dice: 1.1051, decode.d1.loss_cls: 0.0211, decode.d1.loss_mask: 0.8201, decode.d1.loss_dice: 0.9357, decode.d2.loss_cls: 0.0128, decode.d2.loss_mask: 0.8004, decode.d2.loss_dice: 0.8993, decode.d3.loss_cls: 0.0064, decode.d3.loss_mask: 0.8048, decode.d3.loss_dice: 0.8955, decode.d4.loss_cls: 0.0060, decode.d4.loss_mask: 0.7982, decode.d4.loss_dice: 0.8965, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.7977, decode.d5.loss_dice: 0.8943, decode.d6.loss_cls: 0.0056, decode.d6.loss_mask: 0.7993, decode.d6.loss_dice: 0.8863, decode.d7.loss_cls: 0.0054, decode.d7.loss_mask: 0.8001, decode.d7.loss_dice: 0.8876, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 0.8053, decode.d8.loss_dice: 0.8890, loss: 19.3211, grad_norm: 603.3116
2023-08-29 15:14:18,520 - mmseg - INFO - Iter [3350/160000]	lr: 1.648e-06, eta: 1 day, 7:30:24, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0047, decode.loss_mask: 0.7806, decode.loss_dice: 0.8508, decode.d0.loss_cls: 1.8581, decode.d0.loss_mask: 0.8634, decode.d0.loss_dice: 0.9972, decode.d1.loss_cls: 0.0197, decode.d1.loss_mask: 0.7820, decode.d1.loss_dice: 0.8617, decode.d2.loss_cls: 0.0108, decode.d2.loss_mask: 0.7771, decode.d2.loss_dice: 0.8491, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.7731, decode.d3.loss_dice: 0.8420, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.7741, decode.d4.loss_dice: 0.8434, decode.d5.loss_cls: 0.0050, decode.d5.loss_mask: 0.7772, decode.d5.loss_dice: 0.8414, decode.d6.loss_cls: 0.0045, decode.d6.loss_mask: 0.7734, decode.d6.loss_dice: 0.8395, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.7724, decode.d7.loss_dice: 0.8414, decode.d8.loss_cls: 0.0046, decode.d8.loss_mask: 0.7719, decode.d8.loss_dice: 0.8460, loss: 18.3803, grad_norm: 563.2720
2023-08-29 15:14:54,951 - mmseg - INFO - Iter [3400/160000]	lr: 1.647e-06, eta: 1 day, 7:29:58, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0042, decode.loss_mask: 0.7594, decode.loss_dice: 0.8238, decode.d0.loss_cls: 1.8499, decode.d0.loss_mask: 0.8306, decode.d0.loss_dice: 0.9873, decode.d1.loss_cls: 0.0187, decode.d1.loss_mask: 0.7658, decode.d1.loss_dice: 0.8404, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.7619, decode.d2.loss_dice: 0.8247, decode.d3.loss_cls: 0.0050, decode.d3.loss_mask: 0.7647, decode.d3.loss_dice: 0.8161, decode.d4.loss_cls: 0.0045, decode.d4.loss_mask: 0.7643, decode.d4.loss_dice: 0.8229, decode.d5.loss_cls: 0.0046, decode.d5.loss_mask: 0.7587, decode.d5.loss_dice: 0.8185, decode.d6.loss_cls: 0.0042, decode.d6.loss_mask: 0.7603, decode.d6.loss_dice: 0.8145, decode.d7.loss_cls: 0.0042, decode.d7.loss_mask: 0.7635, decode.d7.loss_dice: 0.8167, decode.d8.loss_cls: 0.0040, decode.d8.loss_mask: 0.7604, decode.d8.loss_dice: 0.8198, loss: 17.9843, grad_norm: 642.0110
2023-08-29 15:15:31,967 - mmseg - INFO - Iter [3450/160000]	lr: 1.647e-06, eta: 1 day, 7:29:59, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0123, decode.loss_mask: 0.7522, decode.loss_dice: 0.7688, decode.d0.loss_cls: 1.8430, decode.d0.loss_mask: 0.8636, decode.d0.loss_dice: 0.9301, decode.d1.loss_cls: 0.0250, decode.d1.loss_mask: 0.7621, decode.d1.loss_dice: 0.7839, decode.d2.loss_cls: 0.0160, decode.d2.loss_mask: 0.7578, decode.d2.loss_dice: 0.7767, decode.d3.loss_cls: 0.0119, decode.d3.loss_mask: 0.7533, decode.d3.loss_dice: 0.7660, decode.d4.loss_cls: 0.0123, decode.d4.loss_mask: 0.7475, decode.d4.loss_dice: 0.7641, decode.d5.loss_cls: 0.0112, decode.d5.loss_mask: 0.7456, decode.d5.loss_dice: 0.7605, decode.d6.loss_cls: 0.0122, decode.d6.loss_mask: 0.7497, decode.d6.loss_dice: 0.7607, decode.d7.loss_cls: 0.0121, decode.d7.loss_mask: 0.7456, decode.d7.loss_dice: 0.7594, decode.d8.loss_cls: 0.0119, decode.d8.loss_mask: 0.7517, decode.d8.loss_dice: 0.7659, loss: 17.4332, grad_norm: 597.5069
2023-08-29 15:16:09,092 - mmseg - INFO - Iter [3500/160000]	lr: 1.646e-06, eta: 1 day, 7:30:03, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0172, decode.loss_mask: 0.7674, decode.loss_dice: 0.8015, decode.d0.loss_cls: 1.8367, decode.d0.loss_mask: 0.8262, decode.d0.loss_dice: 0.9506, decode.d1.loss_cls: 0.0273, decode.d1.loss_mask: 0.7794, decode.d1.loss_dice: 0.8216, decode.d2.loss_cls: 0.0225, decode.d2.loss_mask: 0.7644, decode.d2.loss_dice: 0.7999, decode.d3.loss_cls: 0.0189, decode.d3.loss_mask: 0.7658, decode.d3.loss_dice: 0.7948, decode.d4.loss_cls: 0.0184, decode.d4.loss_mask: 0.7608, decode.d4.loss_dice: 0.7971, decode.d5.loss_cls: 0.0182, decode.d5.loss_mask: 0.7683, decode.d5.loss_dice: 0.7948, decode.d6.loss_cls: 0.0175, decode.d6.loss_mask: 0.7641, decode.d6.loss_dice: 0.7923, decode.d7.loss_cls: 0.0176, decode.d7.loss_mask: 0.7603, decode.d7.loss_dice: 0.7940, decode.d8.loss_cls: 0.0173, decode.d8.loss_mask: 0.7613, decode.d8.loss_dice: 0.7995, loss: 17.8756, grad_norm: 573.0039
2023-08-29 15:16:43,760 - mmseg - INFO - Iter [3550/160000]	lr: 1.646e-06, eta: 1 day, 7:28:18, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0039, decode.loss_mask: 0.7598, decode.loss_dice: 0.7824, decode.d0.loss_cls: 1.8269, decode.d0.loss_mask: 0.8264, decode.d0.loss_dice: 0.9328, decode.d1.loss_cls: 0.0172, decode.d1.loss_mask: 0.7578, decode.d1.loss_dice: 0.8072, decode.d2.loss_cls: 0.0096, decode.d2.loss_mask: 0.7467, decode.d2.loss_dice: 0.7890, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.7521, decode.d3.loss_dice: 0.7799, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.7503, decode.d4.loss_dice: 0.7827, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.7596, decode.d5.loss_dice: 0.7829, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.7553, decode.d6.loss_dice: 0.7777, decode.d7.loss_cls: 0.0039, decode.d7.loss_mask: 0.7516, decode.d7.loss_dice: 0.7741, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.7585, decode.d8.loss_dice: 0.7816, loss: 17.4905, grad_norm: 632.8643
2023-08-29 15:17:20,216 - mmseg - INFO - Iter [3600/160000]	lr: 1.645e-06, eta: 1 day, 7:27:52, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0125, decode.loss_mask: 0.7625, decode.loss_dice: 0.8320, decode.d0.loss_cls: 1.8197, decode.d0.loss_mask: 0.8654, decode.d0.loss_dice: 0.9692, decode.d1.loss_cls: 0.0269, decode.d1.loss_mask: 0.7616, decode.d1.loss_dice: 0.8351, decode.d2.loss_cls: 0.0229, decode.d2.loss_mask: 0.7421, decode.d2.loss_dice: 0.8193, decode.d3.loss_cls: 0.0182, decode.d3.loss_mask: 0.7430, decode.d3.loss_dice: 0.8135, decode.d4.loss_cls: 0.0177, decode.d4.loss_mask: 0.7425, decode.d4.loss_dice: 0.8176, decode.d5.loss_cls: 0.0156, decode.d5.loss_mask: 0.7398, decode.d5.loss_dice: 0.8146, decode.d6.loss_cls: 0.0173, decode.d6.loss_mask: 0.7467, decode.d6.loss_dice: 0.8093, decode.d7.loss_cls: 0.0186, decode.d7.loss_mask: 0.7497, decode.d7.loss_dice: 0.8091, decode.d8.loss_cls: 0.0196, decode.d8.loss_mask: 0.7482, decode.d8.loss_dice: 0.8194, loss: 17.9296, grad_norm: 581.8197
2023-08-29 15:17:57,496 - mmseg - INFO - Iter [3650/160000]	lr: 1.645e-06, eta: 1 day, 7:28:02, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0063, decode.loss_mask: 0.6919, decode.loss_dice: 0.7438, decode.d0.loss_cls: 1.8125, decode.d0.loss_mask: 0.7568, decode.d0.loss_dice: 0.8794, decode.d1.loss_cls: 0.0170, decode.d1.loss_mask: 0.6984, decode.d1.loss_dice: 0.7626, decode.d2.loss_cls: 0.0113, decode.d2.loss_mask: 0.6899, decode.d2.loss_dice: 0.7501, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.6850, decode.d3.loss_dice: 0.7479, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.6917, decode.d4.loss_dice: 0.7473, decode.d5.loss_cls: 0.0063, decode.d5.loss_mask: 0.6929, decode.d5.loss_dice: 0.7456, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.6886, decode.d6.loss_dice: 0.7459, decode.d7.loss_cls: 0.0055, decode.d7.loss_mask: 0.6886, decode.d7.loss_dice: 0.7416, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.6895, decode.d8.loss_dice: 0.7413, loss: 16.4612, grad_norm: 548.8812
2023-08-29 15:18:34,431 - mmseg - INFO - Iter [3700/160000]	lr: 1.644e-06, eta: 1 day, 7:27:56, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0107, decode.loss_mask: 0.6829, decode.loss_dice: 0.7347, decode.d0.loss_cls: 1.8044, decode.d0.loss_mask: 0.7849, decode.d0.loss_dice: 0.8887, decode.d1.loss_cls: 0.0167, decode.d1.loss_mask: 0.6941, decode.d1.loss_dice: 0.7625, decode.d2.loss_cls: 0.0109, decode.d2.loss_mask: 0.6838, decode.d2.loss_dice: 0.7462, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.6877, decode.d3.loss_dice: 0.7401, decode.d4.loss_cls: 0.0052, decode.d4.loss_mask: 0.6946, decode.d4.loss_dice: 0.7379, decode.d5.loss_cls: 0.0049, decode.d5.loss_mask: 0.6908, decode.d5.loss_dice: 0.7363, decode.d6.loss_cls: 0.0049, decode.d6.loss_mask: 0.6949, decode.d6.loss_dice: 0.7339, decode.d7.loss_cls: 0.0051, decode.d7.loss_mask: 0.6967, decode.d7.loss_dice: 0.7370, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 0.6916, decode.d8.loss_dice: 0.7365, loss: 16.4294, grad_norm: 595.3362
2023-08-29 15:19:09,368 - mmseg - INFO - Iter [3750/160000]	lr: 1.644e-06, eta: 1 day, 7:26:25, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0143, decode.loss_mask: 0.7322, decode.loss_dice: 0.7640, decode.d0.loss_cls: 1.7954, decode.d0.loss_mask: 0.8183, decode.d0.loss_dice: 0.9101, decode.d1.loss_cls: 0.0251, decode.d1.loss_mask: 0.7395, decode.d1.loss_dice: 0.7742, decode.d2.loss_cls: 0.0209, decode.d2.loss_mask: 0.7255, decode.d2.loss_dice: 0.7632, decode.d3.loss_cls: 0.0083, decode.d3.loss_mask: 0.7428, decode.d3.loss_dice: 0.7717, decode.d4.loss_cls: 0.0082, decode.d4.loss_mask: 0.7449, decode.d4.loss_dice: 0.7645, decode.d5.loss_cls: 0.0080, decode.d5.loss_mask: 0.7447, decode.d5.loss_dice: 0.7661, decode.d6.loss_cls: 0.0139, decode.d6.loss_mask: 0.7377, decode.d6.loss_dice: 0.7615, decode.d7.loss_cls: 0.0138, decode.d7.loss_mask: 0.7377, decode.d7.loss_dice: 0.7598, decode.d8.loss_cls: 0.0079, decode.d8.loss_mask: 0.7447, decode.d8.loss_dice: 0.7633, loss: 17.1823, grad_norm: 592.1179
2023-08-29 15:19:45,982 - mmseg - INFO - Iter [3800/160000]	lr: 1.643e-06, eta: 1 day, 7:26:05, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.7633, decode.loss_dice: 0.8402, decode.d0.loss_cls: 1.7870, decode.d0.loss_mask: 0.8915, decode.d0.loss_dice: 0.9866, decode.d1.loss_cls: 0.0150, decode.d1.loss_mask: 0.7685, decode.d1.loss_dice: 0.8594, decode.d2.loss_cls: 0.0091, decode.d2.loss_mask: 0.7550, decode.d2.loss_dice: 0.8399, decode.d3.loss_cls: 0.0045, decode.d3.loss_mask: 0.7580, decode.d3.loss_dice: 0.8395, decode.d4.loss_cls: 0.0041, decode.d4.loss_mask: 0.7607, decode.d4.loss_dice: 0.8412, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.7571, decode.d5.loss_dice: 0.8401, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.7607, decode.d6.loss_dice: 0.8351, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.7622, decode.d7.loss_dice: 0.8387, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.7624, decode.d8.loss_dice: 0.8413, loss: 18.1387, grad_norm: 670.3246
2023-08-29 15:20:23,052 - mmseg - INFO - Iter [3850/160000]	lr: 1.643e-06, eta: 1 day, 7:26:03, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0030, decode.loss_mask: 0.7156, decode.loss_dice: 0.7771, decode.d0.loss_cls: 1.7795, decode.d0.loss_mask: 0.7883, decode.d0.loss_dice: 0.9101, decode.d1.loss_cls: 0.0143, decode.d1.loss_mask: 0.7132, decode.d1.loss_dice: 0.7895, decode.d2.loss_cls: 0.0086, decode.d2.loss_mask: 0.7038, decode.d2.loss_dice: 0.7798, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.7062, decode.d3.loss_dice: 0.7774, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.7092, decode.d4.loss_dice: 0.7772, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.7132, decode.d5.loss_dice: 0.7755, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.7118, decode.d6.loss_dice: 0.7717, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.7127, decode.d7.loss_dice: 0.7720, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.7114, decode.d8.loss_dice: 0.7781, loss: 16.9194, grad_norm: 513.4371
2023-08-29 15:21:00,246 - mmseg - INFO - Iter [3900/160000]	lr: 1.642e-06, eta: 1 day, 7:26:05, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0037, decode.loss_mask: 0.7282, decode.loss_dice: 0.7594, decode.d0.loss_cls: 1.7707, decode.d0.loss_mask: 0.8342, decode.d0.loss_dice: 0.9098, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.7258, decode.d1.loss_dice: 0.7679, decode.d2.loss_cls: 0.0093, decode.d2.loss_mask: 0.7268, decode.d2.loss_dice: 0.7689, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.7340, decode.d3.loss_dice: 0.7618, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.7274, decode.d4.loss_dice: 0.7621, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.7286, decode.d5.loss_dice: 0.7602, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.7319, decode.d6.loss_dice: 0.7559, decode.d7.loss_cls: 0.0038, decode.d7.loss_mask: 0.7263, decode.d7.loss_dice: 0.7607, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.7313, decode.d8.loss_dice: 0.7570, loss: 16.9803, grad_norm: 618.9416
2023-08-29 15:21:35,139 - mmseg - INFO - Iter [3950/160000]	lr: 1.642e-06, eta: 1 day, 7:24:36, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.7164, decode.loss_dice: 0.7285, decode.d0.loss_cls: 1.7639, decode.d0.loss_mask: 0.7676, decode.d0.loss_dice: 0.8589, decode.d1.loss_cls: 0.0150, decode.d1.loss_mask: 0.7157, decode.d1.loss_dice: 0.7432, decode.d2.loss_cls: 0.0094, decode.d2.loss_mask: 0.7220, decode.d2.loss_dice: 0.7342, decode.d3.loss_cls: 0.0050, decode.d3.loss_mask: 0.7242, decode.d3.loss_dice: 0.7310, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.7165, decode.d4.loss_dice: 0.7307, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.7260, decode.d5.loss_dice: 0.7255, decode.d6.loss_cls: 0.0042, decode.d6.loss_mask: 0.7256, decode.d6.loss_dice: 0.7249, decode.d7.loss_cls: 0.0044, decode.d7.loss_mask: 0.7169, decode.d7.loss_dice: 0.7253, decode.d8.loss_cls: 0.0041, decode.d8.loss_mask: 0.7190, decode.d8.loss_dice: 0.7276, loss: 16.4988, grad_norm: 600.9243
2023-08-29 15:22:11,608 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-08-29 15:22:14,758 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 15:22:14,758 - mmseg - INFO - Iter [4000/160000]	lr: 1.641e-06, eta: 1 day, 7:26:12, time: 0.792, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0184, decode.loss_mask: 0.7154, decode.loss_dice: 0.7461, decode.d0.loss_cls: 1.7567, decode.d0.loss_mask: 0.7964, decode.d0.loss_dice: 0.8884, decode.d1.loss_cls: 0.0252, decode.d1.loss_mask: 0.7302, decode.d1.loss_dice: 0.7676, decode.d2.loss_cls: 0.0216, decode.d2.loss_mask: 0.7212, decode.d2.loss_dice: 0.7539, decode.d3.loss_cls: 0.0222, decode.d3.loss_mask: 0.7137, decode.d3.loss_dice: 0.7481, decode.d4.loss_cls: 0.0175, decode.d4.loss_mask: 0.7153, decode.d4.loss_dice: 0.7480, decode.d5.loss_cls: 0.0179, decode.d5.loss_mask: 0.7141, decode.d5.loss_dice: 0.7441, decode.d6.loss_cls: 0.0178, decode.d6.loss_mask: 0.7110, decode.d6.loss_dice: 0.7428, decode.d7.loss_cls: 0.0182, decode.d7.loss_mask: 0.7145, decode.d7.loss_dice: 0.7442, decode.d8.loss_cls: 0.0184, decode.d8.loss_mask: 0.7186, decode.d8.loss_dice: 0.7443, loss: 16.8116, grad_norm: 543.0398
2023-08-29 15:22:51,850 - mmseg - INFO - Iter [4050/160000]	lr: 1.641e-06, eta: 1 day, 7:26:07, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0209, decode.loss_mask: 0.6436, decode.loss_dice: 0.6694, decode.d0.loss_cls: 1.7466, decode.d0.loss_mask: 0.7420, decode.d0.loss_dice: 0.8476, decode.d1.loss_cls: 0.0308, decode.d1.loss_mask: 0.6520, decode.d1.loss_dice: 0.6889, decode.d2.loss_cls: 0.0343, decode.d2.loss_mask: 0.6388, decode.d2.loss_dice: 0.6760, decode.d3.loss_cls: 0.0309, decode.d3.loss_mask: 0.6375, decode.d3.loss_dice: 0.6689, decode.d4.loss_cls: 0.0275, decode.d4.loss_mask: 0.6333, decode.d4.loss_dice: 0.6687, decode.d5.loss_cls: 0.0303, decode.d5.loss_mask: 0.6407, decode.d5.loss_dice: 0.6718, decode.d6.loss_cls: 0.0301, decode.d6.loss_mask: 0.6380, decode.d6.loss_dice: 0.6680, decode.d7.loss_cls: 0.0280, decode.d7.loss_mask: 0.6409, decode.d7.loss_dice: 0.6684, decode.d8.loss_cls: 0.0205, decode.d8.loss_mask: 0.6478, decode.d8.loss_dice: 0.6728, loss: 15.4149, grad_norm: 476.7894
2023-08-29 15:23:29,291 - mmseg - INFO - Iter [4100/160000]	lr: 1.640e-06, eta: 1 day, 7:26:15, time: 0.749, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0043, decode.loss_mask: 0.7044, decode.loss_dice: 0.7396, decode.d0.loss_cls: 1.7365, decode.d0.loss_mask: 0.7646, decode.d0.loss_dice: 0.8793, decode.d1.loss_cls: 0.0136, decode.d1.loss_mask: 0.7124, decode.d1.loss_dice: 0.7539, decode.d2.loss_cls: 0.0093, decode.d2.loss_mask: 0.7045, decode.d2.loss_dice: 0.7445, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.7020, decode.d3.loss_dice: 0.7400, decode.d4.loss_cls: 0.0046, decode.d4.loss_mask: 0.7021, decode.d4.loss_dice: 0.7402, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.7003, decode.d5.loss_dice: 0.7379, decode.d6.loss_cls: 0.0042, decode.d6.loss_mask: 0.6986, decode.d6.loss_dice: 0.7416, decode.d7.loss_cls: 0.0040, decode.d7.loss_mask: 0.7030, decode.d7.loss_dice: 0.7463, decode.d8.loss_cls: 0.0092, decode.d8.loss_mask: 0.6940, decode.d8.loss_dice: 0.7376, loss: 16.4417, grad_norm: 621.7789
2023-08-29 15:24:04,106 - mmseg - INFO - Iter [4150/160000]	lr: 1.640e-06, eta: 1 day, 7:24:43, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0054, decode.loss_mask: 0.6671, decode.loss_dice: 0.6967, decode.d0.loss_cls: 1.7293, decode.d0.loss_mask: 0.7596, decode.d0.loss_dice: 0.8575, decode.d1.loss_cls: 0.0146, decode.d1.loss_mask: 0.6644, decode.d1.loss_dice: 0.7105, decode.d2.loss_cls: 0.0099, decode.d2.loss_mask: 0.6616, decode.d2.loss_dice: 0.6928, decode.d3.loss_cls: 0.0052, decode.d3.loss_mask: 0.6620, decode.d3.loss_dice: 0.6916, decode.d4.loss_cls: 0.0053, decode.d4.loss_mask: 0.6700, decode.d4.loss_dice: 0.6905, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.6710, decode.d5.loss_dice: 0.6932, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.6717, decode.d6.loss_dice: 0.6929, decode.d7.loss_cls: 0.0052, decode.d7.loss_mask: 0.6681, decode.d7.loss_dice: 0.6955, decode.d8.loss_cls: 0.0053, decode.d8.loss_mask: 0.6673, decode.d8.loss_dice: 0.6956, loss: 15.6700, grad_norm: 585.7397
2023-08-29 15:24:40,684 - mmseg - INFO - Iter [4200/160000]	lr: 1.639e-06, eta: 1 day, 7:24:17, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0162, decode.loss_mask: 0.6680, decode.loss_dice: 0.7064, decode.d0.loss_cls: 1.7192, decode.d0.loss_mask: 0.7351, decode.d0.loss_dice: 0.8503, decode.d1.loss_cls: 0.0186, decode.d1.loss_mask: 0.6818, decode.d1.loss_dice: 0.7238, decode.d2.loss_cls: 0.0201, decode.d2.loss_mask: 0.6563, decode.d2.loss_dice: 0.7142, decode.d3.loss_cls: 0.0106, decode.d3.loss_mask: 0.6683, decode.d3.loss_dice: 0.7102, decode.d4.loss_cls: 0.0164, decode.d4.loss_mask: 0.6610, decode.d4.loss_dice: 0.7111, decode.d5.loss_cls: 0.0164, decode.d5.loss_mask: 0.6658, decode.d5.loss_dice: 0.7038, decode.d6.loss_cls: 0.0162, decode.d6.loss_mask: 0.6603, decode.d6.loss_dice: 0.7053, decode.d7.loss_cls: 0.0166, decode.d7.loss_mask: 0.6605, decode.d7.loss_dice: 0.7032, decode.d8.loss_cls: 0.0172, decode.d8.loss_mask: 0.6647, decode.d8.loss_dice: 0.7070, loss: 15.8246, grad_norm: 611.6149
2023-08-29 15:25:17,423 - mmseg - INFO - Iter [4250/160000]	lr: 1.639e-06, eta: 1 day, 7:23:58, time: 0.735, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.7048, decode.loss_dice: 0.7044, decode.d0.loss_cls: 1.7127, decode.d0.loss_mask: 0.7215, decode.d0.loss_dice: 0.8274, decode.d1.loss_cls: 0.0178, decode.d1.loss_mask: 0.6839, decode.d1.loss_dice: 0.7167, decode.d2.loss_cls: 0.0194, decode.d2.loss_mask: 0.6710, decode.d2.loss_dice: 0.6984, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.6991, decode.d3.loss_dice: 0.6970, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.7020, decode.d4.loss_dice: 0.7012, decode.d5.loss_cls: 0.0093, decode.d5.loss_mask: 0.6960, decode.d5.loss_dice: 0.6954, decode.d6.loss_cls: 0.0095, decode.d6.loss_mask: 0.6918, decode.d6.loss_dice: 0.6971, decode.d7.loss_cls: 0.0099, decode.d7.loss_mask: 0.6913, decode.d7.loss_dice: 0.6980, decode.d8.loss_cls: 0.0096, decode.d8.loss_mask: 0.6944, decode.d8.loss_dice: 0.6983, loss: 15.8891, grad_norm: 582.0148
2023-08-29 15:25:54,527 - mmseg - INFO - Iter [4300/160000]	lr: 1.638e-06, eta: 1 day, 7:23:51, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.6772, decode.loss_dice: 0.6832, decode.d0.loss_cls: 1.7018, decode.d0.loss_mask: 0.7444, decode.d0.loss_dice: 0.7994, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.6878, decode.d1.loss_dice: 0.6979, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.6727, decode.d2.loss_dice: 0.6825, decode.d3.loss_cls: 0.0036, decode.d3.loss_mask: 0.6774, decode.d3.loss_dice: 0.6862, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.6738, decode.d4.loss_dice: 0.6831, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.6737, decode.d5.loss_dice: 0.6814, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.6758, decode.d6.loss_dice: 0.6836, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.6753, decode.d7.loss_dice: 0.6820, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.6782, decode.d8.loss_dice: 0.6820, loss: 15.5411, grad_norm: 482.9453
2023-08-29 15:26:29,174 - mmseg - INFO - Iter [4350/160000]	lr: 1.637e-06, eta: 1 day, 7:22:16, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.6669, decode.loss_dice: 0.6601, decode.d0.loss_cls: 1.6907, decode.d0.loss_mask: 0.7171, decode.d0.loss_dice: 0.7914, decode.d1.loss_cls: 0.0117, decode.d1.loss_mask: 0.6660, decode.d1.loss_dice: 0.6810, decode.d2.loss_cls: 0.0072, decode.d2.loss_mask: 0.6575, decode.d2.loss_dice: 0.6636, decode.d3.loss_cls: 0.0036, decode.d3.loss_mask: 0.6610, decode.d3.loss_dice: 0.6631, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.6620, decode.d4.loss_dice: 0.6594, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.6590, decode.d5.loss_dice: 0.6566, decode.d6.loss_cls: 0.0031, decode.d6.loss_mask: 0.6620, decode.d6.loss_dice: 0.6596, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.6680, decode.d7.loss_dice: 0.6605, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.6642, decode.d8.loss_dice: 0.6601, loss: 15.1708, grad_norm: 538.4343
2023-08-29 15:27:05,610 - mmseg - INFO - Iter [4400/160000]	lr: 1.637e-06, eta: 1 day, 7:21:45, time: 0.729, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0308, decode.loss_mask: 0.6882, decode.loss_dice: 0.6716, decode.d0.loss_cls: 1.6815, decode.d0.loss_mask: 0.7530, decode.d0.loss_dice: 0.8092, decode.d1.loss_cls: 0.0353, decode.d1.loss_mask: 0.6893, decode.d1.loss_dice: 0.6931, decode.d2.loss_cls: 0.0344, decode.d2.loss_mask: 0.6793, decode.d2.loss_dice: 0.6795, decode.d3.loss_cls: 0.0305, decode.d3.loss_mask: 0.6756, decode.d3.loss_dice: 0.6725, decode.d4.loss_cls: 0.0303, decode.d4.loss_mask: 0.6773, decode.d4.loss_dice: 0.6689, decode.d5.loss_cls: 0.0302, decode.d5.loss_mask: 0.6763, decode.d5.loss_dice: 0.6705, decode.d6.loss_cls: 0.0320, decode.d6.loss_mask: 0.6764, decode.d6.loss_dice: 0.6699, decode.d7.loss_cls: 0.0330, decode.d7.loss_mask: 0.6715, decode.d7.loss_dice: 0.6702, decode.d8.loss_cls: 0.0319, decode.d8.loss_mask: 0.6748, decode.d8.loss_dice: 0.6754, loss: 15.7124, grad_norm: 565.6092
2023-08-29 15:27:42,168 - mmseg - INFO - Iter [4450/160000]	lr: 1.636e-06, eta: 1 day, 7:21:18, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.6434, decode.loss_dice: 0.6851, decode.d0.loss_cls: 1.6756, decode.d0.loss_mask: 0.7325, decode.d0.loss_dice: 0.8203, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.6590, decode.d1.loss_dice: 0.7014, decode.d2.loss_cls: 0.0073, decode.d2.loss_mask: 0.6406, decode.d2.loss_dice: 0.6771, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.6409, decode.d3.loss_dice: 0.6713, decode.d4.loss_cls: 0.0035, decode.d4.loss_mask: 0.6450, decode.d4.loss_dice: 0.6798, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.6442, decode.d5.loss_dice: 0.6816, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.6442, decode.d6.loss_dice: 0.6786, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.6491, decode.d7.loss_dice: 0.6798, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.6428, decode.d8.loss_dice: 0.6824, loss: 15.2164, grad_norm: 736.2310
2023-08-29 15:28:19,365 - mmseg - INFO - Iter [4500/160000]	lr: 1.636e-06, eta: 1 day, 7:21:14, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0103, decode.loss_mask: 0.7436, decode.loss_dice: 0.7466, decode.d0.loss_cls: 1.6672, decode.d0.loss_mask: 0.7747, decode.d0.loss_dice: 0.8400, decode.d1.loss_cls: 0.0163, decode.d1.loss_mask: 0.7371, decode.d1.loss_dice: 0.7381, decode.d2.loss_cls: 0.0194, decode.d2.loss_mask: 0.7304, decode.d2.loss_dice: 0.7408, decode.d3.loss_cls: 0.0180, decode.d3.loss_mask: 0.7262, decode.d3.loss_dice: 0.7418, decode.d4.loss_cls: 0.0165, decode.d4.loss_mask: 0.7296, decode.d4.loss_dice: 0.7387, decode.d5.loss_cls: 0.0166, decode.d5.loss_mask: 0.7333, decode.d5.loss_dice: 0.7441, decode.d6.loss_cls: 0.0165, decode.d6.loss_mask: 0.7304, decode.d6.loss_dice: 0.7430, decode.d7.loss_cls: 0.0090, decode.d7.loss_mask: 0.7418, decode.d7.loss_dice: 0.7439, decode.d8.loss_cls: 0.0088, decode.d8.loss_mask: 0.7454, decode.d8.loss_dice: 0.7426, loss: 16.7106, grad_norm: 694.5489
2023-08-29 15:28:54,071 - mmseg - INFO - Iter [4550/160000]	lr: 1.635e-06, eta: 1 day, 7:19:43, time: 0.694, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0040, decode.loss_mask: 0.6104, decode.loss_dice: 0.6695, decode.d0.loss_cls: 1.6628, decode.d0.loss_mask: 0.6812, decode.d0.loss_dice: 0.8024, decode.d1.loss_cls: 0.0115, decode.d1.loss_mask: 0.6241, decode.d1.loss_dice: 0.6944, decode.d2.loss_cls: 0.0084, decode.d2.loss_mask: 0.6111, decode.d2.loss_dice: 0.6760, decode.d3.loss_cls: 0.0049, decode.d3.loss_mask: 0.6094, decode.d3.loss_dice: 0.6712, decode.d4.loss_cls: 0.0046, decode.d4.loss_mask: 0.6105, decode.d4.loss_dice: 0.6715, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.6124, decode.d5.loss_dice: 0.6725, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.6101, decode.d6.loss_dice: 0.6702, decode.d7.loss_cls: 0.0042, decode.d7.loss_mask: 0.6116, decode.d7.loss_dice: 0.6673, decode.d8.loss_cls: 0.0041, decode.d8.loss_mask: 0.6121, decode.d8.loss_dice: 0.6756, loss: 14.7768, grad_norm: 576.7214
2023-08-29 15:29:30,845 - mmseg - INFO - Iter [4600/160000]	lr: 1.635e-06, eta: 1 day, 7:19:23, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.6457, decode.loss_dice: 0.6567, decode.d0.loss_cls: 1.6513, decode.d0.loss_mask: 0.6983, decode.d0.loss_dice: 0.7830, decode.d1.loss_cls: 0.0115, decode.d1.loss_mask: 0.6603, decode.d1.loss_dice: 0.6728, decode.d2.loss_cls: 0.0084, decode.d2.loss_mask: 0.6466, decode.d2.loss_dice: 0.6560, decode.d3.loss_cls: 0.0045, decode.d3.loss_mask: 0.6436, decode.d3.loss_dice: 0.6483, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.6407, decode.d4.loss_dice: 0.6464, decode.d5.loss_cls: 0.0044, decode.d5.loss_mask: 0.6426, decode.d5.loss_dice: 0.6470, decode.d6.loss_cls: 0.0042, decode.d6.loss_mask: 0.6443, decode.d6.loss_dice: 0.6477, decode.d7.loss_cls: 0.0041, decode.d7.loss_mask: 0.6413, decode.d7.loss_dice: 0.6516, decode.d8.loss_cls: 0.0041, decode.d8.loss_mask: 0.6428, decode.d8.loss_dice: 0.6550, loss: 14.8712, grad_norm: 567.9887
2023-08-29 15:30:07,328 - mmseg - INFO - Iter [4650/160000]	lr: 1.634e-06, eta: 1 day, 7:18:54, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.6253, decode.loss_dice: 0.6610, decode.d0.loss_cls: 1.6436, decode.d0.loss_mask: 0.6935, decode.d0.loss_dice: 0.7991, decode.d1.loss_cls: 0.0105, decode.d1.loss_mask: 0.6317, decode.d1.loss_dice: 0.6854, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.6234, decode.d2.loss_dice: 0.6691, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.6240, decode.d3.loss_dice: 0.6612, decode.d4.loss_cls: 0.0035, decode.d4.loss_mask: 0.6212, decode.d4.loss_dice: 0.6615, decode.d5.loss_cls: 0.0035, decode.d5.loss_mask: 0.6195, decode.d5.loss_dice: 0.6570, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.6258, decode.d6.loss_dice: 0.6641, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.6197, decode.d7.loss_dice: 0.6598, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.6250, decode.d8.loss_dice: 0.6645, loss: 14.7761, grad_norm: 600.0126
2023-08-29 15:30:44,489 - mmseg - INFO - Iter [4700/160000]	lr: 1.634e-06, eta: 1 day, 7:18:47, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.5744, decode.loss_dice: 0.5710, decode.d0.loss_cls: 1.6327, decode.d0.loss_mask: 0.6097, decode.d0.loss_dice: 0.6935, decode.d1.loss_cls: 0.0103, decode.d1.loss_mask: 0.5742, decode.d1.loss_dice: 0.5898, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.5722, decode.d2.loss_dice: 0.5795, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.5759, decode.d3.loss_dice: 0.5750, decode.d4.loss_cls: 0.0035, decode.d4.loss_mask: 0.5765, decode.d4.loss_dice: 0.5722, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.5749, decode.d5.loss_dice: 0.5716, decode.d6.loss_cls: 0.0031, decode.d6.loss_mask: 0.5756, decode.d6.loss_dice: 0.5701, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.5755, decode.d7.loss_dice: 0.5679, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.5757, decode.d8.loss_dice: 0.5691, loss: 13.3168, grad_norm: 555.6134
2023-08-29 15:31:19,379 - mmseg - INFO - Iter [4750/160000]	lr: 1.633e-06, eta: 1 day, 7:17:24, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0175, decode.loss_mask: 0.7143, decode.loss_dice: 0.7013, decode.d0.loss_cls: 1.6281, decode.d0.loss_mask: 0.7332, decode.d0.loss_dice: 0.7911, decode.d1.loss_cls: 0.0206, decode.d1.loss_mask: 0.7206, decode.d1.loss_dice: 0.7106, decode.d2.loss_cls: 0.0199, decode.d2.loss_mask: 0.7101, decode.d2.loss_dice: 0.7015, decode.d3.loss_cls: 0.0174, decode.d3.loss_mask: 0.7132, decode.d3.loss_dice: 0.6946, decode.d4.loss_cls: 0.0164, decode.d4.loss_mask: 0.7143, decode.d4.loss_dice: 0.6974, decode.d5.loss_cls: 0.0161, decode.d5.loss_mask: 0.7108, decode.d5.loss_dice: 0.6944, decode.d6.loss_cls: 0.0174, decode.d6.loss_mask: 0.7152, decode.d6.loss_dice: 0.6912, decode.d7.loss_cls: 0.0177, decode.d7.loss_mask: 0.7105, decode.d7.loss_dice: 0.6957, decode.d8.loss_cls: 0.0165, decode.d8.loss_mask: 0.7171, decode.d8.loss_dice: 0.6987, loss: 16.0233, grad_norm: 747.2914
2023-08-29 15:31:56,303 - mmseg - INFO - Iter [4800/160000]	lr: 1.633e-06, eta: 1 day, 7:17:09, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0146, decode.loss_mask: 0.6340, decode.loss_dice: 0.6732, decode.d0.loss_cls: 1.6188, decode.d0.loss_mask: 0.6858, decode.d0.loss_dice: 0.7519, decode.d1.loss_cls: 0.0202, decode.d1.loss_mask: 0.6344, decode.d1.loss_dice: 0.6742, decode.d2.loss_cls: 0.0186, decode.d2.loss_mask: 0.6282, decode.d2.loss_dice: 0.6727, decode.d3.loss_cls: 0.0163, decode.d3.loss_mask: 0.6264, decode.d3.loss_dice: 0.6627, decode.d4.loss_cls: 0.0155, decode.d4.loss_mask: 0.6314, decode.d4.loss_dice: 0.6713, decode.d5.loss_cls: 0.0149, decode.d5.loss_mask: 0.6289, decode.d5.loss_dice: 0.6707, decode.d6.loss_cls: 0.0148, decode.d6.loss_mask: 0.6346, decode.d6.loss_dice: 0.6644, decode.d7.loss_cls: 0.0157, decode.d7.loss_mask: 0.6305, decode.d7.loss_dice: 0.6735, decode.d8.loss_cls: 0.0150, decode.d8.loss_mask: 0.6339, decode.d8.loss_dice: 0.6696, loss: 14.9165, grad_norm: 552.7511
2023-08-29 15:32:32,799 - mmseg - INFO - Iter [4850/160000]	lr: 1.632e-06, eta: 1 day, 7:16:40, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0157, decode.loss_mask: 0.6559, decode.loss_dice: 0.6669, decode.d0.loss_cls: 1.6107, decode.d0.loss_mask: 0.6758, decode.d0.loss_dice: 0.7498, decode.d1.loss_cls: 0.0277, decode.d1.loss_mask: 0.6437, decode.d1.loss_dice: 0.6629, decode.d2.loss_cls: 0.0263, decode.d2.loss_mask: 0.6344, decode.d2.loss_dice: 0.6660, decode.d3.loss_cls: 0.0159, decode.d3.loss_mask: 0.6423, decode.d3.loss_dice: 0.6666, decode.d4.loss_cls: 0.0205, decode.d4.loss_mask: 0.6330, decode.d4.loss_dice: 0.6572, decode.d5.loss_cls: 0.0177, decode.d5.loss_mask: 0.6522, decode.d5.loss_dice: 0.6577, decode.d6.loss_cls: 0.0113, decode.d6.loss_mask: 0.6633, decode.d6.loss_dice: 0.6620, decode.d7.loss_cls: 0.0118, decode.d7.loss_mask: 0.6625, decode.d7.loss_dice: 0.6622, decode.d8.loss_cls: 0.0165, decode.d8.loss_mask: 0.6495, decode.d8.loss_dice: 0.6697, loss: 15.0079, grad_norm: 587.0310
2023-08-29 15:33:09,711 - mmseg - INFO - Iter [4900/160000]	lr: 1.632e-06, eta: 1 day, 7:16:23, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0036, decode.loss_mask: 0.6717, decode.loss_dice: 0.7171, decode.d0.loss_cls: 1.6033, decode.d0.loss_mask: 0.7236, decode.d0.loss_dice: 0.7956, decode.d1.loss_cls: 0.0099, decode.d1.loss_mask: 0.6693, decode.d1.loss_dice: 0.7128, decode.d2.loss_cls: 0.0072, decode.d2.loss_mask: 0.6657, decode.d2.loss_dice: 0.7045, decode.d3.loss_cls: 0.0042, decode.d3.loss_mask: 0.6673, decode.d3.loss_dice: 0.7078, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.6654, decode.d4.loss_dice: 0.7093, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.6672, decode.d5.loss_dice: 0.7119, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.6644, decode.d6.loss_dice: 0.7117, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.6687, decode.d7.loss_dice: 0.7136, decode.d8.loss_cls: 0.0036, decode.d8.loss_mask: 0.6686, decode.d8.loss_dice: 0.7136, loss: 15.5766, grad_norm: 643.4448
2023-08-29 15:33:44,724 - mmseg - INFO - Iter [4950/160000]	lr: 1.631e-06, eta: 1 day, 7:15:07, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.6586, decode.loss_dice: 0.6877, decode.d0.loss_cls: 1.5937, decode.d0.loss_mask: 0.7098, decode.d0.loss_dice: 0.7924, decode.d1.loss_cls: 0.0165, decode.d1.loss_mask: 0.6486, decode.d1.loss_dice: 0.6919, decode.d2.loss_cls: 0.0110, decode.d2.loss_mask: 0.6537, decode.d2.loss_dice: 0.6855, decode.d3.loss_cls: 0.0100, decode.d3.loss_mask: 0.6501, decode.d3.loss_dice: 0.6823, decode.d4.loss_cls: 0.0093, decode.d4.loss_mask: 0.6552, decode.d4.loss_dice: 0.6796, decode.d5.loss_cls: 0.0097, decode.d5.loss_mask: 0.6546, decode.d5.loss_dice: 0.6800, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.6577, decode.d6.loss_dice: 0.6794, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.6616, decode.d7.loss_dice: 0.6829, decode.d8.loss_cls: 0.0047, decode.d8.loss_mask: 0.6652, decode.d8.loss_dice: 0.6847, loss: 15.2303, grad_norm: 556.7400
2023-08-29 15:34:21,545 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-08-29 15:34:27,020 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 15:34:27,020 - mmseg - INFO - Iter [5000/160000]	lr: 1.631e-06, eta: 1 day, 7:17:37, time: 0.846, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.6721, decode.loss_dice: 0.6886, decode.d0.loss_cls: 1.5853, decode.d0.loss_mask: 0.6940, decode.d0.loss_dice: 0.7762, decode.d1.loss_cls: 0.0149, decode.d1.loss_mask: 0.6689, decode.d1.loss_dice: 0.6949, decode.d2.loss_cls: 0.0126, decode.d2.loss_mask: 0.6533, decode.d2.loss_dice: 0.6855, decode.d3.loss_cls: 0.0094, decode.d3.loss_mask: 0.6526, decode.d3.loss_dice: 0.6811, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.6719, decode.d4.loss_dice: 0.6791, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.6673, decode.d5.loss_dice: 0.6769, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.6669, decode.d6.loss_dice: 0.6806, decode.d7.loss_cls: 0.0074, decode.d7.loss_mask: 0.6516, decode.d7.loss_dice: 0.6823, decode.d8.loss_cls: 0.0070, decode.d8.loss_mask: 0.6513, decode.d8.loss_dice: 0.6832, loss: 15.2266, grad_norm: 515.8888
2023-08-29 15:35:03,258 - mmseg - INFO - Iter [5050/160000]	lr: 1.630e-06, eta: 1 day, 7:16:57, time: 0.725, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.5947, decode.loss_dice: 0.6548, decode.d0.loss_cls: 1.5765, decode.d0.loss_mask: 0.6695, decode.d0.loss_dice: 0.7818, decode.d1.loss_cls: 0.0099, decode.d1.loss_mask: 0.6097, decode.d1.loss_dice: 0.6737, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.5980, decode.d2.loss_dice: 0.6587, decode.d3.loss_cls: 0.0044, decode.d3.loss_mask: 0.5953, decode.d3.loss_dice: 0.6568, decode.d4.loss_cls: 0.0040, decode.d4.loss_mask: 0.5957, decode.d4.loss_dice: 0.6521, decode.d5.loss_cls: 0.0092, decode.d5.loss_mask: 0.5901, decode.d5.loss_dice: 0.6523, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.5916, decode.d6.loss_dice: 0.6549, decode.d7.loss_cls: 0.0037, decode.d7.loss_mask: 0.5942, decode.d7.loss_dice: 0.6539, decode.d8.loss_cls: 0.0036, decode.d8.loss_mask: 0.5961, decode.d8.loss_dice: 0.6564, loss: 14.3561, grad_norm: 604.2895
2023-08-29 15:35:40,418 - mmseg - INFO - Iter [5100/160000]	lr: 1.630e-06, eta: 1 day, 7:16:46, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0169, decode.loss_mask: 0.6601, decode.loss_dice: 0.7031, decode.d0.loss_cls: 1.5662, decode.d0.loss_mask: 0.6803, decode.d0.loss_dice: 0.7754, decode.d1.loss_cls: 0.0225, decode.d1.loss_mask: 0.6556, decode.d1.loss_dice: 0.7021, decode.d2.loss_cls: 0.0209, decode.d2.loss_mask: 0.6523, decode.d2.loss_dice: 0.7012, decode.d3.loss_cls: 0.0178, decode.d3.loss_mask: 0.6534, decode.d3.loss_dice: 0.7002, decode.d4.loss_cls: 0.0151, decode.d4.loss_mask: 0.6549, decode.d4.loss_dice: 0.7026, decode.d5.loss_cls: 0.0157, decode.d5.loss_mask: 0.6576, decode.d5.loss_dice: 0.7039, decode.d6.loss_cls: 0.0159, decode.d6.loss_mask: 0.6581, decode.d6.loss_dice: 0.7066, decode.d7.loss_cls: 0.0160, decode.d7.loss_mask: 0.6604, decode.d7.loss_dice: 0.7052, decode.d8.loss_cls: 0.0167, decode.d8.loss_mask: 0.6586, decode.d8.loss_dice: 0.7043, loss: 15.4197, grad_norm: 550.5568
2023-08-29 15:36:17,538 - mmseg - INFO - Iter [5150/160000]	lr: 1.629e-06, eta: 1 day, 7:16:33, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.6042, decode.loss_dice: 0.6468, decode.d0.loss_cls: 1.5614, decode.d0.loss_mask: 0.6882, decode.d0.loss_dice: 0.7621, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.6119, decode.d1.loss_dice: 0.6586, decode.d2.loss_cls: 0.0059, decode.d2.loss_mask: 0.6031, decode.d2.loss_dice: 0.6454, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.6023, decode.d3.loss_dice: 0.6408, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.6027, decode.d4.loss_dice: 0.6425, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.6025, decode.d5.loss_dice: 0.6416, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.6001, decode.d6.loss_dice: 0.6437, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.6006, decode.d7.loss_dice: 0.6411, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.6018, decode.d8.loss_dice: 0.6426, loss: 14.2743, grad_norm: 568.8919
2023-08-29 15:36:52,193 - mmseg - INFO - Iter [5200/160000]	lr: 1.629e-06, eta: 1 day, 7:15:06, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0082, decode.loss_mask: 0.5695, decode.loss_dice: 0.6186, decode.d0.loss_cls: 1.5493, decode.d0.loss_mask: 0.6111, decode.d0.loss_dice: 0.7404, decode.d1.loss_cls: 0.0089, decode.d1.loss_mask: 0.5835, decode.d1.loss_dice: 0.6363, decode.d2.loss_cls: 0.0066, decode.d2.loss_mask: 0.5733, decode.d2.loss_dice: 0.6137, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.5806, decode.d3.loss_dice: 0.6177, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.5808, decode.d4.loss_dice: 0.6154, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.5817, decode.d5.loss_dice: 0.6129, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.5851, decode.d6.loss_dice: 0.6186, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.5819, decode.d7.loss_dice: 0.6185, decode.d8.loss_cls: 0.0084, decode.d8.loss_mask: 0.5654, decode.d8.loss_dice: 0.6150, loss: 13.7187, grad_norm: 557.6075
2023-08-29 15:37:28,532 - mmseg - INFO - Iter [5250/160000]	lr: 1.628e-06, eta: 1 day, 7:14:29, time: 0.727, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0184, decode.loss_mask: 0.6716, decode.loss_dice: 0.6617, decode.d0.loss_cls: 1.5406, decode.d0.loss_mask: 0.7144, decode.d0.loss_dice: 0.7677, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.6720, decode.d1.loss_dice: 0.6715, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.6634, decode.d2.loss_dice: 0.6618, decode.d3.loss_cls: 0.0158, decode.d3.loss_mask: 0.6641, decode.d3.loss_dice: 0.6554, decode.d4.loss_cls: 0.0143, decode.d4.loss_mask: 0.6654, decode.d4.loss_dice: 0.6549, decode.d5.loss_cls: 0.0158, decode.d5.loss_mask: 0.6841, decode.d5.loss_dice: 0.6528, decode.d6.loss_cls: 0.0171, decode.d6.loss_mask: 0.6795, decode.d6.loss_dice: 0.6518, decode.d7.loss_cls: 0.0175, decode.d7.loss_mask: 0.6712, decode.d7.loss_dice: 0.6579, decode.d8.loss_cls: 0.0230, decode.d8.loss_mask: 0.6656, decode.d8.loss_dice: 0.6522, loss: 15.1403, grad_norm: 695.0804
2023-08-29 15:38:05,592 - mmseg - INFO - Iter [5300/160000]	lr: 1.627e-06, eta: 1 day, 7:14:14, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0052, decode.loss_mask: 0.6249, decode.loss_dice: 0.6274, decode.d0.loss_cls: 1.5320, decode.d0.loss_mask: 0.6686, decode.d0.loss_dice: 0.7126, decode.d1.loss_cls: 0.0090, decode.d1.loss_mask: 0.6328, decode.d1.loss_dice: 0.6287, decode.d2.loss_cls: 0.0066, decode.d2.loss_mask: 0.6313, decode.d2.loss_dice: 0.6221, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.6235, decode.d3.loss_dice: 0.6179, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.6231, decode.d4.loss_dice: 0.6196, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.6246, decode.d5.loss_dice: 0.6173, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.6195, decode.d6.loss_dice: 0.6154, decode.d7.loss_cls: 0.0044, decode.d7.loss_mask: 0.6226, decode.d7.loss_dice: 0.6174, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.6201, decode.d8.loss_dice: 0.6209, loss: 14.1682, grad_norm: 630.4165
2023-08-29 15:38:42,794 - mmseg - INFO - Iter [5350/160000]	lr: 1.627e-06, eta: 1 day, 7:14:03, time: 0.744, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0108, decode.loss_mask: 0.5795, decode.loss_dice: 0.6195, decode.d0.loss_cls: 1.5238, decode.d0.loss_mask: 0.6307, decode.d0.loss_dice: 0.7173, decode.d1.loss_cls: 0.0144, decode.d1.loss_mask: 0.5768, decode.d1.loss_dice: 0.6321, decode.d2.loss_cls: 0.0058, decode.d2.loss_mask: 0.5767, decode.d2.loss_dice: 0.6188, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.5797, decode.d3.loss_dice: 0.6198, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.5808, decode.d4.loss_dice: 0.6203, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.5851, decode.d5.loss_dice: 0.6154, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.5873, decode.d6.loss_dice: 0.6206, decode.d7.loss_cls: 0.0109, decode.d7.loss_mask: 0.5812, decode.d7.loss_dice: 0.6174, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.5868, decode.d8.loss_dice: 0.6172, loss: 13.7438, grad_norm: 629.0355
2023-08-29 15:39:17,821 - mmseg - INFO - Iter [5400/160000]	lr: 1.626e-06, eta: 1 day, 7:12:48, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0097, decode.loss_mask: 0.6069, decode.loss_dice: 0.6067, decode.d0.loss_cls: 1.5188, decode.d0.loss_mask: 0.6504, decode.d0.loss_dice: 0.7077, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.6042, decode.d1.loss_dice: 0.6235, decode.d2.loss_cls: 0.0194, decode.d2.loss_mask: 0.6020, decode.d2.loss_dice: 0.6124, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.5962, decode.d3.loss_dice: 0.6118, decode.d4.loss_cls: 0.0145, decode.d4.loss_mask: 0.5993, decode.d4.loss_dice: 0.6092, decode.d5.loss_cls: 0.0144, decode.d5.loss_mask: 0.6074, decode.d5.loss_dice: 0.6087, decode.d6.loss_cls: 0.0169, decode.d6.loss_mask: 0.6012, decode.d6.loss_dice: 0.6050, decode.d7.loss_cls: 0.0175, decode.d7.loss_mask: 0.6002, decode.d7.loss_dice: 0.6063, decode.d8.loss_cls: 0.0175, decode.d8.loss_mask: 0.5964, decode.d8.loss_dice: 0.6053, loss: 13.9259, grad_norm: 689.6899
2023-08-29 15:39:54,067 - mmseg - INFO - Iter [5450/160000]	lr: 1.626e-06, eta: 1 day, 7:12:09, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.5548, decode.loss_dice: 0.5852, decode.d0.loss_cls: 1.5090, decode.d0.loss_mask: 0.5948, decode.d0.loss_dice: 0.6921, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.5584, decode.d1.loss_dice: 0.6058, decode.d2.loss_cls: 0.0062, decode.d2.loss_mask: 0.5530, decode.d2.loss_dice: 0.5910, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.5490, decode.d3.loss_dice: 0.5861, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.5528, decode.d4.loss_dice: 0.5844, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.5530, decode.d5.loss_dice: 0.5838, decode.d6.loss_cls: 0.0031, decode.d6.loss_mask: 0.5549, decode.d6.loss_dice: 0.5816, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.5512, decode.d7.loss_dice: 0.5844, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.5549, decode.d8.loss_dice: 0.5841, loss: 13.1017, grad_norm: 538.5326
2023-08-29 15:40:31,232 - mmseg - INFO - Iter [5500/160000]	lr: 1.625e-06, eta: 1 day, 7:11:56, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0238, decode.loss_mask: 0.6787, decode.loss_dice: 0.6225, decode.d0.loss_cls: 1.5005, decode.d0.loss_mask: 0.6971, decode.d0.loss_dice: 0.7004, decode.d1.loss_cls: 0.0209, decode.d1.loss_mask: 0.6810, decode.d1.loss_dice: 0.6325, decode.d2.loss_cls: 0.0191, decode.d2.loss_mask: 0.6808, decode.d2.loss_dice: 0.6274, decode.d3.loss_cls: 0.0096, decode.d3.loss_mask: 0.6987, decode.d3.loss_dice: 0.6298, decode.d4.loss_cls: 0.0095, decode.d4.loss_mask: 0.6961, decode.d4.loss_dice: 0.6295, decode.d5.loss_cls: 0.0098, decode.d5.loss_mask: 0.6964, decode.d5.loss_dice: 0.6299, decode.d6.loss_cls: 0.0098, decode.d6.loss_mask: 0.6980, decode.d6.loss_dice: 0.6318, decode.d7.loss_cls: 0.0216, decode.d7.loss_mask: 0.6781, decode.d7.loss_dice: 0.6224, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.7134, decode.d8.loss_dice: 0.6297, loss: 14.9022, grad_norm: 616.1833
2023-08-29 15:41:08,367 - mmseg - INFO - Iter [5550/160000]	lr: 1.625e-06, eta: 1 day, 7:11:41, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.5867, decode.loss_dice: 0.6225, decode.d0.loss_cls: 1.4924, decode.d0.loss_mask: 0.6188, decode.d0.loss_dice: 0.7072, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.5846, decode.d1.loss_dice: 0.6287, decode.d2.loss_cls: 0.0049, decode.d2.loss_mask: 0.5819, decode.d2.loss_dice: 0.6234, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.5764, decode.d3.loss_dice: 0.6233, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.5791, decode.d4.loss_dice: 0.6290, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.5796, decode.d5.loss_dice: 0.6273, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.5813, decode.d6.loss_dice: 0.6258, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.5822, decode.d7.loss_dice: 0.6294, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.5822, decode.d8.loss_dice: 0.6284, loss: 13.7201, grad_norm: 479.6176
2023-08-29 15:41:43,269 - mmseg - INFO - Iter [5600/160000]	lr: 1.624e-06, eta: 1 day, 7:10:25, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0179, decode.loss_mask: 0.6026, decode.loss_dice: 0.6180, decode.d0.loss_cls: 1.4826, decode.d0.loss_mask: 0.6413, decode.d0.loss_dice: 0.7094, decode.d1.loss_cls: 0.0200, decode.d1.loss_mask: 0.6096, decode.d1.loss_dice: 0.6369, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.5977, decode.d2.loss_dice: 0.6216, decode.d3.loss_cls: 0.0157, decode.d3.loss_mask: 0.5965, decode.d3.loss_dice: 0.6183, decode.d4.loss_cls: 0.0147, decode.d4.loss_mask: 0.6022, decode.d4.loss_dice: 0.6179, decode.d5.loss_cls: 0.0155, decode.d5.loss_mask: 0.6005, decode.d5.loss_dice: 0.6184, decode.d6.loss_cls: 0.0174, decode.d6.loss_mask: 0.5996, decode.d6.loss_dice: 0.6187, decode.d7.loss_cls: 0.0171, decode.d7.loss_mask: 0.5957, decode.d7.loss_dice: 0.6172, decode.d8.loss_cls: 0.0177, decode.d8.loss_mask: 0.6008, decode.d8.loss_dice: 0.6227, loss: 13.9836, grad_norm: 568.0189
2023-08-29 15:42:19,640 - mmseg - INFO - Iter [5650/160000]	lr: 1.624e-06, eta: 1 day, 7:09:49, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0157, decode.loss_mask: 0.6183, decode.loss_dice: 0.6491, decode.d0.loss_cls: 1.4754, decode.d0.loss_mask: 0.6175, decode.d0.loss_dice: 0.7248, decode.d1.loss_cls: 0.0198, decode.d1.loss_mask: 0.5925, decode.d1.loss_dice: 0.6464, decode.d2.loss_cls: 0.0209, decode.d2.loss_mask: 0.5826, decode.d2.loss_dice: 0.6326, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.5911, decode.d3.loss_dice: 0.6280, decode.d4.loss_cls: 0.0158, decode.d4.loss_mask: 0.5946, decode.d4.loss_dice: 0.6295, decode.d5.loss_cls: 0.0222, decode.d5.loss_mask: 0.5959, decode.d5.loss_dice: 0.6270, decode.d6.loss_cls: 0.0245, decode.d6.loss_mask: 0.5864, decode.d6.loss_dice: 0.6309, decode.d7.loss_cls: 0.0221, decode.d7.loss_mask: 0.5937, decode.d7.loss_dice: 0.6330, decode.d8.loss_cls: 0.0213, decode.d8.loss_mask: 0.5843, decode.d8.loss_dice: 0.6399, loss: 14.0533, grad_norm: 557.4521
2023-08-29 15:42:56,853 - mmseg - INFO - Iter [5700/160000]	lr: 1.623e-06, eta: 1 day, 7:09:36, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0054, decode.loss_mask: 0.5935, decode.loss_dice: 0.6356, decode.d0.loss_cls: 1.4648, decode.d0.loss_mask: 0.6366, decode.d0.loss_dice: 0.7252, decode.d1.loss_cls: 0.0092, decode.d1.loss_mask: 0.5948, decode.d1.loss_dice: 0.6414, decode.d2.loss_cls: 0.0077, decode.d2.loss_mask: 0.5883, decode.d2.loss_dice: 0.6363, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.5907, decode.d3.loss_dice: 0.6283, decode.d4.loss_cls: 0.0052, decode.d4.loss_mask: 0.5915, decode.d4.loss_dice: 0.6297, decode.d5.loss_cls: 0.0051, decode.d5.loss_mask: 0.5899, decode.d5.loss_dice: 0.6277, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.5924, decode.d6.loss_dice: 0.6279, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.5911, decode.d7.loss_dice: 0.6361, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 0.5894, decode.d8.loss_dice: 0.6351, loss: 13.9006, grad_norm: 566.4937
2023-08-29 15:43:34,262 - mmseg - INFO - Iter [5750/160000]	lr: 1.623e-06, eta: 1 day, 7:09:29, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.5855, decode.loss_dice: 0.5860, decode.d0.loss_cls: 1.4571, decode.d0.loss_mask: 0.5993, decode.d0.loss_dice: 0.6643, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.5831, decode.d1.loss_dice: 0.5905, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.5864, decode.d2.loss_dice: 0.5869, decode.d3.loss_cls: 0.0105, decode.d3.loss_mask: 0.5803, decode.d3.loss_dice: 0.5845, decode.d4.loss_cls: 0.0180, decode.d4.loss_mask: 0.5685, decode.d4.loss_dice: 0.5816, decode.d5.loss_cls: 0.0172, decode.d5.loss_mask: 0.5719, decode.d5.loss_dice: 0.5836, decode.d6.loss_cls: 0.0186, decode.d6.loss_mask: 0.5666, decode.d6.loss_dice: 0.5799, decode.d7.loss_cls: 0.0183, decode.d7.loss_mask: 0.5665, decode.d7.loss_dice: 0.5793, decode.d8.loss_cls: 0.0189, decode.d8.loss_mask: 0.5722, decode.d8.loss_dice: 0.5819, loss: 13.2754, grad_norm: 537.1369
2023-08-29 15:44:09,206 - mmseg - INFO - Iter [5800/160000]	lr: 1.622e-06, eta: 1 day, 7:08:15, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.6471, decode.loss_dice: 0.6750, decode.d0.loss_cls: 1.4477, decode.d0.loss_mask: 0.6720, decode.d0.loss_dice: 0.7727, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.6454, decode.d1.loss_dice: 0.6803, decode.d2.loss_cls: 0.0062, decode.d2.loss_mask: 0.6416, decode.d2.loss_dice: 0.6755, decode.d3.loss_cls: 0.0039, decode.d3.loss_mask: 0.6427, decode.d3.loss_dice: 0.6669, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.6479, decode.d4.loss_dice: 0.6685, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.6443, decode.d5.loss_dice: 0.6670, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.6481, decode.d6.loss_dice: 0.6688, decode.d7.loss_cls: 0.0095, decode.d7.loss_mask: 0.6417, decode.d7.loss_dice: 0.6616, decode.d8.loss_cls: 0.0040, decode.d8.loss_mask: 0.6444, decode.d8.loss_dice: 0.6729, loss: 14.7794, grad_norm: 672.6966
2023-08-29 15:44:45,695 - mmseg - INFO - Iter [5850/160000]	lr: 1.622e-06, eta: 1 day, 7:07:42, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0030, decode.loss_mask: 0.5387, decode.loss_dice: 0.5675, decode.d0.loss_cls: 1.4380, decode.d0.loss_mask: 0.5880, decode.d0.loss_dice: 0.6556, decode.d1.loss_cls: 0.0074, decode.d1.loss_mask: 0.5461, decode.d1.loss_dice: 0.5766, decode.d2.loss_cls: 0.0050, decode.d2.loss_mask: 0.5355, decode.d2.loss_dice: 0.5722, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.5363, decode.d3.loss_dice: 0.5682, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.5350, decode.d4.loss_dice: 0.5653, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.5389, decode.d5.loss_dice: 0.5698, decode.d6.loss_cls: 0.0031, decode.d6.loss_mask: 0.5343, decode.d6.loss_dice: 0.5661, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.5366, decode.d7.loss_dice: 0.5648, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.5348, decode.d8.loss_dice: 0.5658, loss: 12.6677, grad_norm: 508.6422
2023-08-29 15:45:22,521 - mmseg - INFO - Iter [5900/160000]	lr: 1.621e-06, eta: 1 day, 7:07:18, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.5465, decode.loss_dice: 0.5203, decode.d0.loss_cls: 1.4272, decode.d0.loss_mask: 0.5884, decode.d0.loss_dice: 0.6316, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.5438, decode.d1.loss_dice: 0.5378, decode.d2.loss_cls: 0.0050, decode.d2.loss_mask: 0.5387, decode.d2.loss_dice: 0.5331, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.5460, decode.d3.loss_dice: 0.5273, decode.d4.loss_cls: 0.0028, decode.d4.loss_mask: 0.5460, decode.d4.loss_dice: 0.5257, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.5459, decode.d5.loss_dice: 0.5233, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.5440, decode.d6.loss_dice: 0.5255, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.5452, decode.d7.loss_dice: 0.5243, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.5457, decode.d8.loss_dice: 0.5238, loss: 12.3214, grad_norm: 477.5566
2023-08-29 15:45:59,586 - mmseg - INFO - Iter [5950/160000]	lr: 1.621e-06, eta: 1 day, 7:07:00, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0331, decode.loss_mask: 0.6176, decode.loss_dice: 0.5959, decode.d0.loss_cls: 1.4184, decode.d0.loss_mask: 0.6316, decode.d0.loss_dice: 0.6705, decode.d1.loss_cls: 0.0345, decode.d1.loss_mask: 0.6060, decode.d1.loss_dice: 0.6005, decode.d2.loss_cls: 0.0342, decode.d2.loss_mask: 0.5978, decode.d2.loss_dice: 0.5990, decode.d3.loss_cls: 0.0323, decode.d3.loss_mask: 0.6059, decode.d3.loss_dice: 0.5938, decode.d4.loss_cls: 0.0337, decode.d4.loss_mask: 0.6124, decode.d4.loss_dice: 0.5964, decode.d5.loss_cls: 0.0334, decode.d5.loss_mask: 0.6036, decode.d5.loss_dice: 0.5947, decode.d6.loss_cls: 0.0331, decode.d6.loss_mask: 0.6043, decode.d6.loss_dice: 0.5937, decode.d7.loss_cls: 0.0331, decode.d7.loss_mask: 0.6025, decode.d7.loss_dice: 0.5998, decode.d8.loss_cls: 0.0330, decode.d8.loss_mask: 0.6111, decode.d8.loss_dice: 0.6003, loss: 13.8563, grad_norm: 677.3184
2023-08-29 15:46:34,439 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-08-29 15:46:37,015 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 15:46:37,016 - mmseg - INFO - Iter [6000/160000]	lr: 1.620e-06, eta: 1 day, 7:06:51, time: 0.749, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0059, decode.loss_mask: 0.5522, decode.loss_dice: 0.5794, decode.d0.loss_cls: 1.4099, decode.d0.loss_mask: 0.5894, decode.d0.loss_dice: 0.6695, decode.d1.loss_cls: 0.0073, decode.d1.loss_mask: 0.5597, decode.d1.loss_dice: 0.5861, decode.d2.loss_cls: 0.0060, decode.d2.loss_mask: 0.5564, decode.d2.loss_dice: 0.5797, decode.d3.loss_cls: 0.0045, decode.d3.loss_mask: 0.5543, decode.d3.loss_dice: 0.5745, decode.d4.loss_cls: 0.0054, decode.d4.loss_mask: 0.5521, decode.d4.loss_dice: 0.5796, decode.d5.loss_cls: 0.0055, decode.d5.loss_mask: 0.5530, decode.d5.loss_dice: 0.5800, decode.d6.loss_cls: 0.0060, decode.d6.loss_mask: 0.5525, decode.d6.loss_dice: 0.5837, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.5533, decode.d7.loss_dice: 0.5744, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.5548, decode.d8.loss_dice: 0.5733, loss: 12.9198, grad_norm: 543.6532
2023-08-29 15:47:13,804 - mmseg - INFO - Iter [6050/160000]	lr: 1.620e-06, eta: 1 day, 7:06:26, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0040, decode.loss_mask: 0.5777, decode.loss_dice: 0.5651, decode.d0.loss_cls: 1.4034, decode.d0.loss_mask: 0.5975, decode.d0.loss_dice: 0.6414, decode.d1.loss_cls: 0.0079, decode.d1.loss_mask: 0.5892, decode.d1.loss_dice: 0.5717, decode.d2.loss_cls: 0.0059, decode.d2.loss_mask: 0.5832, decode.d2.loss_dice: 0.5597, decode.d3.loss_cls: 0.0044, decode.d3.loss_mask: 0.5840, decode.d3.loss_dice: 0.5589, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.5857, decode.d4.loss_dice: 0.5588, decode.d5.loss_cls: 0.0047, decode.d5.loss_mask: 0.5811, decode.d5.loss_dice: 0.5568, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.5782, decode.d6.loss_dice: 0.5603, decode.d7.loss_cls: 0.0044, decode.d7.loss_mask: 0.5845, decode.d7.loss_dice: 0.5589, decode.d8.loss_cls: 0.0039, decode.d8.loss_mask: 0.5821, decode.d8.loss_dice: 0.5606, loss: 12.9838, grad_norm: 645.0892
2023-08-29 15:47:50,358 - mmseg - INFO - Iter [6100/160000]	lr: 1.619e-06, eta: 1 day, 7:05:54, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0040, decode.loss_mask: 0.5549, decode.loss_dice: 0.5396, decode.d0.loss_cls: 1.3942, decode.d0.loss_mask: 0.5746, decode.d0.loss_dice: 0.6181, decode.d1.loss_cls: 0.0085, decode.d1.loss_mask: 0.5399, decode.d1.loss_dice: 0.5470, decode.d2.loss_cls: 0.0060, decode.d2.loss_mask: 0.5432, decode.d2.loss_dice: 0.5369, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.5483, decode.d3.loss_dice: 0.5381, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.5456, decode.d4.loss_dice: 0.5352, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.5471, decode.d5.loss_dice: 0.5352, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.5523, decode.d6.loss_dice: 0.5385, decode.d7.loss_cls: 0.0044, decode.d7.loss_mask: 0.5531, decode.d7.loss_dice: 0.5383, decode.d8.loss_cls: 0.0040, decode.d8.loss_mask: 0.5521, decode.d8.loss_dice: 0.5394, loss: 12.4177, grad_norm: 523.2099
2023-08-29 15:48:27,632 - mmseg - INFO - Iter [6150/160000]	lr: 1.619e-06, eta: 1 day, 7:05:40, time: 0.746, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0096, decode.loss_mask: 0.5136, decode.loss_dice: 0.5503, decode.d0.loss_cls: 1.3865, decode.d0.loss_mask: 0.5439, decode.d0.loss_dice: 0.6293, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.5168, decode.d1.loss_dice: 0.5589, decode.d2.loss_cls: 0.0194, decode.d2.loss_mask: 0.5065, decode.d2.loss_dice: 0.5483, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.5074, decode.d3.loss_dice: 0.5443, decode.d4.loss_cls: 0.0172, decode.d4.loss_mask: 0.5071, decode.d4.loss_dice: 0.5438, decode.d5.loss_cls: 0.0167, decode.d5.loss_mask: 0.5072, decode.d5.loss_dice: 0.5434, decode.d6.loss_cls: 0.0113, decode.d6.loss_mask: 0.5111, decode.d6.loss_dice: 0.5458, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.5194, decode.d7.loss_dice: 0.5475, decode.d8.loss_cls: 0.0100, decode.d8.loss_mask: 0.5145, decode.d8.loss_dice: 0.5512, loss: 12.2214, grad_norm: 477.0520
2023-08-29 15:49:02,586 - mmseg - INFO - Iter [6200/160000]	lr: 1.618e-06, eta: 1 day, 7:04:28, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0160, decode.loss_mask: 0.5278, decode.loss_dice: 0.5114, decode.d0.loss_cls: 1.3746, decode.d0.loss_mask: 0.5559, decode.d0.loss_dice: 0.5830, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.5298, decode.d1.loss_dice: 0.5142, decode.d2.loss_cls: 0.0188, decode.d2.loss_mask: 0.5249, decode.d2.loss_dice: 0.5090, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.5246, decode.d3.loss_dice: 0.5106, decode.d4.loss_cls: 0.0181, decode.d4.loss_mask: 0.5253, decode.d4.loss_dice: 0.5066, decode.d5.loss_cls: 0.0179, decode.d5.loss_mask: 0.5278, decode.d5.loss_dice: 0.5065, decode.d6.loss_cls: 0.0172, decode.d6.loss_mask: 0.5247, decode.d6.loss_dice: 0.5086, decode.d7.loss_cls: 0.0184, decode.d7.loss_mask: 0.5245, decode.d7.loss_dice: 0.5099, decode.d8.loss_cls: 0.0160, decode.d8.loss_mask: 0.5235, decode.d8.loss_dice: 0.5130, loss: 11.9955, grad_norm: 426.7792
2023-08-29 15:49:39,185 - mmseg - INFO - Iter [6250/160000]	lr: 1.617e-06, eta: 1 day, 7:03:57, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.5846, decode.loss_dice: 0.5680, decode.d0.loss_cls: 1.3672, decode.d0.loss_mask: 0.6159, decode.d0.loss_dice: 0.6620, decode.d1.loss_cls: 0.0129, decode.d1.loss_mask: 0.5774, decode.d1.loss_dice: 0.5776, decode.d2.loss_cls: 0.0118, decode.d2.loss_mask: 0.5775, decode.d2.loss_dice: 0.5728, decode.d3.loss_cls: 0.0102, decode.d3.loss_mask: 0.5701, decode.d3.loss_dice: 0.5667, decode.d4.loss_cls: 0.0097, decode.d4.loss_mask: 0.5715, decode.d4.loss_dice: 0.5632, decode.d5.loss_cls: 0.0094, decode.d5.loss_mask: 0.5700, decode.d5.loss_dice: 0.5678, decode.d6.loss_cls: 0.0087, decode.d6.loss_mask: 0.5748, decode.d6.loss_dice: 0.5668, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.5821, decode.d7.loss_dice: 0.5709, decode.d8.loss_cls: 0.0078, decode.d8.loss_mask: 0.5689, decode.d8.loss_dice: 0.5688, loss: 13.0210, grad_norm: 562.4203
2023-08-29 15:50:15,893 - mmseg - INFO - Iter [6300/160000]	lr: 1.617e-06, eta: 1 day, 7:03:30, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.5036, decode.loss_dice: 0.5235, decode.d0.loss_cls: 1.3566, decode.d0.loss_mask: 0.5501, decode.d0.loss_dice: 0.6057, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.5061, decode.d1.loss_dice: 0.5307, decode.d2.loss_cls: 0.0046, decode.d2.loss_mask: 0.5033, decode.d2.loss_dice: 0.5279, decode.d3.loss_cls: 0.0032, decode.d3.loss_mask: 0.4975, decode.d3.loss_dice: 0.5195, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.5027, decode.d4.loss_dice: 0.5243, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.5000, decode.d5.loss_dice: 0.5255, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.5051, decode.d6.loss_dice: 0.5215, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.5046, decode.d7.loss_dice: 0.5214, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.5036, decode.d8.loss_dice: 0.5257, loss: 11.7904, grad_norm: 520.7159
2023-08-29 15:50:53,015 - mmseg - INFO - Iter [6350/160000]	lr: 1.616e-06, eta: 1 day, 7:03:11, time: 0.743, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.5255, decode.loss_dice: 0.5554, decode.d0.loss_cls: 1.3498, decode.d0.loss_mask: 0.5722, decode.d0.loss_dice: 0.6448, decode.d1.loss_cls: 0.0067, decode.d1.loss_mask: 0.5295, decode.d1.loss_dice: 0.5657, decode.d2.loss_cls: 0.0047, decode.d2.loss_mask: 0.5193, decode.d2.loss_dice: 0.5582, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.5212, decode.d3.loss_dice: 0.5561, decode.d4.loss_cls: 0.0030, decode.d4.loss_mask: 0.5233, decode.d4.loss_dice: 0.5566, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.5245, decode.d5.loss_dice: 0.5596, decode.d6.loss_cls: 0.0078, decode.d6.loss_mask: 0.5214, decode.d6.loss_dice: 0.5549, decode.d7.loss_cls: 0.0076, decode.d7.loss_mask: 0.5243, decode.d7.loss_dice: 0.5552, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.5260, decode.d8.loss_dice: 0.5589, loss: 12.3439, grad_norm: 550.9418
2023-08-29 15:51:27,893 - mmseg - INFO - Iter [6400/160000]	lr: 1.616e-06, eta: 1 day, 7:01:59, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0176, decode.loss_mask: 0.6129, decode.loss_dice: 0.6213, decode.d0.loss_cls: 1.3440, decode.d0.loss_mask: 0.6306, decode.d0.loss_dice: 0.6897, decode.d1.loss_cls: 0.0182, decode.d1.loss_mask: 0.6071, decode.d1.loss_dice: 0.6234, decode.d2.loss_cls: 0.0188, decode.d2.loss_mask: 0.5967, decode.d2.loss_dice: 0.6162, decode.d3.loss_cls: 0.0181, decode.d3.loss_mask: 0.6029, decode.d3.loss_dice: 0.6167, decode.d4.loss_cls: 0.0160, decode.d4.loss_mask: 0.6040, decode.d4.loss_dice: 0.6128, decode.d5.loss_cls: 0.0163, decode.d5.loss_mask: 0.6012, decode.d5.loss_dice: 0.6186, decode.d6.loss_cls: 0.0177, decode.d6.loss_mask: 0.6031, decode.d6.loss_dice: 0.6160, decode.d7.loss_cls: 0.0185, decode.d7.loss_mask: 0.6051, decode.d7.loss_dice: 0.6173, decode.d8.loss_cls: 0.0173, decode.d8.loss_mask: 0.6057, decode.d8.loss_dice: 0.6197, loss: 13.8235, grad_norm: 499.4790
2023-08-29 15:52:04,750 - mmseg - INFO - Iter [6450/160000]	lr: 1.615e-06, eta: 1 day, 7:01:34, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0261, decode.loss_mask: 0.5274, decode.loss_dice: 0.5341, decode.d0.loss_cls: 1.3337, decode.d0.loss_mask: 0.5485, decode.d0.loss_dice: 0.5969, decode.d1.loss_cls: 0.0264, decode.d1.loss_mask: 0.5223, decode.d1.loss_dice: 0.5393, decode.d2.loss_cls: 0.0279, decode.d2.loss_mask: 0.5245, decode.d2.loss_dice: 0.5344, decode.d3.loss_cls: 0.0240, decode.d3.loss_mask: 0.5286, decode.d3.loss_dice: 0.5314, decode.d4.loss_cls: 0.0238, decode.d4.loss_mask: 0.5425, decode.d4.loss_dice: 0.5265, decode.d5.loss_cls: 0.0203, decode.d5.loss_mask: 0.5419, decode.d5.loss_dice: 0.5309, decode.d6.loss_cls: 0.0162, decode.d6.loss_mask: 0.5418, decode.d6.loss_dice: 0.5350, decode.d7.loss_cls: 0.0218, decode.d7.loss_mask: 0.5391, decode.d7.loss_dice: 0.5320, decode.d8.loss_cls: 0.0261, decode.d8.loss_mask: 0.5266, decode.d8.loss_dice: 0.5284, loss: 12.2781, grad_norm: 523.1001
2023-08-29 15:52:41,199 - mmseg - INFO - Iter [6500/160000]	lr: 1.615e-06, eta: 1 day, 7:00:59, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0172, decode.loss_mask: 0.5250, decode.loss_dice: 0.5388, decode.d0.loss_cls: 1.3281, decode.d0.loss_mask: 0.5573, decode.d0.loss_dice: 0.6200, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.5361, decode.d1.loss_dice: 0.5583, decode.d2.loss_cls: 0.0095, decode.d2.loss_mask: 0.5357, decode.d2.loss_dice: 0.5495, decode.d3.loss_cls: 0.0082, decode.d3.loss_mask: 0.5363, decode.d3.loss_dice: 0.5434, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.5315, decode.d4.loss_dice: 0.5425, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.5438, decode.d5.loss_dice: 0.5539, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.5464, decode.d6.loss_dice: 0.5540, decode.d7.loss_cls: 0.0081, decode.d7.loss_mask: 0.5366, decode.d7.loss_dice: 0.5432, decode.d8.loss_cls: 0.0078, decode.d8.loss_mask: 0.5379, decode.d8.loss_dice: 0.5436, loss: 12.3381, grad_norm: 580.7286
2023-08-29 15:53:18,874 - mmseg - INFO - Iter [6550/160000]	lr: 1.614e-06, eta: 1 day, 7:00:54, time: 0.754, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0083, decode.loss_mask: 0.5449, decode.loss_dice: 0.5313, decode.d0.loss_cls: 1.3172, decode.d0.loss_mask: 0.5619, decode.d0.loss_dice: 0.5945, decode.d1.loss_cls: 0.0116, decode.d1.loss_mask: 0.5402, decode.d1.loss_dice: 0.5346, decode.d2.loss_cls: 0.0103, decode.d2.loss_mask: 0.5427, decode.d2.loss_dice: 0.5328, decode.d3.loss_cls: 0.0089, decode.d3.loss_mask: 0.5397, decode.d3.loss_dice: 0.5300, decode.d4.loss_cls: 0.0086, decode.d4.loss_mask: 0.5413, decode.d4.loss_dice: 0.5289, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.5481, decode.d5.loss_dice: 0.5349, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.5533, decode.d6.loss_dice: 0.5360, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.5537, decode.d7.loss_dice: 0.5364, decode.d8.loss_cls: 0.0084, decode.d8.loss_mask: 0.5434, decode.d8.loss_dice: 0.5317, loss: 12.2409, grad_norm: 483.1275
2023-08-29 15:53:53,840 - mmseg - INFO - Iter [6600/160000]	lr: 1.614e-06, eta: 1 day, 6:59:44, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0180, decode.loss_mask: 0.5370, decode.loss_dice: 0.5383, decode.d0.loss_cls: 1.3092, decode.d0.loss_mask: 0.5772, decode.d0.loss_dice: 0.6350, decode.d1.loss_cls: 0.0213, decode.d1.loss_mask: 0.5449, decode.d1.loss_dice: 0.5533, decode.d2.loss_cls: 0.0208, decode.d2.loss_mask: 0.5353, decode.d2.loss_dice: 0.5380, decode.d3.loss_cls: 0.0183, decode.d3.loss_mask: 0.5343, decode.d3.loss_dice: 0.5328, decode.d4.loss_cls: 0.0215, decode.d4.loss_mask: 0.5345, decode.d4.loss_dice: 0.5320, decode.d5.loss_cls: 0.0209, decode.d5.loss_mask: 0.5328, decode.d5.loss_dice: 0.5322, decode.d6.loss_cls: 0.0166, decode.d6.loss_mask: 0.5359, decode.d6.loss_dice: 0.5330, decode.d7.loss_cls: 0.0189, decode.d7.loss_mask: 0.5366, decode.d7.loss_dice: 0.5313, decode.d8.loss_cls: 0.0184, decode.d8.loss_mask: 0.5367, decode.d8.loss_dice: 0.5322, loss: 12.3471, grad_norm: 536.8288
2023-08-29 15:54:30,951 - mmseg - INFO - Iter [6650/160000]	lr: 1.613e-06, eta: 1 day, 6:59:25, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0036, decode.loss_mask: 0.5304, decode.loss_dice: 0.5198, decode.d0.loss_cls: 1.3004, decode.d0.loss_mask: 0.5545, decode.d0.loss_dice: 0.5915, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.5399, decode.d1.loss_dice: 0.5289, decode.d2.loss_cls: 0.0052, decode.d2.loss_mask: 0.5348, decode.d2.loss_dice: 0.5259, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.5304, decode.d3.loss_dice: 0.5214, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.5296, decode.d4.loss_dice: 0.5219, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.5314, decode.d5.loss_dice: 0.5239, decode.d6.loss_cls: 0.0037, decode.d6.loss_mask: 0.5279, decode.d6.loss_dice: 0.5248, decode.d7.loss_cls: 0.0034, decode.d7.loss_mask: 0.5311, decode.d7.loss_dice: 0.5209, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.5317, decode.d8.loss_dice: 0.5242, loss: 11.9837, grad_norm: 607.6139
2023-08-29 15:55:07,310 - mmseg - INFO - Iter [6700/160000]	lr: 1.613e-06, eta: 1 day, 6:58:48, time: 0.727, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0255, decode.loss_mask: 0.5630, decode.loss_dice: 0.5617, decode.d0.loss_cls: 1.2978, decode.d0.loss_mask: 0.6003, decode.d0.loss_dice: 0.6336, decode.d1.loss_cls: 0.0239, decode.d1.loss_mask: 0.5841, decode.d1.loss_dice: 0.5757, decode.d2.loss_cls: 0.0253, decode.d2.loss_mask: 0.5648, decode.d2.loss_dice: 0.5661, decode.d3.loss_cls: 0.0233, decode.d3.loss_mask: 0.5638, decode.d3.loss_dice: 0.5617, decode.d4.loss_cls: 0.0225, decode.d4.loss_mask: 0.5611, decode.d4.loss_dice: 0.5564, decode.d5.loss_cls: 0.0214, decode.d5.loss_mask: 0.5630, decode.d5.loss_dice: 0.5604, decode.d6.loss_cls: 0.0212, decode.d6.loss_mask: 0.5612, decode.d6.loss_dice: 0.5542, decode.d7.loss_cls: 0.0235, decode.d7.loss_mask: 0.5608, decode.d7.loss_dice: 0.5571, decode.d8.loss_cls: 0.0241, decode.d8.loss_mask: 0.5644, decode.d8.loss_dice: 0.5649, loss: 12.8870, grad_norm: 506.2261
2023-08-29 15:55:44,391 - mmseg - INFO - Iter [6750/160000]	lr: 1.612e-06, eta: 1 day, 6:58:28, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0088, decode.loss_mask: 0.5463, decode.loss_dice: 0.5451, decode.d0.loss_cls: 1.2852, decode.d0.loss_mask: 0.5555, decode.d0.loss_dice: 0.5980, decode.d1.loss_cls: 0.0088, decode.d1.loss_mask: 0.5518, decode.d1.loss_dice: 0.5531, decode.d2.loss_cls: 0.0099, decode.d2.loss_mask: 0.5479, decode.d2.loss_dice: 0.5497, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.5529, decode.d3.loss_dice: 0.5491, decode.d4.loss_cls: 0.0071, decode.d4.loss_mask: 0.5517, decode.d4.loss_dice: 0.5496, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.5552, decode.d5.loss_dice: 0.5531, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.5539, decode.d6.loss_dice: 0.5514, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.5568, decode.d7.loss_dice: 0.5524, decode.d8.loss_cls: 0.0082, decode.d8.loss_mask: 0.5493, decode.d8.loss_dice: 0.5459, loss: 12.4068, grad_norm: 597.6635
2023-08-29 15:56:21,712 - mmseg - INFO - Iter [6800/160000]	lr: 1.612e-06, eta: 1 day, 6:58:13, time: 0.747, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.5043, decode.loss_dice: 0.5188, decode.d0.loss_cls: 1.2745, decode.d0.loss_mask: 0.5514, decode.d0.loss_dice: 0.6044, decode.d1.loss_cls: 0.0058, decode.d1.loss_mask: 0.5133, decode.d1.loss_dice: 0.5324, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.5072, decode.d2.loss_dice: 0.5205, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.5053, decode.d3.loss_dice: 0.5178, decode.d4.loss_cls: 0.0027, decode.d4.loss_mask: 0.5057, decode.d4.loss_dice: 0.5197, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.5013, decode.d5.loss_dice: 0.5198, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.5038, decode.d6.loss_dice: 0.5175, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.5057, decode.d7.loss_dice: 0.5201, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.5011, decode.d8.loss_dice: 0.5202, loss: 11.6935, grad_norm: 512.8990
2023-08-29 15:56:56,530 - mmseg - INFO - Iter [6850/160000]	lr: 1.611e-06, eta: 1 day, 6:57:01, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0037, decode.loss_mask: 0.5108, decode.loss_dice: 0.5108, decode.d0.loss_cls: 1.2674, decode.d0.loss_mask: 0.5411, decode.d0.loss_dice: 0.5880, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.5119, decode.d1.loss_dice: 0.5240, decode.d2.loss_cls: 0.0130, decode.d2.loss_mask: 0.5005, decode.d2.loss_dice: 0.5148, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.5079, decode.d3.loss_dice: 0.5134, decode.d4.loss_cls: 0.0040, decode.d4.loss_mask: 0.5114, decode.d4.loss_dice: 0.5146, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.5115, decode.d5.loss_dice: 0.5151, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.5141, decode.d6.loss_dice: 0.5115, decode.d7.loss_cls: 0.0038, decode.d7.loss_mask: 0.5162, decode.d7.loss_dice: 0.5123, decode.d8.loss_cls: 0.0036, decode.d8.loss_mask: 0.5158, decode.d8.loss_dice: 0.5132, loss: 11.6738, grad_norm: 550.0599
2023-08-29 15:57:32,912 - mmseg - INFO - Iter [6900/160000]	lr: 1.611e-06, eta: 1 day, 6:56:25, time: 0.728, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0219, decode.loss_mask: 0.5425, decode.loss_dice: 0.5490, decode.d0.loss_cls: 1.2605, decode.d0.loss_mask: 0.5743, decode.d0.loss_dice: 0.6222, decode.d1.loss_cls: 0.0173, decode.d1.loss_mask: 0.5523, decode.d1.loss_dice: 0.5598, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.5516, decode.d2.loss_dice: 0.5507, decode.d3.loss_cls: 0.0166, decode.d3.loss_mask: 0.5516, decode.d3.loss_dice: 0.5464, decode.d4.loss_cls: 0.0140, decode.d4.loss_mask: 0.5525, decode.d4.loss_dice: 0.5451, decode.d5.loss_cls: 0.0155, decode.d5.loss_mask: 0.5517, decode.d5.loss_dice: 0.5474, decode.d6.loss_cls: 0.0214, decode.d6.loss_mask: 0.5388, decode.d6.loss_dice: 0.5476, decode.d7.loss_cls: 0.0171, decode.d7.loss_mask: 0.5504, decode.d7.loss_dice: 0.5538, decode.d8.loss_cls: 0.0166, decode.d8.loss_mask: 0.5497, decode.d8.loss_dice: 0.5523, loss: 12.5100, grad_norm: 578.5367
2023-08-29 15:58:10,060 - mmseg - INFO - Iter [6950/160000]	lr: 1.610e-06, eta: 1 day, 6:56:06, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0148, decode.loss_mask: 0.5201, decode.loss_dice: 0.5180, decode.d0.loss_cls: 1.2526, decode.d0.loss_mask: 0.5384, decode.d0.loss_dice: 0.5875, decode.d1.loss_cls: 0.0172, decode.d1.loss_mask: 0.5168, decode.d1.loss_dice: 0.5289, decode.d2.loss_cls: 0.0183, decode.d2.loss_mask: 0.5115, decode.d2.loss_dice: 0.5165, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.5172, decode.d3.loss_dice: 0.5159, decode.d4.loss_cls: 0.0176, decode.d4.loss_mask: 0.5221, decode.d4.loss_dice: 0.5149, decode.d5.loss_cls: 0.0163, decode.d5.loss_mask: 0.5219, decode.d5.loss_dice: 0.5139, decode.d6.loss_cls: 0.0160, decode.d6.loss_mask: 0.5244, decode.d6.loss_dice: 0.5144, decode.d7.loss_cls: 0.0180, decode.d7.loss_mask: 0.5217, decode.d7.loss_dice: 0.5184, decode.d8.loss_cls: 0.0152, decode.d8.loss_mask: 0.5209, decode.d8.loss_dice: 0.5179, loss: 11.8646, grad_norm: 598.0242
2023-08-29 15:58:47,335 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-08-29 15:58:49,575 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 15:58:49,575 - mmseg - INFO - Iter [7000/160000]	lr: 1.610e-06, eta: 1 day, 6:56:38, time: 0.790, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.5600, decode.loss_dice: 0.6203, decode.d0.loss_cls: 1.2454, decode.d0.loss_mask: 0.5815, decode.d0.loss_dice: 0.6840, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.5602, decode.d1.loss_dice: 0.6254, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.5573, decode.d2.loss_dice: 0.6220, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.5626, decode.d3.loss_dice: 0.6205, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5660, decode.d4.loss_dice: 0.6201, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.5587, decode.d5.loss_dice: 0.6236, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.5589, decode.d6.loss_dice: 0.6154, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.5592, decode.d7.loss_dice: 0.6141, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.5623, decode.d8.loss_dice: 0.6202, loss: 13.1661, grad_norm: 589.1909
2023-08-29 15:59:24,431 - mmseg - INFO - Iter [7050/160000]	lr: 1.609e-06, eta: 1 day, 6:55:28, time: 0.697, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0166, decode.loss_mask: 0.5501, decode.loss_dice: 0.5799, decode.d0.loss_cls: 1.2405, decode.d0.loss_mask: 0.5867, decode.d0.loss_dice: 0.6478, decode.d1.loss_cls: 0.0224, decode.d1.loss_mask: 0.5503, decode.d1.loss_dice: 0.5857, decode.d2.loss_cls: 0.0178, decode.d2.loss_mask: 0.5382, decode.d2.loss_dice: 0.5768, decode.d3.loss_cls: 0.0156, decode.d3.loss_mask: 0.5436, decode.d3.loss_dice: 0.5731, decode.d4.loss_cls: 0.0141, decode.d4.loss_mask: 0.5408, decode.d4.loss_dice: 0.5751, decode.d5.loss_cls: 0.0156, decode.d5.loss_mask: 0.5453, decode.d5.loss_dice: 0.5712, decode.d6.loss_cls: 0.0169, decode.d6.loss_mask: 0.5401, decode.d6.loss_dice: 0.5784, decode.d7.loss_cls: 0.0174, decode.d7.loss_mask: 0.5394, decode.d7.loss_dice: 0.5738, decode.d8.loss_cls: 0.0167, decode.d8.loss_mask: 0.5384, decode.d8.loss_dice: 0.5739, loss: 12.7020, grad_norm: 516.1170
2023-08-29 16:00:00,978 - mmseg - INFO - Iter [7100/160000]	lr: 1.609e-06, eta: 1 day, 6:54:55, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.5403, decode.loss_dice: 0.5473, decode.d0.loss_cls: 1.2315, decode.d0.loss_mask: 0.5832, decode.d0.loss_dice: 0.6186, decode.d1.loss_cls: 0.0047, decode.d1.loss_mask: 0.5467, decode.d1.loss_dice: 0.5477, decode.d2.loss_cls: 0.0041, decode.d2.loss_mask: 0.5371, decode.d2.loss_dice: 0.5496, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.5430, decode.d3.loss_dice: 0.5442, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.5478, decode.d4.loss_dice: 0.5374, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.5508, decode.d5.loss_dice: 0.5414, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.5510, decode.d6.loss_dice: 0.5447, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.5433, decode.d7.loss_dice: 0.5468, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.5454, decode.d8.loss_dice: 0.5452, loss: 12.2672, grad_norm: 571.0971
2023-08-29 16:00:37,947 - mmseg - INFO - Iter [7150/160000]	lr: 1.608e-06, eta: 1 day, 6:54:30, time: 0.739, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.5126, decode.loss_dice: 0.5295, decode.d0.loss_cls: 1.2216, decode.d0.loss_mask: 0.5092, decode.d0.loss_dice: 0.5854, decode.d1.loss_cls: 0.0178, decode.d1.loss_mask: 0.4951, decode.d1.loss_dice: 0.5296, decode.d2.loss_cls: 0.0110, decode.d2.loss_mask: 0.5021, decode.d2.loss_dice: 0.5269, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.5238, decode.d3.loss_dice: 0.5234, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.5209, decode.d4.loss_dice: 0.5209, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.5166, decode.d5.loss_dice: 0.5244, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.5156, decode.d6.loss_dice: 0.5234, decode.d7.loss_cls: 0.0079, decode.d7.loss_mask: 0.5095, decode.d7.loss_dice: 0.5230, decode.d8.loss_cls: 0.0077, decode.d8.loss_mask: 0.5098, decode.d8.loss_dice: 0.5251, loss: 11.7068, grad_norm: 444.3140
2023-08-29 16:01:15,320 - mmseg - INFO - Iter [7200/160000]	lr: 1.607e-06, eta: 1 day, 6:54:15, time: 0.748, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0149, decode.loss_mask: 0.6160, decode.loss_dice: 0.5569, decode.d0.loss_cls: 1.2142, decode.d0.loss_mask: 0.5928, decode.d0.loss_dice: 0.6193, decode.d1.loss_cls: 0.0229, decode.d1.loss_mask: 0.6015, decode.d1.loss_dice: 0.5628, decode.d2.loss_cls: 0.0230, decode.d2.loss_mask: 0.5982, decode.d2.loss_dice: 0.5601, decode.d3.loss_cls: 0.0150, decode.d3.loss_mask: 0.6077, decode.d3.loss_dice: 0.5574, decode.d4.loss_cls: 0.0158, decode.d4.loss_mask: 0.6085, decode.d4.loss_dice: 0.5594, decode.d5.loss_cls: 0.0176, decode.d5.loss_mask: 0.6014, decode.d5.loss_dice: 0.5575, decode.d6.loss_cls: 0.0174, decode.d6.loss_mask: 0.6030, decode.d6.loss_dice: 0.5582, decode.d7.loss_cls: 0.0181, decode.d7.loss_mask: 0.6273, decode.d7.loss_dice: 0.5551, decode.d8.loss_cls: 0.0149, decode.d8.loss_mask: 0.6144, decode.d8.loss_dice: 0.5570, loss: 13.0885, grad_norm: 498.8980
2023-08-29 16:01:50,418 - mmseg - INFO - Iter [7250/160000]	lr: 1.607e-06, eta: 1 day, 6:53:11, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0212, decode.loss_mask: 0.4770, decode.loss_dice: 0.5343, decode.d0.loss_cls: 1.2055, decode.d0.loss_mask: 0.5179, decode.d0.loss_dice: 0.5811, decode.d1.loss_cls: 0.0191, decode.d1.loss_mask: 0.4918, decode.d1.loss_dice: 0.5323, decode.d2.loss_cls: 0.0170, decode.d2.loss_mask: 0.4839, decode.d2.loss_dice: 0.5256, decode.d3.loss_cls: 0.0155, decode.d3.loss_mask: 0.4837, decode.d3.loss_dice: 0.5225, decode.d4.loss_cls: 0.0171, decode.d4.loss_mask: 0.4791, decode.d4.loss_dice: 0.5233, decode.d5.loss_cls: 0.0180, decode.d5.loss_mask: 0.4773, decode.d5.loss_dice: 0.5251, decode.d6.loss_cls: 0.0197, decode.d6.loss_mask: 0.4823, decode.d6.loss_dice: 0.5241, decode.d7.loss_cls: 0.0196, decode.d7.loss_mask: 0.4811, decode.d7.loss_dice: 0.5185, decode.d8.loss_cls: 0.0193, decode.d8.loss_mask: 0.4803, decode.d8.loss_dice: 0.5299, loss: 11.5429, grad_norm: 478.8240
2023-08-29 16:02:27,001 - mmseg - INFO - Iter [7300/160000]	lr: 1.606e-06, eta: 1 day, 6:52:38, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.5739, decode.loss_dice: 0.5375, decode.d0.loss_cls: 1.1971, decode.d0.loss_mask: 0.5957, decode.d0.loss_dice: 0.5932, decode.d1.loss_cls: 0.0125, decode.d1.loss_mask: 0.5605, decode.d1.loss_dice: 0.5370, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.5668, decode.d2.loss_dice: 0.5340, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.5710, decode.d3.loss_dice: 0.5337, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.5716, decode.d4.loss_dice: 0.5311, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.5761, decode.d5.loss_dice: 0.5352, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.5793, decode.d6.loss_dice: 0.5333, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.5752, decode.d7.loss_dice: 0.5334, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.5744, decode.d8.loss_dice: 0.5389, loss: 12.3876, grad_norm: 514.3201
2023-08-29 16:03:04,123 - mmseg - INFO - Iter [7350/160000]	lr: 1.606e-06, eta: 1 day, 6:52:17, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.5578, decode.loss_dice: 0.5472, decode.d0.loss_cls: 1.1880, decode.d0.loss_mask: 0.5431, decode.d0.loss_dice: 0.5846, decode.d1.loss_cls: 0.0121, decode.d1.loss_mask: 0.5439, decode.d1.loss_dice: 0.5479, decode.d2.loss_cls: 0.0106, decode.d2.loss_mask: 0.5417, decode.d2.loss_dice: 0.5426, decode.d3.loss_cls: 0.0097, decode.d3.loss_mask: 0.5355, decode.d3.loss_dice: 0.5437, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.5587, decode.d4.loss_dice: 0.5453, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.5592, decode.d5.loss_dice: 0.5443, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.5613, decode.d6.loss_dice: 0.5477, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.5603, decode.d7.loss_dice: 0.5462, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.5574, decode.d8.loss_dice: 0.5459, loss: 12.2518, grad_norm: 532.3874
2023-08-29 16:03:41,437 - mmseg - INFO - Iter [7400/160000]	lr: 1.605e-06, eta: 1 day, 6:51:59, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.5140, decode.loss_dice: 0.5087, decode.d0.loss_cls: 1.1815, decode.d0.loss_mask: 0.5156, decode.d0.loss_dice: 0.5595, decode.d1.loss_cls: 0.0108, decode.d1.loss_mask: 0.4993, decode.d1.loss_dice: 0.4994, decode.d2.loss_cls: 0.0088, decode.d2.loss_mask: 0.4957, decode.d2.loss_dice: 0.4965, decode.d3.loss_cls: 0.0070, decode.d3.loss_mask: 0.4971, decode.d3.loss_dice: 0.4949, decode.d4.loss_cls: 0.0138, decode.d4.loss_mask: 0.4902, decode.d4.loss_dice: 0.4932, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.5055, decode.d5.loss_dice: 0.5024, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.5115, decode.d6.loss_dice: 0.5008, decode.d7.loss_cls: 0.0149, decode.d7.loss_mask: 0.4931, decode.d7.loss_dice: 0.4921, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.5094, decode.d8.loss_dice: 0.5022, loss: 11.3233, grad_norm: 651.2203
2023-08-29 16:04:16,045 - mmseg - INFO - Iter [7450/160000]	lr: 1.605e-06, eta: 1 day, 6:50:46, time: 0.692, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0072, decode.loss_mask: 0.4625, decode.loss_dice: 0.4798, decode.d0.loss_cls: 1.1745, decode.d0.loss_mask: 0.4987, decode.d0.loss_dice: 0.5584, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.4626, decode.d1.loss_dice: 0.4913, decode.d2.loss_cls: 0.0037, decode.d2.loss_mask: 0.4563, decode.d2.loss_dice: 0.4863, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 0.4514, decode.d3.loss_dice: 0.4790, decode.d4.loss_cls: 0.0090, decode.d4.loss_mask: 0.4503, decode.d4.loss_dice: 0.4752, decode.d5.loss_cls: 0.0088, decode.d5.loss_mask: 0.4551, decode.d5.loss_dice: 0.4787, decode.d6.loss_cls: 0.0091, decode.d6.loss_mask: 0.4537, decode.d6.loss_dice: 0.4796, decode.d7.loss_cls: 0.0091, decode.d7.loss_mask: 0.4538, decode.d7.loss_dice: 0.4793, decode.d8.loss_cls: 0.0074, decode.d8.loss_mask: 0.4602, decode.d8.loss_dice: 0.4799, loss: 10.7389, grad_norm: 545.3667
2023-08-29 16:04:52,469 - mmseg - INFO - Iter [7500/160000]	lr: 1.604e-06, eta: 1 day, 6:50:10, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0263, decode.loss_mask: 0.5073, decode.loss_dice: 0.5050, decode.d0.loss_cls: 1.1688, decode.d0.loss_mask: 0.5192, decode.d0.loss_dice: 0.5643, decode.d1.loss_cls: 0.0246, decode.d1.loss_mask: 0.5070, decode.d1.loss_dice: 0.5088, decode.d2.loss_cls: 0.0195, decode.d2.loss_mask: 0.5140, decode.d2.loss_dice: 0.5055, decode.d3.loss_cls: 0.0184, decode.d3.loss_mask: 0.5130, decode.d3.loss_dice: 0.5043, decode.d4.loss_cls: 0.0194, decode.d4.loss_mask: 0.5129, decode.d4.loss_dice: 0.5000, decode.d5.loss_cls: 0.0202, decode.d5.loss_mask: 0.5161, decode.d5.loss_dice: 0.4997, decode.d6.loss_cls: 0.0198, decode.d6.loss_mask: 0.5111, decode.d6.loss_dice: 0.5005, decode.d7.loss_cls: 0.0185, decode.d7.loss_mask: 0.5164, decode.d7.loss_dice: 0.4975, decode.d8.loss_cls: 0.0270, decode.d8.loss_mask: 0.5071, decode.d8.loss_dice: 0.4995, loss: 11.5718, grad_norm: 634.6382
2023-08-29 16:05:29,451 - mmseg - INFO - Iter [7550/160000]	lr: 1.604e-06, eta: 1 day, 6:49:46, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.5241, decode.loss_dice: 0.5075, decode.d0.loss_cls: 1.1597, decode.d0.loss_mask: 0.5637, decode.d0.loss_dice: 0.5729, decode.d1.loss_cls: 0.0054, decode.d1.loss_mask: 0.5303, decode.d1.loss_dice: 0.5184, decode.d2.loss_cls: 0.0039, decode.d2.loss_mask: 0.5246, decode.d2.loss_dice: 0.5119, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.5238, decode.d3.loss_dice: 0.5069, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.5237, decode.d4.loss_dice: 0.5080, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.5255, decode.d5.loss_dice: 0.5073, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.5282, decode.d6.loss_dice: 0.5087, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.5240, decode.d7.loss_dice: 0.5077, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.5295, decode.d8.loss_dice: 0.5064, loss: 11.6410, grad_norm: 571.3605
2023-08-29 16:06:06,545 - mmseg - INFO - Iter [7600/160000]	lr: 1.603e-06, eta: 1 day, 6:49:23, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4222, decode.loss_dice: 0.4520, decode.d0.loss_cls: 1.1514, decode.d0.loss_mask: 0.4522, decode.d0.loss_dice: 0.5020, decode.d1.loss_cls: 0.0055, decode.d1.loss_mask: 0.4251, decode.d1.loss_dice: 0.4585, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.4210, decode.d2.loss_dice: 0.4524, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.4232, decode.d3.loss_dice: 0.4476, decode.d4.loss_cls: 0.0028, decode.d4.loss_mask: 0.4223, decode.d4.loss_dice: 0.4505, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4212, decode.d5.loss_dice: 0.4514, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.4201, decode.d6.loss_dice: 0.4491, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.4179, decode.d7.loss_dice: 0.4479, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.4222, decode.d8.loss_dice: 0.4513, loss: 9.9909, grad_norm: 538.8456
2023-08-29 16:06:41,345 - mmseg - INFO - Iter [7650/160000]	lr: 1.603e-06, eta: 1 day, 6:48:15, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0141, decode.loss_mask: 0.4736, decode.loss_dice: 0.4783, decode.d0.loss_cls: 1.1443, decode.d0.loss_mask: 0.5021, decode.d0.loss_dice: 0.5616, decode.d1.loss_cls: 0.0160, decode.d1.loss_mask: 0.4747, decode.d1.loss_dice: 0.4869, decode.d2.loss_cls: 0.0163, decode.d2.loss_mask: 0.4712, decode.d2.loss_dice: 0.4809, decode.d3.loss_cls: 0.0150, decode.d3.loss_mask: 0.4683, decode.d3.loss_dice: 0.4764, decode.d4.loss_cls: 0.0158, decode.d4.loss_mask: 0.4688, decode.d4.loss_dice: 0.4760, decode.d5.loss_cls: 0.0148, decode.d5.loss_mask: 0.4713, decode.d5.loss_dice: 0.4771, decode.d6.loss_cls: 0.0153, decode.d6.loss_mask: 0.4763, decode.d6.loss_dice: 0.4800, decode.d7.loss_cls: 0.0158, decode.d7.loss_mask: 0.4723, decode.d7.loss_dice: 0.4802, decode.d8.loss_cls: 0.0149, decode.d8.loss_mask: 0.4740, decode.d8.loss_dice: 0.4801, loss: 10.9124, grad_norm: 489.5169
2023-08-29 16:07:17,627 - mmseg - INFO - Iter [7700/160000]	lr: 1.602e-06, eta: 1 day, 6:47:36, time: 0.726, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0093, decode.loss_mask: 0.5687, decode.loss_dice: 0.5544, decode.d0.loss_cls: 1.1365, decode.d0.loss_mask: 0.6182, decode.d0.loss_dice: 0.6193, decode.d1.loss_cls: 0.0176, decode.d1.loss_mask: 0.5723, decode.d1.loss_dice: 0.5625, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.5745, decode.d2.loss_dice: 0.5641, decode.d3.loss_cls: 0.0027, decode.d3.loss_mask: 0.5763, decode.d3.loss_dice: 0.5597, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.5735, decode.d4.loss_dice: 0.5555, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.5737, decode.d5.loss_dice: 0.5604, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.5787, decode.d6.loss_dice: 0.5578, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.5751, decode.d7.loss_dice: 0.5570, decode.d8.loss_cls: 0.0099, decode.d8.loss_mask: 0.5655, decode.d8.loss_dice: 0.5525, loss: 12.6090, grad_norm: 550.5551
2023-08-29 16:07:54,276 - mmseg - INFO - Iter [7750/160000]	lr: 1.602e-06, eta: 1 day, 6:47:05, time: 0.733, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.4749, decode.loss_dice: 0.4781, decode.d0.loss_cls: 1.1277, decode.d0.loss_mask: 0.5101, decode.d0.loss_dice: 0.5540, decode.d1.loss_cls: 0.0042, decode.d1.loss_mask: 0.4791, decode.d1.loss_dice: 0.4890, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.4686, decode.d2.loss_dice: 0.4839, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.4701, decode.d3.loss_dice: 0.4818, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.4718, decode.d4.loss_dice: 0.4809, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.4700, decode.d5.loss_dice: 0.4752, decode.d6.loss_cls: 0.0014, decode.d6.loss_mask: 0.4757, decode.d6.loss_dice: 0.4755, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.4777, decode.d7.loss_dice: 0.4789, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.4755, decode.d8.loss_dice: 0.4773, loss: 10.7927, grad_norm: 488.5095
2023-08-29 16:08:31,470 - mmseg - INFO - Iter [7800/160000]	lr: 1.601e-06, eta: 1 day, 6:46:44, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.4775, decode.loss_dice: 0.4855, decode.d0.loss_cls: 1.1215, decode.d0.loss_mask: 0.5059, decode.d0.loss_dice: 0.5550, decode.d1.loss_cls: 0.0051, decode.d1.loss_mask: 0.4784, decode.d1.loss_dice: 0.4954, decode.d2.loss_cls: 0.0037, decode.d2.loss_mask: 0.4740, decode.d2.loss_dice: 0.4911, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.4734, decode.d3.loss_dice: 0.4870, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4726, decode.d4.loss_dice: 0.4889, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.4785, decode.d5.loss_dice: 0.4879, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.4775, decode.d6.loss_dice: 0.4845, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.4789, decode.d7.loss_dice: 0.4871, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.4792, decode.d8.loss_dice: 0.4855, loss: 10.8926, grad_norm: 534.9810
2023-08-29 16:09:06,266 - mmseg - INFO - Iter [7850/160000]	lr: 1.601e-06, eta: 1 day, 6:45:36, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0176, decode.loss_mask: 0.5026, decode.loss_dice: 0.4970, decode.d0.loss_cls: 1.1164, decode.d0.loss_mask: 0.5244, decode.d0.loss_dice: 0.5560, decode.d1.loss_cls: 0.0238, decode.d1.loss_mask: 0.5013, decode.d1.loss_dice: 0.5019, decode.d2.loss_cls: 0.0187, decode.d2.loss_mask: 0.5162, decode.d2.loss_dice: 0.5029, decode.d3.loss_cls: 0.0235, decode.d3.loss_mask: 0.5037, decode.d3.loss_dice: 0.5001, decode.d4.loss_cls: 0.0244, decode.d4.loss_mask: 0.5004, decode.d4.loss_dice: 0.4977, decode.d5.loss_cls: 0.0253, decode.d5.loss_mask: 0.5035, decode.d5.loss_dice: 0.4987, decode.d6.loss_cls: 0.0246, decode.d6.loss_mask: 0.5043, decode.d6.loss_dice: 0.5001, decode.d7.loss_cls: 0.0248, decode.d7.loss_mask: 0.4995, decode.d7.loss_dice: 0.4999, decode.d8.loss_cls: 0.0187, decode.d8.loss_mask: 0.4982, decode.d8.loss_dice: 0.4964, loss: 11.4225, grad_norm: 485.1961
2023-08-29 16:09:42,750 - mmseg - INFO - Iter [7900/160000]	lr: 1.600e-06, eta: 1 day, 6:45:01, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0075, decode.loss_mask: 0.5297, decode.loss_dice: 0.5292, decode.d0.loss_cls: 1.1054, decode.d0.loss_mask: 0.5445, decode.d0.loss_dice: 0.5825, decode.d1.loss_cls: 0.0050, decode.d1.loss_mask: 0.5301, decode.d1.loss_dice: 0.5200, decode.d2.loss_cls: 0.0050, decode.d2.loss_mask: 0.5255, decode.d2.loss_dice: 0.5219, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.5275, decode.d3.loss_dice: 0.5204, decode.d4.loss_cls: 0.0107, decode.d4.loss_mask: 0.5210, decode.d4.loss_dice: 0.5213, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.5239, decode.d5.loss_dice: 0.5241, decode.d6.loss_cls: 0.0037, decode.d6.loss_mask: 0.5211, decode.d6.loss_dice: 0.5254, decode.d7.loss_cls: 0.0069, decode.d7.loss_mask: 0.5213, decode.d7.loss_dice: 0.5249, decode.d8.loss_cls: 0.0073, decode.d8.loss_mask: 0.5248, decode.d8.loss_dice: 0.5250, loss: 11.7223, grad_norm: 521.1239
2023-08-29 16:10:19,598 - mmseg - INFO - Iter [7950/160000]	lr: 1.600e-06, eta: 1 day, 6:44:34, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0095, decode.loss_mask: 0.5302, decode.loss_dice: 0.5299, decode.d0.loss_cls: 1.1011, decode.d0.loss_mask: 0.5663, decode.d0.loss_dice: 0.5979, decode.d1.loss_cls: 0.0052, decode.d1.loss_mask: 0.5420, decode.d1.loss_dice: 0.5253, decode.d2.loss_cls: 0.0038, decode.d2.loss_mask: 0.5346, decode.d2.loss_dice: 0.5214, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.5426, decode.d3.loss_dice: 0.5271, decode.d4.loss_cls: 0.0027, decode.d4.loss_mask: 0.5407, decode.d4.loss_dice: 0.5270, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.5415, decode.d5.loss_dice: 0.5284, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.5443, decode.d6.loss_dice: 0.5304, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.5393, decode.d7.loss_dice: 0.5292, decode.d8.loss_cls: 0.0100, decode.d8.loss_mask: 0.5273, decode.d8.loss_dice: 0.5260, loss: 11.8949, grad_norm: 626.8225
2023-08-29 16:10:56,704 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-08-29 16:10:59,096 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 16:10:59,096 - mmseg - INFO - Iter [8000/160000]	lr: 1.599e-06, eta: 1 day, 6:44:57, time: 0.790, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.4597, decode.loss_dice: 0.4803, decode.d0.loss_cls: 1.0924, decode.d0.loss_mask: 0.4871, decode.d0.loss_dice: 0.5375, decode.d1.loss_cls: 0.0042, decode.d1.loss_mask: 0.4655, decode.d1.loss_dice: 0.5007, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.4626, decode.d2.loss_dice: 0.4905, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.4604, decode.d3.loss_dice: 0.4791, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.4603, decode.d4.loss_dice: 0.4795, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.4626, decode.d5.loss_dice: 0.4782, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.4630, decode.d6.loss_dice: 0.4832, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.4632, decode.d7.loss_dice: 0.4816, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.4625, decode.d8.loss_dice: 0.4788, loss: 10.6472, grad_norm: 496.7041
2023-08-29 16:11:34,417 - mmseg - INFO - Iter [8050/160000]	lr: 1.599e-06, eta: 1 day, 6:44:00, time: 0.706, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0152, decode.loss_mask: 0.4668, decode.loss_dice: 0.4630, decode.d0.loss_cls: 1.0845, decode.d0.loss_mask: 0.5111, decode.d0.loss_dice: 0.5283, decode.d1.loss_cls: 0.0178, decode.d1.loss_mask: 0.4716, decode.d1.loss_dice: 0.4763, decode.d2.loss_cls: 0.0167, decode.d2.loss_mask: 0.4669, decode.d2.loss_dice: 0.4693, decode.d3.loss_cls: 0.0165, decode.d3.loss_mask: 0.4654, decode.d3.loss_dice: 0.4642, decode.d4.loss_cls: 0.0174, decode.d4.loss_mask: 0.4607, decode.d4.loss_dice: 0.4627, decode.d5.loss_cls: 0.0175, decode.d5.loss_mask: 0.4642, decode.d5.loss_dice: 0.4653, decode.d6.loss_cls: 0.0176, decode.d6.loss_mask: 0.4627, decode.d6.loss_dice: 0.4623, decode.d7.loss_cls: 0.0177, decode.d7.loss_mask: 0.4642, decode.d7.loss_dice: 0.4657, decode.d8.loss_cls: 0.0129, decode.d8.loss_mask: 0.4710, decode.d8.loss_dice: 0.4647, loss: 10.6603, grad_norm: 446.4208
2023-08-29 16:12:11,390 - mmseg - INFO - Iter [8100/160000]	lr: 1.598e-06, eta: 1 day, 6:43:34, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.4746, decode.loss_dice: 0.4928, decode.d0.loss_cls: 1.0801, decode.d0.loss_mask: 0.5022, decode.d0.loss_dice: 0.5562, decode.d1.loss_cls: 0.0049, decode.d1.loss_mask: 0.4810, decode.d1.loss_dice: 0.5001, decode.d2.loss_cls: 0.0037, decode.d2.loss_mask: 0.4723, decode.d2.loss_dice: 0.4928, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.4736, decode.d3.loss_dice: 0.4904, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4749, decode.d4.loss_dice: 0.4935, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.4758, decode.d5.loss_dice: 0.4936, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.4756, decode.d6.loss_dice: 0.4922, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4766, decode.d7.loss_dice: 0.4922, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.4763, decode.d8.loss_dice: 0.4972, loss: 10.8894, grad_norm: 526.1792
2023-08-29 16:12:47,752 - mmseg - INFO - Iter [8150/160000]	lr: 1.598e-06, eta: 1 day, 6:42:56, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0310, decode.loss_mask: 0.5076, decode.loss_dice: 0.4842, decode.d0.loss_cls: 1.0704, decode.d0.loss_mask: 0.5423, decode.d0.loss_dice: 0.5466, decode.d1.loss_cls: 0.0323, decode.d1.loss_mask: 0.5151, decode.d1.loss_dice: 0.4935, decode.d2.loss_cls: 0.0330, decode.d2.loss_mask: 0.5024, decode.d2.loss_dice: 0.4814, decode.d3.loss_cls: 0.0307, decode.d3.loss_mask: 0.5030, decode.d3.loss_dice: 0.4844, decode.d4.loss_cls: 0.0330, decode.d4.loss_mask: 0.5114, decode.d4.loss_dice: 0.4840, decode.d5.loss_cls: 0.0330, decode.d5.loss_mask: 0.5063, decode.d5.loss_dice: 0.4805, decode.d6.loss_cls: 0.0338, decode.d6.loss_mask: 0.5019, decode.d6.loss_dice: 0.4820, decode.d7.loss_cls: 0.0329, decode.d7.loss_mask: 0.5061, decode.d7.loss_dice: 0.4803, decode.d8.loss_cls: 0.0324, decode.d8.loss_mask: 0.5042, decode.d8.loss_dice: 0.4824, loss: 11.3620, grad_norm: 389.2226
2023-08-29 16:13:25,143 - mmseg - INFO - Iter [8200/160000]	lr: 1.597e-06, eta: 1 day, 6:42:38, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0182, decode.loss_mask: 0.4869, decode.loss_dice: 0.5026, decode.d0.loss_cls: 1.0649, decode.d0.loss_mask: 0.5116, decode.d0.loss_dice: 0.5539, decode.d1.loss_cls: 0.0186, decode.d1.loss_mask: 0.4930, decode.d1.loss_dice: 0.5082, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.4877, decode.d2.loss_dice: 0.5070, decode.d3.loss_cls: 0.0166, decode.d3.loss_mask: 0.4800, decode.d3.loss_dice: 0.5121, decode.d4.loss_cls: 0.0167, decode.d4.loss_mask: 0.4835, decode.d4.loss_dice: 0.5130, decode.d5.loss_cls: 0.0168, decode.d5.loss_mask: 0.4867, decode.d5.loss_dice: 0.5094, decode.d6.loss_cls: 0.0184, decode.d6.loss_mask: 0.4889, decode.d6.loss_dice: 0.5149, decode.d7.loss_cls: 0.0182, decode.d7.loss_mask: 0.4874, decode.d7.loss_dice: 0.5106, decode.d8.loss_cls: 0.0187, decode.d8.loss_mask: 0.4881, decode.d8.loss_dice: 0.5091, loss: 11.2609, grad_norm: 496.9179
2023-08-29 16:14:00,194 - mmseg - INFO - Iter [8250/160000]	lr: 1.596e-06, eta: 1 day, 6:41:37, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0154, decode.loss_mask: 0.4972, decode.loss_dice: 0.5031, decode.d0.loss_cls: 1.0554, decode.d0.loss_mask: 0.4929, decode.d0.loss_dice: 0.5475, decode.d1.loss_cls: 0.0221, decode.d1.loss_mask: 0.4933, decode.d1.loss_dice: 0.5062, decode.d2.loss_cls: 0.0230, decode.d2.loss_mask: 0.4885, decode.d2.loss_dice: 0.5043, decode.d3.loss_cls: 0.0144, decode.d3.loss_mask: 0.5029, decode.d3.loss_dice: 0.5064, decode.d4.loss_cls: 0.0209, decode.d4.loss_mask: 0.4965, decode.d4.loss_dice: 0.5079, decode.d5.loss_cls: 0.0198, decode.d5.loss_mask: 0.4890, decode.d5.loss_dice: 0.4972, decode.d6.loss_cls: 0.0214, decode.d6.loss_mask: 0.4948, decode.d6.loss_dice: 0.5026, decode.d7.loss_cls: 0.0192, decode.d7.loss_mask: 0.4938, decode.d7.loss_dice: 0.5034, decode.d8.loss_cls: 0.0189, decode.d8.loss_mask: 0.4948, decode.d8.loss_dice: 0.5076, loss: 11.2603, grad_norm: 493.3063
2023-08-29 16:14:37,179 - mmseg - INFO - Iter [8300/160000]	lr: 1.596e-06, eta: 1 day, 6:41:11, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.4805, decode.loss_dice: 0.4786, decode.d0.loss_cls: 1.0494, decode.d0.loss_mask: 0.5114, decode.d0.loss_dice: 0.5342, decode.d1.loss_cls: 0.0057, decode.d1.loss_mask: 0.4996, decode.d1.loss_dice: 0.4856, decode.d2.loss_cls: 0.0052, decode.d2.loss_mask: 0.4920, decode.d2.loss_dice: 0.4791, decode.d3.loss_cls: 0.0042, decode.d3.loss_mask: 0.4898, decode.d3.loss_dice: 0.4764, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.4915, decode.d4.loss_dice: 0.4769, decode.d5.loss_cls: 0.0040, decode.d5.loss_mask: 0.4882, decode.d5.loss_dice: 0.4785, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.4826, decode.d6.loss_dice: 0.4754, decode.d7.loss_cls: 0.0040, decode.d7.loss_mask: 0.4837, decode.d7.loss_dice: 0.4777, decode.d8.loss_cls: 0.0039, decode.d8.loss_mask: 0.4817, decode.d8.loss_dice: 0.4781, loss: 10.8299, grad_norm: 484.7576
2023-08-29 16:15:13,703 - mmseg - INFO - Iter [8350/160000]	lr: 1.595e-06, eta: 1 day, 6:40:36, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0161, decode.loss_mask: 0.5214, decode.loss_dice: 0.5143, decode.d0.loss_cls: 1.0395, decode.d0.loss_mask: 0.5360, decode.d0.loss_dice: 0.5566, decode.d1.loss_cls: 0.0183, decode.d1.loss_mask: 0.5261, decode.d1.loss_dice: 0.5153, decode.d2.loss_cls: 0.0189, decode.d2.loss_mask: 0.5210, decode.d2.loss_dice: 0.5109, decode.d3.loss_cls: 0.0150, decode.d3.loss_mask: 0.5178, decode.d3.loss_dice: 0.5096, decode.d4.loss_cls: 0.0165, decode.d4.loss_mask: 0.5221, decode.d4.loss_dice: 0.5115, decode.d5.loss_cls: 0.0170, decode.d5.loss_mask: 0.5202, decode.d5.loss_dice: 0.5109, decode.d6.loss_cls: 0.0174, decode.d6.loss_mask: 0.5173, decode.d6.loss_dice: 0.5128, decode.d7.loss_cls: 0.0180, decode.d7.loss_mask: 0.5155, decode.d7.loss_dice: 0.5127, decode.d8.loss_cls: 0.0165, decode.d8.loss_mask: 0.5185, decode.d8.loss_dice: 0.5155, loss: 11.5792, grad_norm: 535.1607
2023-08-29 16:15:50,821 - mmseg - INFO - Iter [8400/160000]	lr: 1.595e-06, eta: 1 day, 6:40:13, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4349, decode.loss_dice: 0.4508, decode.d0.loss_cls: 1.0321, decode.d0.loss_mask: 0.4645, decode.d0.loss_dice: 0.5061, decode.d1.loss_cls: 0.0045, decode.d1.loss_mask: 0.4473, decode.d1.loss_dice: 0.4615, decode.d2.loss_cls: 0.0039, decode.d2.loss_mask: 0.4380, decode.d2.loss_dice: 0.4543, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.4353, decode.d3.loss_dice: 0.4475, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.4376, decode.d4.loss_dice: 0.4452, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.4346, decode.d5.loss_dice: 0.4452, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.4339, decode.d6.loss_dice: 0.4507, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.4356, decode.d7.loss_dice: 0.4516, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.4314, decode.d8.loss_dice: 0.4487, loss: 10.0150, grad_norm: 429.5236
2023-08-29 16:16:28,128 - mmseg - INFO - Iter [8450/160000]	lr: 1.594e-06, eta: 1 day, 6:39:52, time: 0.746, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0016, decode.loss_mask: 0.4611, decode.loss_dice: 0.4635, decode.d0.loss_cls: 1.0239, decode.d0.loss_mask: 0.4972, decode.d0.loss_dice: 0.5226, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4639, decode.d1.loss_dice: 0.4714, decode.d2.loss_cls: 0.0068, decode.d2.loss_mask: 0.4581, decode.d2.loss_dice: 0.4659, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.4630, decode.d3.loss_dice: 0.4697, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4643, decode.d4.loss_dice: 0.4651, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.4646, decode.d5.loss_dice: 0.4681, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.4619, decode.d6.loss_dice: 0.4637, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.4586, decode.d7.loss_dice: 0.4636, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.4607, decode.d8.loss_dice: 0.4656, loss: 10.4199, grad_norm: 412.2104
2023-08-29 16:17:03,016 - mmseg - INFO - Iter [8500/160000]	lr: 1.594e-06, eta: 1 day, 6:38:49, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.4867, decode.loss_dice: 0.5004, decode.d0.loss_cls: 1.0170, decode.d0.loss_mask: 0.5123, decode.d0.loss_dice: 0.5555, decode.d1.loss_cls: 0.0050, decode.d1.loss_mask: 0.4904, decode.d1.loss_dice: 0.5097, decode.d2.loss_cls: 0.0042, decode.d2.loss_mask: 0.4825, decode.d2.loss_dice: 0.5021, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.4825, decode.d3.loss_dice: 0.4993, decode.d4.loss_cls: 0.0032, decode.d4.loss_mask: 0.4884, decode.d4.loss_dice: 0.5037, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.4885, decode.d5.loss_dice: 0.5013, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.4879, decode.d6.loss_dice: 0.5005, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.4873, decode.d7.loss_dice: 0.4989, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.4916, decode.d8.loss_dice: 0.5023, loss: 11.0196, grad_norm: 473.9245
2023-08-29 16:17:39,411 - mmseg - INFO - Iter [8550/160000]	lr: 1.593e-06, eta: 1 day, 6:38:12, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.4260, decode.loss_dice: 0.4239, decode.d0.loss_cls: 1.0102, decode.d0.loss_mask: 0.4574, decode.d0.loss_dice: 0.4967, decode.d1.loss_cls: 0.0041, decode.d1.loss_mask: 0.4283, decode.d1.loss_dice: 0.4392, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.4261, decode.d2.loss_dice: 0.4303, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.4266, decode.d3.loss_dice: 0.4291, decode.d4.loss_cls: 0.0030, decode.d4.loss_mask: 0.4262, decode.d4.loss_dice: 0.4243, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.4272, decode.d5.loss_dice: 0.4271, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.4236, decode.d6.loss_dice: 0.4285, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.4250, decode.d7.loss_dice: 0.4275, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.4274, decode.d8.loss_dice: 0.4239, loss: 9.6813, grad_norm: 387.1572
2023-08-29 16:18:16,418 - mmseg - INFO - Iter [8600/160000]	lr: 1.593e-06, eta: 1 day, 6:37:46, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.4341, decode.loss_dice: 0.4384, decode.d0.loss_cls: 1.0025, decode.d0.loss_mask: 0.4565, decode.d0.loss_dice: 0.4975, decode.d1.loss_cls: 0.0049, decode.d1.loss_mask: 0.4394, decode.d1.loss_dice: 0.4502, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.4322, decode.d2.loss_dice: 0.4410, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.4327, decode.d3.loss_dice: 0.4412, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.4335, decode.d4.loss_dice: 0.4439, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4328, decode.d5.loss_dice: 0.4423, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.4330, decode.d6.loss_dice: 0.4370, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.4300, decode.d7.loss_dice: 0.4410, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.4355, decode.d8.loss_dice: 0.4381, loss: 9.8615, grad_norm: 486.8240
2023-08-29 16:18:53,645 - mmseg - INFO - Iter [8650/160000]	lr: 1.592e-06, eta: 1 day, 6:37:24, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0132, decode.loss_mask: 0.4498, decode.loss_dice: 0.4855, decode.d0.loss_cls: 0.9953, decode.d0.loss_mask: 0.4760, decode.d0.loss_dice: 0.5400, decode.d1.loss_cls: 0.0166, decode.d1.loss_mask: 0.4566, decode.d1.loss_dice: 0.4928, decode.d2.loss_cls: 0.0179, decode.d2.loss_mask: 0.4466, decode.d2.loss_dice: 0.4913, decode.d3.loss_cls: 0.0138, decode.d3.loss_mask: 0.4519, decode.d3.loss_dice: 0.4864, decode.d4.loss_cls: 0.0163, decode.d4.loss_mask: 0.4509, decode.d4.loss_dice: 0.4866, decode.d5.loss_cls: 0.0151, decode.d5.loss_mask: 0.4505, decode.d5.loss_dice: 0.4820, decode.d6.loss_cls: 0.0155, decode.d6.loss_mask: 0.4564, decode.d6.loss_dice: 0.4824, decode.d7.loss_cls: 0.0157, decode.d7.loss_mask: 0.4494, decode.d7.loss_dice: 0.4905, decode.d8.loss_cls: 0.0149, decode.d8.loss_mask: 0.4506, decode.d8.loss_dice: 0.4906, loss: 10.6014, grad_norm: 450.2199
2023-08-29 16:19:28,298 - mmseg - INFO - Iter [8700/160000]	lr: 1.592e-06, eta: 1 day, 6:36:17, time: 0.693, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4204, decode.loss_dice: 0.4096, decode.d0.loss_cls: 0.9871, decode.d0.loss_mask: 0.4436, decode.d0.loss_dice: 0.4651, decode.d1.loss_cls: 0.0046, decode.d1.loss_mask: 0.4234, decode.d1.loss_dice: 0.4172, decode.d2.loss_cls: 0.0042, decode.d2.loss_mask: 0.4208, decode.d2.loss_dice: 0.4102, decode.d3.loss_cls: 0.0032, decode.d3.loss_mask: 0.4194, decode.d3.loss_dice: 0.4090, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.4219, decode.d4.loss_dice: 0.4040, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4241, decode.d5.loss_dice: 0.4084, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.4250, decode.d6.loss_dice: 0.4066, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.4218, decode.d7.loss_dice: 0.4074, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.4208, decode.d8.loss_dice: 0.4087, loss: 9.4036, grad_norm: 455.8368
2023-08-29 16:20:04,584 - mmseg - INFO - Iter [8750/160000]	lr: 1.591e-06, eta: 1 day, 6:35:38, time: 0.726, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0163, decode.loss_mask: 0.4680, decode.loss_dice: 0.4883, decode.d0.loss_cls: 0.9816, decode.d0.loss_mask: 0.4874, decode.d0.loss_dice: 0.5369, decode.d1.loss_cls: 0.0174, decode.d1.loss_mask: 0.4749, decode.d1.loss_dice: 0.4930, decode.d2.loss_cls: 0.0215, decode.d2.loss_mask: 0.4650, decode.d2.loss_dice: 0.4852, decode.d3.loss_cls: 0.0154, decode.d3.loss_mask: 0.4745, decode.d3.loss_dice: 0.4911, decode.d4.loss_cls: 0.0206, decode.d4.loss_mask: 0.4703, decode.d4.loss_dice: 0.4836, decode.d5.loss_cls: 0.0210, decode.d5.loss_mask: 0.4706, decode.d5.loss_dice: 0.4846, decode.d6.loss_cls: 0.0217, decode.d6.loss_mask: 0.4735, decode.d6.loss_dice: 0.4835, decode.d7.loss_cls: 0.0174, decode.d7.loss_mask: 0.4727, decode.d7.loss_dice: 0.4912, decode.d8.loss_cls: 0.0161, decode.d8.loss_mask: 0.4714, decode.d8.loss_dice: 0.4900, loss: 10.8045, grad_norm: 452.6588
2023-08-29 16:20:41,725 - mmseg - INFO - Iter [8800/160000]	lr: 1.591e-06, eta: 1 day, 6:35:14, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0176, decode.loss_mask: 0.5211, decode.loss_dice: 0.5000, decode.d0.loss_cls: 0.9747, decode.d0.loss_mask: 0.5227, decode.d0.loss_dice: 0.5478, decode.d1.loss_cls: 0.0171, decode.d1.loss_mask: 0.5201, decode.d1.loss_dice: 0.5056, decode.d2.loss_cls: 0.0177, decode.d2.loss_mask: 0.5181, decode.d2.loss_dice: 0.5011, decode.d3.loss_cls: 0.0150, decode.d3.loss_mask: 0.5181, decode.d3.loss_dice: 0.4997, decode.d4.loss_cls: 0.0170, decode.d4.loss_mask: 0.5165, decode.d4.loss_dice: 0.4989, decode.d5.loss_cls: 0.0161, decode.d5.loss_mask: 0.5189, decode.d5.loss_dice: 0.4993, decode.d6.loss_cls: 0.0162, decode.d6.loss_mask: 0.5182, decode.d6.loss_dice: 0.4992, decode.d7.loss_cls: 0.0165, decode.d7.loss_mask: 0.5214, decode.d7.loss_dice: 0.4975, decode.d8.loss_cls: 0.0175, decode.d8.loss_mask: 0.5164, decode.d8.loss_dice: 0.5023, loss: 11.3683, grad_norm: 513.0946
2023-08-29 16:21:18,898 - mmseg - INFO - Iter [8850/160000]	lr: 1.590e-06, eta: 1 day, 6:34:51, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4154, decode.loss_dice: 0.4107, decode.d0.loss_cls: 0.9675, decode.d0.loss_mask: 0.4502, decode.d0.loss_dice: 0.4593, decode.d1.loss_cls: 0.0044, decode.d1.loss_mask: 0.4251, decode.d1.loss_dice: 0.4213, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.4163, decode.d2.loss_dice: 0.4110, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.4162, decode.d3.loss_dice: 0.4094, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.4179, decode.d4.loss_dice: 0.4142, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4142, decode.d5.loss_dice: 0.4110, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.4149, decode.d6.loss_dice: 0.4119, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.4118, decode.d7.loss_dice: 0.4103, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.4126, decode.d8.loss_dice: 0.4092, loss: 9.3590, grad_norm: 445.2455
2023-08-29 16:21:53,740 - mmseg - INFO - Iter [8900/160000]	lr: 1.590e-06, eta: 1 day, 6:33:48, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.4393, decode.loss_dice: 0.4481, decode.d0.loss_cls: 0.9600, decode.d0.loss_mask: 0.4515, decode.d0.loss_dice: 0.4959, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.4342, decode.d1.loss_dice: 0.4545, decode.d2.loss_cls: 0.0033, decode.d2.loss_mask: 0.4308, decode.d2.loss_dice: 0.4450, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.4316, decode.d3.loss_dice: 0.4441, decode.d4.loss_cls: 0.0067, decode.d4.loss_mask: 0.4310, decode.d4.loss_dice: 0.4432, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.4315, decode.d5.loss_dice: 0.4440, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.4316, decode.d6.loss_dice: 0.4427, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.4388, decode.d7.loss_dice: 0.4473, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.4366, decode.d8.loss_dice: 0.4465, loss: 9.8669, grad_norm: 505.1148
2023-08-29 16:22:30,303 - mmseg - INFO - Iter [8950/160000]	lr: 1.589e-06, eta: 1 day, 6:33:14, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4600, decode.loss_dice: 0.4820, decode.d0.loss_cls: 0.9557, decode.d0.loss_mask: 0.4863, decode.d0.loss_dice: 0.5452, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.4704, decode.d1.loss_dice: 0.4835, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.4612, decode.d2.loss_dice: 0.4754, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.4620, decode.d3.loss_dice: 0.4749, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.4626, decode.d4.loss_dice: 0.4754, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4654, decode.d5.loss_dice: 0.4788, decode.d6.loss_cls: 0.0061, decode.d6.loss_mask: 0.4614, decode.d6.loss_dice: 0.4728, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.4655, decode.d7.loss_dice: 0.4773, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4620, decode.d8.loss_dice: 0.4755, loss: 10.4785, grad_norm: 544.6660
2023-08-29 16:23:07,229 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-08-29 16:23:09,566 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 16:23:09,566 - mmseg - INFO - Iter [9000/160000]	lr: 1.589e-06, eta: 1 day, 6:33:25, time: 0.785, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.4393, decode.loss_dice: 0.4588, decode.d0.loss_cls: 0.9469, decode.d0.loss_mask: 0.4621, decode.d0.loss_dice: 0.5046, decode.d1.loss_cls: 0.0042, decode.d1.loss_mask: 0.4427, decode.d1.loss_dice: 0.4713, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.4369, decode.d2.loss_dice: 0.4622, decode.d3.loss_cls: 0.0027, decode.d3.loss_mask: 0.4405, decode.d3.loss_dice: 0.4578, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4397, decode.d4.loss_dice: 0.4585, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.4402, decode.d5.loss_dice: 0.4611, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4406, decode.d6.loss_dice: 0.4560, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4393, decode.d7.loss_dice: 0.4562, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.4398, decode.d8.loss_dice: 0.4586, loss: 10.0379, grad_norm: 488.3381
2023-08-29 16:23:46,924 - mmseg - INFO - Iter [9050/160000]	lr: 1.588e-06, eta: 1 day, 6:33:04, time: 0.747, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0339, decode.loss_mask: 0.5212, decode.loss_dice: 0.4939, decode.d0.loss_cls: 0.9452, decode.d0.loss_mask: 0.5323, decode.d0.loss_dice: 0.5471, decode.d1.loss_cls: 0.0467, decode.d1.loss_mask: 0.5014, decode.d1.loss_dice: 0.5028, decode.d2.loss_cls: 0.0358, decode.d2.loss_mask: 0.5084, decode.d2.loss_dice: 0.4976, decode.d3.loss_cls: 0.0288, decode.d3.loss_mask: 0.5235, decode.d3.loss_dice: 0.4995, decode.d4.loss_cls: 0.0266, decode.d4.loss_mask: 0.5261, decode.d4.loss_dice: 0.4986, decode.d5.loss_cls: 0.0210, decode.d5.loss_mask: 0.5318, decode.d5.loss_dice: 0.4994, decode.d6.loss_cls: 0.0266, decode.d6.loss_mask: 0.5269, decode.d6.loss_dice: 0.4964, decode.d7.loss_cls: 0.0309, decode.d7.loss_mask: 0.5282, decode.d7.loss_dice: 0.4936, decode.d8.loss_cls: 0.0333, decode.d8.loss_mask: 0.5243, decode.d8.loss_dice: 0.4910, loss: 11.4726, grad_norm: 497.7295
2023-08-29 16:24:21,857 - mmseg - INFO - Iter [9100/160000]	lr: 1.588e-06, eta: 1 day, 6:32:03, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.5041, decode.loss_dice: 0.4855, decode.d0.loss_cls: 0.9349, decode.d0.loss_mask: 0.5222, decode.d0.loss_dice: 0.5387, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.4968, decode.d1.loss_dice: 0.4892, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4995, decode.d2.loss_dice: 0.4828, decode.d3.loss_cls: 0.0078, decode.d3.loss_mask: 0.4920, decode.d3.loss_dice: 0.4782, decode.d4.loss_cls: 0.0071, decode.d4.loss_mask: 0.4895, decode.d4.loss_dice: 0.4814, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.5036, decode.d5.loss_dice: 0.4819, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.4985, decode.d6.loss_dice: 0.4799, decode.d7.loss_cls: 0.0071, decode.d7.loss_mask: 0.4944, decode.d7.loss_dice: 0.4803, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 0.4920, decode.d8.loss_dice: 0.4818, loss: 10.8567, grad_norm: 560.4048
2023-08-29 16:24:58,388 - mmseg - INFO - Iter [9150/160000]	lr: 1.587e-06, eta: 1 day, 6:31:28, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.4537, decode.loss_dice: 0.4644, decode.d0.loss_cls: 0.9290, decode.d0.loss_mask: 0.4812, decode.d0.loss_dice: 0.5087, decode.d1.loss_cls: 0.0044, decode.d1.loss_mask: 0.4546, decode.d1.loss_dice: 0.4685, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.4532, decode.d2.loss_dice: 0.4662, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.4543, decode.d3.loss_dice: 0.4614, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4541, decode.d4.loss_dice: 0.4638, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.4571, decode.d5.loss_dice: 0.4619, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.4545, decode.d6.loss_dice: 0.4649, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.4543, decode.d7.loss_dice: 0.4603, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.4519, decode.d8.loss_dice: 0.4623, loss: 10.2068, grad_norm: 532.4806
2023-08-29 16:25:35,084 - mmseg - INFO - Iter [9200/160000]	lr: 1.586e-06, eta: 1 day, 6:30:57, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0150, decode.loss_mask: 0.4613, decode.loss_dice: 0.4830, decode.d0.loss_cls: 0.9242, decode.d0.loss_mask: 0.4788, decode.d0.loss_dice: 0.5360, decode.d1.loss_cls: 0.0163, decode.d1.loss_mask: 0.4617, decode.d1.loss_dice: 0.4846, decode.d2.loss_cls: 0.0151, decode.d2.loss_mask: 0.4611, decode.d2.loss_dice: 0.4864, decode.d3.loss_cls: 0.0138, decode.d3.loss_mask: 0.4618, decode.d3.loss_dice: 0.4828, decode.d4.loss_cls: 0.0138, decode.d4.loss_mask: 0.4571, decode.d4.loss_dice: 0.4770, decode.d5.loss_cls: 0.0082, decode.d5.loss_mask: 0.4722, decode.d5.loss_dice: 0.4887, decode.d6.loss_cls: 0.0068, decode.d6.loss_mask: 0.4711, decode.d6.loss_dice: 0.4947, decode.d7.loss_cls: 0.0151, decode.d7.loss_mask: 0.4584, decode.d7.loss_dice: 0.4809, decode.d8.loss_cls: 0.0151, decode.d8.loss_mask: 0.4595, decode.d8.loss_dice: 0.4831, loss: 10.5836, grad_norm: 491.8939
2023-08-29 16:26:12,132 - mmseg - INFO - Iter [9250/160000]	lr: 1.586e-06, eta: 1 day, 6:30:30, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0165, decode.loss_mask: 0.4873, decode.loss_dice: 0.4653, decode.d0.loss_cls: 0.9169, decode.d0.loss_mask: 0.5107, decode.d0.loss_dice: 0.5156, decode.d1.loss_cls: 0.0236, decode.d1.loss_mask: 0.4808, decode.d1.loss_dice: 0.4687, decode.d2.loss_cls: 0.0175, decode.d2.loss_mask: 0.4895, decode.d2.loss_dice: 0.4661, decode.d3.loss_cls: 0.0219, decode.d3.loss_mask: 0.4798, decode.d3.loss_dice: 0.4635, decode.d4.loss_cls: 0.0227, decode.d4.loss_mask: 0.4776, decode.d4.loss_dice: 0.4624, decode.d5.loss_cls: 0.0145, decode.d5.loss_mask: 0.4864, decode.d5.loss_dice: 0.4648, decode.d6.loss_cls: 0.0154, decode.d6.loss_mask: 0.4847, decode.d6.loss_dice: 0.4642, decode.d7.loss_cls: 0.0227, decode.d7.loss_mask: 0.4780, decode.d7.loss_dice: 0.4617, decode.d8.loss_cls: 0.0207, decode.d8.loss_mask: 0.4755, decode.d8.loss_dice: 0.4599, loss: 10.6351, grad_norm: 547.1217
2023-08-29 16:26:47,157 - mmseg - INFO - Iter [9300/160000]	lr: 1.585e-06, eta: 1 day, 6:29:31, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0229, decode.loss_mask: 0.4790, decode.loss_dice: 0.4825, decode.d0.loss_cls: 0.9139, decode.d0.loss_mask: 0.5027, decode.d0.loss_dice: 0.5300, decode.d1.loss_cls: 0.0230, decode.d1.loss_mask: 0.4845, decode.d1.loss_dice: 0.4853, decode.d2.loss_cls: 0.0274, decode.d2.loss_mask: 0.4775, decode.d2.loss_dice: 0.4731, decode.d3.loss_cls: 0.0219, decode.d3.loss_mask: 0.4824, decode.d3.loss_dice: 0.4764, decode.d4.loss_cls: 0.0246, decode.d4.loss_mask: 0.4778, decode.d4.loss_dice: 0.4730, decode.d5.loss_cls: 0.0188, decode.d5.loss_mask: 0.4818, decode.d5.loss_dice: 0.4773, decode.d6.loss_cls: 0.0196, decode.d6.loss_mask: 0.4801, decode.d6.loss_dice: 0.4738, decode.d7.loss_cls: 0.0203, decode.d7.loss_mask: 0.4795, decode.d7.loss_dice: 0.4764, decode.d8.loss_cls: 0.0239, decode.d8.loss_mask: 0.4778, decode.d8.loss_dice: 0.4796, loss: 10.7671, grad_norm: 454.2451
2023-08-29 16:27:23,882 - mmseg - INFO - Iter [9350/160000]	lr: 1.585e-06, eta: 1 day, 6:28:59, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.5092, decode.loss_dice: 0.4790, decode.d0.loss_cls: 0.9060, decode.d0.loss_mask: 0.5079, decode.d0.loss_dice: 0.5286, decode.d1.loss_cls: 0.0084, decode.d1.loss_mask: 0.5050, decode.d1.loss_dice: 0.4829, decode.d2.loss_cls: 0.0103, decode.d2.loss_mask: 0.5012, decode.d2.loss_dice: 0.4775, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.5089, decode.d3.loss_dice: 0.4808, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.5095, decode.d4.loss_dice: 0.4776, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.5134, decode.d5.loss_dice: 0.4806, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.5143, decode.d6.loss_dice: 0.4804, decode.d7.loss_cls: 0.0105, decode.d7.loss_mask: 0.5036, decode.d7.loss_dice: 0.4738, decode.d8.loss_cls: 0.0095, decode.d8.loss_mask: 0.5018, decode.d8.loss_dice: 0.4785, loss: 10.8723, grad_norm: 477.0081
2023-08-29 16:28:00,562 - mmseg - INFO - Iter [9400/160000]	lr: 1.584e-06, eta: 1 day, 6:28:27, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0082, decode.loss_mask: 0.4417, decode.loss_dice: 0.4600, decode.d0.loss_cls: 0.8982, decode.d0.loss_mask: 0.4593, decode.d0.loss_dice: 0.5136, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.4392, decode.d1.loss_dice: 0.4641, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.4417, decode.d2.loss_dice: 0.4600, decode.d3.loss_cls: 0.0086, decode.d3.loss_mask: 0.4381, decode.d3.loss_dice: 0.4566, decode.d4.loss_cls: 0.0075, decode.d4.loss_mask: 0.4341, decode.d4.loss_dice: 0.4542, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.4387, decode.d5.loss_dice: 0.4585, decode.d6.loss_cls: 0.0076, decode.d6.loss_mask: 0.4365, decode.d6.loss_dice: 0.4567, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.4378, decode.d7.loss_dice: 0.4544, decode.d8.loss_cls: 0.0083, decode.d8.loss_mask: 0.4374, decode.d8.loss_dice: 0.4532, loss: 10.0002, grad_norm: 514.3454
2023-08-29 16:28:37,715 - mmseg - INFO - Iter [9450/160000]	lr: 1.584e-06, eta: 1 day, 6:28:02, time: 0.743, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0103, decode.loss_mask: 0.4973, decode.loss_dice: 0.5066, decode.d0.loss_cls: 0.8911, decode.d0.loss_mask: 0.5187, decode.d0.loss_dice: 0.5612, decode.d1.loss_cls: 0.0047, decode.d1.loss_mask: 0.5154, decode.d1.loss_dice: 0.5149, decode.d2.loss_cls: 0.0046, decode.d2.loss_mask: 0.4996, decode.d2.loss_dice: 0.5113, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.5011, decode.d3.loss_dice: 0.5082, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.4984, decode.d4.loss_dice: 0.5084, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.5006, decode.d5.loss_dice: 0.5129, decode.d6.loss_cls: 0.0045, decode.d6.loss_mask: 0.4988, decode.d6.loss_dice: 0.5082, decode.d7.loss_cls: 0.0099, decode.d7.loss_mask: 0.4970, decode.d7.loss_dice: 0.5075, decode.d8.loss_cls: 0.0099, decode.d8.loss_mask: 0.4965, decode.d8.loss_dice: 0.5059, loss: 11.1159, grad_norm: 555.1289
2023-08-29 16:29:12,597 - mmseg - INFO - Iter [9500/160000]	lr: 1.583e-06, eta: 1 day, 6:27:01, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0244, decode.loss_mask: 0.4362, decode.loss_dice: 0.4482, decode.d0.loss_cls: 0.8884, decode.d0.loss_mask: 0.4398, decode.d0.loss_dice: 0.4972, decode.d1.loss_cls: 0.0229, decode.d1.loss_mask: 0.4438, decode.d1.loss_dice: 0.4537, decode.d2.loss_cls: 0.0249, decode.d2.loss_mask: 0.4318, decode.d2.loss_dice: 0.4523, decode.d3.loss_cls: 0.0201, decode.d3.loss_mask: 0.4322, decode.d3.loss_dice: 0.4483, decode.d4.loss_cls: 0.0193, decode.d4.loss_mask: 0.4376, decode.d4.loss_dice: 0.4517, decode.d5.loss_cls: 0.0210, decode.d5.loss_mask: 0.4337, decode.d5.loss_dice: 0.4512, decode.d6.loss_cls: 0.0252, decode.d6.loss_mask: 0.4293, decode.d6.loss_dice: 0.4501, decode.d7.loss_cls: 0.0253, decode.d7.loss_mask: 0.4332, decode.d7.loss_dice: 0.4466, decode.d8.loss_cls: 0.0261, decode.d8.loss_mask: 0.4314, decode.d8.loss_dice: 0.4489, loss: 9.9944, grad_norm: 478.7585
2023-08-29 16:29:49,302 - mmseg - INFO - Iter [9550/160000]	lr: 1.583e-06, eta: 1 day, 6:26:30, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0204, decode.loss_mask: 0.4077, decode.loss_dice: 0.4153, decode.d0.loss_cls: 0.8793, decode.d0.loss_mask: 0.4343, decode.d0.loss_dice: 0.4619, decode.d1.loss_cls: 0.0175, decode.d1.loss_mask: 0.4114, decode.d1.loss_dice: 0.4157, decode.d2.loss_cls: 0.0180, decode.d2.loss_mask: 0.4058, decode.d2.loss_dice: 0.4152, decode.d3.loss_cls: 0.0140, decode.d3.loss_mask: 0.4043, decode.d3.loss_dice: 0.4168, decode.d4.loss_cls: 0.0150, decode.d4.loss_mask: 0.4058, decode.d4.loss_dice: 0.4164, decode.d5.loss_cls: 0.0154, decode.d5.loss_mask: 0.4097, decode.d5.loss_dice: 0.4149, decode.d6.loss_cls: 0.0162, decode.d6.loss_mask: 0.4090, decode.d6.loss_dice: 0.4168, decode.d7.loss_cls: 0.0179, decode.d7.loss_mask: 0.4081, decode.d7.loss_dice: 0.4167, decode.d8.loss_cls: 0.0192, decode.d8.loss_mask: 0.4073, decode.d8.loss_dice: 0.4166, loss: 9.3425, grad_norm: 420.1017
2023-08-29 16:30:25,909 - mmseg - INFO - Iter [9600/160000]	lr: 1.582e-06, eta: 1 day, 6:25:56, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.4071, decode.loss_dice: 0.4007, decode.d0.loss_cls: 0.8736, decode.d0.loss_mask: 0.4114, decode.d0.loss_dice: 0.4406, decode.d1.loss_cls: 0.0090, decode.d1.loss_mask: 0.3975, decode.d1.loss_dice: 0.4033, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.4005, decode.d2.loss_dice: 0.3945, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.4047, decode.d3.loss_dice: 0.3980, decode.d4.loss_cls: 0.0056, decode.d4.loss_mask: 0.4033, decode.d4.loss_dice: 0.3968, decode.d5.loss_cls: 0.0055, decode.d5.loss_mask: 0.4046, decode.d5.loss_dice: 0.3962, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.4007, decode.d6.loss_dice: 0.3956, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.4055, decode.d7.loss_dice: 0.4029, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4060, decode.d8.loss_dice: 0.3995, loss: 8.9849, grad_norm: 496.2167
2023-08-29 16:31:02,983 - mmseg - INFO - Iter [9650/160000]	lr: 1.582e-06, eta: 1 day, 6:25:30, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.4620, decode.loss_dice: 0.4746, decode.d0.loss_cls: 0.8674, decode.d0.loss_mask: 0.4925, decode.d0.loss_dice: 0.5287, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.4781, decode.d1.loss_dice: 0.4855, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.4662, decode.d2.loss_dice: 0.4773, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4597, decode.d3.loss_dice: 0.4774, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.4616, decode.d4.loss_dice: 0.4737, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.4628, decode.d5.loss_dice: 0.4774, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.4633, decode.d6.loss_dice: 0.4751, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.4613, decode.d7.loss_dice: 0.4762, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4653, decode.d8.loss_dice: 0.4746, loss: 10.3811, grad_norm: 508.6891
2023-08-29 16:31:38,250 - mmseg - INFO - Iter [9700/160000]	lr: 1.581e-06, eta: 1 day, 6:24:35, time: 0.705, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4722, decode.loss_dice: 0.4845, decode.d0.loss_cls: 0.8607, decode.d0.loss_mask: 0.4719, decode.d0.loss_dice: 0.5128, decode.d1.loss_cls: 0.0160, decode.d1.loss_mask: 0.4551, decode.d1.loss_dice: 0.4872, decode.d2.loss_cls: 0.0082, decode.d2.loss_mask: 0.4649, decode.d2.loss_dice: 0.4918, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.4712, decode.d3.loss_dice: 0.4880, decode.d4.loss_cls: 0.0073, decode.d4.loss_mask: 0.4638, decode.d4.loss_dice: 0.4858, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.4687, decode.d5.loss_dice: 0.4840, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.4711, decode.d6.loss_dice: 0.4830, decode.d7.loss_cls: 0.0067, decode.d7.loss_mask: 0.4615, decode.d7.loss_dice: 0.4798, decode.d8.loss_cls: 0.0068, decode.d8.loss_mask: 0.4651, decode.d8.loss_dice: 0.4800, loss: 10.4598, grad_norm: 451.5732
2023-08-29 16:32:15,283 - mmseg - INFO - Iter [9750/160000]	lr: 1.581e-06, eta: 1 day, 6:24:08, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0166, decode.loss_mask: 0.4220, decode.loss_dice: 0.4121, decode.d0.loss_cls: 0.8557, decode.d0.loss_mask: 0.4411, decode.d0.loss_dice: 0.4501, decode.d1.loss_cls: 0.0167, decode.d1.loss_mask: 0.4229, decode.d1.loss_dice: 0.4175, decode.d2.loss_cls: 0.0191, decode.d2.loss_mask: 0.4151, decode.d2.loss_dice: 0.4073, decode.d3.loss_cls: 0.0156, decode.d3.loss_mask: 0.4129, decode.d3.loss_dice: 0.4160, decode.d4.loss_cls: 0.0157, decode.d4.loss_mask: 0.4120, decode.d4.loss_dice: 0.4155, decode.d5.loss_cls: 0.0143, decode.d5.loss_mask: 0.4119, decode.d5.loss_dice: 0.4155, decode.d6.loss_cls: 0.0161, decode.d6.loss_mask: 0.4145, decode.d6.loss_dice: 0.4133, decode.d7.loss_cls: 0.0165, decode.d7.loss_mask: 0.4157, decode.d7.loss_dice: 0.4116, decode.d8.loss_cls: 0.0229, decode.d8.loss_mask: 0.4161, decode.d8.loss_dice: 0.4111, loss: 9.3633, grad_norm: 494.7861
2023-08-29 16:32:51,870 - mmseg - INFO - Iter [9800/160000]	lr: 1.580e-06, eta: 1 day, 6:23:35, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.4629, decode.loss_dice: 0.4544, decode.d0.loss_cls: 0.8481, decode.d0.loss_mask: 0.4833, decode.d0.loss_dice: 0.5045, decode.d1.loss_cls: 0.0161, decode.d1.loss_mask: 0.4572, decode.d1.loss_dice: 0.4682, decode.d2.loss_cls: 0.0082, decode.d2.loss_mask: 0.4602, decode.d2.loss_dice: 0.4571, decode.d3.loss_cls: 0.0061, decode.d3.loss_mask: 0.4620, decode.d3.loss_dice: 0.4582, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.4579, decode.d4.loss_dice: 0.4518, decode.d5.loss_cls: 0.0062, decode.d5.loss_mask: 0.4568, decode.d5.loss_dice: 0.4517, decode.d6.loss_cls: 0.0060, decode.d6.loss_mask: 0.4581, decode.d6.loss_dice: 0.4522, decode.d7.loss_cls: 0.0060, decode.d7.loss_mask: 0.4591, decode.d7.loss_dice: 0.4528, decode.d8.loss_cls: 0.0088, decode.d8.loss_mask: 0.4586, decode.d8.loss_dice: 0.4515, loss: 10.1319, grad_norm: 436.9293
2023-08-29 16:33:29,219 - mmseg - INFO - Iter [9850/160000]	lr: 1.580e-06, eta: 1 day, 6:23:12, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0071, decode.loss_mask: 0.4233, decode.loss_dice: 0.4195, decode.d0.loss_cls: 0.8422, decode.d0.loss_mask: 0.4403, decode.d0.loss_dice: 0.4551, decode.d1.loss_cls: 0.0199, decode.d1.loss_mask: 0.4223, decode.d1.loss_dice: 0.4257, decode.d2.loss_cls: 0.0151, decode.d2.loss_mask: 0.4240, decode.d2.loss_dice: 0.4209, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.4246, decode.d3.loss_dice: 0.4166, decode.d4.loss_cls: 0.0079, decode.d4.loss_mask: 0.4278, decode.d4.loss_dice: 0.4141, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.4459, decode.d5.loss_dice: 0.4190, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.4327, decode.d6.loss_dice: 0.4146, decode.d7.loss_cls: 0.0067, decode.d7.loss_mask: 0.4319, decode.d7.loss_dice: 0.4183, decode.d8.loss_cls: 0.0102, decode.d8.loss_mask: 0.4290, decode.d8.loss_dice: 0.4141, loss: 9.4450, grad_norm: 435.8161
2023-08-29 16:34:04,267 - mmseg - INFO - Iter [9900/160000]	lr: 1.579e-06, eta: 1 day, 6:22:15, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.3962, decode.loss_dice: 0.4167, decode.d0.loss_cls: 0.8349, decode.d0.loss_mask: 0.4244, decode.d0.loss_dice: 0.4647, decode.d1.loss_cls: 0.0031, decode.d1.loss_mask: 0.3984, decode.d1.loss_dice: 0.4223, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3950, decode.d2.loss_dice: 0.4167, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3968, decode.d3.loss_dice: 0.4170, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.3964, decode.d4.loss_dice: 0.4156, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.3948, decode.d5.loss_dice: 0.4146, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.3932, decode.d6.loss_dice: 0.4130, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.3971, decode.d7.loss_dice: 0.4157, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.3973, decode.d8.loss_dice: 0.4154, loss: 9.0568, grad_norm: 501.8593
2023-08-29 16:34:41,065 - mmseg - INFO - Iter [9950/160000]	lr: 1.579e-06, eta: 1 day, 6:21:44, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.3610, decode.loss_dice: 0.3754, decode.d0.loss_cls: 0.8311, decode.d0.loss_mask: 0.3818, decode.d0.loss_dice: 0.4243, decode.d1.loss_cls: 0.0046, decode.d1.loss_mask: 0.3629, decode.d1.loss_dice: 0.3759, decode.d2.loss_cls: 0.0038, decode.d2.loss_mask: 0.3588, decode.d2.loss_dice: 0.3793, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.3614, decode.d3.loss_dice: 0.3727, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.3592, decode.d4.loss_dice: 0.3750, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.3576, decode.d5.loss_dice: 0.3740, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.3606, decode.d6.loss_dice: 0.3743, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.3574, decode.d7.loss_dice: 0.3709, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.3604, decode.d8.loss_dice: 0.3754, loss: 8.2804, grad_norm: 477.4712
2023-08-29 16:35:17,547 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-08-29 16:35:20,132 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 16:35:20,132 - mmseg - INFO - Iter [10000/160000]	lr: 1.578e-06, eta: 1 day, 6:21:47, time: 0.782, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0261, decode.loss_mask: 0.4504, decode.loss_dice: 0.4320, decode.d0.loss_cls: 0.8270, decode.d0.loss_mask: 0.4708, decode.d0.loss_dice: 0.4692, decode.d1.loss_cls: 0.0315, decode.d1.loss_mask: 0.4516, decode.d1.loss_dice: 0.4326, decode.d2.loss_cls: 0.0284, decode.d2.loss_mask: 0.4457, decode.d2.loss_dice: 0.4341, decode.d3.loss_cls: 0.0230, decode.d3.loss_mask: 0.4448, decode.d3.loss_dice: 0.4321, decode.d4.loss_cls: 0.0188, decode.d4.loss_mask: 0.4467, decode.d4.loss_dice: 0.4288, decode.d5.loss_cls: 0.0203, decode.d5.loss_mask: 0.4417, decode.d5.loss_dice: 0.4309, decode.d6.loss_cls: 0.0255, decode.d6.loss_mask: 0.4430, decode.d6.loss_dice: 0.4291, decode.d7.loss_cls: 0.0279, decode.d7.loss_mask: 0.4418, decode.d7.loss_dice: 0.4316, decode.d8.loss_cls: 0.0281, decode.d8.loss_mask: 0.4432, decode.d8.loss_dice: 0.4320, loss: 9.8888, grad_norm: 508.7891
2023-08-29 16:35:57,401 - mmseg - INFO - Iter [10050/160000]	lr: 1.578e-06, eta: 1 day, 6:21:23, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4323, decode.loss_dice: 0.4145, decode.d0.loss_cls: 0.8193, decode.d0.loss_mask: 0.4568, decode.d0.loss_dice: 0.4565, decode.d1.loss_cls: 0.0040, decode.d1.loss_mask: 0.4297, decode.d1.loss_dice: 0.4207, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.4287, decode.d2.loss_dice: 0.4202, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.4296, decode.d3.loss_dice: 0.4155, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.4295, decode.d4.loss_dice: 0.4209, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.4360, decode.d5.loss_dice: 0.4300, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.4338, decode.d6.loss_dice: 0.4182, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.4337, decode.d7.loss_dice: 0.4155, decode.d8.loss_cls: 0.0036, decode.d8.loss_mask: 0.4332, decode.d8.loss_dice: 0.4141, loss: 9.4129, grad_norm: 485.9939
2023-08-29 16:36:34,553 - mmseg - INFO - Iter [10100/160000]	lr: 1.577e-06, eta: 1 day, 6:20:58, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.3989, decode.loss_dice: 0.4049, decode.d0.loss_cls: 0.8121, decode.d0.loss_mask: 0.4263, decode.d0.loss_dice: 0.4561, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.4044, decode.d1.loss_dice: 0.4150, decode.d2.loss_cls: 0.0033, decode.d2.loss_mask: 0.3993, decode.d2.loss_dice: 0.4101, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4010, decode.d3.loss_dice: 0.4061, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4009, decode.d4.loss_dice: 0.4076, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.4017, decode.d5.loss_dice: 0.4116, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.3964, decode.d6.loss_dice: 0.4048, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.4011, decode.d7.loss_dice: 0.4074, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.4002, decode.d8.loss_dice: 0.4068, loss: 8.9979, grad_norm: 538.0296
2023-08-29 16:37:09,085 - mmseg - INFO - Iter [10150/160000]	lr: 1.576e-06, eta: 1 day, 6:19:53, time: 0.691, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0172, decode.loss_mask: 0.4420, decode.loss_dice: 0.4210, decode.d0.loss_cls: 0.8080, decode.d0.loss_mask: 0.4400, decode.d0.loss_dice: 0.4635, decode.d1.loss_cls: 0.0229, decode.d1.loss_mask: 0.4211, decode.d1.loss_dice: 0.4287, decode.d2.loss_cls: 0.0260, decode.d2.loss_mask: 0.4161, decode.d2.loss_dice: 0.4211, decode.d3.loss_cls: 0.0160, decode.d3.loss_mask: 0.4392, decode.d3.loss_dice: 0.4179, decode.d4.loss_cls: 0.0141, decode.d4.loss_mask: 0.4464, decode.d4.loss_dice: 0.4170, decode.d5.loss_cls: 0.0149, decode.d5.loss_mask: 0.4530, decode.d5.loss_dice: 0.4153, decode.d6.loss_cls: 0.0161, decode.d6.loss_mask: 0.4405, decode.d6.loss_dice: 0.4158, decode.d7.loss_cls: 0.0171, decode.d7.loss_mask: 0.4393, decode.d7.loss_dice: 0.4184, decode.d8.loss_cls: 0.0168, decode.d8.loss_mask: 0.4402, decode.d8.loss_dice: 0.4170, loss: 9.5827, grad_norm: 453.4450
2023-08-29 16:37:45,441 - mmseg - INFO - Iter [10200/160000]	lr: 1.576e-06, eta: 1 day, 6:19:15, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.4190, decode.loss_dice: 0.4228, decode.d0.loss_cls: 0.8008, decode.d0.loss_mask: 0.4389, decode.d0.loss_dice: 0.4580, decode.d1.loss_cls: 0.0040, decode.d1.loss_mask: 0.4309, decode.d1.loss_dice: 0.4222, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.4233, decode.d2.loss_dice: 0.4192, decode.d3.loss_cls: 0.0027, decode.d3.loss_mask: 0.4208, decode.d3.loss_dice: 0.4198, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.4207, decode.d4.loss_dice: 0.4209, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.4207, decode.d5.loss_dice: 0.4264, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4175, decode.d6.loss_dice: 0.4213, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.4211, decode.d7.loss_dice: 0.4233, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.4246, decode.d8.loss_dice: 0.4218, loss: 9.3187, grad_norm: 468.0621
2023-08-29 16:38:22,493 - mmseg - INFO - Iter [10250/160000]	lr: 1.575e-06, eta: 1 day, 6:18:48, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.4258, decode.loss_dice: 0.4046, decode.d0.loss_cls: 0.7953, decode.d0.loss_mask: 0.4452, decode.d0.loss_dice: 0.4452, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.4273, decode.d1.loss_dice: 0.4042, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.4265, decode.d2.loss_dice: 0.4036, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.4266, decode.d3.loss_dice: 0.3986, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4254, decode.d4.loss_dice: 0.4003, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.4256, decode.d5.loss_dice: 0.4020, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.4258, decode.d6.loss_dice: 0.4055, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.4225, decode.d7.loss_dice: 0.4010, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.4226, decode.d8.loss_dice: 0.3993, loss: 9.1523, grad_norm: 527.4191
2023-08-29 16:38:59,959 - mmseg - INFO - Iter [10300/160000]	lr: 1.575e-06, eta: 1 day, 6:18:26, time: 0.749, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.4361, decode.loss_dice: 0.4222, decode.d0.loss_cls: 0.7897, decode.d0.loss_mask: 0.4674, decode.d0.loss_dice: 0.4611, decode.d1.loss_cls: 0.0038, decode.d1.loss_mask: 0.4364, decode.d1.loss_dice: 0.4235, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4349, decode.d2.loss_dice: 0.4227, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4334, decode.d3.loss_dice: 0.4202, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.4356, decode.d4.loss_dice: 0.4265, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.4374, decode.d5.loss_dice: 0.4255, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4360, decode.d6.loss_dice: 0.4238, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4336, decode.d7.loss_dice: 0.4251, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.4340, decode.d8.loss_dice: 0.4207, loss: 9.4693, grad_norm: 480.1643
2023-08-29 16:39:34,732 - mmseg - INFO - Iter [10350/160000]	lr: 1.574e-06, eta: 1 day, 6:17:26, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0010, decode.loss_mask: 0.4959, decode.loss_dice: 0.4743, decode.d0.loss_cls: 0.7837, decode.d0.loss_mask: 0.5198, decode.d0.loss_dice: 0.5076, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.5009, decode.d1.loss_dice: 0.4775, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.4969, decode.d2.loss_dice: 0.4717, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.4947, decode.d3.loss_dice: 0.4695, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.4972, decode.d4.loss_dice: 0.4730, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.4955, decode.d5.loss_dice: 0.4741, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.4970, decode.d6.loss_dice: 0.4719, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.4956, decode.d7.loss_dice: 0.4765, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.4951, decode.d8.loss_dice: 0.4739, loss: 10.5541, grad_norm: 501.5946
2023-08-29 16:40:11,011 - mmseg - INFO - Iter [10400/160000]	lr: 1.574e-06, eta: 1 day, 6:16:47, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0123, decode.loss_mask: 0.4511, decode.loss_dice: 0.4457, decode.d0.loss_cls: 0.7795, decode.d0.loss_mask: 0.4734, decode.d0.loss_dice: 0.4992, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.4722, decode.d1.loss_dice: 0.4569, decode.d2.loss_cls: 0.0088, decode.d2.loss_mask: 0.4549, decode.d2.loss_dice: 0.4471, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.4686, decode.d3.loss_dice: 0.4507, decode.d4.loss_cls: 0.0064, decode.d4.loss_mask: 0.4545, decode.d4.loss_dice: 0.4460, decode.d5.loss_cls: 0.0071, decode.d5.loss_mask: 0.4620, decode.d5.loss_dice: 0.4465, decode.d6.loss_cls: 0.0113, decode.d6.loss_mask: 0.4496, decode.d6.loss_dice: 0.4419, decode.d7.loss_cls: 0.0110, decode.d7.loss_mask: 0.4487, decode.d7.loss_dice: 0.4440, decode.d8.loss_cls: 0.0125, decode.d8.loss_mask: 0.4483, decode.d8.loss_dice: 0.4396, loss: 9.9548, grad_norm: 485.2699
2023-08-29 16:40:48,122 - mmseg - INFO - Iter [10450/160000]	lr: 1.573e-06, eta: 1 day, 6:16:20, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4462, decode.loss_dice: 0.4344, decode.d0.loss_cls: 0.7723, decode.d0.loss_mask: 0.4773, decode.d0.loss_dice: 0.4756, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4452, decode.d1.loss_dice: 0.4373, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4440, decode.d2.loss_dice: 0.4348, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4418, decode.d3.loss_dice: 0.4348, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.4441, decode.d4.loss_dice: 0.4333, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4456, decode.d5.loss_dice: 0.4353, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4472, decode.d6.loss_dice: 0.4357, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.4462, decode.d7.loss_dice: 0.4356, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.4439, decode.d8.loss_dice: 0.4333, loss: 9.6672, grad_norm: 449.6121
2023-08-29 16:41:25,499 - mmseg - INFO - Iter [10500/160000]	lr: 1.573e-06, eta: 1 day, 6:15:57, time: 0.748, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4154, decode.loss_dice: 0.4090, decode.d0.loss_cls: 0.7663, decode.d0.loss_mask: 0.4608, decode.d0.loss_dice: 0.4620, decode.d1.loss_cls: 0.0034, decode.d1.loss_mask: 0.4212, decode.d1.loss_dice: 0.4180, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.4208, decode.d2.loss_dice: 0.4101, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.4165, decode.d3.loss_dice: 0.4097, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.4213, decode.d4.loss_dice: 0.4118, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4181, decode.d5.loss_dice: 0.4074, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.4183, decode.d6.loss_dice: 0.4094, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.4176, decode.d7.loss_dice: 0.4101, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4140, decode.d8.loss_dice: 0.4104, loss: 9.1692, grad_norm: 488.8018
2023-08-29 16:42:00,394 - mmseg - INFO - Iter [10550/160000]	lr: 1.572e-06, eta: 1 day, 6:14:59, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0060, decode.loss_mask: 0.3990, decode.loss_dice: 0.3955, decode.d0.loss_cls: 0.7611, decode.d0.loss_mask: 0.4171, decode.d0.loss_dice: 0.4316, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.4088, decode.d1.loss_dice: 0.4086, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.4077, decode.d2.loss_dice: 0.4024, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.4107, decode.d3.loss_dice: 0.4001, decode.d4.loss_cls: 0.0077, decode.d4.loss_mask: 0.3989, decode.d4.loss_dice: 0.3965, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.4110, decode.d5.loss_dice: 0.3978, decode.d6.loss_cls: 0.0064, decode.d6.loss_mask: 0.3974, decode.d6.loss_dice: 0.3957, decode.d7.loss_cls: 0.0060, decode.d7.loss_mask: 0.3959, decode.d7.loss_dice: 0.3973, decode.d8.loss_cls: 0.0058, decode.d8.loss_mask: 0.3967, decode.d8.loss_dice: 0.3931, loss: 8.8626, grad_norm: 441.2724
2023-08-29 16:42:36,819 - mmseg - INFO - Iter [10600/160000]	lr: 1.572e-06, eta: 1 day, 6:14:22, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0380, decode.loss_mask: 0.4577, decode.loss_dice: 0.4648, decode.d0.loss_cls: 0.7601, decode.d0.loss_mask: 0.4633, decode.d0.loss_dice: 0.5088, decode.d1.loss_cls: 0.0297, decode.d1.loss_mask: 0.4654, decode.d1.loss_dice: 0.4759, decode.d2.loss_cls: 0.0315, decode.d2.loss_mask: 0.4602, decode.d2.loss_dice: 0.4709, decode.d3.loss_cls: 0.0187, decode.d3.loss_mask: 0.4703, decode.d3.loss_dice: 0.4744, decode.d4.loss_cls: 0.0225, decode.d4.loss_mask: 0.4658, decode.d4.loss_dice: 0.4713, decode.d5.loss_cls: 0.0209, decode.d5.loss_mask: 0.4709, decode.d5.loss_dice: 0.4733, decode.d6.loss_cls: 0.0243, decode.d6.loss_mask: 0.4679, decode.d6.loss_dice: 0.4717, decode.d7.loss_cls: 0.0246, decode.d7.loss_mask: 0.4728, decode.d7.loss_dice: 0.4744, decode.d8.loss_cls: 0.0267, decode.d8.loss_mask: 0.4750, decode.d8.loss_dice: 0.4754, loss: 10.4272, grad_norm: 463.1053
2023-08-29 16:43:13,676 - mmseg - INFO - Iter [10650/160000]	lr: 1.571e-06, eta: 1 day, 6:13:52, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0298, decode.loss_mask: 0.4681, decode.loss_dice: 0.4760, decode.d0.loss_cls: 0.7540, decode.d0.loss_mask: 0.4897, decode.d0.loss_dice: 0.5240, decode.d1.loss_cls: 0.0207, decode.d1.loss_mask: 0.4792, decode.d1.loss_dice: 0.4880, decode.d2.loss_cls: 0.0190, decode.d2.loss_mask: 0.4761, decode.d2.loss_dice: 0.4780, decode.d3.loss_cls: 0.0174, decode.d3.loss_mask: 0.4721, decode.d3.loss_dice: 0.4736, decode.d4.loss_cls: 0.0210, decode.d4.loss_mask: 0.4730, decode.d4.loss_dice: 0.4749, decode.d5.loss_cls: 0.0212, decode.d5.loss_mask: 0.4752, decode.d5.loss_dice: 0.4735, decode.d6.loss_cls: 0.0221, decode.d6.loss_mask: 0.4780, decode.d6.loss_dice: 0.4743, decode.d7.loss_cls: 0.0236, decode.d7.loss_mask: 0.4729, decode.d7.loss_dice: 0.4760, decode.d8.loss_cls: 0.0240, decode.d8.loss_mask: 0.4724, decode.d8.loss_dice: 0.4781, loss: 10.5258, grad_norm: 514.6977
2023-08-29 16:43:50,695 - mmseg - INFO - Iter [10700/160000]	lr: 1.571e-06, eta: 1 day, 6:13:24, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0121, decode.loss_mask: 0.4400, decode.loss_dice: 0.4228, decode.d0.loss_cls: 0.7449, decode.d0.loss_mask: 0.4559, decode.d0.loss_dice: 0.4748, decode.d1.loss_cls: 0.0079, decode.d1.loss_mask: 0.4356, decode.d1.loss_dice: 0.4279, decode.d2.loss_cls: 0.0091, decode.d2.loss_mask: 0.4362, decode.d2.loss_dice: 0.4225, decode.d3.loss_cls: 0.0098, decode.d3.loss_mask: 0.4380, decode.d3.loss_dice: 0.4237, decode.d4.loss_cls: 0.0097, decode.d4.loss_mask: 0.4390, decode.d4.loss_dice: 0.4230, decode.d5.loss_cls: 0.0095, decode.d5.loss_mask: 0.4416, decode.d5.loss_dice: 0.4244, decode.d6.loss_cls: 0.0107, decode.d6.loss_mask: 0.4439, decode.d6.loss_dice: 0.4233, decode.d7.loss_cls: 0.0096, decode.d7.loss_mask: 0.4437, decode.d7.loss_dice: 0.4257, decode.d8.loss_cls: 0.0122, decode.d8.loss_mask: 0.4393, decode.d8.loss_dice: 0.4262, loss: 9.5430, grad_norm: 491.6306
2023-08-29 16:44:25,443 - mmseg - INFO - Iter [10750/160000]	lr: 1.570e-06, eta: 1 day, 6:12:24, time: 0.695, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.3910, decode.loss_dice: 0.4002, decode.d0.loss_cls: 0.7395, decode.d0.loss_mask: 0.4153, decode.d0.loss_dice: 0.4454, decode.d1.loss_cls: 0.0042, decode.d1.loss_mask: 0.3942, decode.d1.loss_dice: 0.4055, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.3894, decode.d2.loss_dice: 0.4012, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.3876, decode.d3.loss_dice: 0.3933, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.3896, decode.d4.loss_dice: 0.3990, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.3909, decode.d5.loss_dice: 0.3971, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.3877, decode.d6.loss_dice: 0.3994, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.3863, decode.d7.loss_dice: 0.3978, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.3882, decode.d8.loss_dice: 0.3986, loss: 8.7261, grad_norm: 393.0547
2023-08-29 16:45:01,682 - mmseg - INFO - Iter [10800/160000]	lr: 1.570e-06, eta: 1 day, 6:11:45, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0302, decode.loss_mask: 0.4850, decode.loss_dice: 0.4464, decode.d0.loss_cls: 0.7373, decode.d0.loss_mask: 0.4883, decode.d0.loss_dice: 0.4685, decode.d1.loss_cls: 0.0372, decode.d1.loss_mask: 0.4863, decode.d1.loss_dice: 0.4455, decode.d2.loss_cls: 0.0389, decode.d2.loss_mask: 0.4793, decode.d2.loss_dice: 0.4441, decode.d3.loss_cls: 0.0350, decode.d3.loss_mask: 0.4815, decode.d3.loss_dice: 0.4432, decode.d4.loss_cls: 0.0314, decode.d4.loss_mask: 0.4790, decode.d4.loss_dice: 0.4423, decode.d5.loss_cls: 0.0314, decode.d5.loss_mask: 0.4786, decode.d5.loss_dice: 0.4419, decode.d6.loss_cls: 0.0357, decode.d6.loss_mask: 0.4792, decode.d6.loss_dice: 0.4439, decode.d7.loss_cls: 0.0349, decode.d7.loss_mask: 0.4778, decode.d7.loss_dice: 0.4443, decode.d8.loss_cls: 0.0341, decode.d8.loss_mask: 0.4802, decode.d8.loss_dice: 0.4432, loss: 10.3246, grad_norm: 477.7869
2023-08-29 16:45:38,490 - mmseg - INFO - Iter [10850/160000]	lr: 1.569e-06, eta: 1 day, 6:11:13, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.3827, decode.loss_dice: 0.3852, decode.d0.loss_cls: 0.7279, decode.d0.loss_mask: 0.3972, decode.d0.loss_dice: 0.4202, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.3840, decode.d1.loss_dice: 0.3869, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.3838, decode.d2.loss_dice: 0.3864, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.3815, decode.d3.loss_dice: 0.3830, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.3829, decode.d4.loss_dice: 0.3854, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.3833, decode.d5.loss_dice: 0.3843, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.3824, decode.d6.loss_dice: 0.3848, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.3802, decode.d7.loss_dice: 0.3815, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.3835, decode.d8.loss_dice: 0.3824, loss: 8.4744, grad_norm: 398.0520
2023-08-29 16:46:15,574 - mmseg - INFO - Iter [10900/160000]	lr: 1.569e-06, eta: 1 day, 6:10:46, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0125, decode.loss_mask: 0.4103, decode.loss_dice: 0.4128, decode.d0.loss_cls: 0.7251, decode.d0.loss_mask: 0.4379, decode.d0.loss_dice: 0.4522, decode.d1.loss_cls: 0.0114, decode.d1.loss_mask: 0.4112, decode.d1.loss_dice: 0.4184, decode.d2.loss_cls: 0.0113, decode.d2.loss_mask: 0.4152, decode.d2.loss_dice: 0.4143, decode.d3.loss_cls: 0.0125, decode.d3.loss_mask: 0.4112, decode.d3.loss_dice: 0.4098, decode.d4.loss_cls: 0.0116, decode.d4.loss_mask: 0.4125, decode.d4.loss_dice: 0.4125, decode.d5.loss_cls: 0.0055, decode.d5.loss_mask: 0.4319, decode.d5.loss_dice: 0.4141, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 0.4113, decode.d6.loss_dice: 0.4147, decode.d7.loss_cls: 0.0128, decode.d7.loss_mask: 0.4135, decode.d7.loss_dice: 0.4138, decode.d8.loss_cls: 0.0136, decode.d8.loss_mask: 0.4122, decode.d8.loss_dice: 0.4131, loss: 9.1723, grad_norm: 484.2081
2023-08-29 16:46:50,359 - mmseg - INFO - Iter [10950/160000]	lr: 1.568e-06, eta: 1 day, 6:09:47, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.3772, decode.loss_dice: 0.3791, decode.d0.loss_cls: 0.7159, decode.d0.loss_mask: 0.4085, decode.d0.loss_dice: 0.4244, decode.d1.loss_cls: 0.0034, decode.d1.loss_mask: 0.3808, decode.d1.loss_dice: 0.3874, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.3767, decode.d2.loss_dice: 0.3793, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.3769, decode.d3.loss_dice: 0.3771, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3774, decode.d4.loss_dice: 0.3782, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3789, decode.d5.loss_dice: 0.3771, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.3793, decode.d6.loss_dice: 0.3770, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3756, decode.d7.loss_dice: 0.3763, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3752, decode.d8.loss_dice: 0.3768, loss: 8.3762, grad_norm: 406.8960
2023-08-29 16:47:26,853 - mmseg - INFO - Saving checkpoint at 11000 iterations
2023-08-29 16:47:29,745 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 16:47:29,745 - mmseg - INFO - Iter [11000/160000]	lr: 1.568e-06, eta: 1 day, 6:09:51, time: 0.788, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4202, decode.loss_dice: 0.4195, decode.d0.loss_cls: 0.7102, decode.d0.loss_mask: 0.4348, decode.d0.loss_dice: 0.4653, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.4149, decode.d1.loss_dice: 0.4259, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.4084, decode.d2.loss_dice: 0.4176, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4149, decode.d3.loss_dice: 0.4163, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4152, decode.d4.loss_dice: 0.4173, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.4169, decode.d5.loss_dice: 0.4215, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.4167, decode.d6.loss_dice: 0.4173, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.4186, decode.d7.loss_dice: 0.4211, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.4195, decode.d8.loss_dice: 0.4249, loss: 9.1563, grad_norm: 475.8556
2023-08-29 16:48:06,427 - mmseg - INFO - Iter [11050/160000]	lr: 1.567e-06, eta: 1 day, 6:09:18, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0136, decode.loss_mask: 0.4239, decode.loss_dice: 0.4079, decode.d0.loss_cls: 0.7064, decode.d0.loss_mask: 0.4465, decode.d0.loss_dice: 0.4516, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.4348, decode.d1.loss_dice: 0.4195, decode.d2.loss_cls: 0.0063, decode.d2.loss_mask: 0.4340, decode.d2.loss_dice: 0.4171, decode.d3.loss_cls: 0.0122, decode.d3.loss_mask: 0.4268, decode.d3.loss_dice: 0.4128, decode.d4.loss_cls: 0.0093, decode.d4.loss_mask: 0.4262, decode.d4.loss_dice: 0.4118, decode.d5.loss_cls: 0.0066, decode.d5.loss_mask: 0.4354, decode.d5.loss_dice: 0.4109, decode.d6.loss_cls: 0.0124, decode.d6.loss_mask: 0.4243, decode.d6.loss_dice: 0.4062, decode.d7.loss_cls: 0.0127, decode.d7.loss_mask: 0.4259, decode.d7.loss_dice: 0.4127, decode.d8.loss_cls: 0.0150, decode.d8.loss_mask: 0.4214, decode.d8.loss_dice: 0.4066, loss: 9.2589, grad_norm: 458.1852
2023-08-29 16:48:43,479 - mmseg - INFO - Iter [11100/160000]	lr: 1.566e-06, eta: 1 day, 6:08:49, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0149, decode.loss_mask: 0.4325, decode.loss_dice: 0.4266, decode.d0.loss_cls: 0.7034, decode.d0.loss_mask: 0.4507, decode.d0.loss_dice: 0.4722, decode.d1.loss_cls: 0.0208, decode.d1.loss_mask: 0.4152, decode.d1.loss_dice: 0.4349, decode.d2.loss_cls: 0.0203, decode.d2.loss_mask: 0.4125, decode.d2.loss_dice: 0.4287, decode.d3.loss_cls: 0.0191, decode.d3.loss_mask: 0.4212, decode.d3.loss_dice: 0.4295, decode.d4.loss_cls: 0.0195, decode.d4.loss_mask: 0.4148, decode.d4.loss_dice: 0.4278, decode.d5.loss_cls: 0.0216, decode.d5.loss_mask: 0.4096, decode.d5.loss_dice: 0.4246, decode.d6.loss_cls: 0.0230, decode.d6.loss_mask: 0.4150, decode.d6.loss_dice: 0.4197, decode.d7.loss_cls: 0.0222, decode.d7.loss_mask: 0.4140, decode.d7.loss_dice: 0.4234, decode.d8.loss_cls: 0.0201, decode.d8.loss_mask: 0.4158, decode.d8.loss_dice: 0.4249, loss: 9.3986, grad_norm: 474.8003
2023-08-29 16:49:18,380 - mmseg - INFO - Iter [11150/160000]	lr: 1.566e-06, eta: 1 day, 6:07:52, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0127, decode.loss_mask: 0.4411, decode.loss_dice: 0.4328, decode.d0.loss_cls: 0.6978, decode.d0.loss_mask: 0.4564, decode.d0.loss_dice: 0.4658, decode.d1.loss_cls: 0.0158, decode.d1.loss_mask: 0.4507, decode.d1.loss_dice: 0.4401, decode.d2.loss_cls: 0.0141, decode.d2.loss_mask: 0.4424, decode.d2.loss_dice: 0.4383, decode.d3.loss_cls: 0.0162, decode.d3.loss_mask: 0.4422, decode.d3.loss_dice: 0.4298, decode.d4.loss_cls: 0.0163, decode.d4.loss_mask: 0.4396, decode.d4.loss_dice: 0.4311, decode.d5.loss_cls: 0.0186, decode.d5.loss_mask: 0.4432, decode.d5.loss_dice: 0.4281, decode.d6.loss_cls: 0.0185, decode.d6.loss_mask: 0.4427, decode.d6.loss_dice: 0.4250, decode.d7.loss_cls: 0.0175, decode.d7.loss_mask: 0.4424, decode.d7.loss_dice: 0.4296, decode.d8.loss_cls: 0.0146, decode.d8.loss_mask: 0.4439, decode.d8.loss_dice: 0.4332, loss: 9.6405, grad_norm: 438.3039
2023-08-29 16:49:55,001 - mmseg - INFO - Iter [11200/160000]	lr: 1.565e-06, eta: 1 day, 6:07:18, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.3849, decode.loss_dice: 0.3862, decode.d0.loss_cls: 0.6898, decode.d0.loss_mask: 0.4094, decode.d0.loss_dice: 0.4215, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3830, decode.d1.loss_dice: 0.3863, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.3790, decode.d2.loss_dice: 0.3853, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3823, decode.d3.loss_dice: 0.3845, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.3818, decode.d4.loss_dice: 0.3841, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3806, decode.d5.loss_dice: 0.3822, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.3796, decode.d6.loss_dice: 0.3849, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3825, decode.d7.loss_dice: 0.3854, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.3825, decode.d8.loss_dice: 0.3846, loss: 8.4400, grad_norm: 450.3613
2023-08-29 16:50:31,722 - mmseg - INFO - Iter [11250/160000]	lr: 1.565e-06, eta: 1 day, 6:06:46, time: 0.735, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.3826, decode.loss_dice: 0.3809, decode.d0.loss_cls: 0.6868, decode.d0.loss_mask: 0.4169, decode.d0.loss_dice: 0.4232, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3964, decode.d1.loss_dice: 0.3952, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.3888, decode.d2.loss_dice: 0.3831, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.3841, decode.d3.loss_dice: 0.3797, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3845, decode.d4.loss_dice: 0.3790, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3863, decode.d5.loss_dice: 0.3768, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.3859, decode.d6.loss_dice: 0.3802, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.3820, decode.d7.loss_dice: 0.3813, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.3819, decode.d8.loss_dice: 0.3796, loss: 8.4553, grad_norm: 482.5532
2023-08-29 16:51:08,944 - mmseg - INFO - Iter [11300/160000]	lr: 1.564e-06, eta: 1 day, 6:06:19, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0246, decode.loss_mask: 0.4236, decode.loss_dice: 0.4311, decode.d0.loss_cls: 0.6834, decode.d0.loss_mask: 0.4514, decode.d0.loss_dice: 0.4759, decode.d1.loss_cls: 0.0300, decode.d1.loss_mask: 0.4216, decode.d1.loss_dice: 0.4405, decode.d2.loss_cls: 0.0302, decode.d2.loss_mask: 0.4211, decode.d2.loss_dice: 0.4361, decode.d3.loss_cls: 0.0259, decode.d3.loss_mask: 0.4240, decode.d3.loss_dice: 0.4327, decode.d4.loss_cls: 0.0234, decode.d4.loss_mask: 0.4264, decode.d4.loss_dice: 0.4348, decode.d5.loss_cls: 0.0256, decode.d5.loss_mask: 0.4254, decode.d5.loss_dice: 0.4338, decode.d6.loss_cls: 0.0253, decode.d6.loss_mask: 0.4223, decode.d6.loss_dice: 0.4283, decode.d7.loss_cls: 0.0265, decode.d7.loss_mask: 0.4251, decode.d7.loss_dice: 0.4291, decode.d8.loss_cls: 0.0241, decode.d8.loss_mask: 0.4225, decode.d8.loss_dice: 0.4313, loss: 9.5560, grad_norm: 397.7051
2023-08-29 16:51:43,978 - mmseg - INFO - Iter [11350/160000]	lr: 1.564e-06, eta: 1 day, 6:05:24, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.3905, decode.loss_dice: 0.3873, decode.d0.loss_cls: 0.6742, decode.d0.loss_mask: 0.4108, decode.d0.loss_dice: 0.4343, decode.d1.loss_cls: 0.0025, decode.d1.loss_mask: 0.3897, decode.d1.loss_dice: 0.3968, decode.d2.loss_cls: 0.0020, decode.d2.loss_mask: 0.3869, decode.d2.loss_dice: 0.3908, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.3888, decode.d3.loss_dice: 0.3845, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.3860, decode.d4.loss_dice: 0.3850, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3881, decode.d5.loss_dice: 0.3839, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3875, decode.d6.loss_dice: 0.3836, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3893, decode.d7.loss_dice: 0.3870, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.3900, decode.d8.loss_dice: 0.3896, loss: 8.5191, grad_norm: 472.9162
2023-08-29 16:52:20,839 - mmseg - INFO - Iter [11400/160000]	lr: 1.563e-06, eta: 1 day, 6:04:54, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.3950, decode.loss_dice: 0.3976, decode.d0.loss_cls: 0.6697, decode.d0.loss_mask: 0.4362, decode.d0.loss_dice: 0.4473, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.3996, decode.d1.loss_dice: 0.3990, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.3974, decode.d2.loss_dice: 0.4028, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.3954, decode.d3.loss_dice: 0.3973, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.3936, decode.d4.loss_dice: 0.3940, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3977, decode.d5.loss_dice: 0.3954, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.3958, decode.d6.loss_dice: 0.3961, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.3974, decode.d7.loss_dice: 0.3976, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.3968, decode.d8.loss_dice: 0.3984, loss: 8.7209, grad_norm: 499.2578
2023-08-29 16:52:57,339 - mmseg - INFO - Iter [11450/160000]	lr: 1.563e-06, eta: 1 day, 6:04:18, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0326, decode.loss_mask: 0.4594, decode.loss_dice: 0.4219, decode.d0.loss_cls: 0.6706, decode.d0.loss_mask: 0.4760, decode.d0.loss_dice: 0.4746, decode.d1.loss_cls: 0.0319, decode.d1.loss_mask: 0.4592, decode.d1.loss_dice: 0.4365, decode.d2.loss_cls: 0.0297, decode.d2.loss_mask: 0.4546, decode.d2.loss_dice: 0.4259, decode.d3.loss_cls: 0.0294, decode.d3.loss_mask: 0.4497, decode.d3.loss_dice: 0.4175, decode.d4.loss_cls: 0.0268, decode.d4.loss_mask: 0.4536, decode.d4.loss_dice: 0.4209, decode.d5.loss_cls: 0.0289, decode.d5.loss_mask: 0.4574, decode.d5.loss_dice: 0.4200, decode.d6.loss_cls: 0.0323, decode.d6.loss_mask: 0.4584, decode.d6.loss_dice: 0.4165, decode.d7.loss_cls: 0.0311, decode.d7.loss_mask: 0.4592, decode.d7.loss_dice: 0.4217, decode.d8.loss_cls: 0.0320, decode.d8.loss_mask: 0.4564, decode.d8.loss_dice: 0.4217, loss: 9.8063, grad_norm: 450.7298
2023-08-29 16:53:34,552 - mmseg - INFO - Iter [11500/160000]	lr: 1.562e-06, eta: 1 day, 6:03:51, time: 0.744, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0088, decode.loss_mask: 0.4129, decode.loss_dice: 0.3975, decode.d0.loss_cls: 0.6612, decode.d0.loss_mask: 0.4131, decode.d0.loss_dice: 0.4319, decode.d1.loss_cls: 0.0145, decode.d1.loss_mask: 0.3845, decode.d1.loss_dice: 0.3998, decode.d2.loss_cls: 0.0128, decode.d2.loss_mask: 0.3903, decode.d2.loss_dice: 0.3919, decode.d3.loss_cls: 0.0081, decode.d3.loss_mask: 0.4127, decode.d3.loss_dice: 0.3954, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.4177, decode.d4.loss_dice: 0.4001, decode.d5.loss_cls: 0.0158, decode.d5.loss_mask: 0.3886, decode.d5.loss_dice: 0.3967, decode.d6.loss_cls: 0.0164, decode.d6.loss_mask: 0.3910, decode.d6.loss_dice: 0.3955, decode.d7.loss_cls: 0.0154, decode.d7.loss_mask: 0.3941, decode.d7.loss_dice: 0.3972, decode.d8.loss_cls: 0.0152, decode.d8.loss_mask: 0.3914, decode.d8.loss_dice: 0.3991, loss: 8.7774, grad_norm: 440.6622
2023-08-29 16:54:09,452 - mmseg - INFO - Iter [11550/160000]	lr: 1.562e-06, eta: 1 day, 6:02:55, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.3878, decode.loss_dice: 0.3881, decode.d0.loss_cls: 0.6545, decode.d0.loss_mask: 0.4041, decode.d0.loss_dice: 0.4229, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.3842, decode.d1.loss_dice: 0.3943, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.3862, decode.d2.loss_dice: 0.3905, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.3890, decode.d3.loss_dice: 0.3933, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3886, decode.d4.loss_dice: 0.3934, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.3876, decode.d5.loss_dice: 0.3886, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.3900, decode.d6.loss_dice: 0.3873, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.3903, decode.d7.loss_dice: 0.3856, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.3894, decode.d8.loss_dice: 0.3869, loss: 8.5063, grad_norm: 427.4244
2023-08-29 16:54:46,277 - mmseg - INFO - Iter [11600/160000]	lr: 1.561e-06, eta: 1 day, 6:02:24, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.3935, decode.loss_dice: 0.3989, decode.d0.loss_cls: 0.6510, decode.d0.loss_mask: 0.4214, decode.d0.loss_dice: 0.4369, decode.d1.loss_cls: 0.0029, decode.d1.loss_mask: 0.3934, decode.d1.loss_dice: 0.4005, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3948, decode.d2.loss_dice: 0.3999, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3951, decode.d3.loss_dice: 0.3960, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.3914, decode.d4.loss_dice: 0.3941, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.3947, decode.d5.loss_dice: 0.3977, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.3936, decode.d6.loss_dice: 0.3979, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.3935, decode.d7.loss_dice: 0.3952, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.3922, decode.d8.loss_dice: 0.4003, loss: 8.6533, grad_norm: 403.9206
2023-08-29 16:55:22,604 - mmseg - INFO - Iter [11650/160000]	lr: 1.561e-06, eta: 1 day, 6:01:46, time: 0.727, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.3860, decode.loss_dice: 0.3790, decode.d0.loss_cls: 0.6442, decode.d0.loss_mask: 0.3967, decode.d0.loss_dice: 0.4217, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.3821, decode.d1.loss_dice: 0.3813, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3783, decode.d2.loss_dice: 0.3809, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3779, decode.d3.loss_dice: 0.3784, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.3834, decode.d4.loss_dice: 0.3802, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.3823, decode.d5.loss_dice: 0.3780, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.3823, decode.d6.loss_dice: 0.3779, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.3868, decode.d7.loss_dice: 0.3789, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.3856, decode.d8.loss_dice: 0.3808, loss: 8.3429, grad_norm: 437.5319
2023-08-29 16:55:59,868 - mmseg - INFO - Iter [11700/160000]	lr: 1.560e-06, eta: 1 day, 6:01:20, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0071, decode.loss_mask: 0.4007, decode.loss_dice: 0.4054, decode.d0.loss_cls: 0.6393, decode.d0.loss_mask: 0.4197, decode.d0.loss_dice: 0.4502, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.3979, decode.d1.loss_dice: 0.4114, decode.d2.loss_cls: 0.0074, decode.d2.loss_mask: 0.4017, decode.d2.loss_dice: 0.4058, decode.d3.loss_cls: 0.0065, decode.d3.loss_mask: 0.3982, decode.d3.loss_dice: 0.4058, decode.d4.loss_cls: 0.0064, decode.d4.loss_mask: 0.3969, decode.d4.loss_dice: 0.4028, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.3972, decode.d5.loss_dice: 0.4042, decode.d6.loss_cls: 0.0073, decode.d6.loss_mask: 0.3988, decode.d6.loss_dice: 0.4043, decode.d7.loss_cls: 0.0066, decode.d7.loss_mask: 0.3957, decode.d7.loss_dice: 0.4028, decode.d8.loss_cls: 0.0070, decode.d8.loss_mask: 0.3995, decode.d8.loss_dice: 0.4034, loss: 8.8048, grad_norm: 411.0006
2023-08-29 16:56:36,865 - mmseg - INFO - Iter [11750/160000]	lr: 1.560e-06, eta: 1 day, 6:00:51, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0208, decode.loss_mask: 0.4021, decode.loss_dice: 0.4090, decode.d0.loss_cls: 0.6381, decode.d0.loss_mask: 0.4096, decode.d0.loss_dice: 0.4438, decode.d1.loss_cls: 0.0211, decode.d1.loss_mask: 0.3982, decode.d1.loss_dice: 0.4126, decode.d2.loss_cls: 0.0144, decode.d2.loss_mask: 0.4135, decode.d2.loss_dice: 0.4158, decode.d3.loss_cls: 0.0218, decode.d3.loss_mask: 0.3969, decode.d3.loss_dice: 0.4099, decode.d4.loss_cls: 0.0223, decode.d4.loss_mask: 0.3976, decode.d4.loss_dice: 0.4093, decode.d5.loss_cls: 0.0201, decode.d5.loss_mask: 0.4040, decode.d5.loss_dice: 0.4088, decode.d6.loss_cls: 0.0213, decode.d6.loss_mask: 0.4010, decode.d6.loss_dice: 0.4145, decode.d7.loss_cls: 0.0220, decode.d7.loss_mask: 0.4012, decode.d7.loss_dice: 0.4103, decode.d8.loss_cls: 0.0225, decode.d8.loss_mask: 0.3993, decode.d8.loss_dice: 0.4101, loss: 8.9921, grad_norm: 473.4581
2023-08-29 16:57:11,529 - mmseg - INFO - Iter [11800/160000]	lr: 1.559e-06, eta: 1 day, 5:59:52, time: 0.693, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.3982, decode.loss_dice: 0.3913, decode.d0.loss_cls: 0.6298, decode.d0.loss_mask: 0.4072, decode.d0.loss_dice: 0.4183, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.3949, decode.d1.loss_dice: 0.3932, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.3834, decode.d2.loss_dice: 0.3836, decode.d3.loss_cls: 0.0054, decode.d3.loss_mask: 0.3842, decode.d3.loss_dice: 0.3869, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.3843, decode.d4.loss_dice: 0.3904, decode.d5.loss_cls: 0.0054, decode.d5.loss_mask: 0.3862, decode.d5.loss_dice: 0.3866, decode.d6.loss_cls: 0.0054, decode.d6.loss_mask: 0.3805, decode.d6.loss_dice: 0.3896, decode.d7.loss_cls: 0.0081, decode.d7.loss_mask: 0.3859, decode.d7.loss_dice: 0.3823, decode.d8.loss_cls: 0.0075, decode.d8.loss_mask: 0.3837, decode.d8.loss_dice: 0.3833, loss: 8.4741, grad_norm: 382.8042
2023-08-29 16:57:47,957 - mmseg - INFO - Iter [11850/160000]	lr: 1.559e-06, eta: 1 day, 5:59:15, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.4125, decode.loss_dice: 0.4027, decode.d0.loss_cls: 0.6249, decode.d0.loss_mask: 0.4294, decode.d0.loss_dice: 0.4316, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4152, decode.d1.loss_dice: 0.4043, decode.d2.loss_cls: 0.0036, decode.d2.loss_mask: 0.4121, decode.d2.loss_dice: 0.4011, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.4129, decode.d3.loss_dice: 0.4004, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.4144, decode.d4.loss_dice: 0.4017, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4121, decode.d5.loss_dice: 0.3991, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.4104, decode.d6.loss_dice: 0.4005, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.4111, decode.d7.loss_dice: 0.4021, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.4124, decode.d8.loss_dice: 0.3998, loss: 8.8383, grad_norm: 370.8616
2023-08-29 16:58:24,931 - mmseg - INFO - Iter [11900/160000]	lr: 1.558e-06, eta: 1 day, 5:58:46, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.3778, decode.loss_dice: 0.3837, decode.d0.loss_cls: 0.6186, decode.d0.loss_mask: 0.3999, decode.d0.loss_dice: 0.4151, decode.d1.loss_cls: 0.0019, decode.d1.loss_mask: 0.3822, decode.d1.loss_dice: 0.3876, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.3808, decode.d2.loss_dice: 0.3863, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3812, decode.d3.loss_dice: 0.3805, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.3791, decode.d4.loss_dice: 0.3799, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.3772, decode.d5.loss_dice: 0.3811, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.3735, decode.d6.loss_dice: 0.3787, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.3763, decode.d7.loss_dice: 0.3807, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3782, decode.d8.loss_dice: 0.3811, loss: 8.2894, grad_norm: 381.8021
2023-08-29 16:59:02,053 - mmseg - INFO - Iter [11950/160000]	lr: 1.558e-06, eta: 1 day, 5:58:18, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0075, decode.loss_mask: 0.4007, decode.loss_dice: 0.3903, decode.d0.loss_cls: 0.6155, decode.d0.loss_mask: 0.4149, decode.d0.loss_dice: 0.4416, decode.d1.loss_cls: 0.0084, decode.d1.loss_mask: 0.4076, decode.d1.loss_dice: 0.4029, decode.d2.loss_cls: 0.0068, decode.d2.loss_mask: 0.4046, decode.d2.loss_dice: 0.3911, decode.d3.loss_cls: 0.0086, decode.d3.loss_mask: 0.3974, decode.d3.loss_dice: 0.3884, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.3988, decode.d4.loss_dice: 0.3898, decode.d5.loss_cls: 0.0063, decode.d5.loss_mask: 0.3988, decode.d5.loss_dice: 0.3889, decode.d6.loss_cls: 0.0097, decode.d6.loss_mask: 0.4007, decode.d6.loss_dice: 0.3888, decode.d7.loss_cls: 0.0063, decode.d7.loss_mask: 0.3957, decode.d7.loss_dice: 0.3888, decode.d8.loss_cls: 0.0111, decode.d8.loss_mask: 0.3993, decode.d8.loss_dice: 0.3896, loss: 8.6662, grad_norm: 457.1183
2023-08-29 16:59:36,568 - mmseg - INFO - Saving checkpoint at 12000 iterations
2023-08-29 16:59:39,583 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 16:59:39,583 - mmseg - INFO - Iter [12000/160000]	lr: 1.557e-06, eta: 1 day, 5:57:55, time: 0.751, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0055, decode.loss_mask: 0.3662, decode.loss_dice: 0.3566, decode.d0.loss_cls: 0.6089, decode.d0.loss_mask: 0.3897, decode.d0.loss_dice: 0.3990, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3756, decode.d1.loss_dice: 0.3722, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3697, decode.d2.loss_dice: 0.3613, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.3617, decode.d3.loss_dice: 0.3571, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.3634, decode.d4.loss_dice: 0.3566, decode.d5.loss_cls: 0.0051, decode.d5.loss_mask: 0.3613, decode.d5.loss_dice: 0.3549, decode.d6.loss_cls: 0.0058, decode.d6.loss_mask: 0.3646, decode.d6.loss_dice: 0.3552, decode.d7.loss_cls: 0.0066, decode.d7.loss_mask: 0.3623, decode.d7.loss_dice: 0.3546, decode.d8.loss_cls: 0.0069, decode.d8.loss_mask: 0.3641, decode.d8.loss_dice: 0.3543, loss: 7.9578, grad_norm: 397.6145
2023-08-29 17:00:16,166 - mmseg - INFO - Iter [12050/160000]	lr: 1.556e-06, eta: 1 day, 5:57:20, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0056, decode.loss_mask: 0.3947, decode.loss_dice: 0.3836, decode.d0.loss_cls: 0.6054, decode.d0.loss_mask: 0.4272, decode.d0.loss_dice: 0.4259, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.4060, decode.d1.loss_dice: 0.3945, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.3967, decode.d2.loss_dice: 0.3926, decode.d3.loss_cls: 0.0068, decode.d3.loss_mask: 0.3943, decode.d3.loss_dice: 0.3846, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.3954, decode.d4.loss_dice: 0.3850, decode.d5.loss_cls: 0.0057, decode.d5.loss_mask: 0.3938, decode.d5.loss_dice: 0.3829, decode.d6.loss_cls: 0.0054, decode.d6.loss_mask: 0.3927, decode.d6.loss_dice: 0.3763, decode.d7.loss_cls: 0.0068, decode.d7.loss_mask: 0.3964, decode.d7.loss_dice: 0.3804, decode.d8.loss_cls: 0.0062, decode.d8.loss_mask: 0.3949, decode.d8.loss_dice: 0.3785, loss: 8.5341, grad_norm: 506.4305
2023-08-29 17:00:53,085 - mmseg - INFO - Iter [12100/160000]	lr: 1.556e-06, eta: 1 day, 5:56:49, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3832, decode.loss_dice: 0.3954, decode.d0.loss_cls: 0.6001, decode.d0.loss_mask: 0.3929, decode.d0.loss_dice: 0.4190, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.3865, decode.d1.loss_dice: 0.3997, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3863, decode.d2.loss_dice: 0.3957, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.3846, decode.d3.loss_dice: 0.3944, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3844, decode.d4.loss_dice: 0.3971, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.3836, decode.d5.loss_dice: 0.3969, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3837, decode.d6.loss_dice: 0.3960, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3822, decode.d7.loss_dice: 0.3953, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3836, decode.d8.loss_dice: 0.3978, loss: 8.4547, grad_norm: 458.2622
2023-08-29 17:01:30,407 - mmseg - INFO - Iter [12150/160000]	lr: 1.555e-06, eta: 1 day, 5:56:24, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.4157, decode.loss_dice: 0.4517, decode.d0.loss_cls: 0.5981, decode.d0.loss_mask: 0.4353, decode.d0.loss_dice: 0.4801, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.4164, decode.d1.loss_dice: 0.4520, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.4159, decode.d2.loss_dice: 0.4492, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4146, decode.d3.loss_dice: 0.4447, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.4184, decode.d4.loss_dice: 0.4490, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4191, decode.d5.loss_dice: 0.4482, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.4189, decode.d6.loss_dice: 0.4496, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.4169, decode.d7.loss_dice: 0.4479, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4183, decode.d8.loss_dice: 0.4476, loss: 9.3272, grad_norm: 470.1348
2023-08-29 17:02:05,138 - mmseg - INFO - Iter [12200/160000]	lr: 1.555e-06, eta: 1 day, 5:55:26, time: 0.694, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.4299, decode.loss_dice: 0.4291, decode.d0.loss_cls: 0.5919, decode.d0.loss_mask: 0.4431, decode.d0.loss_dice: 0.4537, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.4332, decode.d1.loss_dice: 0.4272, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.4290, decode.d2.loss_dice: 0.4248, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.4142, decode.d3.loss_dice: 0.4228, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.4184, decode.d4.loss_dice: 0.4261, decode.d5.loss_cls: 0.0087, decode.d5.loss_mask: 0.4175, decode.d5.loss_dice: 0.4237, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 0.4177, decode.d6.loss_dice: 0.4229, decode.d7.loss_cls: 0.0094, decode.d7.loss_mask: 0.4154, decode.d7.loss_dice: 0.4211, decode.d8.loss_cls: 0.0092, decode.d8.loss_mask: 0.4161, decode.d8.loss_dice: 0.4254, loss: 9.1545, grad_norm: 411.0224
2023-08-29 17:02:41,823 - mmseg - INFO - Iter [12250/160000]	lr: 1.554e-06, eta: 1 day, 5:54:52, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0064, decode.loss_mask: 0.3940, decode.loss_dice: 0.3803, decode.d0.loss_cls: 0.5879, decode.d0.loss_mask: 0.4292, decode.d0.loss_dice: 0.4201, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.3981, decode.d1.loss_dice: 0.3913, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.3948, decode.d2.loss_dice: 0.3842, decode.d3.loss_cls: 0.0075, decode.d3.loss_mask: 0.3946, decode.d3.loss_dice: 0.3728, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.3959, decode.d4.loss_dice: 0.3754, decode.d5.loss_cls: 0.0073, decode.d5.loss_mask: 0.3963, decode.d5.loss_dice: 0.3769, decode.d6.loss_cls: 0.0067, decode.d6.loss_mask: 0.3964, decode.d6.loss_dice: 0.3797, decode.d7.loss_cls: 0.0069, decode.d7.loss_mask: 0.3944, decode.d7.loss_dice: 0.3770, decode.d8.loss_cls: 0.0061, decode.d8.loss_mask: 0.3954, decode.d8.loss_dice: 0.3759, loss: 8.4657, grad_norm: 389.9902
2023-08-29 17:03:18,632 - mmseg - INFO - Iter [12300/160000]	lr: 1.554e-06, eta: 1 day, 5:54:21, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0291, decode.loss_mask: 0.4106, decode.loss_dice: 0.3928, decode.d0.loss_cls: 0.5871, decode.d0.loss_mask: 0.4061, decode.d0.loss_dice: 0.4327, decode.d1.loss_cls: 0.0362, decode.d1.loss_mask: 0.3959, decode.d1.loss_dice: 0.3940, decode.d2.loss_cls: 0.0244, decode.d2.loss_mask: 0.4110, decode.d2.loss_dice: 0.3959, decode.d3.loss_cls: 0.0251, decode.d3.loss_mask: 0.4176, decode.d3.loss_dice: 0.3972, decode.d4.loss_cls: 0.0234, decode.d4.loss_mask: 0.4168, decode.d4.loss_dice: 0.3958, decode.d5.loss_cls: 0.0227, decode.d5.loss_mask: 0.4187, decode.d5.loss_dice: 0.3944, decode.d6.loss_cls: 0.0272, decode.d6.loss_mask: 0.4172, decode.d6.loss_dice: 0.3934, decode.d7.loss_cls: 0.0248, decode.d7.loss_mask: 0.4118, decode.d7.loss_dice: 0.3916, decode.d8.loss_cls: 0.0256, decode.d8.loss_mask: 0.4139, decode.d8.loss_dice: 0.3935, loss: 8.9263, grad_norm: 450.9348
2023-08-29 17:03:55,818 - mmseg - INFO - Iter [12350/160000]	lr: 1.553e-06, eta: 1 day, 5:53:53, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.3625, decode.loss_dice: 0.3564, decode.d0.loss_cls: 0.5768, decode.d0.loss_mask: 0.3712, decode.d0.loss_dice: 0.3911, decode.d1.loss_cls: 0.0029, decode.d1.loss_mask: 0.3655, decode.d1.loss_dice: 0.3572, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.3619, decode.d2.loss_dice: 0.3552, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.3604, decode.d3.loss_dice: 0.3535, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.3624, decode.d4.loss_dice: 0.3551, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.3634, decode.d5.loss_dice: 0.3533, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.3646, decode.d6.loss_dice: 0.3530, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.3640, decode.d7.loss_dice: 0.3527, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.3633, decode.d8.loss_dice: 0.3537, loss: 7.8198, grad_norm: 450.2085
2023-08-29 17:04:30,571 - mmseg - INFO - Iter [12400/160000]	lr: 1.553e-06, eta: 1 day, 5:52:56, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.4278, decode.loss_dice: 0.4151, decode.d0.loss_cls: 0.5759, decode.d0.loss_mask: 0.4393, decode.d0.loss_dice: 0.4450, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.4345, decode.d1.loss_dice: 0.4145, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.4276, decode.d2.loss_dice: 0.4093, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4331, decode.d3.loss_dice: 0.4106, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4282, decode.d4.loss_dice: 0.4087, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4277, decode.d5.loss_dice: 0.4095, decode.d6.loss_cls: 0.0070, decode.d6.loss_mask: 0.4241, decode.d6.loss_dice: 0.4088, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4294, decode.d7.loss_dice: 0.4094, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.4308, decode.d8.loss_dice: 0.4160, loss: 9.0521, grad_norm: 459.5801
2023-08-29 17:05:06,971 - mmseg - INFO - Iter [12450/160000]	lr: 1.552e-06, eta: 1 day, 5:52:19, time: 0.728, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0310, decode.loss_mask: 0.4122, decode.loss_dice: 0.3932, decode.d0.loss_cls: 0.5737, decode.d0.loss_mask: 0.4357, decode.d0.loss_dice: 0.4314, decode.d1.loss_cls: 0.0293, decode.d1.loss_mask: 0.4052, decode.d1.loss_dice: 0.3889, decode.d2.loss_cls: 0.0254, decode.d2.loss_mask: 0.4042, decode.d2.loss_dice: 0.3895, decode.d3.loss_cls: 0.0233, decode.d3.loss_mask: 0.4048, decode.d3.loss_dice: 0.3925, decode.d4.loss_cls: 0.0232, decode.d4.loss_mask: 0.4079, decode.d4.loss_dice: 0.3912, decode.d5.loss_cls: 0.0266, decode.d5.loss_mask: 0.4036, decode.d5.loss_dice: 0.3903, decode.d6.loss_cls: 0.0306, decode.d6.loss_mask: 0.4066, decode.d6.loss_dice: 0.3888, decode.d7.loss_cls: 0.0282, decode.d7.loss_mask: 0.4037, decode.d7.loss_dice: 0.3851, decode.d8.loss_cls: 0.0315, decode.d8.loss_mask: 0.4040, decode.d8.loss_dice: 0.3881, loss: 8.8499, grad_norm: 427.9052
2023-08-29 17:05:43,688 - mmseg - INFO - Iter [12500/160000]	lr: 1.552e-06, eta: 1 day, 5:51:46, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4141, decode.loss_dice: 0.4017, decode.d0.loss_cls: 0.5654, decode.d0.loss_mask: 0.3980, decode.d0.loss_dice: 0.4393, decode.d1.loss_cls: 0.0090, decode.d1.loss_mask: 0.4001, decode.d1.loss_dice: 0.4041, decode.d2.loss_cls: 0.0131, decode.d2.loss_mask: 0.3893, decode.d2.loss_dice: 0.4052, decode.d3.loss_cls: 0.0101, decode.d3.loss_mask: 0.3937, decode.d3.loss_dice: 0.3970, decode.d4.loss_cls: 0.0099, decode.d4.loss_mask: 0.3930, decode.d4.loss_dice: 0.4002, decode.d5.loss_cls: 0.0103, decode.d5.loss_mask: 0.3972, decode.d5.loss_dice: 0.4041, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.4147, decode.d6.loss_dice: 0.4061, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.4107, decode.d7.loss_dice: 0.4055, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.4121, decode.d8.loss_dice: 0.4035, loss: 8.7197, grad_norm: 422.1322
2023-08-29 17:06:20,709 - mmseg - INFO - Iter [12550/160000]	lr: 1.551e-06, eta: 1 day, 5:51:17, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.3712, decode.loss_dice: 0.3793, decode.d0.loss_cls: 0.5612, decode.d0.loss_mask: 0.3766, decode.d0.loss_dice: 0.4103, decode.d1.loss_cls: 0.0029, decode.d1.loss_mask: 0.3761, decode.d1.loss_dice: 0.3786, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.3743, decode.d2.loss_dice: 0.3784, decode.d3.loss_cls: 0.0086, decode.d3.loss_mask: 0.3582, decode.d3.loss_dice: 0.3706, decode.d4.loss_cls: 0.0082, decode.d4.loss_mask: 0.3615, decode.d4.loss_dice: 0.3708, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.3743, decode.d5.loss_dice: 0.3765, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.3730, decode.d6.loss_dice: 0.3758, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.3706, decode.d7.loss_dice: 0.3775, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.3728, decode.d8.loss_dice: 0.3806, loss: 8.1052, grad_norm: 361.9279
2023-08-29 17:06:55,772 - mmseg - INFO - Iter [12600/160000]	lr: 1.551e-06, eta: 1 day, 5:50:24, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.3678, decode.loss_dice: 0.3577, decode.d0.loss_cls: 0.5546, decode.d0.loss_mask: 0.3822, decode.d0.loss_dice: 0.3950, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.3706, decode.d1.loss_dice: 0.3641, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.3681, decode.d2.loss_dice: 0.3605, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3704, decode.d3.loss_dice: 0.3603, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.3677, decode.d4.loss_dice: 0.3584, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.3717, decode.d5.loss_dice: 0.3603, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.3681, decode.d6.loss_dice: 0.3581, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.3646, decode.d7.loss_dice: 0.3585, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.3654, decode.d8.loss_dice: 0.3573, loss: 7.9005, grad_norm: 391.6591
2023-08-29 17:07:32,231 - mmseg - INFO - Iter [12650/160000]	lr: 1.550e-06, eta: 1 day, 5:49:48, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0012, decode.loss_mask: 0.4164, decode.loss_dice: 0.4014, decode.d0.loss_cls: 0.5499, decode.d0.loss_mask: 0.4335, decode.d0.loss_dice: 0.4248, decode.d1.loss_cls: 0.0021, decode.d1.loss_mask: 0.4144, decode.d1.loss_dice: 0.4004, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.4135, decode.d2.loss_dice: 0.3980, decode.d3.loss_cls: 0.0068, decode.d3.loss_mask: 0.4069, decode.d3.loss_dice: 0.3924, decode.d4.loss_cls: 0.0077, decode.d4.loss_mask: 0.4031, decode.d4.loss_dice: 0.3921, decode.d5.loss_cls: 0.0089, decode.d5.loss_mask: 0.4072, decode.d5.loss_dice: 0.3923, decode.d6.loss_cls: 0.0081, decode.d6.loss_mask: 0.4066, decode.d6.loss_dice: 0.3915, decode.d7.loss_cls: 0.0077, decode.d7.loss_mask: 0.4068, decode.d7.loss_dice: 0.3974, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.4130, decode.d8.loss_dice: 0.3991, loss: 8.7062, grad_norm: 464.6535
2023-08-29 17:08:08,803 - mmseg - INFO - Iter [12700/160000]	lr: 1.550e-06, eta: 1 day, 5:49:13, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0165, decode.loss_mask: 0.4107, decode.loss_dice: 0.4147, decode.d0.loss_cls: 0.5498, decode.d0.loss_mask: 0.4249, decode.d0.loss_dice: 0.4509, decode.d1.loss_cls: 0.0141, decode.d1.loss_mask: 0.4055, decode.d1.loss_dice: 0.4184, decode.d2.loss_cls: 0.0120, decode.d2.loss_mask: 0.4000, decode.d2.loss_dice: 0.4135, decode.d3.loss_cls: 0.0107, decode.d3.loss_mask: 0.4001, decode.d3.loss_dice: 0.4090, decode.d4.loss_cls: 0.0112, decode.d4.loss_mask: 0.4011, decode.d4.loss_dice: 0.4115, decode.d5.loss_cls: 0.0121, decode.d5.loss_mask: 0.4024, decode.d5.loss_dice: 0.4082, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 0.4053, decode.d6.loss_dice: 0.4157, decode.d7.loss_cls: 0.0148, decode.d7.loss_mask: 0.4055, decode.d7.loss_dice: 0.4151, decode.d8.loss_cls: 0.0150, decode.d8.loss_mask: 0.4107, decode.d8.loss_dice: 0.4141, loss: 8.9064, grad_norm: 560.6719
2023-08-29 17:08:45,883 - mmseg - INFO - Iter [12750/160000]	lr: 1.549e-06, eta: 1 day, 5:48:44, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0174, decode.loss_mask: 0.3864, decode.loss_dice: 0.3908, decode.d0.loss_cls: 0.5439, decode.d0.loss_mask: 0.4031, decode.d0.loss_dice: 0.4354, decode.d1.loss_cls: 0.0140, decode.d1.loss_mask: 0.3880, decode.d1.loss_dice: 0.3995, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.3865, decode.d2.loss_dice: 0.3967, decode.d3.loss_cls: 0.0111, decode.d3.loss_mask: 0.3839, decode.d3.loss_dice: 0.3930, decode.d4.loss_cls: 0.0099, decode.d4.loss_mask: 0.3839, decode.d4.loss_dice: 0.3900, decode.d5.loss_cls: 0.0152, decode.d5.loss_mask: 0.3840, decode.d5.loss_dice: 0.3931, decode.d6.loss_cls: 0.0166, decode.d6.loss_mask: 0.3889, decode.d6.loss_dice: 0.3915, decode.d7.loss_cls: 0.0162, decode.d7.loss_mask: 0.3853, decode.d7.loss_dice: 0.3910, decode.d8.loss_cls: 0.0176, decode.d8.loss_mask: 0.3864, decode.d8.loss_dice: 0.3902, loss: 8.5289, grad_norm: 411.3121
2023-08-29 17:09:20,891 - mmseg - INFO - Iter [12800/160000]	lr: 1.549e-06, eta: 1 day, 5:47:51, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.3670, decode.loss_dice: 0.3554, decode.d0.loss_cls: 0.5382, decode.d0.loss_mask: 0.3677, decode.d0.loss_dice: 0.3878, decode.d1.loss_cls: 0.0079, decode.d1.loss_mask: 0.3550, decode.d1.loss_dice: 0.3577, decode.d2.loss_cls: 0.0072, decode.d2.loss_mask: 0.3564, decode.d2.loss_dice: 0.3575, decode.d3.loss_cls: 0.0087, decode.d3.loss_mask: 0.3566, decode.d3.loss_dice: 0.3554, decode.d4.loss_cls: 0.0087, decode.d4.loss_mask: 0.3550, decode.d4.loss_dice: 0.3576, decode.d5.loss_cls: 0.0082, decode.d5.loss_mask: 0.3571, decode.d5.loss_dice: 0.3546, decode.d6.loss_cls: 0.0077, decode.d6.loss_mask: 0.3571, decode.d6.loss_dice: 0.3540, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.3559, decode.d7.loss_dice: 0.3566, decode.d8.loss_cls: 0.0086, decode.d8.loss_mask: 0.3538, decode.d8.loss_dice: 0.3537, loss: 7.7766, grad_norm: 417.8969
2023-08-29 17:09:57,806 - mmseg - INFO - Iter [12850/160000]	lr: 1.548e-06, eta: 1 day, 5:47:20, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0014, decode.loss_mask: 0.3914, decode.loss_dice: 0.3838, decode.d0.loss_cls: 0.5339, decode.d0.loss_mask: 0.4080, decode.d0.loss_dice: 0.4181, decode.d1.loss_cls: 0.0024, decode.d1.loss_mask: 0.3944, decode.d1.loss_dice: 0.3848, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3931, decode.d2.loss_dice: 0.3819, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.3946, decode.d3.loss_dice: 0.3806, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3948, decode.d4.loss_dice: 0.3828, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3956, decode.d5.loss_dice: 0.3837, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3962, decode.d6.loss_dice: 0.3803, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3899, decode.d7.loss_dice: 0.3821, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3910, decode.d8.loss_dice: 0.3818, loss: 8.3581, grad_norm: 470.6908
2023-08-29 17:10:34,247 - mmseg - INFO - Iter [12900/160000]	lr: 1.548e-06, eta: 1 day, 5:46:43, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0185, decode.loss_mask: 0.4098, decode.loss_dice: 0.4081, decode.d0.loss_cls: 0.5340, decode.d0.loss_mask: 0.4336, decode.d0.loss_dice: 0.4478, decode.d1.loss_cls: 0.0298, decode.d1.loss_mask: 0.4132, decode.d1.loss_dice: 0.4158, decode.d2.loss_cls: 0.0281, decode.d2.loss_mask: 0.4053, decode.d2.loss_dice: 0.4103, decode.d3.loss_cls: 0.0272, decode.d3.loss_mask: 0.4091, decode.d3.loss_dice: 0.4108, decode.d4.loss_cls: 0.0238, decode.d4.loss_mask: 0.4081, decode.d4.loss_dice: 0.4072, decode.d5.loss_cls: 0.0210, decode.d5.loss_mask: 0.4068, decode.d5.loss_dice: 0.4067, decode.d6.loss_cls: 0.0219, decode.d6.loss_mask: 0.4101, decode.d6.loss_dice: 0.4082, decode.d7.loss_cls: 0.0195, decode.d7.loss_mask: 0.4074, decode.d7.loss_dice: 0.4073, decode.d8.loss_cls: 0.0216, decode.d8.loss_mask: 0.4097, decode.d8.loss_dice: 0.4076, loss: 8.9881, grad_norm: 397.8769
2023-08-29 17:11:11,489 - mmseg - INFO - Iter [12950/160000]	lr: 1.547e-06, eta: 1 day, 5:46:16, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.3924, decode.loss_dice: 0.4442, decode.d0.loss_cls: 0.5298, decode.d0.loss_mask: 0.4064, decode.d0.loss_dice: 0.4650, decode.d1.loss_cls: 0.0119, decode.d1.loss_mask: 0.3967, decode.d1.loss_dice: 0.4362, decode.d2.loss_cls: 0.0066, decode.d2.loss_mask: 0.3885, decode.d2.loss_dice: 0.4372, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.3879, decode.d3.loss_dice: 0.4355, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.3914, decode.d4.loss_dice: 0.4386, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.3947, decode.d5.loss_dice: 0.4364, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.3937, decode.d6.loss_dice: 0.4406, decode.d7.loss_cls: 0.0034, decode.d7.loss_mask: 0.3936, decode.d7.loss_dice: 0.4422, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.3940, decode.d8.loss_dice: 0.4464, loss: 8.9360, grad_norm: 485.7726
2023-08-29 17:11:46,434 - mmseg - INFO - Saving checkpoint at 13000 iterations
2023-08-29 17:11:48,950 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 17:11:48,950 - mmseg - INFO - Iter [13000/160000]	lr: 1.546e-06, eta: 1 day, 5:45:51, time: 0.749, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3575, decode.loss_dice: 0.3801, decode.d0.loss_cls: 0.5235, decode.d0.loss_mask: 0.3713, decode.d0.loss_dice: 0.4078, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.3588, decode.d1.loss_dice: 0.3832, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3544, decode.d2.loss_dice: 0.3866, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.3601, decode.d3.loss_dice: 0.3798, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3600, decode.d4.loss_dice: 0.3846, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.3590, decode.d5.loss_dice: 0.3814, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3616, decode.d6.loss_dice: 0.3836, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.3598, decode.d7.loss_dice: 0.3865, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3617, decode.d8.loss_dice: 0.3849, loss: 8.0014, grad_norm: 412.2630
2023-08-29 17:12:25,657 - mmseg - INFO - Iter [13050/160000]	lr: 1.546e-06, eta: 1 day, 5:45:18, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.4010, decode.loss_dice: 0.3820, decode.d0.loss_cls: 0.5199, decode.d0.loss_mask: 0.4157, decode.d0.loss_dice: 0.4128, decode.d1.loss_cls: 0.0076, decode.d1.loss_mask: 0.3932, decode.d1.loss_dice: 0.3821, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3962, decode.d2.loss_dice: 0.3816, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3974, decode.d3.loss_dice: 0.3777, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.3865, decode.d4.loss_dice: 0.3796, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.4005, decode.d5.loss_dice: 0.3861, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 0.3889, decode.d6.loss_dice: 0.3799, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.4009, decode.d7.loss_dice: 0.3828, decode.d8.loss_cls: 0.0087, decode.d8.loss_mask: 0.3907, decode.d8.loss_dice: 0.3817, loss: 8.3783, grad_norm: 373.2473
2023-08-29 17:13:02,186 - mmseg - INFO - Iter [13100/160000]	lr: 1.545e-06, eta: 1 day, 5:44:42, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.3370, decode.loss_dice: 0.3404, decode.d0.loss_cls: 0.5150, decode.d0.loss_mask: 0.3378, decode.d0.loss_dice: 0.3681, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.3359, decode.d1.loss_dice: 0.3473, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3338, decode.d2.loss_dice: 0.3463, decode.d3.loss_cls: 0.0060, decode.d3.loss_mask: 0.3243, decode.d3.loss_dice: 0.3360, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.3338, decode.d4.loss_dice: 0.3421, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3360, decode.d5.loss_dice: 0.3420, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.3381, decode.d6.loss_dice: 0.3381, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3372, decode.d7.loss_dice: 0.3396, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3403, decode.d8.loss_dice: 0.3412, loss: 7.3304, grad_norm: 365.1822
2023-08-29 17:13:39,337 - mmseg - INFO - Iter [13150/160000]	lr: 1.545e-06, eta: 1 day, 5:44:13, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.3694, decode.loss_dice: 0.3453, decode.d0.loss_cls: 0.5104, decode.d0.loss_mask: 0.3763, decode.d0.loss_dice: 0.3769, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.3711, decode.d1.loss_dice: 0.3481, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.3712, decode.d2.loss_dice: 0.3463, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.3709, decode.d3.loss_dice: 0.3446, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.3688, decode.d4.loss_dice: 0.3424, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.3695, decode.d5.loss_dice: 0.3444, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.3708, decode.d6.loss_dice: 0.3437, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.3685, decode.d7.loss_dice: 0.3437, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.3714, decode.d8.loss_dice: 0.3474, loss: 7.7246, grad_norm: 436.9389
2023-08-29 17:14:14,566 - mmseg - INFO - Iter [13200/160000]	lr: 1.544e-06, eta: 1 day, 5:43:23, time: 0.705, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0202, decode.loss_mask: 0.4434, decode.loss_dice: 0.4247, decode.d0.loss_cls: 0.5108, decode.d0.loss_mask: 0.4418, decode.d0.loss_dice: 0.4490, decode.d1.loss_cls: 0.0373, decode.d1.loss_mask: 0.4350, decode.d1.loss_dice: 0.4246, decode.d2.loss_cls: 0.0252, decode.d2.loss_mask: 0.4378, decode.d2.loss_dice: 0.4222, decode.d3.loss_cls: 0.0261, decode.d3.loss_mask: 0.4304, decode.d3.loss_dice: 0.4180, decode.d4.loss_cls: 0.0183, decode.d4.loss_mask: 0.4395, decode.d4.loss_dice: 0.4198, decode.d5.loss_cls: 0.0175, decode.d5.loss_mask: 0.4394, decode.d5.loss_dice: 0.4221, decode.d6.loss_cls: 0.0151, decode.d6.loss_mask: 0.4401, decode.d6.loss_dice: 0.4218, decode.d7.loss_cls: 0.0176, decode.d7.loss_mask: 0.4385, decode.d7.loss_dice: 0.4225, decode.d8.loss_cls: 0.0219, decode.d8.loss_mask: 0.4333, decode.d8.loss_dice: 0.4191, loss: 9.3333, grad_norm: 461.5294
2023-08-29 17:14:51,459 - mmseg - INFO - Iter [13250/160000]	lr: 1.544e-06, eta: 1 day, 5:42:52, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.3730, decode.loss_dice: 0.3755, decode.d0.loss_cls: 0.5029, decode.d0.loss_mask: 0.4039, decode.d0.loss_dice: 0.4159, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.3836, decode.d1.loss_dice: 0.3871, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.3774, decode.d2.loss_dice: 0.3790, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.3753, decode.d3.loss_dice: 0.3807, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.3718, decode.d4.loss_dice: 0.3810, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.3747, decode.d5.loss_dice: 0.3769, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.3756, decode.d6.loss_dice: 0.3792, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.3717, decode.d7.loss_dice: 0.3771, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.3738, decode.d8.loss_dice: 0.3790, loss: 8.1426, grad_norm: 392.4677
2023-08-29 17:15:27,842 - mmseg - INFO - Iter [13300/160000]	lr: 1.543e-06, eta: 1 day, 5:42:15, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0011, decode.loss_mask: 0.4164, decode.loss_dice: 0.3975, decode.d0.loss_cls: 0.5001, decode.d0.loss_mask: 0.4150, decode.d0.loss_dice: 0.4184, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.4070, decode.d1.loss_dice: 0.3962, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.4142, decode.d2.loss_dice: 0.3972, decode.d3.loss_cls: 0.0101, decode.d3.loss_mask: 0.3989, decode.d3.loss_dice: 0.3871, decode.d4.loss_cls: 0.0055, decode.d4.loss_mask: 0.4083, decode.d4.loss_dice: 0.3889, decode.d5.loss_cls: 0.0102, decode.d5.loss_mask: 0.3979, decode.d5.loss_dice: 0.3845, decode.d6.loss_cls: 0.0045, decode.d6.loss_mask: 0.4122, decode.d6.loss_dice: 0.3903, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.4123, decode.d7.loss_dice: 0.3926, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.4138, decode.d8.loss_dice: 0.3943, loss: 8.5865, grad_norm: 402.4519
2023-08-29 17:16:04,761 - mmseg - INFO - Iter [13350/160000]	lr: 1.543e-06, eta: 1 day, 5:41:44, time: 0.738, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.3392, decode.loss_dice: 0.3356, decode.d0.loss_cls: 0.4941, decode.d0.loss_mask: 0.3564, decode.d0.loss_dice: 0.3670, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3406, decode.d1.loss_dice: 0.3389, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3347, decode.d2.loss_dice: 0.3359, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.3372, decode.d3.loss_dice: 0.3341, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3375, decode.d4.loss_dice: 0.3352, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.3385, decode.d5.loss_dice: 0.3333, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3376, decode.d6.loss_dice: 0.3374, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3378, decode.d7.loss_dice: 0.3358, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3395, decode.d8.loss_dice: 0.3383, loss: 7.3044, grad_norm: 347.0338
2023-08-29 17:16:41,917 - mmseg - INFO - Iter [13400/160000]	lr: 1.542e-06, eta: 1 day, 5:41:15, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0089, decode.loss_mask: 0.4200, decode.loss_dice: 0.4177, decode.d0.loss_cls: 0.4946, decode.d0.loss_mask: 0.4331, decode.d0.loss_dice: 0.4498, decode.d1.loss_cls: 0.0136, decode.d1.loss_mask: 0.4175, decode.d1.loss_dice: 0.4129, decode.d2.loss_cls: 0.0111, decode.d2.loss_mask: 0.4151, decode.d2.loss_dice: 0.4087, decode.d3.loss_cls: 0.0099, decode.d3.loss_mask: 0.4232, decode.d3.loss_dice: 0.4075, decode.d4.loss_cls: 0.0137, decode.d4.loss_mask: 0.4139, decode.d4.loss_dice: 0.4074, decode.d5.loss_cls: 0.0128, decode.d5.loss_mask: 0.4148, decode.d5.loss_dice: 0.4071, decode.d6.loss_cls: 0.0139, decode.d6.loss_mask: 0.4178, decode.d6.loss_dice: 0.4088, decode.d7.loss_cls: 0.0138, decode.d7.loss_mask: 0.4147, decode.d7.loss_dice: 0.4043, decode.d8.loss_cls: 0.0124, decode.d8.loss_mask: 0.4242, decode.d8.loss_dice: 0.4109, loss: 8.9344, grad_norm: 424.6805
2023-08-29 17:17:16,708 - mmseg - INFO - Iter [13450/160000]	lr: 1.542e-06, eta: 1 day, 5:40:20, time: 0.696, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0059, decode.loss_mask: 0.3598, decode.loss_dice: 0.3854, decode.d0.loss_cls: 0.4863, decode.d0.loss_mask: 0.3816, decode.d0.loss_dice: 0.4189, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.3602, decode.d1.loss_dice: 0.3889, decode.d2.loss_cls: 0.0050, decode.d2.loss_mask: 0.3593, decode.d2.loss_dice: 0.3909, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.3637, decode.d3.loss_dice: 0.3885, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.3640, decode.d4.loss_dice: 0.3896, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.3627, decode.d5.loss_dice: 0.3871, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.3646, decode.d6.loss_dice: 0.3943, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.3627, decode.d7.loss_dice: 0.3919, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.3632, decode.d8.loss_dice: 0.3914, loss: 8.0922, grad_norm: 406.5638
2023-08-29 17:17:53,319 - mmseg - INFO - Iter [13500/160000]	lr: 1.541e-06, eta: 1 day, 5:39:46, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.3577, decode.loss_dice: 0.3391, decode.d0.loss_cls: 0.4827, decode.d0.loss_mask: 0.3783, decode.d0.loss_dice: 0.3763, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3577, decode.d1.loss_dice: 0.3407, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3581, decode.d2.loss_dice: 0.3418, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.3572, decode.d3.loss_dice: 0.3394, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.3572, decode.d4.loss_dice: 0.3392, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.3585, decode.d5.loss_dice: 0.3402, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.3540, decode.d6.loss_dice: 0.3397, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.3583, decode.d7.loss_dice: 0.3396, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.3586, decode.d8.loss_dice: 0.3392, loss: 7.5271, grad_norm: 468.9951
2023-08-29 17:18:30,276 - mmseg - INFO - Iter [13550/160000]	lr: 1.541e-06, eta: 1 day, 5:39:15, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.3720, decode.loss_dice: 0.3653, decode.d0.loss_cls: 0.4815, decode.d0.loss_mask: 0.3890, decode.d0.loss_dice: 0.4027, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.3831, decode.d1.loss_dice: 0.3698, decode.d2.loss_cls: 0.0151, decode.d2.loss_mask: 0.3698, decode.d2.loss_dice: 0.3680, decode.d3.loss_cls: 0.0116, decode.d3.loss_mask: 0.3705, decode.d3.loss_dice: 0.3622, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.3733, decode.d4.loss_dice: 0.3635, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.3743, decode.d5.loss_dice: 0.3620, decode.d6.loss_cls: 0.0034, decode.d6.loss_mask: 0.3695, decode.d6.loss_dice: 0.3599, decode.d7.loss_cls: 0.0037, decode.d7.loss_mask: 0.3721, decode.d7.loss_dice: 0.3619, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.3720, decode.d8.loss_dice: 0.3642, loss: 7.9646, grad_norm: 455.3599
2023-08-29 17:19:07,637 - mmseg - INFO - Iter [13600/160000]	lr: 1.540e-06, eta: 1 day, 5:38:48, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.3994, decode.loss_dice: 0.3830, decode.d0.loss_cls: 0.4741, decode.d0.loss_mask: 0.4211, decode.d0.loss_dice: 0.4104, decode.d1.loss_cls: 0.0017, decode.d1.loss_mask: 0.4036, decode.d1.loss_dice: 0.3822, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.3972, decode.d2.loss_dice: 0.3805, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.3995, decode.d3.loss_dice: 0.3807, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.3977, decode.d4.loss_dice: 0.3805, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3977, decode.d5.loss_dice: 0.3823, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.3976, decode.d6.loss_dice: 0.3825, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.3990, decode.d7.loss_dice: 0.3799, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.3979, decode.d8.loss_dice: 0.3823, loss: 8.3385, grad_norm: 450.9835
2023-08-29 17:19:42,604 - mmseg - INFO - Iter [13650/160000]	lr: 1.540e-06, eta: 1 day, 5:37:56, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3946, decode.loss_dice: 0.3983, decode.d0.loss_cls: 0.4719, decode.d0.loss_mask: 0.4160, decode.d0.loss_dice: 0.4286, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3969, decode.d1.loss_dice: 0.4014, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3978, decode.d2.loss_dice: 0.3999, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.3959, decode.d3.loss_dice: 0.3976, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3956, decode.d4.loss_dice: 0.3991, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.3955, decode.d5.loss_dice: 0.3939, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3939, decode.d6.loss_dice: 0.3962, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3928, decode.d7.loss_dice: 0.3963, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3950, decode.d8.loss_dice: 0.3986, loss: 8.4708, grad_norm: 402.7758
2023-08-29 17:20:18,920 - mmseg - INFO - Iter [13700/160000]	lr: 1.539e-06, eta: 1 day, 5:37:18, time: 0.726, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0101, decode.loss_mask: 0.3545, decode.loss_dice: 0.3733, decode.d0.loss_cls: 0.4696, decode.d0.loss_mask: 0.3638, decode.d0.loss_dice: 0.4036, decode.d1.loss_cls: 0.0096, decode.d1.loss_mask: 0.3514, decode.d1.loss_dice: 0.3741, decode.d2.loss_cls: 0.0090, decode.d2.loss_mask: 0.3514, decode.d2.loss_dice: 0.3777, decode.d3.loss_cls: 0.0079, decode.d3.loss_mask: 0.3522, decode.d3.loss_dice: 0.3704, decode.d4.loss_cls: 0.0082, decode.d4.loss_mask: 0.3552, decode.d4.loss_dice: 0.3746, decode.d5.loss_cls: 0.0100, decode.d5.loss_mask: 0.3539, decode.d5.loss_dice: 0.3709, decode.d6.loss_cls: 0.0094, decode.d6.loss_mask: 0.3541, decode.d6.loss_dice: 0.3702, decode.d7.loss_cls: 0.0090, decode.d7.loss_mask: 0.3551, decode.d7.loss_dice: 0.3694, decode.d8.loss_cls: 0.0112, decode.d8.loss_mask: 0.3557, decode.d8.loss_dice: 0.3701, loss: 7.8557, grad_norm: 394.4932
2023-08-29 17:20:56,139 - mmseg - INFO - Iter [13750/160000]	lr: 1.539e-06, eta: 1 day, 5:36:50, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0150, decode.loss_mask: 0.3967, decode.loss_dice: 0.3855, decode.d0.loss_cls: 0.4659, decode.d0.loss_mask: 0.4132, decode.d0.loss_dice: 0.4199, decode.d1.loss_cls: 0.0162, decode.d1.loss_mask: 0.3953, decode.d1.loss_dice: 0.3869, decode.d2.loss_cls: 0.0167, decode.d2.loss_mask: 0.3940, decode.d2.loss_dice: 0.3875, decode.d3.loss_cls: 0.0218, decode.d3.loss_mask: 0.3903, decode.d3.loss_dice: 0.3828, decode.d4.loss_cls: 0.0191, decode.d4.loss_mask: 0.3909, decode.d4.loss_dice: 0.3817, decode.d5.loss_cls: 0.0242, decode.d5.loss_mask: 0.3849, decode.d5.loss_dice: 0.3770, decode.d6.loss_cls: 0.0222, decode.d6.loss_mask: 0.3830, decode.d6.loss_dice: 0.3764, decode.d7.loss_cls: 0.0173, decode.d7.loss_mask: 0.3913, decode.d7.loss_dice: 0.3811, decode.d8.loss_cls: 0.0171, decode.d8.loss_mask: 0.3944, decode.d8.loss_dice: 0.3839, loss: 8.4320, grad_norm: 469.3703
2023-08-29 17:21:33,237 - mmseg - INFO - Iter [13800/160000]	lr: 1.538e-06, eta: 1 day, 5:36:20, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0057, decode.loss_mask: 0.3640, decode.loss_dice: 0.3520, decode.d0.loss_cls: 0.4633, decode.d0.loss_mask: 0.3837, decode.d0.loss_dice: 0.3817, decode.d1.loss_cls: 0.0176, decode.d1.loss_mask: 0.3688, decode.d1.loss_dice: 0.3555, decode.d2.loss_cls: 0.0131, decode.d2.loss_mask: 0.3629, decode.d2.loss_dice: 0.3560, decode.d3.loss_cls: 0.0111, decode.d3.loss_mask: 0.3644, decode.d3.loss_dice: 0.3516, decode.d4.loss_cls: 0.0089, decode.d4.loss_mask: 0.3634, decode.d4.loss_dice: 0.3544, decode.d5.loss_cls: 0.0090, decode.d5.loss_mask: 0.3651, decode.d5.loss_dice: 0.3545, decode.d6.loss_cls: 0.0091, decode.d6.loss_mask: 0.3643, decode.d6.loss_dice: 0.3536, decode.d7.loss_cls: 0.0088, decode.d7.loss_mask: 0.3649, decode.d7.loss_dice: 0.3497, decode.d8.loss_cls: 0.0078, decode.d8.loss_mask: 0.3640, decode.d8.loss_dice: 0.3495, loss: 7.7782, grad_norm: 416.1660
2023-08-29 17:22:08,147 - mmseg - INFO - Iter [13850/160000]	lr: 1.538e-06, eta: 1 day, 5:35:27, time: 0.698, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.3957, decode.loss_dice: 0.4004, decode.d0.loss_cls: 0.4608, decode.d0.loss_mask: 0.4023, decode.d0.loss_dice: 0.4156, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.4038, decode.d1.loss_dice: 0.4116, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.3950, decode.d2.loss_dice: 0.4040, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.3892, decode.d3.loss_dice: 0.3939, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.3915, decode.d4.loss_dice: 0.3985, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.3939, decode.d5.loss_dice: 0.3957, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.3962, decode.d6.loss_dice: 0.3987, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.3966, decode.d7.loss_dice: 0.4042, decode.d8.loss_cls: 0.0036, decode.d8.loss_mask: 0.3976, decode.d8.loss_dice: 0.4032, loss: 8.4848, grad_norm: 462.5888
2023-08-29 17:22:44,457 - mmseg - INFO - Iter [13900/160000]	lr: 1.537e-06, eta: 1 day, 5:34:50, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0114, decode.loss_mask: 0.3974, decode.loss_dice: 0.4019, decode.d0.loss_cls: 0.4552, decode.d0.loss_mask: 0.4177, decode.d0.loss_dice: 0.4281, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.4017, decode.d1.loss_dice: 0.4079, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4123, decode.d2.loss_dice: 0.4062, decode.d3.loss_cls: 0.0077, decode.d3.loss_mask: 0.3946, decode.d3.loss_dice: 0.4024, decode.d4.loss_cls: 0.0090, decode.d4.loss_mask: 0.3885, decode.d4.loss_dice: 0.3949, decode.d5.loss_cls: 0.0135, decode.d5.loss_mask: 0.3912, decode.d5.loss_dice: 0.4009, decode.d6.loss_cls: 0.0100, decode.d6.loss_mask: 0.3917, decode.d6.loss_dice: 0.3982, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.4134, decode.d7.loss_dice: 0.4054, decode.d8.loss_cls: 0.0117, decode.d8.loss_mask: 0.3970, decode.d8.loss_dice: 0.4037, loss: 8.5881, grad_norm: 391.7381
2023-08-29 17:23:21,424 - mmseg - INFO - Iter [13950/160000]	lr: 1.536e-06, eta: 1 day, 5:34:19, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.3472, decode.loss_dice: 0.3410, decode.d0.loss_cls: 0.4494, decode.d0.loss_mask: 0.3816, decode.d0.loss_dice: 0.3768, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.3493, decode.d1.loss_dice: 0.3455, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3452, decode.d2.loss_dice: 0.3430, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3444, decode.d3.loss_dice: 0.3408, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.3433, decode.d4.loss_dice: 0.3373, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.3455, decode.d5.loss_dice: 0.3378, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.3471, decode.d6.loss_dice: 0.3407, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.3447, decode.d7.loss_dice: 0.3414, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.3459, decode.d8.loss_dice: 0.3409, loss: 7.4074, grad_norm: 404.0332
2023-08-29 17:23:58,556 - mmseg - INFO - Saving checkpoint at 14000 iterations
2023-08-29 17:24:00,841 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 17:24:00,841 - mmseg - INFO - Iter [14000/160000]	lr: 1.536e-06, eta: 1 day, 5:34:13, time: 0.788, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.3297, decode.loss_dice: 0.3373, decode.d0.loss_cls: 0.4456, decode.d0.loss_mask: 0.3437, decode.d0.loss_dice: 0.3674, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3283, decode.d1.loss_dice: 0.3385, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3284, decode.d2.loss_dice: 0.3414, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.3309, decode.d3.loss_dice: 0.3393, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3314, decode.d4.loss_dice: 0.3385, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.3298, decode.d5.loss_dice: 0.3385, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.3310, decode.d6.loss_dice: 0.3367, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.3289, decode.d7.loss_dice: 0.3409, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.3305, decode.d8.loss_dice: 0.3382, loss: 7.1949, grad_norm: 429.7843
2023-08-29 17:24:35,886 - mmseg - INFO - Iter [14050/160000]	lr: 1.535e-06, eta: 1 day, 5:33:22, time: 0.701, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.3281, decode.loss_dice: 0.3366, decode.d0.loss_cls: 0.4432, decode.d0.loss_mask: 0.3401, decode.d0.loss_dice: 0.3691, decode.d1.loss_cls: 0.0078, decode.d1.loss_mask: 0.3313, decode.d1.loss_dice: 0.3394, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3333, decode.d2.loss_dice: 0.3420, decode.d3.loss_cls: 0.0049, decode.d3.loss_mask: 0.3247, decode.d3.loss_dice: 0.3332, decode.d4.loss_cls: 0.0046, decode.d4.loss_mask: 0.3245, decode.d4.loss_dice: 0.3320, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.3242, decode.d5.loss_dice: 0.3313, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.3272, decode.d6.loss_dice: 0.3342, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.3265, decode.d7.loss_dice: 0.3322, decode.d8.loss_cls: 0.0065, decode.d8.loss_mask: 0.3270, decode.d8.loss_dice: 0.3339, loss: 7.1612, grad_norm: 427.0075
2023-08-29 17:25:12,388 - mmseg - INFO - Iter [14100/160000]	lr: 1.535e-06, eta: 1 day, 5:32:46, time: 0.730, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0072, decode.loss_mask: 0.3452, decode.loss_dice: 0.3290, decode.d0.loss_cls: 0.4399, decode.d0.loss_mask: 0.3606, decode.d0.loss_dice: 0.3661, decode.d1.loss_cls: 0.0130, decode.d1.loss_mask: 0.3474, decode.d1.loss_dice: 0.3352, decode.d2.loss_cls: 0.0074, decode.d2.loss_mask: 0.3483, decode.d2.loss_dice: 0.3371, decode.d3.loss_cls: 0.0086, decode.d3.loss_mask: 0.3443, decode.d3.loss_dice: 0.3289, decode.d4.loss_cls: 0.0079, decode.d4.loss_mask: 0.3435, decode.d4.loss_dice: 0.3272, decode.d5.loss_cls: 0.0106, decode.d5.loss_mask: 0.3437, decode.d5.loss_dice: 0.3265, decode.d6.loss_cls: 0.0098, decode.d6.loss_mask: 0.3424, decode.d6.loss_dice: 0.3255, decode.d7.loss_cls: 0.0091, decode.d7.loss_mask: 0.3419, decode.d7.loss_dice: 0.3275, decode.d8.loss_cls: 0.0085, decode.d8.loss_mask: 0.3414, decode.d8.loss_dice: 0.3252, loss: 7.3090, grad_norm: 355.9037
2023-08-29 17:25:49,297 - mmseg - INFO - Iter [14150/160000]	lr: 1.534e-06, eta: 1 day, 5:32:14, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.3562, decode.loss_dice: 0.3428, decode.d0.loss_cls: 0.4359, decode.d0.loss_mask: 0.3761, decode.d0.loss_dice: 0.3809, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3577, decode.d1.loss_dice: 0.3482, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.3595, decode.d2.loss_dice: 0.3508, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.3556, decode.d3.loss_dice: 0.3419, decode.d4.loss_cls: 0.0028, decode.d4.loss_mask: 0.3548, decode.d4.loss_dice: 0.3430, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.3546, decode.d5.loss_dice: 0.3426, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.3546, decode.d6.loss_dice: 0.3416, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.3516, decode.d7.loss_dice: 0.3421, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.3537, decode.d8.loss_dice: 0.3429, loss: 7.5096, grad_norm: 471.7503
2023-08-29 17:26:26,434 - mmseg - INFO - Iter [14200/160000]	lr: 1.534e-06, eta: 1 day, 5:31:45, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0163, decode.loss_mask: 0.3245, decode.loss_dice: 0.3159, decode.d0.loss_cls: 0.4340, decode.d0.loss_mask: 0.3419, decode.d0.loss_dice: 0.3557, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.3277, decode.d1.loss_dice: 0.3232, decode.d2.loss_cls: 0.0154, decode.d2.loss_mask: 0.3249, decode.d2.loss_dice: 0.3193, decode.d3.loss_cls: 0.0166, decode.d3.loss_mask: 0.3266, decode.d3.loss_dice: 0.3198, decode.d4.loss_cls: 0.0148, decode.d4.loss_mask: 0.3261, decode.d4.loss_dice: 0.3156, decode.d5.loss_cls: 0.0162, decode.d5.loss_mask: 0.3205, decode.d5.loss_dice: 0.3173, decode.d6.loss_cls: 0.0161, decode.d6.loss_mask: 0.3262, decode.d6.loss_dice: 0.3178, decode.d7.loss_cls: 0.0145, decode.d7.loss_mask: 0.3240, decode.d7.loss_dice: 0.3201, decode.d8.loss_cls: 0.0156, decode.d8.loss_mask: 0.3249, decode.d8.loss_dice: 0.3160, loss: 7.0668, grad_norm: 385.3287
2023-08-29 17:27:01,361 - mmseg - INFO - Iter [14250/160000]	lr: 1.533e-06, eta: 1 day, 5:30:53, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.3282, decode.loss_dice: 0.3241, decode.d0.loss_cls: 0.4278, decode.d0.loss_mask: 0.3363, decode.d0.loss_dice: 0.3495, decode.d1.loss_cls: 0.0025, decode.d1.loss_mask: 0.3268, decode.d1.loss_dice: 0.3237, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3255, decode.d2.loss_dice: 0.3230, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.3270, decode.d3.loss_dice: 0.3220, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3280, decode.d4.loss_dice: 0.3227, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.3274, decode.d5.loss_dice: 0.3242, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.3299, decode.d6.loss_dice: 0.3236, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.3263, decode.d7.loss_dice: 0.3246, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.3293, decode.d8.loss_dice: 0.3249, loss: 6.9952, grad_norm: 364.1022
2023-08-29 17:27:37,868 - mmseg - INFO - Iter [14300/160000]	lr: 1.533e-06, eta: 1 day, 5:30:17, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.3754, decode.loss_dice: 0.3626, decode.d0.loss_cls: 0.4257, decode.d0.loss_mask: 0.3816, decode.d0.loss_dice: 0.3881, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.3727, decode.d1.loss_dice: 0.3652, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.3758, decode.d2.loss_dice: 0.3643, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.3767, decode.d3.loss_dice: 0.3615, decode.d4.loss_cls: 0.0048, decode.d4.loss_mask: 0.3745, decode.d4.loss_dice: 0.3610, decode.d5.loss_cls: 0.0062, decode.d5.loss_mask: 0.3776, decode.d5.loss_dice: 0.3572, decode.d6.loss_cls: 0.0077, decode.d6.loss_mask: 0.3731, decode.d6.loss_dice: 0.3564, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.3735, decode.d7.loss_dice: 0.3559, decode.d8.loss_cls: 0.0061, decode.d8.loss_mask: 0.3771, decode.d8.loss_dice: 0.3560, loss: 7.8685, grad_norm: 423.1897
2023-08-29 17:28:14,771 - mmseg - INFO - Iter [14350/160000]	lr: 1.532e-06, eta: 1 day, 5:29:45, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.3576, decode.loss_dice: 0.3569, decode.d0.loss_cls: 0.4204, decode.d0.loss_mask: 0.3862, decode.d0.loss_dice: 0.3996, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.3638, decode.d1.loss_dice: 0.3629, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3593, decode.d2.loss_dice: 0.3597, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.3595, decode.d3.loss_dice: 0.3567, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.3582, decode.d4.loss_dice: 0.3565, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.3586, decode.d5.loss_dice: 0.3569, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.3582, decode.d6.loss_dice: 0.3557, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.3562, decode.d7.loss_dice: 0.3550, decode.d8.loss_cls: 0.0026, decode.d8.loss_mask: 0.3571, decode.d8.loss_dice: 0.3573, loss: 7.6747, grad_norm: 472.2991
2023-08-29 17:28:51,741 - mmseg - INFO - Iter [14400/160000]	lr: 1.532e-06, eta: 1 day, 5:29:14, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0014, decode.loss_mask: 0.3212, decode.loss_dice: 0.3450, decode.d0.loss_cls: 0.4171, decode.d0.loss_mask: 0.3358, decode.d0.loss_dice: 0.3781, decode.d1.loss_cls: 0.0021, decode.d1.loss_mask: 0.3210, decode.d1.loss_dice: 0.3534, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3180, decode.d2.loss_dice: 0.3432, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.3194, decode.d3.loss_dice: 0.3473, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3191, decode.d4.loss_dice: 0.3444, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3193, decode.d5.loss_dice: 0.3435, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3173, decode.d6.loss_dice: 0.3454, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.3196, decode.d7.loss_dice: 0.3440, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3192, decode.d8.loss_dice: 0.3422, loss: 7.1285, grad_norm: 382.7142
2023-08-29 17:29:26,800 - mmseg - INFO - Iter [14450/160000]	lr: 1.531e-06, eta: 1 day, 5:28:23, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0071, decode.loss_mask: 0.3704, decode.loss_dice: 0.3630, decode.d0.loss_cls: 0.4177, decode.d0.loss_mask: 0.3718, decode.d0.loss_dice: 0.3856, decode.d1.loss_cls: 0.0069, decode.d1.loss_mask: 0.3728, decode.d1.loss_dice: 0.3680, decode.d2.loss_cls: 0.0077, decode.d2.loss_mask: 0.3708, decode.d2.loss_dice: 0.3651, decode.d3.loss_cls: 0.0051, decode.d3.loss_mask: 0.3714, decode.d3.loss_dice: 0.3628, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.3663, decode.d4.loss_dice: 0.3609, decode.d5.loss_cls: 0.0155, decode.d5.loss_mask: 0.3658, decode.d5.loss_dice: 0.3588, decode.d6.loss_cls: 0.0168, decode.d6.loss_mask: 0.3638, decode.d6.loss_dice: 0.3623, decode.d7.loss_cls: 0.0100, decode.d7.loss_mask: 0.3699, decode.d7.loss_dice: 0.3614, decode.d8.loss_cls: 0.0095, decode.d8.loss_mask: 0.3702, decode.d8.loss_dice: 0.3625, loss: 7.8473, grad_norm: 465.6482
2023-08-29 17:30:03,576 - mmseg - INFO - Iter [14500/160000]	lr: 1.531e-06, eta: 1 day, 5:27:50, time: 0.735, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0112, decode.loss_mask: 0.3646, decode.loss_dice: 0.3620, decode.d0.loss_cls: 0.4136, decode.d0.loss_mask: 0.3783, decode.d0.loss_dice: 0.3881, decode.d1.loss_cls: 0.0138, decode.d1.loss_mask: 0.3643, decode.d1.loss_dice: 0.3687, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.3633, decode.d2.loss_dice: 0.3615, decode.d3.loss_cls: 0.0104, decode.d3.loss_mask: 0.3616, decode.d3.loss_dice: 0.3592, decode.d4.loss_cls: 0.0103, decode.d4.loss_mask: 0.3604, decode.d4.loss_dice: 0.3585, decode.d5.loss_cls: 0.0120, decode.d5.loss_mask: 0.3632, decode.d5.loss_dice: 0.3571, decode.d6.loss_cls: 0.0122, decode.d6.loss_mask: 0.3649, decode.d6.loss_dice: 0.3593, decode.d7.loss_cls: 0.0103, decode.d7.loss_mask: 0.3624, decode.d7.loss_dice: 0.3555, decode.d8.loss_cls: 0.0110, decode.d8.loss_mask: 0.3631, decode.d8.loss_dice: 0.3598, loss: 7.7912, grad_norm: 457.1053
2023-08-29 17:30:40,088 - mmseg - INFO - Iter [14550/160000]	lr: 1.530e-06, eta: 1 day, 5:27:14, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0061, decode.loss_mask: 0.3380, decode.loss_dice: 0.3509, decode.d0.loss_cls: 0.4083, decode.d0.loss_mask: 0.3584, decode.d0.loss_dice: 0.3779, decode.d1.loss_cls: 0.0066, decode.d1.loss_mask: 0.3425, decode.d1.loss_dice: 0.3578, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.3414, decode.d2.loss_dice: 0.3586, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.3371, decode.d3.loss_dice: 0.3555, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.3387, decode.d4.loss_dice: 0.3553, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.3378, decode.d5.loss_dice: 0.3535, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.3362, decode.d6.loss_dice: 0.3517, decode.d7.loss_cls: 0.0049, decode.d7.loss_mask: 0.3402, decode.d7.loss_dice: 0.3514, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.3483, decode.d8.loss_dice: 0.3567, loss: 7.4342, grad_norm: 333.1353
2023-08-29 17:31:17,132 - mmseg - INFO - Iter [14600/160000]	lr: 1.530e-06, eta: 1 day, 5:26:44, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0229, decode.loss_mask: 0.4266, decode.loss_dice: 0.4107, decode.d0.loss_cls: 0.4159, decode.d0.loss_mask: 0.4203, decode.d0.loss_dice: 0.4373, decode.d1.loss_cls: 0.0587, decode.d1.loss_mask: 0.4131, decode.d1.loss_dice: 0.4165, decode.d2.loss_cls: 0.0294, decode.d2.loss_mask: 0.4252, decode.d2.loss_dice: 0.4093, decode.d3.loss_cls: 0.0288, decode.d3.loss_mask: 0.4190, decode.d3.loss_dice: 0.4015, decode.d4.loss_cls: 0.0234, decode.d4.loss_mask: 0.4172, decode.d4.loss_dice: 0.4028, decode.d5.loss_cls: 0.0395, decode.d5.loss_mask: 0.4091, decode.d5.loss_dice: 0.3972, decode.d6.loss_cls: 0.0276, decode.d6.loss_mask: 0.4216, decode.d6.loss_dice: 0.3999, decode.d7.loss_cls: 0.0262, decode.d7.loss_mask: 0.4359, decode.d7.loss_dice: 0.4017, decode.d8.loss_cls: 0.0270, decode.d8.loss_mask: 0.4397, decode.d8.loss_dice: 0.4057, loss: 9.0096, grad_norm: 499.3649
2023-08-29 17:31:52,266 - mmseg - INFO - Iter [14650/160000]	lr: 1.529e-06, eta: 1 day, 5:25:54, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.3928, decode.loss_dice: 0.3847, decode.d0.loss_cls: 0.4011, decode.d0.loss_mask: 0.4191, decode.d0.loss_dice: 0.4123, decode.d1.loss_cls: 0.0014, decode.d1.loss_mask: 0.3984, decode.d1.loss_dice: 0.3904, decode.d2.loss_cls: 0.0015, decode.d2.loss_mask: 0.3965, decode.d2.loss_dice: 0.3877, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.3964, decode.d3.loss_dice: 0.3875, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.3963, decode.d4.loss_dice: 0.3864, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.3989, decode.d5.loss_dice: 0.3828, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.3942, decode.d6.loss_dice: 0.3844, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.3962, decode.d7.loss_dice: 0.3789, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.3966, decode.d8.loss_dice: 0.3832, loss: 8.2768, grad_norm: 494.5853
2023-08-29 17:32:28,973 - mmseg - INFO - Iter [14700/160000]	lr: 1.529e-06, eta: 1 day, 5:25:20, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0014, decode.loss_mask: 0.3428, decode.loss_dice: 0.3509, decode.d0.loss_cls: 0.3995, decode.d0.loss_mask: 0.3642, decode.d0.loss_dice: 0.3798, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3481, decode.d1.loss_dice: 0.3601, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.3462, decode.d2.loss_dice: 0.3559, decode.d3.loss_cls: 0.0042, decode.d3.loss_mask: 0.3435, decode.d3.loss_dice: 0.3503, decode.d4.loss_cls: 0.0041, decode.d4.loss_mask: 0.3405, decode.d4.loss_dice: 0.3478, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3451, decode.d5.loss_dice: 0.3498, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.3425, decode.d6.loss_dice: 0.3490, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3415, decode.d7.loss_dice: 0.3513, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.3415, decode.d8.loss_dice: 0.3497, loss: 7.4190, grad_norm: 423.6783
2023-08-29 17:33:05,467 - mmseg - INFO - Iter [14750/160000]	lr: 1.528e-06, eta: 1 day, 5:24:44, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0171, decode.loss_mask: 0.3532, decode.loss_dice: 0.3690, decode.d0.loss_cls: 0.3982, decode.d0.loss_mask: 0.3576, decode.d0.loss_dice: 0.3899, decode.d1.loss_cls: 0.0174, decode.d1.loss_mask: 0.3482, decode.d1.loss_dice: 0.3660, decode.d2.loss_cls: 0.0166, decode.d2.loss_mask: 0.3486, decode.d2.loss_dice: 0.3647, decode.d3.loss_cls: 0.0157, decode.d3.loss_mask: 0.3523, decode.d3.loss_dice: 0.3698, decode.d4.loss_cls: 0.0137, decode.d4.loss_mask: 0.3509, decode.d4.loss_dice: 0.3700, decode.d5.loss_cls: 0.0143, decode.d5.loss_mask: 0.3533, decode.d5.loss_dice: 0.3705, decode.d6.loss_cls: 0.0166, decode.d6.loss_mask: 0.3491, decode.d6.loss_dice: 0.3706, decode.d7.loss_cls: 0.0142, decode.d7.loss_mask: 0.3548, decode.d7.loss_dice: 0.3714, decode.d8.loss_cls: 0.0141, decode.d8.loss_mask: 0.3566, decode.d8.loss_dice: 0.3697, loss: 7.7740, grad_norm: 468.6118
2023-08-29 17:33:42,406 - mmseg - INFO - Iter [14800/160000]	lr: 1.528e-06, eta: 1 day, 5:24:13, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.3571, decode.loss_dice: 0.3542, decode.d0.loss_cls: 0.3929, decode.d0.loss_mask: 0.3924, decode.d0.loss_dice: 0.3924, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.3657, decode.d1.loss_dice: 0.3624, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.3606, decode.d2.loss_dice: 0.3599, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.3581, decode.d3.loss_dice: 0.3552, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.3601, decode.d4.loss_dice: 0.3549, decode.d5.loss_cls: 0.0040, decode.d5.loss_mask: 0.3601, decode.d5.loss_dice: 0.3551, decode.d6.loss_cls: 0.0043, decode.d6.loss_mask: 0.3590, decode.d6.loss_dice: 0.3523, decode.d7.loss_cls: 0.0041, decode.d7.loss_mask: 0.3564, decode.d7.loss_dice: 0.3532, decode.d8.loss_cls: 0.0045, decode.d8.loss_mask: 0.3561, decode.d8.loss_dice: 0.3541, loss: 7.6475, grad_norm: 431.1781
2023-08-29 17:34:17,431 - mmseg - INFO - Iter [14850/160000]	lr: 1.527e-06, eta: 1 day, 5:23:22, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.3307, decode.loss_dice: 0.3257, decode.d0.loss_cls: 0.3897, decode.d0.loss_mask: 0.3460, decode.d0.loss_dice: 0.3545, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3309, decode.d1.loss_dice: 0.3288, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3334, decode.d2.loss_dice: 0.3286, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.3329, decode.d3.loss_dice: 0.3280, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.3298, decode.d4.loss_dice: 0.3236, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.3305, decode.d5.loss_dice: 0.3250, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.3297, decode.d6.loss_dice: 0.3223, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.3292, decode.d7.loss_dice: 0.3251, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.3296, decode.d8.loss_dice: 0.3226, loss: 7.0195, grad_norm: 355.8224
2023-08-29 17:34:54,219 - mmseg - INFO - Iter [14900/160000]	lr: 1.526e-06, eta: 1 day, 5:22:49, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.3718, decode.loss_dice: 0.3432, decode.d0.loss_cls: 0.3865, decode.d0.loss_mask: 0.3870, decode.d0.loss_dice: 0.3733, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.3770, decode.d1.loss_dice: 0.3513, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.3716, decode.d2.loss_dice: 0.3438, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3718, decode.d3.loss_dice: 0.3428, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3705, decode.d4.loss_dice: 0.3425, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.3713, decode.d5.loss_dice: 0.3427, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.3705, decode.d6.loss_dice: 0.3429, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.3714, decode.d7.loss_dice: 0.3434, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.3719, decode.d8.loss_dice: 0.3408, loss: 7.6097, grad_norm: 451.2274
2023-08-29 17:35:30,580 - mmseg - INFO - Iter [14950/160000]	lr: 1.526e-06, eta: 1 day, 5:22:12, time: 0.727, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0007, decode.loss_mask: 0.3649, decode.loss_dice: 0.3614, decode.d0.loss_cls: 0.3829, decode.d0.loss_mask: 0.3806, decode.d0.loss_dice: 0.3922, decode.d1.loss_cls: 0.0014, decode.d1.loss_mask: 0.3656, decode.d1.loss_dice: 0.3688, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.3643, decode.d2.loss_dice: 0.3642, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.3636, decode.d3.loss_dice: 0.3612, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.3638, decode.d4.loss_dice: 0.3622, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.3653, decode.d5.loss_dice: 0.3657, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.3635, decode.d6.loss_dice: 0.3614, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.3625, decode.d7.loss_dice: 0.3614, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.3672, decode.d8.loss_dice: 0.3632, loss: 7.7141, grad_norm: 422.9852
2023-08-29 17:36:07,856 - mmseg - INFO - Saving checkpoint at 15000 iterations
2023-08-29 17:36:10,182 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 17:36:10,182 - mmseg - INFO - Iter [15000/160000]	lr: 1.525e-06, eta: 1 day, 5:22:06, time: 0.792, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0108, decode.loss_mask: 0.3276, decode.loss_dice: 0.3466, decode.d0.loss_cls: 0.3841, decode.d0.loss_mask: 0.3373, decode.d0.loss_dice: 0.3755, decode.d1.loss_cls: 0.0137, decode.d1.loss_mask: 0.3286, decode.d1.loss_dice: 0.3466, decode.d2.loss_cls: 0.0100, decode.d2.loss_mask: 0.3267, decode.d2.loss_dice: 0.3474, decode.d3.loss_cls: 0.0081, decode.d3.loss_mask: 0.3266, decode.d3.loss_dice: 0.3464, decode.d4.loss_cls: 0.0064, decode.d4.loss_mask: 0.3267, decode.d4.loss_dice: 0.3464, decode.d5.loss_cls: 0.0061, decode.d5.loss_mask: 0.3272, decode.d5.loss_dice: 0.3440, decode.d6.loss_cls: 0.0060, decode.d6.loss_mask: 0.3299, decode.d6.loss_dice: 0.3461, decode.d7.loss_cls: 0.0109, decode.d7.loss_mask: 0.3272, decode.d7.loss_dice: 0.3417, decode.d8.loss_cls: 0.0144, decode.d8.loss_mask: 0.3269, decode.d8.loss_dice: 0.3415, loss: 7.2372, grad_norm: 366.1844
2023-08-29 17:36:47,332 - mmseg - INFO - Iter [15050/160000]	lr: 1.525e-06, eta: 1 day, 5:21:36, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3229, decode.loss_dice: 0.3087, decode.d0.loss_cls: 0.3768, decode.d0.loss_mask: 0.3381, decode.d0.loss_dice: 0.3334, decode.d1.loss_cls: 0.0018, decode.d1.loss_mask: 0.3229, decode.d1.loss_dice: 0.3119, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3220, decode.d2.loss_dice: 0.3084, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.3233, decode.d3.loss_dice: 0.3064, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3222, decode.d4.loss_dice: 0.3033, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.3210, decode.d5.loss_dice: 0.3042, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3190, decode.d6.loss_dice: 0.3039, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3185, decode.d7.loss_dice: 0.3035, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3219, decode.d8.loss_dice: 0.3059, loss: 6.7128, grad_norm: 378.5464
2023-08-29 17:37:22,037 - mmseg - INFO - Iter [15100/160000]	lr: 1.524e-06, eta: 1 day, 5:20:43, time: 0.694, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.3719, decode.loss_dice: 0.3413, decode.d0.loss_cls: 0.3736, decode.d0.loss_mask: 0.3890, decode.d0.loss_dice: 0.3827, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.3736, decode.d1.loss_dice: 0.3474, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.3722, decode.d2.loss_dice: 0.3435, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3740, decode.d3.loss_dice: 0.3427, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.3764, decode.d4.loss_dice: 0.3413, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.3716, decode.d5.loss_dice: 0.3408, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.3741, decode.d6.loss_dice: 0.3409, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.3722, decode.d7.loss_dice: 0.3362, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.3719, decode.d8.loss_dice: 0.3401, loss: 7.5962, grad_norm: 470.4825
2023-08-29 17:37:58,151 - mmseg - INFO - Iter [15150/160000]	lr: 1.524e-06, eta: 1 day, 5:20:03, time: 0.722, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.3251, decode.loss_dice: 0.3157, decode.d0.loss_cls: 0.3707, decode.d0.loss_mask: 0.3488, decode.d0.loss_dice: 0.3498, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3296, decode.d1.loss_dice: 0.3231, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3272, decode.d2.loss_dice: 0.3166, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3281, decode.d3.loss_dice: 0.3177, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.3237, decode.d4.loss_dice: 0.3122, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.3241, decode.d5.loss_dice: 0.3142, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3244, decode.d6.loss_dice: 0.3164, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3246, decode.d7.loss_dice: 0.3138, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3257, decode.d8.loss_dice: 0.3139, loss: 6.8635, grad_norm: 377.2536
2023-08-29 17:38:35,188 - mmseg - INFO - Iter [15200/160000]	lr: 1.523e-06, eta: 1 day, 5:19:32, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0072, decode.loss_mask: 0.3919, decode.loss_dice: 0.3810, decode.d0.loss_cls: 0.3712, decode.d0.loss_mask: 0.4181, decode.d0.loss_dice: 0.4146, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.4038, decode.d1.loss_dice: 0.3905, decode.d2.loss_cls: 0.0122, decode.d2.loss_mask: 0.3968, decode.d2.loss_dice: 0.3859, decode.d3.loss_cls: 0.0104, decode.d3.loss_mask: 0.3993, decode.d3.loss_dice: 0.3862, decode.d4.loss_cls: 0.0089, decode.d4.loss_mask: 0.3923, decode.d4.loss_dice: 0.3807, decode.d5.loss_cls: 0.0102, decode.d5.loss_mask: 0.3949, decode.d5.loss_dice: 0.3840, decode.d6.loss_cls: 0.0101, decode.d6.loss_mask: 0.3935, decode.d6.loss_dice: 0.3834, decode.d7.loss_cls: 0.0089, decode.d7.loss_mask: 0.3966, decode.d7.loss_dice: 0.3822, decode.d8.loss_cls: 0.0102, decode.d8.loss_mask: 0.3941, decode.d8.loss_dice: 0.3821, loss: 8.3203, grad_norm: 436.5380
2023-08-29 17:39:12,294 - mmseg - INFO - Iter [15250/160000]	lr: 1.523e-06, eta: 1 day, 5:19:02, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0060, decode.loss_mask: 0.3631, decode.loss_dice: 0.3450, decode.d0.loss_cls: 0.3658, decode.d0.loss_mask: 0.3914, decode.d0.loss_dice: 0.3882, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.3669, decode.d1.loss_dice: 0.3523, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.3633, decode.d2.loss_dice: 0.3472, decode.d3.loss_cls: 0.0054, decode.d3.loss_mask: 0.3618, decode.d3.loss_dice: 0.3440, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.3605, decode.d4.loss_dice: 0.3465, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.3612, decode.d5.loss_dice: 0.3440, decode.d6.loss_cls: 0.0069, decode.d6.loss_mask: 0.3626, decode.d6.loss_dice: 0.3487, decode.d7.loss_cls: 0.0080, decode.d7.loss_mask: 0.3612, decode.d7.loss_dice: 0.3446, decode.d8.loss_cls: 0.0087, decode.d8.loss_mask: 0.3620, decode.d8.loss_dice: 0.3429, loss: 7.5847, grad_norm: 396.1309
2023-08-29 17:39:47,026 - mmseg - INFO - Iter [15300/160000]	lr: 1.522e-06, eta: 1 day, 5:18:09, time: 0.694, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0012, decode.loss_mask: 0.3709, decode.loss_dice: 0.3480, decode.d0.loss_cls: 0.3633, decode.d0.loss_mask: 0.3997, decode.d0.loss_dice: 0.3756, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3769, decode.d1.loss_dice: 0.3460, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.3727, decode.d2.loss_dice: 0.3454, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.3748, decode.d3.loss_dice: 0.3428, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.3722, decode.d4.loss_dice: 0.3456, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.3733, decode.d5.loss_dice: 0.3455, decode.d6.loss_cls: 0.0014, decode.d6.loss_mask: 0.3709, decode.d6.loss_dice: 0.3446, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.3721, decode.d7.loss_dice: 0.3460, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.3736, decode.d8.loss_dice: 0.3467, loss: 7.6198, grad_norm: 401.9910
2023-08-29 17:40:23,432 - mmseg - INFO - Iter [15350/160000]	lr: 1.522e-06, eta: 1 day, 5:17:32, time: 0.728, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0014, decode.loss_mask: 0.3441, decode.loss_dice: 0.3242, decode.d0.loss_cls: 0.3580, decode.d0.loss_mask: 0.3534, decode.d0.loss_dice: 0.3554, decode.d1.loss_cls: 0.0018, decode.d1.loss_mask: 0.3410, decode.d1.loss_dice: 0.3240, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.3466, decode.d2.loss_dice: 0.3307, decode.d3.loss_cls: 0.0018, decode.d3.loss_mask: 0.3438, decode.d3.loss_dice: 0.3280, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3465, decode.d4.loss_dice: 0.3258, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3470, decode.d5.loss_dice: 0.3219, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3448, decode.d6.loss_dice: 0.3231, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.3434, decode.d7.loss_dice: 0.3233, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.3452, decode.d8.loss_dice: 0.3233, loss: 7.1079, grad_norm: 406.3914
2023-08-29 17:41:00,482 - mmseg - INFO - Iter [15400/160000]	lr: 1.521e-06, eta: 1 day, 5:17:01, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0226, decode.loss_mask: 0.4083, decode.loss_dice: 0.3972, decode.d0.loss_cls: 0.3617, decode.d0.loss_mask: 0.4234, decode.d0.loss_dice: 0.4280, decode.d1.loss_cls: 0.0252, decode.d1.loss_mask: 0.4084, decode.d1.loss_dice: 0.3948, decode.d2.loss_cls: 0.0222, decode.d2.loss_mask: 0.4012, decode.d2.loss_dice: 0.3922, decode.d3.loss_cls: 0.0237, decode.d3.loss_mask: 0.4013, decode.d3.loss_dice: 0.3957, decode.d4.loss_cls: 0.0232, decode.d4.loss_mask: 0.4019, decode.d4.loss_dice: 0.3976, decode.d5.loss_cls: 0.0244, decode.d5.loss_mask: 0.4052, decode.d5.loss_dice: 0.3950, decode.d6.loss_cls: 0.0243, decode.d6.loss_mask: 0.4037, decode.d6.loss_dice: 0.3953, decode.d7.loss_cls: 0.0217, decode.d7.loss_mask: 0.4066, decode.d7.loss_dice: 0.3937, decode.d8.loss_cls: 0.0234, decode.d8.loss_mask: 0.4139, decode.d8.loss_dice: 0.3986, loss: 8.6345, grad_norm: 451.2180
2023-08-29 17:41:37,748 - mmseg - INFO - Iter [15450/160000]	lr: 1.521e-06, eta: 1 day, 5:16:33, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0012, decode.loss_mask: 0.3695, decode.loss_dice: 0.3351, decode.d0.loss_cls: 0.3537, decode.d0.loss_mask: 0.3872, decode.d0.loss_dice: 0.3658, decode.d1.loss_cls: 0.0012, decode.d1.loss_mask: 0.3749, decode.d1.loss_dice: 0.3399, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.3749, decode.d2.loss_dice: 0.3367, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3770, decode.d3.loss_dice: 0.3334, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.3729, decode.d4.loss_dice: 0.3328, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3740, decode.d5.loss_dice: 0.3333, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.3735, decode.d6.loss_dice: 0.3363, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.3721, decode.d7.loss_dice: 0.3346, decode.d8.loss_cls: 0.0012, decode.d8.loss_mask: 0.3705, decode.d8.loss_dice: 0.3337, loss: 7.4917, grad_norm: 362.3652
2023-08-29 17:42:12,663 - mmseg - INFO - Iter [15500/160000]	lr: 1.520e-06, eta: 1 day, 5:15:42, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0194, decode.loss_mask: 0.3607, decode.loss_dice: 0.3442, decode.d0.loss_cls: 0.3550, decode.d0.loss_mask: 0.3696, decode.d0.loss_dice: 0.3788, decode.d1.loss_cls: 0.0213, decode.d1.loss_mask: 0.3502, decode.d1.loss_dice: 0.3452, decode.d2.loss_cls: 0.0152, decode.d2.loss_mask: 0.3462, decode.d2.loss_dice: 0.3417, decode.d3.loss_cls: 0.0135, decode.d3.loss_mask: 0.3481, decode.d3.loss_dice: 0.3419, decode.d4.loss_cls: 0.0160, decode.d4.loss_mask: 0.3426, decode.d4.loss_dice: 0.3404, decode.d5.loss_cls: 0.0202, decode.d5.loss_mask: 0.3454, decode.d5.loss_dice: 0.3435, decode.d6.loss_cls: 0.0208, decode.d6.loss_mask: 0.3449, decode.d6.loss_dice: 0.3450, decode.d7.loss_cls: 0.0210, decode.d7.loss_mask: 0.3461, decode.d7.loss_dice: 0.3395, decode.d8.loss_cls: 0.0235, decode.d8.loss_mask: 0.3513, decode.d8.loss_dice: 0.3459, loss: 7.4969, grad_norm: 326.5939
2023-08-29 17:42:49,155 - mmseg - INFO - Iter [15550/160000]	lr: 1.520e-06, eta: 1 day, 5:15:06, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.3408, decode.loss_dice: 0.3380, decode.d0.loss_cls: 0.3470, decode.d0.loss_mask: 0.3631, decode.d0.loss_dice: 0.3735, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.3416, decode.d1.loss_dice: 0.3373, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3396, decode.d2.loss_dice: 0.3371, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3396, decode.d3.loss_dice: 0.3368, decode.d4.loss_cls: 0.0022, decode.d4.loss_mask: 0.3375, decode.d4.loss_dice: 0.3364, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3398, decode.d5.loss_dice: 0.3387, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.3416, decode.d6.loss_dice: 0.3372, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.3385, decode.d7.loss_dice: 0.3403, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.3404, decode.d8.loss_dice: 0.3366, loss: 7.2024, grad_norm: 429.9626
2023-08-29 17:43:26,180 - mmseg - INFO - Iter [15600/160000]	lr: 1.519e-06, eta: 1 day, 5:14:35, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0042, decode.loss_mask: 0.3443, decode.loss_dice: 0.3128, decode.d0.loss_cls: 0.3473, decode.d0.loss_mask: 0.3493, decode.d0.loss_dice: 0.3388, decode.d1.loss_cls: 0.0162, decode.d1.loss_mask: 0.3365, decode.d1.loss_dice: 0.3175, decode.d2.loss_cls: 0.0089, decode.d2.loss_mask: 0.3426, decode.d2.loss_dice: 0.3155, decode.d3.loss_cls: 0.0106, decode.d3.loss_mask: 0.3397, decode.d3.loss_dice: 0.3095, decode.d4.loss_cls: 0.0070, decode.d4.loss_mask: 0.3447, decode.d4.loss_dice: 0.3120, decode.d5.loss_cls: 0.0063, decode.d5.loss_mask: 0.3483, decode.d5.loss_dice: 0.3117, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.3460, decode.d6.loss_dice: 0.3106, decode.d7.loss_cls: 0.0066, decode.d7.loss_mask: 0.3385, decode.d7.loss_dice: 0.3127, decode.d8.loss_cls: 0.0064, decode.d8.loss_mask: 0.3396, decode.d8.loss_dice: 0.3131, loss: 7.0031, grad_norm: 429.6899
2023-08-29 17:44:03,207 - mmseg - INFO - Iter [15650/160000]	lr: 1.519e-06, eta: 1 day, 5:14:03, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0080, decode.loss_mask: 0.3151, decode.loss_dice: 0.3207, decode.d0.loss_cls: 0.3419, decode.d0.loss_mask: 0.3404, decode.d0.loss_dice: 0.3525, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3209, decode.d1.loss_dice: 0.3212, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.3176, decode.d2.loss_dice: 0.3211, decode.d3.loss_cls: 0.0068, decode.d3.loss_mask: 0.3160, decode.d3.loss_dice: 0.3178, decode.d4.loss_cls: 0.0068, decode.d4.loss_mask: 0.3161, decode.d4.loss_dice: 0.3180, decode.d5.loss_cls: 0.0091, decode.d5.loss_mask: 0.3162, decode.d5.loss_dice: 0.3150, decode.d6.loss_cls: 0.0077, decode.d6.loss_mask: 0.3158, decode.d6.loss_dice: 0.3177, decode.d7.loss_cls: 0.0062, decode.d7.loss_mask: 0.3177, decode.d7.loss_dice: 0.3181, decode.d8.loss_cls: 0.0062, decode.d8.loss_mask: 0.3185, decode.d8.loss_dice: 0.3174, loss: 6.8176, grad_norm: 379.7259
2023-08-29 17:44:37,778 - mmseg - INFO - Iter [15700/160000]	lr: 1.518e-06, eta: 1 day, 5:13:10, time: 0.691, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0065, decode.loss_mask: 0.3597, decode.loss_dice: 0.3325, decode.d0.loss_cls: 0.3406, decode.d0.loss_mask: 0.3720, decode.d0.loss_dice: 0.3555, decode.d1.loss_cls: 0.0076, decode.d1.loss_mask: 0.3602, decode.d1.loss_dice: 0.3373, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.3602, decode.d2.loss_dice: 0.3358, decode.d3.loss_cls: 0.0054, decode.d3.loss_mask: 0.3588, decode.d3.loss_dice: 0.3325, decode.d4.loss_cls: 0.0070, decode.d4.loss_mask: 0.3568, decode.d4.loss_dice: 0.3305, decode.d5.loss_cls: 0.0078, decode.d5.loss_mask: 0.3591, decode.d5.loss_dice: 0.3295, decode.d6.loss_cls: 0.0078, decode.d6.loss_mask: 0.3591, decode.d6.loss_dice: 0.3302, decode.d7.loss_cls: 0.0072, decode.d7.loss_mask: 0.3559, decode.d7.loss_dice: 0.3274, decode.d8.loss_cls: 0.0082, decode.d8.loss_mask: 0.3582, decode.d8.loss_dice: 0.3299, loss: 7.3456, grad_norm: 438.5573
2023-08-29 17:45:14,193 - mmseg - INFO - Iter [15750/160000]	lr: 1.518e-06, eta: 1 day, 5:12:33, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0049, decode.loss_mask: 0.3551, decode.loss_dice: 0.3652, decode.d0.loss_cls: 0.3377, decode.d0.loss_mask: 0.3829, decode.d0.loss_dice: 0.4064, decode.d1.loss_cls: 0.0064, decode.d1.loss_mask: 0.3615, decode.d1.loss_dice: 0.3767, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.3584, decode.d2.loss_dice: 0.3723, decode.d3.loss_cls: 0.0057, decode.d3.loss_mask: 0.3548, decode.d3.loss_dice: 0.3661, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.3458, decode.d4.loss_dice: 0.3615, decode.d5.loss_cls: 0.0129, decode.d5.loss_mask: 0.3469, decode.d5.loss_dice: 0.3620, decode.d6.loss_cls: 0.0081, decode.d6.loss_mask: 0.3447, decode.d6.loss_dice: 0.3569, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.3554, decode.d7.loss_dice: 0.3638, decode.d8.loss_cls: 0.0046, decode.d8.loss_mask: 0.3550, decode.d8.loss_dice: 0.3659, loss: 7.6573, grad_norm: 428.0889
2023-08-29 17:45:51,144 - mmseg - INFO - Iter [15800/160000]	lr: 1.517e-06, eta: 1 day, 5:12:01, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.3591, decode.loss_dice: 0.3673, decode.d0.loss_cls: 0.3354, decode.d0.loss_mask: 0.3870, decode.d0.loss_dice: 0.3996, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.3630, decode.d1.loss_dice: 0.3714, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.3648, decode.d2.loss_dice: 0.3746, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.3592, decode.d3.loss_dice: 0.3665, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.3581, decode.d4.loss_dice: 0.3606, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.3624, decode.d5.loss_dice: 0.3655, decode.d6.loss_cls: 0.0031, decode.d6.loss_mask: 0.3606, decode.d6.loss_dice: 0.3623, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.3616, decode.d7.loss_dice: 0.3616, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.3649, decode.d8.loss_dice: 0.3653, loss: 7.7004, grad_norm: 384.9575
2023-08-29 17:46:28,037 - mmseg - INFO - Iter [15850/160000]	lr: 1.516e-06, eta: 1 day, 5:11:29, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3310, decode.loss_dice: 0.3360, decode.d0.loss_cls: 0.3315, decode.d0.loss_mask: 0.3529, decode.d0.loss_dice: 0.3631, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3276, decode.d1.loss_dice: 0.3392, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.3298, decode.d2.loss_dice: 0.3391, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.3302, decode.d3.loss_dice: 0.3372, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3289, decode.d4.loss_dice: 0.3319, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.3305, decode.d5.loss_dice: 0.3338, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.3291, decode.d6.loss_dice: 0.3353, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3312, decode.d7.loss_dice: 0.3355, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.3294, decode.d8.loss_dice: 0.3333, loss: 7.0519, grad_norm: 355.2387
2023-08-29 17:47:03,177 - mmseg - INFO - Iter [15900/160000]	lr: 1.516e-06, eta: 1 day, 5:10:40, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0157, decode.loss_mask: 0.4222, decode.loss_dice: 0.3613, decode.d0.loss_cls: 0.3356, decode.d0.loss_mask: 0.4265, decode.d0.loss_dice: 0.3787, decode.d1.loss_cls: 0.0248, decode.d1.loss_mask: 0.4199, decode.d1.loss_dice: 0.3622, decode.d2.loss_cls: 0.0191, decode.d2.loss_mask: 0.4179, decode.d2.loss_dice: 0.3605, decode.d3.loss_cls: 0.0168, decode.d3.loss_mask: 0.4191, decode.d3.loss_dice: 0.3596, decode.d4.loss_cls: 0.0147, decode.d4.loss_mask: 0.4176, decode.d4.loss_dice: 0.3571, decode.d5.loss_cls: 0.0144, decode.d5.loss_mask: 0.4169, decode.d5.loss_dice: 0.3567, decode.d6.loss_cls: 0.0140, decode.d6.loss_mask: 0.4214, decode.d6.loss_dice: 0.3586, decode.d7.loss_cls: 0.0163, decode.d7.loss_mask: 0.4161, decode.d7.loss_dice: 0.3546, decode.d8.loss_cls: 0.0170, decode.d8.loss_mask: 0.4144, decode.d8.loss_dice: 0.3568, loss: 8.2865, grad_norm: 386.2229
2023-08-29 17:47:39,664 - mmseg - INFO - Iter [15950/160000]	lr: 1.515e-06, eta: 1 day, 5:10:04, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.3210, decode.loss_dice: 0.3321, decode.d0.loss_cls: 0.3258, decode.d0.loss_mask: 0.3361, decode.d0.loss_dice: 0.3576, decode.d1.loss_cls: 0.0015, decode.d1.loss_mask: 0.3186, decode.d1.loss_dice: 0.3344, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.3178, decode.d2.loss_dice: 0.3340, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.3193, decode.d3.loss_dice: 0.3310, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.3160, decode.d4.loss_dice: 0.3269, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.3184, decode.d5.loss_dice: 0.3300, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.3199, decode.d6.loss_dice: 0.3299, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.3185, decode.d7.loss_dice: 0.3285, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.3186, decode.d8.loss_dice: 0.3301, loss: 6.8733, grad_norm: 356.4360
2023-08-29 17:48:16,284 - mmseg - INFO - Saving checkpoint at 16000 iterations
2023-08-29 17:48:21,377 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 17:48:21,377 - mmseg - INFO - Iter [16000/160000]	lr: 1.515e-06, eta: 1 day, 5:10:15, time: 0.834, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.3350, decode.loss_dice: 0.3142, decode.d0.loss_cls: 0.3233, decode.d0.loss_mask: 0.3454, decode.d0.loss_dice: 0.3422, decode.d1.loss_cls: 0.0017, decode.d1.loss_mask: 0.3291, decode.d1.loss_dice: 0.3154, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.3300, decode.d2.loss_dice: 0.3171, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3298, decode.d3.loss_dice: 0.3147, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.3312, decode.d4.loss_dice: 0.3137, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3311, decode.d5.loss_dice: 0.3128, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.3332, decode.d6.loss_dice: 0.3145, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.3345, decode.d7.loss_dice: 0.3143, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.3336, decode.d8.loss_dice: 0.3132, loss: 6.8373, grad_norm: 334.0864
