2023-08-28 23:46:48,699 - mmseg - INFO - Multi-processing start method is `None`
2023-08-28 23:46:48,701 - mmseg - INFO - OpenCV num_threads is `12
2023-08-28 23:46:48,701 - mmseg - INFO - OMP num threads is 1
2023-08-28 23:46:48,751 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce GTX 1080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 12.1, V12.1.66
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+cefb275
------------------------------------------------------------

2023-08-28 23:46:48,751 - mmseg - INFO - Distributed training: True
2023-08-28 23:46:49,704 - mmseg - INFO - Config:
num_things_classes = 0
num_stuff_classes = 2
num_classes = 2
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoderMask2Former',
    pretrained=None,
    backbone=dict(
        type='InternImage',
        core_op='DCNv3',
        channels=112,
        depths=[4, 4, 21, 4],
        groups=[7, 14, 28, 56],
        mlp_ratio=4.0,
        drop_path_rate=0.4,
        norm_layer='LN',
        layer_scale=1.0,
        offset_scale=1.0,
        post_norm=True,
        with_cp=False,
        out_indices=(0, 1, 2, 3),
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
        )),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[112, 224, 448, 896],
        feat_channels=256,
        out_channels=256,
        in_index=[0, 1, 2, 3],
        num_things_classes=0,
        num_stuff_classes=2,
        num_queries=100,
        num_transformer_feat_level=3,
        pixel_decoder=dict(
            type='MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        num_heads=8,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=False,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True),
                        with_cp=True),
                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),
                init_cfg=None),
            positional_encoding=dict(
                type='SinePositionalEncoding', num_feats=128, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(
            type='SinePositionalEncoding', num_feats=128, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=256,
                    num_heads=8,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=256,
                    feedforward_channels=2048,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True,
                    with_cp=True),
                feedforward_channels=2048,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[1.0, 1.0, 0.1]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0)),
    train_cfg=dict(
        num_points=12544,
        oversample_ratio=3.0,
        importance_sample_ratio=0.75,
        assigner=dict(
            type='MaskHungarianAssigner',
            cls_cost=dict(type='ClassificationCost', weight=2.0),
            mask_cost=dict(
                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
            dice_cost=dict(
                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
        sampler=dict(type='MaskPseudoSampler')),
    test_cfg=dict(
        panoptic_on=True,
        semantic_on=False,
        instance_on=True,
        max_per_image=100,
        iou_thr=0.8,
        filter_low_score=True,
        mode='slide',
        crop_size=(200, 664),
        stride=(341, 341)),
    init_cfg=None)
dataset_type = 'UPBDataset'
data_root = '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation'
img_norm_cfg = dict(
    mean=[89.497, 93.675, 92.645], std=[76.422, 78.611, 80.487], to_rgb=True)
crop_size = (200, 664)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=False),
    dict(type='LoadCategory'),
    dict(type='Resize', img_scale=(664, 200), ratio_range=None),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[89.497, 93.675, 92.645],
        std=[76.422, 78.611, 80.487],
        to_rgb=True),
    dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
    dict(type='ToMask'),
    dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels', 'category'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(200, 664),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir='self_supervised_labels_30',
        split='splits/val_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=False),
            dict(type='LoadCategory'),
            dict(type='Resize', img_scale=(664, 200), ratio_range=None),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
            dict(type='ToMask'),
            dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=[
                    'img', 'gt_semantic_seg', 'gt_masks', 'gt_labels',
                    'category'
                ])
        ]),
    val=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    constructor='CustomLayerDecayOptimizerConstructor',
    paramwise_cfg=dict(
        num_layers=39,
        layer_decay_rate=0.94,
        depths=[5, 5, 24, 5],
        offset_lr_scale=1.0))
optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
evaluation = dict(
    interval=16000, metric='mIoU', pre_eval=True, save_best='mIoU')
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
work_dir = 'work_dirs/mask2former_internimage_b_kitti'
gpu_ids = range(0, 2)
auto_resume = False

2023-08-28 23:46:52,877 - mmseg - INFO - Set random seed to 948791995, deterministic: False
2023-08-28 23:46:52,878 - mmseg - INFO - using core type: DCNv3
2023-08-28 23:46:52,878 - mmseg - INFO - using activation layer: GELU
2023-08-28 23:46:52,878 - mmseg - INFO - using main norm layer: LN
2023-08-28 23:46:52,878 - mmseg - INFO - using dpr: linear, 0.4
2023-08-28 23:46:52,878 - mmseg - INFO - level2_post_norm: False
2023-08-28 23:46:52,878 - mmseg - INFO - level2_post_norm_block_ids: None
2023-08-28 23:46:52,878 - mmseg - INFO - res_post_norm: False
2023-08-28 23:46:54,198 - mmseg - INFO - load checkpoint from http path: https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth
2023-08-28 23:46:55,070 - mmseg - INFO - _IncompatibleKeys(missing_keys=[], unexpected_keys=['conv_head.0.weight', 'conv_head.1.0.weight', 'conv_head.1.0.bias', 'conv_head.1.0.running_mean', 'conv_head.1.0.running_var', 'conv_head.1.0.num_batches_tracked', 'head.weight', 'head.bias'])
Name of parameter - Initialization information

backbone.patch_embed.conv1.weight - torch.Size([56, 3, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.weight - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.weight - torch.Size([112, 56, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.conv.weight - torch.Size([224, 112, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.conv.weight - torch.Size([448, 224, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.conv.weight - torch.Size([896, 448, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 896, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 448, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 224, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 112, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  
2023-08-28 23:46:55,380 - mmseg - INFO - Loaded 20598 images
2023-08-28 23:47:08,874 - mmseg - INFO - {'num_layers': 39, 'layer_decay_rate': 0.94, 'depths': [5, 5, 24, 5], 'offset_lr_scale': 1.0}
2023-08-28 23:47:08,874 - mmseg - INFO - Build CustomLayerDecayOptimizerConstructor 0.940000 - 41
2023-08-28 23:47:08,879 - mmseg - INFO - Param groups = {
  "layer_0_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.weight",
      "backbone.patch_embed.conv2.weight",
      "decode_head.query_embed.weight",
      "decode_head.query_feat.weight",
      "decode_head.level_embed.weight",
      "decode_head.cls_embed.weight",
      "decode_head.mask_embed.0.weight",
      "decode_head.mask_embed.2.weight",
      "decode_head.mask_embed.4.weight"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.05
  },
  "layer_0_no_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.bias",
      "backbone.patch_embed.norm1.1.weight",
      "backbone.patch_embed.norm1.1.bias",
      "backbone.patch_embed.conv2.bias",
      "backbone.patch_embed.norm2.1.weight",
      "backbone.patch_embed.norm2.1.bias",
      "decode_head.cls_embed.bias",
      "decode_head.mask_embed.0.bias",
      "decode_head.mask_embed.2.bias",
      "decode_head.mask_embed.4.bias"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.0
  },
  "layer_1_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.gamma1",
      "backbone.levels.0.blocks.0.gamma2",
      "backbone.levels.0.blocks.0.norm1.0.weight",
      "backbone.levels.0.blocks.0.norm1.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.0.dcn.offset.bias",
      "backbone.levels.0.blocks.0.dcn.mask.bias",
      "backbone.levels.0.blocks.0.dcn.input_proj.bias",
      "backbone.levels.0.blocks.0.dcn.output_proj.bias",
      "backbone.levels.0.blocks.0.norm2.0.weight",
      "backbone.levels.0.blocks.0.norm2.0.bias",
      "backbone.levels.0.blocks.0.mlp.fc1.bias",
      "backbone.levels.0.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.0
  },
  "layer_1_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.0.dcn.offset.weight",
      "backbone.levels.0.blocks.0.dcn.mask.weight",
      "backbone.levels.0.blocks.0.dcn.input_proj.weight",
      "backbone.levels.0.blocks.0.dcn.output_proj.weight",
      "backbone.levels.0.blocks.0.mlp.fc1.weight",
      "backbone.levels.0.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.05
  },
  "layer_2_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.gamma1",
      "backbone.levels.0.blocks.1.gamma2",
      "backbone.levels.0.blocks.1.norm1.0.weight",
      "backbone.levels.0.blocks.1.norm1.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.1.dcn.offset.bias",
      "backbone.levels.0.blocks.1.dcn.mask.bias",
      "backbone.levels.0.blocks.1.dcn.input_proj.bias",
      "backbone.levels.0.blocks.1.dcn.output_proj.bias",
      "backbone.levels.0.blocks.1.norm2.0.weight",
      "backbone.levels.0.blocks.1.norm2.0.bias",
      "backbone.levels.0.blocks.1.mlp.fc1.bias",
      "backbone.levels.0.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.0
  },
  "layer_2_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.1.dcn.offset.weight",
      "backbone.levels.0.blocks.1.dcn.mask.weight",
      "backbone.levels.0.blocks.1.dcn.input_proj.weight",
      "backbone.levels.0.blocks.1.dcn.output_proj.weight",
      "backbone.levels.0.blocks.1.mlp.fc1.weight",
      "backbone.levels.0.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.05
  },
  "layer_3_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.gamma1",
      "backbone.levels.0.blocks.2.gamma2",
      "backbone.levels.0.blocks.2.norm1.0.weight",
      "backbone.levels.0.blocks.2.norm1.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.2.dcn.offset.bias",
      "backbone.levels.0.blocks.2.dcn.mask.bias",
      "backbone.levels.0.blocks.2.dcn.input_proj.bias",
      "backbone.levels.0.blocks.2.dcn.output_proj.bias",
      "backbone.levels.0.blocks.2.norm2.0.weight",
      "backbone.levels.0.blocks.2.norm2.0.bias",
      "backbone.levels.0.blocks.2.mlp.fc1.bias",
      "backbone.levels.0.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.0
  },
  "layer_3_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.2.dcn.offset.weight",
      "backbone.levels.0.blocks.2.dcn.mask.weight",
      "backbone.levels.0.blocks.2.dcn.input_proj.weight",
      "backbone.levels.0.blocks.2.dcn.output_proj.weight",
      "backbone.levels.0.blocks.2.mlp.fc1.weight",
      "backbone.levels.0.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.05
  },
  "layer_4_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.gamma1",
      "backbone.levels.0.blocks.3.gamma2",
      "backbone.levels.0.blocks.3.norm1.0.weight",
      "backbone.levels.0.blocks.3.norm1.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.3.dcn.offset.bias",
      "backbone.levels.0.blocks.3.dcn.mask.bias",
      "backbone.levels.0.blocks.3.dcn.input_proj.bias",
      "backbone.levels.0.blocks.3.dcn.output_proj.bias",
      "backbone.levels.0.blocks.3.norm2.0.weight",
      "backbone.levels.0.blocks.3.norm2.0.bias",
      "backbone.levels.0.blocks.3.mlp.fc1.bias",
      "backbone.levels.0.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.0
  },
  "layer_4_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.3.dcn.offset.weight",
      "backbone.levels.0.blocks.3.dcn.mask.weight",
      "backbone.levels.0.blocks.3.dcn.input_proj.weight",
      "backbone.levels.0.blocks.3.dcn.output_proj.weight",
      "backbone.levels.0.blocks.3.mlp.fc1.weight",
      "backbone.levels.0.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.05
  },
  "layer_6_decay": {
    "param_names": [
      "backbone.levels.0.downsample.conv.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.0.dcn.offset.weight",
      "backbone.levels.1.blocks.0.dcn.mask.weight",
      "backbone.levels.1.blocks.0.dcn.input_proj.weight",
      "backbone.levels.1.blocks.0.dcn.output_proj.weight",
      "backbone.levels.1.blocks.0.mlp.fc1.weight",
      "backbone.levels.1.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.05
  },
  "layer_6_no_decay": {
    "param_names": [
      "backbone.levels.0.downsample.norm.1.weight",
      "backbone.levels.0.downsample.norm.1.bias",
      "backbone.levels.1.blocks.0.gamma1",
      "backbone.levels.1.blocks.0.gamma2",
      "backbone.levels.1.blocks.0.norm1.0.weight",
      "backbone.levels.1.blocks.0.norm1.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.0.dcn.offset.bias",
      "backbone.levels.1.blocks.0.dcn.mask.bias",
      "backbone.levels.1.blocks.0.dcn.input_proj.bias",
      "backbone.levels.1.blocks.0.dcn.output_proj.bias",
      "backbone.levels.1.blocks.0.norm2.0.weight",
      "backbone.levels.1.blocks.0.norm2.0.bias",
      "backbone.levels.1.blocks.0.mlp.fc1.bias",
      "backbone.levels.1.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.0
  },
  "layer_7_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.gamma1",
      "backbone.levels.1.blocks.1.gamma2",
      "backbone.levels.1.blocks.1.norm1.0.weight",
      "backbone.levels.1.blocks.1.norm1.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.1.dcn.offset.bias",
      "backbone.levels.1.blocks.1.dcn.mask.bias",
      "backbone.levels.1.blocks.1.dcn.input_proj.bias",
      "backbone.levels.1.blocks.1.dcn.output_proj.bias",
      "backbone.levels.1.blocks.1.norm2.0.weight",
      "backbone.levels.1.blocks.1.norm2.0.bias",
      "backbone.levels.1.blocks.1.mlp.fc1.bias",
      "backbone.levels.1.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.0
  },
  "layer_7_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.1.dcn.offset.weight",
      "backbone.levels.1.blocks.1.dcn.mask.weight",
      "backbone.levels.1.blocks.1.dcn.input_proj.weight",
      "backbone.levels.1.blocks.1.dcn.output_proj.weight",
      "backbone.levels.1.blocks.1.mlp.fc1.weight",
      "backbone.levels.1.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.05
  },
  "layer_8_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.gamma1",
      "backbone.levels.1.blocks.2.gamma2",
      "backbone.levels.1.blocks.2.norm1.0.weight",
      "backbone.levels.1.blocks.2.norm1.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.2.dcn.offset.bias",
      "backbone.levels.1.blocks.2.dcn.mask.bias",
      "backbone.levels.1.blocks.2.dcn.input_proj.bias",
      "backbone.levels.1.blocks.2.dcn.output_proj.bias",
      "backbone.levels.1.blocks.2.norm2.0.weight",
      "backbone.levels.1.blocks.2.norm2.0.bias",
      "backbone.levels.1.blocks.2.mlp.fc1.bias",
      "backbone.levels.1.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.0
  },
  "layer_8_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.2.dcn.offset.weight",
      "backbone.levels.1.blocks.2.dcn.mask.weight",
      "backbone.levels.1.blocks.2.dcn.input_proj.weight",
      "backbone.levels.1.blocks.2.dcn.output_proj.weight",
      "backbone.levels.1.blocks.2.mlp.fc1.weight",
      "backbone.levels.1.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.05
  },
  "layer_9_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.gamma1",
      "backbone.levels.1.blocks.3.gamma2",
      "backbone.levels.1.blocks.3.norm1.0.weight",
      "backbone.levels.1.blocks.3.norm1.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.3.dcn.offset.bias",
      "backbone.levels.1.blocks.3.dcn.mask.bias",
      "backbone.levels.1.blocks.3.dcn.input_proj.bias",
      "backbone.levels.1.blocks.3.dcn.output_proj.bias",
      "backbone.levels.1.blocks.3.norm2.0.weight",
      "backbone.levels.1.blocks.3.norm2.0.bias",
      "backbone.levels.1.blocks.3.mlp.fc1.bias",
      "backbone.levels.1.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.0
  },
  "layer_9_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.3.dcn.offset.weight",
      "backbone.levels.1.blocks.3.dcn.mask.weight",
      "backbone.levels.1.blocks.3.dcn.input_proj.weight",
      "backbone.levels.1.blocks.3.dcn.output_proj.weight",
      "backbone.levels.1.blocks.3.mlp.fc1.weight",
      "backbone.levels.1.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.05
  },
  "layer_11_decay": {
    "param_names": [
      "backbone.levels.1.downsample.conv.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.0.dcn.offset.weight",
      "backbone.levels.2.blocks.0.dcn.mask.weight",
      "backbone.levels.2.blocks.0.dcn.input_proj.weight",
      "backbone.levels.2.blocks.0.dcn.output_proj.weight",
      "backbone.levels.2.blocks.0.mlp.fc1.weight",
      "backbone.levels.2.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.05
  },
  "layer_11_no_decay": {
    "param_names": [
      "backbone.levels.1.downsample.norm.1.weight",
      "backbone.levels.1.downsample.norm.1.bias",
      "backbone.levels.2.blocks.0.gamma1",
      "backbone.levels.2.blocks.0.gamma2",
      "backbone.levels.2.blocks.0.norm1.0.weight",
      "backbone.levels.2.blocks.0.norm1.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.0.dcn.offset.bias",
      "backbone.levels.2.blocks.0.dcn.mask.bias",
      "backbone.levels.2.blocks.0.dcn.input_proj.bias",
      "backbone.levels.2.blocks.0.dcn.output_proj.bias",
      "backbone.levels.2.blocks.0.norm2.0.weight",
      "backbone.levels.2.blocks.0.norm2.0.bias",
      "backbone.levels.2.blocks.0.mlp.fc1.bias",
      "backbone.levels.2.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.0
  },
  "layer_12_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.gamma1",
      "backbone.levels.2.blocks.1.gamma2",
      "backbone.levels.2.blocks.1.norm1.0.weight",
      "backbone.levels.2.blocks.1.norm1.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.1.dcn.offset.bias",
      "backbone.levels.2.blocks.1.dcn.mask.bias",
      "backbone.levels.2.blocks.1.dcn.input_proj.bias",
      "backbone.levels.2.blocks.1.dcn.output_proj.bias",
      "backbone.levels.2.blocks.1.norm2.0.weight",
      "backbone.levels.2.blocks.1.norm2.0.bias",
      "backbone.levels.2.blocks.1.mlp.fc1.bias",
      "backbone.levels.2.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.0
  },
  "layer_12_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.1.dcn.offset.weight",
      "backbone.levels.2.blocks.1.dcn.mask.weight",
      "backbone.levels.2.blocks.1.dcn.input_proj.weight",
      "backbone.levels.2.blocks.1.dcn.output_proj.weight",
      "backbone.levels.2.blocks.1.mlp.fc1.weight",
      "backbone.levels.2.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.05
  },
  "layer_13_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.gamma1",
      "backbone.levels.2.blocks.2.gamma2",
      "backbone.levels.2.blocks.2.norm1.0.weight",
      "backbone.levels.2.blocks.2.norm1.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.2.dcn.offset.bias",
      "backbone.levels.2.blocks.2.dcn.mask.bias",
      "backbone.levels.2.blocks.2.dcn.input_proj.bias",
      "backbone.levels.2.blocks.2.dcn.output_proj.bias",
      "backbone.levels.2.blocks.2.norm2.0.weight",
      "backbone.levels.2.blocks.2.norm2.0.bias",
      "backbone.levels.2.blocks.2.mlp.fc1.bias",
      "backbone.levels.2.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.0
  },
  "layer_13_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.2.dcn.offset.weight",
      "backbone.levels.2.blocks.2.dcn.mask.weight",
      "backbone.levels.2.blocks.2.dcn.input_proj.weight",
      "backbone.levels.2.blocks.2.dcn.output_proj.weight",
      "backbone.levels.2.blocks.2.mlp.fc1.weight",
      "backbone.levels.2.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.05
  },
  "layer_14_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.gamma1",
      "backbone.levels.2.blocks.3.gamma2",
      "backbone.levels.2.blocks.3.norm1.0.weight",
      "backbone.levels.2.blocks.3.norm1.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.3.dcn.offset.bias",
      "backbone.levels.2.blocks.3.dcn.mask.bias",
      "backbone.levels.2.blocks.3.dcn.input_proj.bias",
      "backbone.levels.2.blocks.3.dcn.output_proj.bias",
      "backbone.levels.2.blocks.3.norm2.0.weight",
      "backbone.levels.2.blocks.3.norm2.0.bias",
      "backbone.levels.2.blocks.3.mlp.fc1.bias",
      "backbone.levels.2.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.0
  },
  "layer_14_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.3.dcn.offset.weight",
      "backbone.levels.2.blocks.3.dcn.mask.weight",
      "backbone.levels.2.blocks.3.dcn.input_proj.weight",
      "backbone.levels.2.blocks.3.dcn.output_proj.weight",
      "backbone.levels.2.blocks.3.mlp.fc1.weight",
      "backbone.levels.2.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.05
  },
  "layer_15_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.gamma1",
      "backbone.levels.2.blocks.4.gamma2",
      "backbone.levels.2.blocks.4.norm1.0.weight",
      "backbone.levels.2.blocks.4.norm1.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.4.dcn.offset.bias",
      "backbone.levels.2.blocks.4.dcn.mask.bias",
      "backbone.levels.2.blocks.4.dcn.input_proj.bias",
      "backbone.levels.2.blocks.4.dcn.output_proj.bias",
      "backbone.levels.2.blocks.4.norm2.0.weight",
      "backbone.levels.2.blocks.4.norm2.0.bias",
      "backbone.levels.2.blocks.4.mlp.fc1.bias",
      "backbone.levels.2.blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.0
  },
  "layer_15_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.4.dcn.offset.weight",
      "backbone.levels.2.blocks.4.dcn.mask.weight",
      "backbone.levels.2.blocks.4.dcn.input_proj.weight",
      "backbone.levels.2.blocks.4.dcn.output_proj.weight",
      "backbone.levels.2.blocks.4.mlp.fc1.weight",
      "backbone.levels.2.blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.05
  },
  "layer_16_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.gamma1",
      "backbone.levels.2.blocks.5.gamma2",
      "backbone.levels.2.blocks.5.norm1.0.weight",
      "backbone.levels.2.blocks.5.norm1.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.5.dcn.offset.bias",
      "backbone.levels.2.blocks.5.dcn.mask.bias",
      "backbone.levels.2.blocks.5.dcn.input_proj.bias",
      "backbone.levels.2.blocks.5.dcn.output_proj.bias",
      "backbone.levels.2.blocks.5.norm2.0.weight",
      "backbone.levels.2.blocks.5.norm2.0.bias",
      "backbone.levels.2.blocks.5.mlp.fc1.bias",
      "backbone.levels.2.blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.0
  },
  "layer_16_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.5.dcn.offset.weight",
      "backbone.levels.2.blocks.5.dcn.mask.weight",
      "backbone.levels.2.blocks.5.dcn.input_proj.weight",
      "backbone.levels.2.blocks.5.dcn.output_proj.weight",
      "backbone.levels.2.blocks.5.mlp.fc1.weight",
      "backbone.levels.2.blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.05
  },
  "layer_17_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.gamma1",
      "backbone.levels.2.blocks.6.gamma2",
      "backbone.levels.2.blocks.6.norm1.0.weight",
      "backbone.levels.2.blocks.6.norm1.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.6.dcn.offset.bias",
      "backbone.levels.2.blocks.6.dcn.mask.bias",
      "backbone.levels.2.blocks.6.dcn.input_proj.bias",
      "backbone.levels.2.blocks.6.dcn.output_proj.bias",
      "backbone.levels.2.blocks.6.norm2.0.weight",
      "backbone.levels.2.blocks.6.norm2.0.bias",
      "backbone.levels.2.blocks.6.mlp.fc1.bias",
      "backbone.levels.2.blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.0
  },
  "layer_17_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.6.dcn.offset.weight",
      "backbone.levels.2.blocks.6.dcn.mask.weight",
      "backbone.levels.2.blocks.6.dcn.input_proj.weight",
      "backbone.levels.2.blocks.6.dcn.output_proj.weight",
      "backbone.levels.2.blocks.6.mlp.fc1.weight",
      "backbone.levels.2.blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.05
  },
  "layer_18_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.gamma1",
      "backbone.levels.2.blocks.7.gamma2",
      "backbone.levels.2.blocks.7.norm1.0.weight",
      "backbone.levels.2.blocks.7.norm1.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.7.dcn.offset.bias",
      "backbone.levels.2.blocks.7.dcn.mask.bias",
      "backbone.levels.2.blocks.7.dcn.input_proj.bias",
      "backbone.levels.2.blocks.7.dcn.output_proj.bias",
      "backbone.levels.2.blocks.7.norm2.0.weight",
      "backbone.levels.2.blocks.7.norm2.0.bias",
      "backbone.levels.2.blocks.7.mlp.fc1.bias",
      "backbone.levels.2.blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.0
  },
  "layer_18_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.7.dcn.offset.weight",
      "backbone.levels.2.blocks.7.dcn.mask.weight",
      "backbone.levels.2.blocks.7.dcn.input_proj.weight",
      "backbone.levels.2.blocks.7.dcn.output_proj.weight",
      "backbone.levels.2.blocks.7.mlp.fc1.weight",
      "backbone.levels.2.blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.05
  },
  "layer_19_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.gamma1",
      "backbone.levels.2.blocks.8.gamma2",
      "backbone.levels.2.blocks.8.norm1.0.weight",
      "backbone.levels.2.blocks.8.norm1.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.8.dcn.offset.bias",
      "backbone.levels.2.blocks.8.dcn.mask.bias",
      "backbone.levels.2.blocks.8.dcn.input_proj.bias",
      "backbone.levels.2.blocks.8.dcn.output_proj.bias",
      "backbone.levels.2.blocks.8.norm2.0.weight",
      "backbone.levels.2.blocks.8.norm2.0.bias",
      "backbone.levels.2.blocks.8.mlp.fc1.bias",
      "backbone.levels.2.blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.0
  },
  "layer_19_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.8.dcn.offset.weight",
      "backbone.levels.2.blocks.8.dcn.mask.weight",
      "backbone.levels.2.blocks.8.dcn.input_proj.weight",
      "backbone.levels.2.blocks.8.dcn.output_proj.weight",
      "backbone.levels.2.blocks.8.mlp.fc1.weight",
      "backbone.levels.2.blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.05
  },
  "layer_20_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.gamma1",
      "backbone.levels.2.blocks.9.gamma2",
      "backbone.levels.2.blocks.9.norm1.0.weight",
      "backbone.levels.2.blocks.9.norm1.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.9.dcn.offset.bias",
      "backbone.levels.2.blocks.9.dcn.mask.bias",
      "backbone.levels.2.blocks.9.dcn.input_proj.bias",
      "backbone.levels.2.blocks.9.dcn.output_proj.bias",
      "backbone.levels.2.blocks.9.norm2.0.weight",
      "backbone.levels.2.blocks.9.norm2.0.bias",
      "backbone.levels.2.blocks.9.mlp.fc1.bias",
      "backbone.levels.2.blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.0
  },
  "layer_20_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.9.dcn.offset.weight",
      "backbone.levels.2.blocks.9.dcn.mask.weight",
      "backbone.levels.2.blocks.9.dcn.input_proj.weight",
      "backbone.levels.2.blocks.9.dcn.output_proj.weight",
      "backbone.levels.2.blocks.9.mlp.fc1.weight",
      "backbone.levels.2.blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.05
  },
  "layer_21_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.gamma1",
      "backbone.levels.2.blocks.10.gamma2",
      "backbone.levels.2.blocks.10.norm1.0.weight",
      "backbone.levels.2.blocks.10.norm1.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.10.dcn.offset.bias",
      "backbone.levels.2.blocks.10.dcn.mask.bias",
      "backbone.levels.2.blocks.10.dcn.input_proj.bias",
      "backbone.levels.2.blocks.10.dcn.output_proj.bias",
      "backbone.levels.2.blocks.10.norm2.0.weight",
      "backbone.levels.2.blocks.10.norm2.0.bias",
      "backbone.levels.2.blocks.10.mlp.fc1.bias",
      "backbone.levels.2.blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.0
  },
  "layer_21_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.10.dcn.offset.weight",
      "backbone.levels.2.blocks.10.dcn.mask.weight",
      "backbone.levels.2.blocks.10.dcn.input_proj.weight",
      "backbone.levels.2.blocks.10.dcn.output_proj.weight",
      "backbone.levels.2.blocks.10.mlp.fc1.weight",
      "backbone.levels.2.blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.05
  },
  "layer_22_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.gamma1",
      "backbone.levels.2.blocks.11.gamma2",
      "backbone.levels.2.blocks.11.norm1.0.weight",
      "backbone.levels.2.blocks.11.norm1.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.11.dcn.offset.bias",
      "backbone.levels.2.blocks.11.dcn.mask.bias",
      "backbone.levels.2.blocks.11.dcn.input_proj.bias",
      "backbone.levels.2.blocks.11.dcn.output_proj.bias",
      "backbone.levels.2.blocks.11.norm2.0.weight",
      "backbone.levels.2.blocks.11.norm2.0.bias",
      "backbone.levels.2.blocks.11.mlp.fc1.bias",
      "backbone.levels.2.blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.0
  },
  "layer_22_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.11.dcn.offset.weight",
      "backbone.levels.2.blocks.11.dcn.mask.weight",
      "backbone.levels.2.blocks.11.dcn.input_proj.weight",
      "backbone.levels.2.blocks.11.dcn.output_proj.weight",
      "backbone.levels.2.blocks.11.mlp.fc1.weight",
      "backbone.levels.2.blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.05
  },
  "layer_23_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.gamma1",
      "backbone.levels.2.blocks.12.gamma2",
      "backbone.levels.2.blocks.12.norm1.0.weight",
      "backbone.levels.2.blocks.12.norm1.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.12.dcn.offset.bias",
      "backbone.levels.2.blocks.12.dcn.mask.bias",
      "backbone.levels.2.blocks.12.dcn.input_proj.bias",
      "backbone.levels.2.blocks.12.dcn.output_proj.bias",
      "backbone.levels.2.blocks.12.norm2.0.weight",
      "backbone.levels.2.blocks.12.norm2.0.bias",
      "backbone.levels.2.blocks.12.mlp.fc1.bias",
      "backbone.levels.2.blocks.12.mlp.fc2.bias"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.0
  },
  "layer_23_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.12.dcn.offset.weight",
      "backbone.levels.2.blocks.12.dcn.mask.weight",
      "backbone.levels.2.blocks.12.dcn.input_proj.weight",
      "backbone.levels.2.blocks.12.dcn.output_proj.weight",
      "backbone.levels.2.blocks.12.mlp.fc1.weight",
      "backbone.levels.2.blocks.12.mlp.fc2.weight"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.05
  },
  "layer_24_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.gamma1",
      "backbone.levels.2.blocks.13.gamma2",
      "backbone.levels.2.blocks.13.norm1.0.weight",
      "backbone.levels.2.blocks.13.norm1.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.13.dcn.offset.bias",
      "backbone.levels.2.blocks.13.dcn.mask.bias",
      "backbone.levels.2.blocks.13.dcn.input_proj.bias",
      "backbone.levels.2.blocks.13.dcn.output_proj.bias",
      "backbone.levels.2.blocks.13.norm2.0.weight",
      "backbone.levels.2.blocks.13.norm2.0.bias",
      "backbone.levels.2.blocks.13.mlp.fc1.bias",
      "backbone.levels.2.blocks.13.mlp.fc2.bias"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.0
  },
  "layer_24_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.13.dcn.offset.weight",
      "backbone.levels.2.blocks.13.dcn.mask.weight",
      "backbone.levels.2.blocks.13.dcn.input_proj.weight",
      "backbone.levels.2.blocks.13.dcn.output_proj.weight",
      "backbone.levels.2.blocks.13.mlp.fc1.weight",
      "backbone.levels.2.blocks.13.mlp.fc2.weight"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.05
  },
  "layer_25_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.gamma1",
      "backbone.levels.2.blocks.14.gamma2",
      "backbone.levels.2.blocks.14.norm1.0.weight",
      "backbone.levels.2.blocks.14.norm1.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.14.dcn.offset.bias",
      "backbone.levels.2.blocks.14.dcn.mask.bias",
      "backbone.levels.2.blocks.14.dcn.input_proj.bias",
      "backbone.levels.2.blocks.14.dcn.output_proj.bias",
      "backbone.levels.2.blocks.14.norm2.0.weight",
      "backbone.levels.2.blocks.14.norm2.0.bias",
      "backbone.levels.2.blocks.14.mlp.fc1.bias",
      "backbone.levels.2.blocks.14.mlp.fc2.bias"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.0
  },
  "layer_25_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.14.dcn.offset.weight",
      "backbone.levels.2.blocks.14.dcn.mask.weight",
      "backbone.levels.2.blocks.14.dcn.input_proj.weight",
      "backbone.levels.2.blocks.14.dcn.output_proj.weight",
      "backbone.levels.2.blocks.14.mlp.fc1.weight",
      "backbone.levels.2.blocks.14.mlp.fc2.weight"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.05
  },
  "layer_26_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.gamma1",
      "backbone.levels.2.blocks.15.gamma2",
      "backbone.levels.2.blocks.15.norm1.0.weight",
      "backbone.levels.2.blocks.15.norm1.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.15.dcn.offset.bias",
      "backbone.levels.2.blocks.15.dcn.mask.bias",
      "backbone.levels.2.blocks.15.dcn.input_proj.bias",
      "backbone.levels.2.blocks.15.dcn.output_proj.bias",
      "backbone.levels.2.blocks.15.norm2.0.weight",
      "backbone.levels.2.blocks.15.norm2.0.bias",
      "backbone.levels.2.blocks.15.mlp.fc1.bias",
      "backbone.levels.2.blocks.15.mlp.fc2.bias"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.0
  },
  "layer_26_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.15.dcn.offset.weight",
      "backbone.levels.2.blocks.15.dcn.mask.weight",
      "backbone.levels.2.blocks.15.dcn.input_proj.weight",
      "backbone.levels.2.blocks.15.dcn.output_proj.weight",
      "backbone.levels.2.blocks.15.mlp.fc1.weight",
      "backbone.levels.2.blocks.15.mlp.fc2.weight"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.05
  },
  "layer_27_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.gamma1",
      "backbone.levels.2.blocks.16.gamma2",
      "backbone.levels.2.blocks.16.norm1.0.weight",
      "backbone.levels.2.blocks.16.norm1.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.16.dcn.offset.bias",
      "backbone.levels.2.blocks.16.dcn.mask.bias",
      "backbone.levels.2.blocks.16.dcn.input_proj.bias",
      "backbone.levels.2.blocks.16.dcn.output_proj.bias",
      "backbone.levels.2.blocks.16.norm2.0.weight",
      "backbone.levels.2.blocks.16.norm2.0.bias",
      "backbone.levels.2.blocks.16.mlp.fc1.bias",
      "backbone.levels.2.blocks.16.mlp.fc2.bias"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.0
  },
  "layer_27_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.16.dcn.offset.weight",
      "backbone.levels.2.blocks.16.dcn.mask.weight",
      "backbone.levels.2.blocks.16.dcn.input_proj.weight",
      "backbone.levels.2.blocks.16.dcn.output_proj.weight",
      "backbone.levels.2.blocks.16.mlp.fc1.weight",
      "backbone.levels.2.blocks.16.mlp.fc2.weight"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.05
  },
  "layer_28_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.gamma1",
      "backbone.levels.2.blocks.17.gamma2",
      "backbone.levels.2.blocks.17.norm1.0.weight",
      "backbone.levels.2.blocks.17.norm1.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.17.dcn.offset.bias",
      "backbone.levels.2.blocks.17.dcn.mask.bias",
      "backbone.levels.2.blocks.17.dcn.input_proj.bias",
      "backbone.levels.2.blocks.17.dcn.output_proj.bias",
      "backbone.levels.2.blocks.17.norm2.0.weight",
      "backbone.levels.2.blocks.17.norm2.0.bias",
      "backbone.levels.2.blocks.17.mlp.fc1.bias",
      "backbone.levels.2.blocks.17.mlp.fc2.bias"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.0
  },
  "layer_28_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.17.dcn.offset.weight",
      "backbone.levels.2.blocks.17.dcn.mask.weight",
      "backbone.levels.2.blocks.17.dcn.input_proj.weight",
      "backbone.levels.2.blocks.17.dcn.output_proj.weight",
      "backbone.levels.2.blocks.17.mlp.fc1.weight",
      "backbone.levels.2.blocks.17.mlp.fc2.weight"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.05
  },
  "layer_29_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.gamma1",
      "backbone.levels.2.blocks.18.gamma2",
      "backbone.levels.2.blocks.18.norm1.0.weight",
      "backbone.levels.2.blocks.18.norm1.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.18.dcn.offset.bias",
      "backbone.levels.2.blocks.18.dcn.mask.bias",
      "backbone.levels.2.blocks.18.dcn.input_proj.bias",
      "backbone.levels.2.blocks.18.dcn.output_proj.bias",
      "backbone.levels.2.blocks.18.norm2.0.weight",
      "backbone.levels.2.blocks.18.norm2.0.bias",
      "backbone.levels.2.blocks.18.mlp.fc1.bias",
      "backbone.levels.2.blocks.18.mlp.fc2.bias"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.0
  },
  "layer_29_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.18.dcn.offset.weight",
      "backbone.levels.2.blocks.18.dcn.mask.weight",
      "backbone.levels.2.blocks.18.dcn.input_proj.weight",
      "backbone.levels.2.blocks.18.dcn.output_proj.weight",
      "backbone.levels.2.blocks.18.mlp.fc1.weight",
      "backbone.levels.2.blocks.18.mlp.fc2.weight"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.05
  },
  "layer_30_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.gamma1",
      "backbone.levels.2.blocks.19.gamma2",
      "backbone.levels.2.blocks.19.norm1.0.weight",
      "backbone.levels.2.blocks.19.norm1.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.19.dcn.offset.bias",
      "backbone.levels.2.blocks.19.dcn.mask.bias",
      "backbone.levels.2.blocks.19.dcn.input_proj.bias",
      "backbone.levels.2.blocks.19.dcn.output_proj.bias",
      "backbone.levels.2.blocks.19.norm2.0.weight",
      "backbone.levels.2.blocks.19.norm2.0.bias",
      "backbone.levels.2.blocks.19.mlp.fc1.bias",
      "backbone.levels.2.blocks.19.mlp.fc2.bias"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.0
  },
  "layer_30_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.19.dcn.offset.weight",
      "backbone.levels.2.blocks.19.dcn.mask.weight",
      "backbone.levels.2.blocks.19.dcn.input_proj.weight",
      "backbone.levels.2.blocks.19.dcn.output_proj.weight",
      "backbone.levels.2.blocks.19.mlp.fc1.weight",
      "backbone.levels.2.blocks.19.mlp.fc2.weight"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.05
  },
  "layer_31_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.gamma1",
      "backbone.levels.2.blocks.20.gamma2",
      "backbone.levels.2.blocks.20.norm1.0.weight",
      "backbone.levels.2.blocks.20.norm1.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.20.dcn.offset.bias",
      "backbone.levels.2.blocks.20.dcn.mask.bias",
      "backbone.levels.2.blocks.20.dcn.input_proj.bias",
      "backbone.levels.2.blocks.20.dcn.output_proj.bias",
      "backbone.levels.2.blocks.20.norm2.0.weight",
      "backbone.levels.2.blocks.20.norm2.0.bias",
      "backbone.levels.2.blocks.20.mlp.fc1.bias",
      "backbone.levels.2.blocks.20.mlp.fc2.bias"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.0
  },
  "layer_31_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.20.dcn.offset.weight",
      "backbone.levels.2.blocks.20.dcn.mask.weight",
      "backbone.levels.2.blocks.20.dcn.input_proj.weight",
      "backbone.levels.2.blocks.20.dcn.output_proj.weight",
      "backbone.levels.2.blocks.20.mlp.fc1.weight",
      "backbone.levels.2.blocks.20.mlp.fc2.weight"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.05
  },
  "layer_35_decay": {
    "param_names": [
      "backbone.levels.2.downsample.conv.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.0.dcn.offset.weight",
      "backbone.levels.3.blocks.0.dcn.mask.weight",
      "backbone.levels.3.blocks.0.dcn.input_proj.weight",
      "backbone.levels.3.blocks.0.dcn.output_proj.weight",
      "backbone.levels.3.blocks.0.mlp.fc1.weight",
      "backbone.levels.3.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.05
  },
  "layer_35_no_decay": {
    "param_names": [
      "backbone.levels.2.downsample.norm.1.weight",
      "backbone.levels.2.downsample.norm.1.bias",
      "backbone.levels.3.blocks.0.gamma1",
      "backbone.levels.3.blocks.0.gamma2",
      "backbone.levels.3.blocks.0.norm1.0.weight",
      "backbone.levels.3.blocks.0.norm1.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.0.dcn.offset.bias",
      "backbone.levels.3.blocks.0.dcn.mask.bias",
      "backbone.levels.3.blocks.0.dcn.input_proj.bias",
      "backbone.levels.3.blocks.0.dcn.output_proj.bias",
      "backbone.levels.3.blocks.0.norm2.0.weight",
      "backbone.levels.3.blocks.0.norm2.0.bias",
      "backbone.levels.3.blocks.0.mlp.fc1.bias",
      "backbone.levels.3.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.0
  },
  "layer_36_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.gamma1",
      "backbone.levels.3.blocks.1.gamma2",
      "backbone.levels.3.blocks.1.norm1.0.weight",
      "backbone.levels.3.blocks.1.norm1.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.1.dcn.offset.bias",
      "backbone.levels.3.blocks.1.dcn.mask.bias",
      "backbone.levels.3.blocks.1.dcn.input_proj.bias",
      "backbone.levels.3.blocks.1.dcn.output_proj.bias",
      "backbone.levels.3.blocks.1.norm2.0.weight",
      "backbone.levels.3.blocks.1.norm2.0.bias",
      "backbone.levels.3.blocks.1.mlp.fc1.bias",
      "backbone.levels.3.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.0
  },
  "layer_36_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.1.dcn.offset.weight",
      "backbone.levels.3.blocks.1.dcn.mask.weight",
      "backbone.levels.3.blocks.1.dcn.input_proj.weight",
      "backbone.levels.3.blocks.1.dcn.output_proj.weight",
      "backbone.levels.3.blocks.1.mlp.fc1.weight",
      "backbone.levels.3.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.05
  },
  "layer_37_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.gamma1",
      "backbone.levels.3.blocks.2.gamma2",
      "backbone.levels.3.blocks.2.norm1.0.weight",
      "backbone.levels.3.blocks.2.norm1.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.2.dcn.offset.bias",
      "backbone.levels.3.blocks.2.dcn.mask.bias",
      "backbone.levels.3.blocks.2.dcn.input_proj.bias",
      "backbone.levels.3.blocks.2.dcn.output_proj.bias",
      "backbone.levels.3.blocks.2.norm2.0.weight",
      "backbone.levels.3.blocks.2.norm2.0.bias",
      "backbone.levels.3.blocks.2.mlp.fc1.bias",
      "backbone.levels.3.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.0
  },
  "layer_37_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.2.dcn.offset.weight",
      "backbone.levels.3.blocks.2.dcn.mask.weight",
      "backbone.levels.3.blocks.2.dcn.input_proj.weight",
      "backbone.levels.3.blocks.2.dcn.output_proj.weight",
      "backbone.levels.3.blocks.2.mlp.fc1.weight",
      "backbone.levels.3.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.05
  },
  "layer_38_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.gamma1",
      "backbone.levels.3.blocks.3.gamma2",
      "backbone.levels.3.blocks.3.norm1.0.weight",
      "backbone.levels.3.blocks.3.norm1.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.3.dcn.offset.bias",
      "backbone.levels.3.blocks.3.dcn.mask.bias",
      "backbone.levels.3.blocks.3.dcn.input_proj.bias",
      "backbone.levels.3.blocks.3.dcn.output_proj.bias",
      "backbone.levels.3.blocks.3.norm2.0.weight",
      "backbone.levels.3.blocks.3.norm2.0.bias",
      "backbone.levels.3.blocks.3.mlp.fc1.bias",
      "backbone.levels.3.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.0
  },
  "layer_38_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.3.dcn.offset.weight",
      "backbone.levels.3.blocks.3.dcn.mask.weight",
      "backbone.levels.3.blocks.3.dcn.input_proj.weight",
      "backbone.levels.3.blocks.3.dcn.output_proj.weight",
      "backbone.levels.3.blocks.3.mlp.fc1.weight",
      "backbone.levels.3.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.05
  },
  "layer_40_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.weight",
      "decode_head.pixel_decoder.input_convs.1.conv.weight",
      "decode_head.pixel_decoder.input_convs.2.conv.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.level_encoding.weight",
      "decode_head.pixel_decoder.lateral_convs.0.conv.weight",
      "decode_head.pixel_decoder.output_convs.0.conv.weight",
      "decode_head.pixel_decoder.mask_feature.weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.05
  },
  "layer_40_no_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.bias",
      "decode_head.pixel_decoder.input_convs.0.gn.weight",
      "decode_head.pixel_decoder.input_convs.0.gn.bias",
      "decode_head.pixel_decoder.input_convs.1.conv.bias",
      "decode_head.pixel_decoder.input_convs.1.gn.weight",
      "decode_head.pixel_decoder.input_convs.1.gn.bias",
      "decode_head.pixel_decoder.input_convs.2.conv.bias",
      "decode_head.pixel_decoder.input_convs.2.gn.weight",
      "decode_head.pixel_decoder.input_convs.2.gn.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.bias",
      "decode_head.pixel_decoder.lateral_convs.0.gn.weight",
      "decode_head.pixel_decoder.lateral_convs.0.gn.bias",
      "decode_head.pixel_decoder.output_convs.0.gn.weight",
      "decode_head.pixel_decoder.output_convs.0.gn.bias",
      "decode_head.pixel_decoder.mask_feature.bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.0.weight",
      "decode_head.transformer_decoder.layers.0.norms.0.bias",
      "decode_head.transformer_decoder.layers.0.norms.1.weight",
      "decode_head.transformer_decoder.layers.0.norms.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.2.weight",
      "decode_head.transformer_decoder.layers.0.norms.2.bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.0.weight",
      "decode_head.transformer_decoder.layers.1.norms.0.bias",
      "decode_head.transformer_decoder.layers.1.norms.1.weight",
      "decode_head.transformer_decoder.layers.1.norms.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.2.weight",
      "decode_head.transformer_decoder.layers.1.norms.2.bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.0.weight",
      "decode_head.transformer_decoder.layers.2.norms.0.bias",
      "decode_head.transformer_decoder.layers.2.norms.1.weight",
      "decode_head.transformer_decoder.layers.2.norms.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.2.weight",
      "decode_head.transformer_decoder.layers.2.norms.2.bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.0.weight",
      "decode_head.transformer_decoder.layers.3.norms.0.bias",
      "decode_head.transformer_decoder.layers.3.norms.1.weight",
      "decode_head.transformer_decoder.layers.3.norms.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.2.weight",
      "decode_head.transformer_decoder.layers.3.norms.2.bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.0.weight",
      "decode_head.transformer_decoder.layers.4.norms.0.bias",
      "decode_head.transformer_decoder.layers.4.norms.1.weight",
      "decode_head.transformer_decoder.layers.4.norms.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.2.weight",
      "decode_head.transformer_decoder.layers.4.norms.2.bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.0.weight",
      "decode_head.transformer_decoder.layers.5.norms.0.bias",
      "decode_head.transformer_decoder.layers.5.norms.1.weight",
      "decode_head.transformer_decoder.layers.5.norms.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.2.weight",
      "decode_head.transformer_decoder.layers.5.norms.2.bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.0.weight",
      "decode_head.transformer_decoder.layers.6.norms.0.bias",
      "decode_head.transformer_decoder.layers.6.norms.1.weight",
      "decode_head.transformer_decoder.layers.6.norms.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.2.weight",
      "decode_head.transformer_decoder.layers.6.norms.2.bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.0.weight",
      "decode_head.transformer_decoder.layers.7.norms.0.bias",
      "decode_head.transformer_decoder.layers.7.norms.1.weight",
      "decode_head.transformer_decoder.layers.7.norms.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.2.weight",
      "decode_head.transformer_decoder.layers.7.norms.2.bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.0.weight",
      "decode_head.transformer_decoder.layers.8.norms.0.bias",
      "decode_head.transformer_decoder.layers.8.norms.1.weight",
      "decode_head.transformer_decoder.layers.8.norms.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.2.weight",
      "decode_head.transformer_decoder.layers.8.norms.2.bias",
      "decode_head.transformer_decoder.post_norm.weight",
      "decode_head.transformer_decoder.post_norm.bias"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.0
  }
}
2023-08-28 23:47:08,932 - mmseg - INFO - Loaded 6861 images
2023-08-28 23:47:08,934 - mmseg - INFO - Start running, host: nemodrive@nemodrive0, work_dir: /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti
2023-08-28 23:47:08,934 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-08-28 23:47:08,934 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-08-28 23:47:08,934 - mmseg - INFO - Checkpoints will be saved to /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti by HardDiskBackend.
2023-08-28 23:47:43,656 - mmseg - INFO - Iter [50/160000]	lr: 5.497e-08, eta: 1 day, 6:50:35, time: 0.694, data_time: 0.006, memory: 6584, decode.loss_cls: 1.9794, decode.loss_mask: 3.5289, decode.loss_dice: 3.1070, decode.d0.loss_cls: 2.3399, decode.d0.loss_mask: 2.6129, decode.d0.loss_dice: 2.7813, decode.d1.loss_cls: 1.9020, decode.d1.loss_mask: 2.8836, decode.d1.loss_dice: 2.8446, decode.d2.loss_cls: 2.4673, decode.d2.loss_mask: 3.1078, decode.d2.loss_dice: 2.9836, decode.d3.loss_cls: 2.1748, decode.d3.loss_mask: 3.3116, decode.d3.loss_dice: 3.0569, decode.d4.loss_cls: 2.2470, decode.d4.loss_mask: 3.4518, decode.d4.loss_dice: 3.0011, decode.d5.loss_cls: 1.6723, decode.d5.loss_mask: 3.4428, decode.d5.loss_dice: 3.0739, decode.d6.loss_cls: 1.6920, decode.d6.loss_mask: 3.4877, decode.d6.loss_dice: 3.0865, decode.d7.loss_cls: 1.6312, decode.d7.loss_mask: 3.5017, decode.d7.loss_dice: 3.1811, decode.d8.loss_cls: 1.9359, decode.d8.loss_mask: 3.5113, decode.d8.loss_dice: 3.1405, loss: 83.1387, grad_norm: 254.4921
2023-08-28 23:48:19,755 - mmseg - INFO - Iter [100/160000]	lr: 1.110e-07, eta: 1 day, 7:27:00, time: 0.722, data_time: 0.050, memory: 6584, decode.loss_cls: 1.3460, decode.loss_mask: 3.5902, decode.loss_dice: 3.0153, decode.d0.loss_cls: 2.3011, decode.d0.loss_mask: 2.3436, decode.d0.loss_dice: 2.6741, decode.d1.loss_cls: 1.6001, decode.d1.loss_mask: 2.5149, decode.d1.loss_dice: 2.6648, decode.d2.loss_cls: 1.8299, decode.d2.loss_mask: 2.7910, decode.d2.loss_dice: 2.8239, decode.d3.loss_cls: 1.4916, decode.d3.loss_mask: 3.0144, decode.d3.loss_dice: 2.9086, decode.d4.loss_cls: 1.4782, decode.d4.loss_mask: 3.2875, decode.d4.loss_dice: 2.9191, decode.d5.loss_cls: 1.2438, decode.d5.loss_mask: 3.3602, decode.d5.loss_dice: 3.0144, decode.d6.loss_cls: 1.2539, decode.d6.loss_mask: 3.4586, decode.d6.loss_dice: 2.9849, decode.d7.loss_cls: 1.2429, decode.d7.loss_mask: 3.4882, decode.d7.loss_dice: 3.0933, decode.d8.loss_cls: 1.3645, decode.d8.loss_mask: 3.5443, decode.d8.loss_dice: 3.0508, loss: 75.6938, grad_norm: 174.8397
2023-08-28 23:48:56,258 - mmseg - INFO - Iter [150/160000]	lr: 1.670e-07, eta: 1 day, 7:45:56, time: 0.730, data_time: 0.049, memory: 6584, decode.loss_cls: 1.1502, decode.loss_mask: 3.5232, decode.loss_dice: 2.9921, decode.d0.loss_cls: 2.2944, decode.d0.loss_mask: 1.6507, decode.d0.loss_dice: 2.5145, decode.d1.loss_cls: 1.2646, decode.d1.loss_mask: 1.6664, decode.d1.loss_dice: 2.5193, decode.d2.loss_cls: 1.2555, decode.d2.loss_mask: 1.9271, decode.d2.loss_dice: 2.6012, decode.d3.loss_cls: 1.0875, decode.d3.loss_mask: 2.0362, decode.d3.loss_dice: 2.6123, decode.d4.loss_cls: 1.1201, decode.d4.loss_mask: 2.6598, decode.d4.loss_dice: 2.7545, decode.d5.loss_cls: 1.1288, decode.d5.loss_mask: 2.8019, decode.d5.loss_dice: 2.8065, decode.d6.loss_cls: 1.1455, decode.d6.loss_mask: 3.0733, decode.d6.loss_dice: 2.9109, decode.d7.loss_cls: 1.1453, decode.d7.loss_mask: 3.2499, decode.d7.loss_dice: 2.9886, decode.d8.loss_cls: 1.1564, decode.d8.loss_mask: 3.4783, decode.d8.loss_dice: 2.9906, loss: 66.5056, grad_norm: 166.0496
2023-08-28 23:49:32,984 - mmseg - INFO - Iter [200/160000]	lr: 2.230e-07, eta: 1 day, 7:58:06, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 1.1259, decode.loss_mask: 2.8544, decode.loss_dice: 2.8082, decode.d0.loss_cls: 2.2936, decode.d0.loss_mask: 1.3310, decode.d0.loss_dice: 2.3783, decode.d1.loss_cls: 1.0272, decode.d1.loss_mask: 1.2771, decode.d1.loss_dice: 2.3688, decode.d2.loss_cls: 1.0183, decode.d2.loss_mask: 1.3150, decode.d2.loss_dice: 2.3600, decode.d3.loss_cls: 0.9296, decode.d3.loss_mask: 1.3163, decode.d3.loss_dice: 2.3419, decode.d4.loss_cls: 1.0046, decode.d4.loss_mask: 1.4706, decode.d4.loss_dice: 2.3191, decode.d5.loss_cls: 1.0500, decode.d5.loss_mask: 1.5167, decode.d5.loss_dice: 2.3380, decode.d6.loss_cls: 1.0977, decode.d6.loss_mask: 1.7059, decode.d6.loss_dice: 2.4558, decode.d7.loss_cls: 1.1194, decode.d7.loss_mask: 2.0524, decode.d7.loss_dice: 2.5205, decode.d8.loss_cls: 1.1173, decode.d8.loss_mask: 2.5595, decode.d8.loss_dice: 2.7005, loss: 53.7738, grad_norm: 150.6110
2023-08-28 23:50:07,684 - mmseg - INFO - Iter [250/160000]	lr: 2.790e-07, eta: 1 day, 7:43:29, time: 0.694, data_time: 0.004, memory: 6584, decode.loss_cls: 0.9589, decode.loss_mask: 1.5298, decode.loss_dice: 2.2435, decode.d0.loss_cls: 2.2940, decode.d0.loss_mask: 1.3625, decode.d0.loss_dice: 2.2230, decode.d1.loss_cls: 0.7975, decode.d1.loss_mask: 1.4424, decode.d1.loss_dice: 2.2476, decode.d2.loss_cls: 0.7062, decode.d2.loss_mask: 1.5040, decode.d2.loss_dice: 2.2169, decode.d3.loss_cls: 0.6199, decode.d3.loss_mask: 1.5428, decode.d3.loss_dice: 2.2036, decode.d4.loss_cls: 0.6438, decode.d4.loss_mask: 1.5473, decode.d4.loss_dice: 2.1948, decode.d5.loss_cls: 0.6573, decode.d5.loss_mask: 1.4746, decode.d5.loss_dice: 2.1893, decode.d6.loss_cls: 0.7107, decode.d6.loss_mask: 1.4805, decode.d6.loss_dice: 2.1957, decode.d7.loss_cls: 0.7584, decode.d7.loss_mask: 1.4517, decode.d7.loss_dice: 2.1791, decode.d8.loss_cls: 0.9027, decode.d8.loss_mask: 1.4944, decode.d8.loss_dice: 2.2189, loss: 45.9917, grad_norm: 121.2545
2023-08-28 23:50:43,978 - mmseg - INFO - Iter [300/160000]	lr: 3.349e-07, eta: 1 day, 7:47:46, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.4906, decode.loss_mask: 1.5853, decode.loss_dice: 2.1809, decode.d0.loss_cls: 2.2918, decode.d0.loss_mask: 1.5441, decode.d0.loss_dice: 2.2012, decode.d1.loss_cls: 0.6306, decode.d1.loss_mask: 1.5620, decode.d1.loss_dice: 2.2302, decode.d2.loss_cls: 0.4710, decode.d2.loss_mask: 1.5938, decode.d2.loss_dice: 2.1800, decode.d3.loss_cls: 0.3013, decode.d3.loss_mask: 1.6099, decode.d3.loss_dice: 2.1374, decode.d4.loss_cls: 0.2768, decode.d4.loss_mask: 1.6099, decode.d4.loss_dice: 2.1472, decode.d5.loss_cls: 0.2398, decode.d5.loss_mask: 1.6189, decode.d5.loss_dice: 2.1174, decode.d6.loss_cls: 0.2372, decode.d6.loss_mask: 1.6211, decode.d6.loss_dice: 2.1392, decode.d7.loss_cls: 0.2561, decode.d7.loss_mask: 1.6151, decode.d7.loss_dice: 2.1604, decode.d8.loss_cls: 0.3529, decode.d8.loss_mask: 1.5999, decode.d8.loss_dice: 2.1766, loss: 43.1784, grad_norm: 161.7731
2023-08-28 23:51:20,769 - mmseg - INFO - Iter [350/160000]	lr: 3.908e-07, eta: 1 day, 7:54:27, time: 0.736, data_time: 0.049, memory: 6584, decode.loss_cls: 0.1928, decode.loss_mask: 1.6474, decode.loss_dice: 2.1007, decode.d0.loss_cls: 2.2896, decode.d0.loss_mask: 1.6212, decode.d0.loss_dice: 2.1862, decode.d1.loss_cls: 0.4844, decode.d1.loss_mask: 1.6219, decode.d1.loss_dice: 2.1451, decode.d2.loss_cls: 0.3168, decode.d2.loss_mask: 1.6369, decode.d2.loss_dice: 2.1183, decode.d3.loss_cls: 0.1678, decode.d3.loss_mask: 1.6573, decode.d3.loss_dice: 2.0775, decode.d4.loss_cls: 0.1378, decode.d4.loss_mask: 1.6643, decode.d4.loss_dice: 2.0681, decode.d5.loss_cls: 0.1058, decode.d5.loss_mask: 1.6721, decode.d5.loss_dice: 2.0508, decode.d6.loss_cls: 0.0993, decode.d6.loss_mask: 1.6595, decode.d6.loss_dice: 2.0912, decode.d7.loss_cls: 0.1002, decode.d7.loss_mask: 1.6585, decode.d7.loss_dice: 2.0919, decode.d8.loss_cls: 0.1324, decode.d8.loss_mask: 1.6515, decode.d8.loss_dice: 2.0844, loss: 41.5318, grad_norm: 172.2399
2023-08-28 23:51:57,673 - mmseg - INFO - Iter [400/160000]	lr: 4.466e-07, eta: 1 day, 8:00:00, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.1085, decode.loss_mask: 1.6181, decode.loss_dice: 2.0336, decode.d0.loss_cls: 2.2896, decode.d0.loss_mask: 1.6244, decode.d0.loss_dice: 2.1570, decode.d1.loss_cls: 0.3938, decode.d1.loss_mask: 1.6187, decode.d1.loss_dice: 2.0886, decode.d2.loss_cls: 0.2283, decode.d2.loss_mask: 1.6394, decode.d2.loss_dice: 2.0456, decode.d3.loss_cls: 0.1146, decode.d3.loss_mask: 1.6528, decode.d3.loss_dice: 2.0220, decode.d4.loss_cls: 0.0930, decode.d4.loss_mask: 1.6491, decode.d4.loss_dice: 2.0144, decode.d5.loss_cls: 0.0675, decode.d5.loss_mask: 1.6609, decode.d5.loss_dice: 1.9967, decode.d6.loss_cls: 0.0660, decode.d6.loss_mask: 1.6294, decode.d6.loss_dice: 2.0273, decode.d7.loss_cls: 0.0628, decode.d7.loss_mask: 1.6298, decode.d7.loss_dice: 2.0285, decode.d8.loss_cls: 0.0757, decode.d8.loss_mask: 1.6292, decode.d8.loss_dice: 2.0217, loss: 40.2865, grad_norm: 238.1673
2023-08-28 23:52:32,413 - mmseg - INFO - Iter [450/160000]	lr: 5.024e-07, eta: 1 day, 7:51:23, time: 0.695, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0804, decode.loss_mask: 1.5619, decode.loss_dice: 1.9083, decode.d0.loss_cls: 2.2893, decode.d0.loss_mask: 1.5809, decode.d0.loss_dice: 2.0910, decode.d1.loss_cls: 0.3378, decode.d1.loss_mask: 1.5563, decode.d1.loss_dice: 1.9845, decode.d2.loss_cls: 0.1784, decode.d2.loss_mask: 1.5670, decode.d2.loss_dice: 1.9448, decode.d3.loss_cls: 0.0880, decode.d3.loss_mask: 1.5748, decode.d3.loss_dice: 1.9087, decode.d4.loss_cls: 0.0712, decode.d4.loss_mask: 1.5795, decode.d4.loss_dice: 1.8994, decode.d5.loss_cls: 0.0547, decode.d5.loss_mask: 1.5742, decode.d5.loss_dice: 1.8848, decode.d6.loss_cls: 0.0516, decode.d6.loss_mask: 1.5662, decode.d6.loss_dice: 1.9160, decode.d7.loss_cls: 0.0483, decode.d7.loss_mask: 1.5603, decode.d7.loss_dice: 1.9017, decode.d8.loss_cls: 0.0603, decode.d8.loss_mask: 1.5594, decode.d8.loss_dice: 1.9044, loss: 38.2841, grad_norm: 289.5119
2023-08-28 23:53:08,978 - mmseg - INFO - Iter [500/160000]	lr: 5.582e-07, eta: 1 day, 7:54:09, time: 0.731, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0528, decode.loss_mask: 1.5602, decode.loss_dice: 1.9482, decode.d0.loss_cls: 2.2872, decode.d0.loss_mask: 1.5712, decode.d0.loss_dice: 2.1004, decode.d1.loss_cls: 0.2880, decode.d1.loss_mask: 1.5487, decode.d1.loss_dice: 2.0037, decode.d2.loss_cls: 0.1403, decode.d2.loss_mask: 1.5651, decode.d2.loss_dice: 1.9724, decode.d3.loss_cls: 0.0652, decode.d3.loss_mask: 1.5709, decode.d3.loss_dice: 1.9468, decode.d4.loss_cls: 0.0527, decode.d4.loss_mask: 1.5749, decode.d4.loss_dice: 1.9416, decode.d5.loss_cls: 0.0390, decode.d5.loss_mask: 1.5683, decode.d5.loss_dice: 1.9303, decode.d6.loss_cls: 0.0368, decode.d6.loss_mask: 1.5594, decode.d6.loss_dice: 1.9618, decode.d7.loss_cls: 0.0320, decode.d7.loss_mask: 1.5620, decode.d7.loss_dice: 1.9534, decode.d8.loss_cls: 0.0421, decode.d8.loss_mask: 1.5582, decode.d8.loss_dice: 1.9534, loss: 38.3871, grad_norm: 300.8444
2023-08-28 23:53:45,965 - mmseg - INFO - Iter [550/160000]	lr: 6.140e-07, eta: 1 day, 7:58:18, time: 0.740, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0434, decode.loss_mask: 1.5245, decode.loss_dice: 1.8712, decode.d0.loss_cls: 2.2854, decode.d0.loss_mask: 1.5583, decode.d0.loss_dice: 2.0542, decode.d1.loss_cls: 0.2511, decode.d1.loss_mask: 1.5275, decode.d1.loss_dice: 1.9369, decode.d2.loss_cls: 0.1165, decode.d2.loss_mask: 1.5418, decode.d2.loss_dice: 1.9095, decode.d3.loss_cls: 0.0551, decode.d3.loss_mask: 1.5411, decode.d3.loss_dice: 1.8872, decode.d4.loss_cls: 0.0444, decode.d4.loss_mask: 1.5453, decode.d4.loss_dice: 1.8717, decode.d5.loss_cls: 0.0333, decode.d5.loss_mask: 1.5399, decode.d5.loss_dice: 1.8619, decode.d6.loss_cls: 0.0317, decode.d6.loss_mask: 1.5373, decode.d6.loss_dice: 1.8733, decode.d7.loss_cls: 0.0272, decode.d7.loss_mask: 1.5233, decode.d7.loss_dice: 1.8790, decode.d8.loss_cls: 0.0344, decode.d8.loss_mask: 1.5211, decode.d8.loss_dice: 1.8769, loss: 37.3045, grad_norm: 369.9167
2023-08-28 23:54:23,180 - mmseg - INFO - Iter [600/160000]	lr: 6.697e-07, eta: 1 day, 8:02:40, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0423, decode.loss_mask: 1.5701, decode.loss_dice: 1.8333, decode.d0.loss_cls: 2.2854, decode.d0.loss_mask: 1.5935, decode.d0.loss_dice: 2.0114, decode.d1.loss_cls: 0.2265, decode.d1.loss_mask: 1.5748, decode.d1.loss_dice: 1.8933, decode.d2.loss_cls: 0.1038, decode.d2.loss_mask: 1.5899, decode.d2.loss_dice: 1.8654, decode.d3.loss_cls: 0.0545, decode.d3.loss_mask: 1.5835, decode.d3.loss_dice: 1.8378, decode.d4.loss_cls: 0.0462, decode.d4.loss_mask: 1.5794, decode.d4.loss_dice: 1.8410, decode.d5.loss_cls: 0.0335, decode.d5.loss_mask: 1.5783, decode.d5.loss_dice: 1.8302, decode.d6.loss_cls: 0.0313, decode.d6.loss_mask: 1.5677, decode.d6.loss_dice: 1.8384, decode.d7.loss_cls: 0.0273, decode.d7.loss_mask: 1.5712, decode.d7.loss_dice: 1.8383, decode.d8.loss_cls: 0.0345, decode.d8.loss_mask: 1.5680, decode.d8.loss_dice: 1.8393, loss: 37.2901, grad_norm: 402.2241
2023-08-28 23:54:58,111 - mmseg - INFO - Iter [650/160000]	lr: 7.253e-07, eta: 1 day, 7:56:55, time: 0.699, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0312, decode.loss_mask: 1.5182, decode.loss_dice: 1.8420, decode.d0.loss_cls: 2.2839, decode.d0.loss_mask: 1.5644, decode.d0.loss_dice: 2.0127, decode.d1.loss_cls: 0.1963, decode.d1.loss_mask: 1.5432, decode.d1.loss_dice: 1.8972, decode.d2.loss_cls: 0.0846, decode.d2.loss_mask: 1.5444, decode.d2.loss_dice: 1.8741, decode.d3.loss_cls: 0.0405, decode.d3.loss_mask: 1.5416, decode.d3.loss_dice: 1.8568, decode.d4.loss_cls: 0.0339, decode.d4.loss_mask: 1.5463, decode.d4.loss_dice: 1.8514, decode.d5.loss_cls: 0.0248, decode.d5.loss_mask: 1.5336, decode.d5.loss_dice: 1.8446, decode.d6.loss_cls: 0.0240, decode.d6.loss_mask: 1.5212, decode.d6.loss_dice: 1.8503, decode.d7.loss_cls: 0.0210, decode.d7.loss_mask: 1.5211, decode.d7.loss_dice: 1.8439, decode.d8.loss_cls: 0.0261, decode.d8.loss_mask: 1.5195, decode.d8.loss_dice: 1.8410, loss: 36.8336, grad_norm: 420.6953
2023-08-28 23:55:34,587 - mmseg - INFO - Iter [700/160000]	lr: 7.810e-07, eta: 1 day, 7:57:48, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0383, decode.loss_mask: 1.4641, decode.loss_dice: 1.7849, decode.d0.loss_cls: 2.2819, decode.d0.loss_mask: 1.5408, decode.d0.loss_dice: 1.9687, decode.d1.loss_cls: 0.1781, decode.d1.loss_mask: 1.4919, decode.d1.loss_dice: 1.8393, decode.d2.loss_cls: 0.0804, decode.d2.loss_mask: 1.5086, decode.d2.loss_dice: 1.8126, decode.d3.loss_cls: 0.0436, decode.d3.loss_mask: 1.4957, decode.d3.loss_dice: 1.7896, decode.d4.loss_cls: 0.0373, decode.d4.loss_mask: 1.5043, decode.d4.loss_dice: 1.7892, decode.d5.loss_cls: 0.0327, decode.d5.loss_mask: 1.4953, decode.d5.loss_dice: 1.7879, decode.d6.loss_cls: 0.0305, decode.d6.loss_mask: 1.4829, decode.d6.loss_dice: 1.7932, decode.d7.loss_cls: 0.0291, decode.d7.loss_mask: 1.4813, decode.d7.loss_dice: 1.7916, decode.d8.loss_cls: 0.0338, decode.d8.loss_mask: 1.4729, decode.d8.loss_dice: 1.7984, loss: 35.8790, grad_norm: 458.1743
2023-08-28 23:56:11,552 - mmseg - INFO - Iter [750/160000]	lr: 8.366e-07, eta: 1 day, 8:00:12, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0381, decode.loss_mask: 1.4596, decode.loss_dice: 1.7274, decode.d0.loss_cls: 2.2808, decode.d0.loss_mask: 1.5435, decode.d0.loss_dice: 1.9337, decode.d1.loss_cls: 0.1617, decode.d1.loss_mask: 1.4929, decode.d1.loss_dice: 1.7918, decode.d2.loss_cls: 0.0725, decode.d2.loss_mask: 1.4967, decode.d2.loss_dice: 1.7741, decode.d3.loss_cls: 0.0419, decode.d3.loss_mask: 1.4849, decode.d3.loss_dice: 1.7476, decode.d4.loss_cls: 0.0369, decode.d4.loss_mask: 1.4777, decode.d4.loss_dice: 1.7444, decode.d5.loss_cls: 0.0324, decode.d5.loss_mask: 1.4668, decode.d5.loss_dice: 1.7321, decode.d6.loss_cls: 0.0313, decode.d6.loss_mask: 1.4704, decode.d6.loss_dice: 1.7429, decode.d7.loss_cls: 0.0319, decode.d7.loss_mask: 1.4628, decode.d7.loss_dice: 1.7321, decode.d8.loss_cls: 0.0344, decode.d8.loss_mask: 1.4551, decode.d8.loss_dice: 1.7252, loss: 35.2237, grad_norm: 466.5844
2023-08-28 23:56:48,853 - mmseg - INFO - Iter [800/160000]	lr: 8.921e-07, eta: 1 day, 8:03:19, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0265, decode.loss_mask: 1.3465, decode.loss_dice: 1.7067, decode.d0.loss_cls: 2.2803, decode.d0.loss_mask: 1.4581, decode.d0.loss_dice: 1.9114, decode.d1.loss_cls: 0.1428, decode.d1.loss_mask: 1.3861, decode.d1.loss_dice: 1.7666, decode.d2.loss_cls: 0.0592, decode.d2.loss_mask: 1.3804, decode.d2.loss_dice: 1.7450, decode.d3.loss_cls: 0.0299, decode.d3.loss_mask: 1.3741, decode.d3.loss_dice: 1.7243, decode.d4.loss_cls: 0.0265, decode.d4.loss_mask: 1.3781, decode.d4.loss_dice: 1.7134, decode.d5.loss_cls: 0.0215, decode.d5.loss_mask: 1.3597, decode.d5.loss_dice: 1.7071, decode.d6.loss_cls: 0.0216, decode.d6.loss_mask: 1.3611, decode.d6.loss_dice: 1.7071, decode.d7.loss_cls: 0.0198, decode.d7.loss_mask: 1.3410, decode.d7.loss_dice: 1.7065, decode.d8.loss_cls: 0.0233, decode.d8.loss_mask: 1.3428, decode.d8.loss_dice: 1.7065, loss: 33.7740, grad_norm: 494.9296
2023-08-28 23:57:23,839 - mmseg - INFO - Iter [850/160000]	lr: 9.477e-07, eta: 1 day, 7:58:48, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0241, decode.loss_mask: 1.3978, decode.loss_dice: 1.6826, decode.d0.loss_cls: 2.2774, decode.d0.loss_mask: 1.4918, decode.d0.loss_dice: 1.8747, decode.d1.loss_cls: 0.1290, decode.d1.loss_mask: 1.4408, decode.d1.loss_dice: 1.7306, decode.d2.loss_cls: 0.0528, decode.d2.loss_mask: 1.4441, decode.d2.loss_dice: 1.7162, decode.d3.loss_cls: 0.0265, decode.d3.loss_mask: 1.4284, decode.d3.loss_dice: 1.6980, decode.d4.loss_cls: 0.0250, decode.d4.loss_mask: 1.4233, decode.d4.loss_dice: 1.6942, decode.d5.loss_cls: 0.0195, decode.d5.loss_mask: 1.4161, decode.d5.loss_dice: 1.6794, decode.d6.loss_cls: 0.0196, decode.d6.loss_mask: 1.4124, decode.d6.loss_dice: 1.6890, decode.d7.loss_cls: 0.0172, decode.d7.loss_mask: 1.4134, decode.d7.loss_dice: 1.6747, decode.d8.loss_cls: 0.0211, decode.d8.loss_mask: 1.4038, decode.d8.loss_dice: 1.6801, loss: 34.0033, grad_norm: 559.1932
2023-08-28 23:58:00,552 - mmseg - INFO - Iter [900/160000]	lr: 1.003e-06, eta: 1 day, 7:59:47, time: 0.734, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0321, decode.loss_mask: 1.3543, decode.loss_dice: 1.6875, decode.d0.loss_cls: 2.2739, decode.d0.loss_mask: 1.4627, decode.d0.loss_dice: 1.8766, decode.d1.loss_cls: 0.1238, decode.d1.loss_mask: 1.3922, decode.d1.loss_dice: 1.7383, decode.d2.loss_cls: 0.0540, decode.d2.loss_mask: 1.3874, decode.d2.loss_dice: 1.7245, decode.d3.loss_cls: 0.0317, decode.d3.loss_mask: 1.3717, decode.d3.loss_dice: 1.7122, decode.d4.loss_cls: 0.0311, decode.d4.loss_mask: 1.3758, decode.d4.loss_dice: 1.7081, decode.d5.loss_cls: 0.0291, decode.d5.loss_mask: 1.3790, decode.d5.loss_dice: 1.6938, decode.d6.loss_cls: 0.0296, decode.d6.loss_mask: 1.3653, decode.d6.loss_dice: 1.7064, decode.d7.loss_cls: 0.0265, decode.d7.loss_mask: 1.3627, decode.d7.loss_dice: 1.6918, decode.d8.loss_cls: 0.0290, decode.d8.loss_mask: 1.3603, decode.d8.loss_dice: 1.6904, loss: 33.7016, grad_norm: 524.4257
2023-08-28 23:58:37,699 - mmseg - INFO - Iter [950/160000]	lr: 1.059e-06, eta: 1 day, 8:01:50, time: 0.743, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0175, decode.loss_mask: 1.2971, decode.loss_dice: 1.6067, decode.d0.loss_cls: 2.2734, decode.d0.loss_mask: 1.3738, decode.d0.loss_dice: 1.8288, decode.d1.loss_cls: 0.1063, decode.d1.loss_mask: 1.3354, decode.d1.loss_dice: 1.6687, decode.d2.loss_cls: 0.0422, decode.d2.loss_mask: 1.3208, decode.d2.loss_dice: 1.6501, decode.d3.loss_cls: 0.0214, decode.d3.loss_mask: 1.3158, decode.d3.loss_dice: 1.6251, decode.d4.loss_cls: 0.0202, decode.d4.loss_mask: 1.3152, decode.d4.loss_dice: 1.6174, decode.d5.loss_cls: 0.0165, decode.d5.loss_mask: 1.2989, decode.d5.loss_dice: 1.6058, decode.d6.loss_cls: 0.0159, decode.d6.loss_mask: 1.3019, decode.d6.loss_dice: 1.6067, decode.d7.loss_cls: 0.0141, decode.d7.loss_mask: 1.2996, decode.d7.loss_dice: 1.6001, decode.d8.loss_cls: 0.0161, decode.d8.loss_mask: 1.3049, decode.d8.loss_dice: 1.6019, loss: 32.1183, grad_norm: 518.4107
2023-08-28 23:59:15,335 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-08-28 23:59:20,734 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-28 23:59:20,734 - mmseg - INFO - Iter [1000/160000]	lr: 1.114e-06, eta: 1 day, 8:19:14, time: 0.861, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0216, decode.loss_mask: 1.3787, decode.loss_dice: 1.5997, decode.d0.loss_cls: 2.2713, decode.d0.loss_mask: 1.4764, decode.d0.loss_dice: 1.7803, decode.d1.loss_cls: 0.0955, decode.d1.loss_mask: 1.4121, decode.d1.loss_dice: 1.6375, decode.d2.loss_cls: 0.0381, decode.d2.loss_mask: 1.3850, decode.d2.loss_dice: 1.6133, decode.d3.loss_cls: 0.0195, decode.d3.loss_mask: 1.3736, decode.d3.loss_dice: 1.5926, decode.d4.loss_cls: 0.0197, decode.d4.loss_mask: 1.3775, decode.d4.loss_dice: 1.5937, decode.d5.loss_cls: 0.0160, decode.d5.loss_mask: 1.3761, decode.d5.loss_dice: 1.5809, decode.d6.loss_cls: 0.0176, decode.d6.loss_mask: 1.3776, decode.d6.loss_dice: 1.5838, decode.d7.loss_cls: 0.0159, decode.d7.loss_mask: 1.3818, decode.d7.loss_dice: 1.5844, decode.d8.loss_cls: 0.0185, decode.d8.loss_mask: 1.3839, decode.d8.loss_dice: 1.5967, loss: 32.6194, grad_norm: 652.2401
2023-08-28 23:59:55,842 - mmseg - INFO - Iter [1050/160000]	lr: 1.169e-06, eta: 1 day, 8:14:52, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0173, decode.loss_mask: 1.3162, decode.loss_dice: 1.5523, decode.d0.loss_cls: 2.2685, decode.d0.loss_mask: 1.3620, decode.d0.loss_dice: 1.7620, decode.d1.loss_cls: 0.0877, decode.d1.loss_mask: 1.3385, decode.d1.loss_dice: 1.6159, decode.d2.loss_cls: 0.0345, decode.d2.loss_mask: 1.3262, decode.d2.loss_dice: 1.5872, decode.d3.loss_cls: 0.0183, decode.d3.loss_mask: 1.3119, decode.d3.loss_dice: 1.5709, decode.d4.loss_cls: 0.0171, decode.d4.loss_mask: 1.3221, decode.d4.loss_dice: 1.5596, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 1.3194, decode.d5.loss_dice: 1.5536, decode.d6.loss_cls: 0.0149, decode.d6.loss_mask: 1.3159, decode.d6.loss_dice: 1.5606, decode.d7.loss_cls: 0.0142, decode.d7.loss_mask: 1.3109, decode.d7.loss_dice: 1.5577, decode.d8.loss_cls: 0.0152, decode.d8.loss_mask: 1.3254, decode.d8.loss_dice: 1.5536, loss: 31.6237, grad_norm: 528.4538
2023-08-29 00:00:32,899 - mmseg - INFO - Iter [1100/160000]	lr: 1.225e-06, eta: 1 day, 8:15:32, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0281, decode.loss_mask: 1.3276, decode.loss_dice: 1.5731, decode.d0.loss_cls: 2.2649, decode.d0.loss_mask: 1.4124, decode.d0.loss_dice: 1.7567, decode.d1.loss_cls: 0.0888, decode.d1.loss_mask: 1.3583, decode.d1.loss_dice: 1.6115, decode.d2.loss_cls: 0.0395, decode.d2.loss_mask: 1.3462, decode.d2.loss_dice: 1.5901, decode.d3.loss_cls: 0.0256, decode.d3.loss_mask: 1.3356, decode.d3.loss_dice: 1.5782, decode.d4.loss_cls: 0.0243, decode.d4.loss_mask: 1.3294, decode.d4.loss_dice: 1.5766, decode.d5.loss_cls: 0.0231, decode.d5.loss_mask: 1.3327, decode.d5.loss_dice: 1.5730, decode.d6.loss_cls: 0.0219, decode.d6.loss_mask: 1.3348, decode.d6.loss_dice: 1.5760, decode.d7.loss_cls: 0.0231, decode.d7.loss_mask: 1.3235, decode.d7.loss_dice: 1.5655, decode.d8.loss_cls: 0.0257, decode.d8.loss_mask: 1.3390, decode.d8.loss_dice: 1.5650, loss: 31.9700, grad_norm: 544.3961
2023-08-29 00:01:09,938 - mmseg - INFO - Iter [1150/160000]	lr: 1.280e-06, eta: 1 day, 8:16:04, time: 0.741, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0314, decode.loss_mask: 1.2409, decode.loss_dice: 1.4861, decode.d0.loss_cls: 2.2621, decode.d0.loss_mask: 1.3163, decode.d0.loss_dice: 1.6748, decode.d1.loss_cls: 0.0816, decode.d1.loss_mask: 1.2695, decode.d1.loss_dice: 1.5454, decode.d2.loss_cls: 0.0376, decode.d2.loss_mask: 1.2582, decode.d2.loss_dice: 1.5203, decode.d3.loss_cls: 0.0279, decode.d3.loss_mask: 1.2494, decode.d3.loss_dice: 1.4995, decode.d4.loss_cls: 0.0273, decode.d4.loss_mask: 1.2577, decode.d4.loss_dice: 1.4945, decode.d5.loss_cls: 0.0258, decode.d5.loss_mask: 1.2565, decode.d5.loss_dice: 1.4844, decode.d6.loss_cls: 0.0277, decode.d6.loss_mask: 1.2482, decode.d6.loss_dice: 1.4911, decode.d7.loss_cls: 0.0267, decode.d7.loss_mask: 1.2509, decode.d7.loss_dice: 1.4886, decode.d8.loss_cls: 0.0286, decode.d8.loss_mask: 1.2509, decode.d8.loss_dice: 1.4886, loss: 30.3487, grad_norm: 568.5527
2023-08-29 00:01:47,512 - mmseg - INFO - Iter [1200/160000]	lr: 1.335e-06, eta: 1 day, 8:17:41, time: 0.752, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0229, decode.loss_mask: 1.3385, decode.loss_dice: 1.5315, decode.d0.loss_cls: 2.2612, decode.d0.loss_mask: 1.3874, decode.d0.loss_dice: 1.7057, decode.d1.loss_cls: 0.0786, decode.d1.loss_mask: 1.3743, decode.d1.loss_dice: 1.5759, decode.d2.loss_cls: 0.0371, decode.d2.loss_mask: 1.3456, decode.d2.loss_dice: 1.5452, decode.d3.loss_cls: 0.0200, decode.d3.loss_mask: 1.3366, decode.d3.loss_dice: 1.5348, decode.d4.loss_cls: 0.0198, decode.d4.loss_mask: 1.3368, decode.d4.loss_dice: 1.5307, decode.d5.loss_cls: 0.0176, decode.d5.loss_mask: 1.3329, decode.d5.loss_dice: 1.5305, decode.d6.loss_cls: 0.0185, decode.d6.loss_mask: 1.3280, decode.d6.loss_dice: 1.5308, decode.d7.loss_cls: 0.0178, decode.d7.loss_mask: 1.3303, decode.d7.loss_dice: 1.5383, decode.d8.loss_cls: 0.0207, decode.d8.loss_mask: 1.3332, decode.d8.loss_dice: 1.5333, loss: 31.5146, grad_norm: 577.4256
2023-08-29 00:02:22,778 - mmseg - INFO - Iter [1250/160000]	lr: 1.391e-06, eta: 1 day, 8:14:15, time: 0.705, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0128, decode.loss_mask: 1.1697, decode.loss_dice: 1.3948, decode.d0.loss_cls: 2.2577, decode.d0.loss_mask: 1.2812, decode.d0.loss_dice: 1.6081, decode.d1.loss_cls: 0.0655, decode.d1.loss_mask: 1.2284, decode.d1.loss_dice: 1.4510, decode.d2.loss_cls: 0.0252, decode.d2.loss_mask: 1.2008, decode.d2.loss_dice: 1.4263, decode.d3.loss_cls: 0.0148, decode.d3.loss_mask: 1.1791, decode.d3.loss_dice: 1.4088, decode.d4.loss_cls: 0.0144, decode.d4.loss_mask: 1.1833, decode.d4.loss_dice: 1.3972, decode.d5.loss_cls: 0.0125, decode.d5.loss_mask: 1.1789, decode.d5.loss_dice: 1.3857, decode.d6.loss_cls: 0.0124, decode.d6.loss_mask: 1.1779, decode.d6.loss_dice: 1.3900, decode.d7.loss_cls: 0.0105, decode.d7.loss_mask: 1.1661, decode.d7.loss_dice: 1.3962, decode.d8.loss_cls: 0.0118, decode.d8.loss_mask: 1.1682, decode.d8.loss_dice: 1.3884, loss: 28.6180, grad_norm: 563.9032
2023-08-29 00:02:59,765 - mmseg - INFO - Iter [1300/160000]	lr: 1.446e-06, eta: 1 day, 8:14:30, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0142, decode.loss_mask: 1.2276, decode.loss_dice: 1.4337, decode.d0.loss_cls: 2.2542, decode.d0.loss_mask: 1.3162, decode.d0.loss_dice: 1.6307, decode.d1.loss_cls: 0.0606, decode.d1.loss_mask: 1.2650, decode.d1.loss_dice: 1.4920, decode.d2.loss_cls: 0.0231, decode.d2.loss_mask: 1.2379, decode.d2.loss_dice: 1.4567, decode.d3.loss_cls: 0.0137, decode.d3.loss_mask: 1.2308, decode.d3.loss_dice: 1.4393, decode.d4.loss_cls: 0.0144, decode.d4.loss_mask: 1.2241, decode.d4.loss_dice: 1.4332, decode.d5.loss_cls: 0.0130, decode.d5.loss_mask: 1.2285, decode.d5.loss_dice: 1.4271, decode.d6.loss_cls: 0.0131, decode.d6.loss_mask: 1.2281, decode.d6.loss_dice: 1.4366, decode.d7.loss_cls: 0.0117, decode.d7.loss_mask: 1.2389, decode.d7.loss_dice: 1.4348, decode.d8.loss_cls: 0.0127, decode.d8.loss_mask: 1.2369, decode.d8.loss_dice: 1.4345, loss: 29.4832, grad_norm: 553.7816
2023-08-29 00:03:36,938 - mmseg - INFO - Iter [1350/160000]	lr: 1.501e-06, eta: 1 day, 8:15:06, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0117, decode.loss_mask: 1.2907, decode.loss_dice: 1.4770, decode.d0.loss_cls: 2.2509, decode.d0.loss_mask: 1.3533, decode.d0.loss_dice: 1.6364, decode.d1.loss_cls: 0.0551, decode.d1.loss_mask: 1.3046, decode.d1.loss_dice: 1.5062, decode.d2.loss_cls: 0.0206, decode.d2.loss_mask: 1.2890, decode.d2.loss_dice: 1.4815, decode.d3.loss_cls: 0.0126, decode.d3.loss_mask: 1.2900, decode.d3.loss_dice: 1.4755, decode.d4.loss_cls: 0.0128, decode.d4.loss_mask: 1.2991, decode.d4.loss_dice: 1.4654, decode.d5.loss_cls: 0.0108, decode.d5.loss_mask: 1.2964, decode.d5.loss_dice: 1.4633, decode.d6.loss_cls: 0.0104, decode.d6.loss_mask: 1.2954, decode.d6.loss_dice: 1.4652, decode.d7.loss_cls: 0.0096, decode.d7.loss_mask: 1.2926, decode.d7.loss_dice: 1.4723, decode.d8.loss_cls: 0.0108, decode.d8.loss_mask: 1.3029, decode.d8.loss_dice: 1.4698, loss: 30.3318, grad_norm: 622.4230
2023-08-29 00:04:14,683 - mmseg - INFO - Iter [1400/160000]	lr: 1.556e-06, eta: 1 day, 8:16:40, time: 0.755, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0126, decode.loss_mask: 1.1894, decode.loss_dice: 1.3713, decode.d0.loss_cls: 2.2479, decode.d0.loss_mask: 1.2566, decode.d0.loss_dice: 1.5435, decode.d1.loss_cls: 0.0513, decode.d1.loss_mask: 1.1978, decode.d1.loss_dice: 1.4127, decode.d2.loss_cls: 0.0203, decode.d2.loss_mask: 1.1963, decode.d2.loss_dice: 1.3874, decode.d3.loss_cls: 0.0130, decode.d3.loss_mask: 1.1873, decode.d3.loss_dice: 1.3769, decode.d4.loss_cls: 0.0136, decode.d4.loss_mask: 1.1867, decode.d4.loss_dice: 1.3753, decode.d5.loss_cls: 0.0121, decode.d5.loss_mask: 1.1903, decode.d5.loss_dice: 1.3671, decode.d6.loss_cls: 0.0123, decode.d6.loss_mask: 1.1842, decode.d6.loss_dice: 1.3767, decode.d7.loss_cls: 0.0113, decode.d7.loss_mask: 1.1957, decode.d7.loss_dice: 1.3699, decode.d8.loss_cls: 0.0119, decode.d8.loss_mask: 1.1962, decode.d8.loss_dice: 1.3685, loss: 28.3363, grad_norm: 520.5931
2023-08-29 00:04:50,094 - mmseg - INFO - Iter [1450/160000]	lr: 1.611e-06, eta: 1 day, 8:13:49, time: 0.708, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0234, decode.loss_mask: 1.1300, decode.loss_dice: 1.2895, decode.d0.loss_cls: 2.2432, decode.d0.loss_mask: 1.2211, decode.d0.loss_dice: 1.4906, decode.d1.loss_cls: 0.0584, decode.d1.loss_mask: 1.1685, decode.d1.loss_dice: 1.3378, decode.d2.loss_cls: 0.0300, decode.d2.loss_mask: 1.1532, decode.d2.loss_dice: 1.3100, decode.d3.loss_cls: 0.0231, decode.d3.loss_mask: 1.1340, decode.d3.loss_dice: 1.2945, decode.d4.loss_cls: 0.0236, decode.d4.loss_mask: 1.1457, decode.d4.loss_dice: 1.2921, decode.d5.loss_cls: 0.0219, decode.d5.loss_mask: 1.1492, decode.d5.loss_dice: 1.2838, decode.d6.loss_cls: 0.0157, decode.d6.loss_mask: 1.1422, decode.d6.loss_dice: 1.2851, decode.d7.loss_cls: 0.0220, decode.d7.loss_mask: 1.1305, decode.d7.loss_dice: 1.2891, decode.d8.loss_cls: 0.0215, decode.d8.loss_mask: 1.1337, decode.d8.loss_dice: 1.2850, loss: 27.1484, grad_norm: 672.3995
2023-08-29 00:05:27,040 - mmseg - INFO - Iter [1500/160000]	lr: 1.666e-06, eta: 1 day, 8:13:50, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0149, decode.loss_mask: 1.2414, decode.loss_dice: 1.4607, decode.d0.loss_cls: 2.2376, decode.d0.loss_mask: 1.2641, decode.d0.loss_dice: 1.5894, decode.d1.loss_cls: 0.0545, decode.d1.loss_mask: 1.2449, decode.d1.loss_dice: 1.4817, decode.d2.loss_cls: 0.0280, decode.d2.loss_mask: 1.2219, decode.d2.loss_dice: 1.4642, decode.d3.loss_cls: 0.0200, decode.d3.loss_mask: 1.2231, decode.d3.loss_dice: 1.4574, decode.d4.loss_cls: 0.0203, decode.d4.loss_mask: 1.2336, decode.d4.loss_dice: 1.4536, decode.d5.loss_cls: 0.0193, decode.d5.loss_mask: 1.2179, decode.d5.loss_dice: 1.4618, decode.d6.loss_cls: 0.0135, decode.d6.loss_mask: 1.2285, decode.d6.loss_dice: 1.4591, decode.d7.loss_cls: 0.0207, decode.d7.loss_mask: 1.2331, decode.d7.loss_dice: 1.4493, decode.d8.loss_cls: 0.0148, decode.d8.loss_mask: 1.2469, decode.d8.loss_dice: 1.4501, loss: 29.5264, grad_norm: 601.2422
2023-08-29 00:06:03,779 - mmseg - INFO - Iter [1550/160000]	lr: 1.667e-06, eta: 1 day, 8:13:28, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0274, decode.loss_mask: 1.1477, decode.loss_dice: 1.3043, decode.d0.loss_cls: 2.2350, decode.d0.loss_mask: 1.2496, decode.d0.loss_dice: 1.4927, decode.d1.loss_cls: 0.0538, decode.d1.loss_mask: 1.1767, decode.d1.loss_dice: 1.3400, decode.d2.loss_cls: 0.0289, decode.d2.loss_mask: 1.1758, decode.d2.loss_dice: 1.3129, decode.d3.loss_cls: 0.0246, decode.d3.loss_mask: 1.1534, decode.d3.loss_dice: 1.3058, decode.d4.loss_cls: 0.0251, decode.d4.loss_mask: 1.1543, decode.d4.loss_dice: 1.3014, decode.d5.loss_cls: 0.0241, decode.d5.loss_mask: 1.1462, decode.d5.loss_dice: 1.2985, decode.d6.loss_cls: 0.0243, decode.d6.loss_mask: 1.1544, decode.d6.loss_dice: 1.2963, decode.d7.loss_cls: 0.0259, decode.d7.loss_mask: 1.1500, decode.d7.loss_dice: 1.3049, decode.d8.loss_cls: 0.0266, decode.d8.loss_mask: 1.1515, decode.d8.loss_dice: 1.3034, loss: 27.4155, grad_norm: 596.2509
2023-08-29 00:06:41,156 - mmseg - INFO - Iter [1600/160000]	lr: 1.666e-06, eta: 1 day, 8:14:07, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0162, decode.loss_mask: 1.1811, decode.loss_dice: 1.3136, decode.d0.loss_cls: 2.2291, decode.d0.loss_mask: 1.2422, decode.d0.loss_dice: 1.4749, decode.d1.loss_cls: 0.0484, decode.d1.loss_mask: 1.1894, decode.d1.loss_dice: 1.3461, decode.d2.loss_cls: 0.0259, decode.d2.loss_mask: 1.1794, decode.d2.loss_dice: 1.3196, decode.d3.loss_cls: 0.0212, decode.d3.loss_mask: 1.1773, decode.d3.loss_dice: 1.3155, decode.d4.loss_cls: 0.0206, decode.d4.loss_mask: 1.1719, decode.d4.loss_dice: 1.3181, decode.d5.loss_cls: 0.0147, decode.d5.loss_mask: 1.1814, decode.d5.loss_dice: 1.3118, decode.d6.loss_cls: 0.0141, decode.d6.loss_mask: 1.1788, decode.d6.loss_dice: 1.3110, decode.d7.loss_cls: 0.0215, decode.d7.loss_mask: 1.1823, decode.d7.loss_dice: 1.3138, decode.d8.loss_cls: 0.0213, decode.d8.loss_mask: 1.1818, decode.d8.loss_dice: 1.3208, loss: 27.6436, grad_norm: 632.0265
2023-08-29 00:07:16,920 - mmseg - INFO - Iter [1650/160000]	lr: 1.666e-06, eta: 1 day, 8:12:07, time: 0.715, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0157, decode.loss_mask: 1.0768, decode.loss_dice: 1.2711, decode.d0.loss_cls: 2.2250, decode.d0.loss_mask: 1.1808, decode.d0.loss_dice: 1.4250, decode.d1.loss_cls: 0.0483, decode.d1.loss_mask: 1.0984, decode.d1.loss_dice: 1.2962, decode.d2.loss_cls: 0.0245, decode.d2.loss_mask: 1.0855, decode.d2.loss_dice: 1.2723, decode.d3.loss_cls: 0.0213, decode.d3.loss_mask: 1.0785, decode.d3.loss_dice: 1.2640, decode.d4.loss_cls: 0.0216, decode.d4.loss_mask: 1.0815, decode.d4.loss_dice: 1.2572, decode.d5.loss_cls: 0.0213, decode.d5.loss_mask: 1.0694, decode.d5.loss_dice: 1.2683, decode.d6.loss_cls: 0.0213, decode.d6.loss_mask: 1.0738, decode.d6.loss_dice: 1.2671, decode.d7.loss_cls: 0.0213, decode.d7.loss_mask: 1.0773, decode.d7.loss_dice: 1.2608, decode.d8.loss_cls: 0.0146, decode.d8.loss_mask: 1.0777, decode.d8.loss_dice: 1.2654, loss: 26.1822, grad_norm: 551.3876
2023-08-29 00:07:54,128 - mmseg - INFO - Iter [1700/160000]	lr: 1.665e-06, eta: 1 day, 8:12:27, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0113, decode.loss_mask: 1.1136, decode.loss_dice: 1.2669, decode.d0.loss_cls: 2.2207, decode.d0.loss_mask: 1.1565, decode.d0.loss_dice: 1.3928, decode.d1.loss_cls: 0.0371, decode.d1.loss_mask: 1.1286, decode.d1.loss_dice: 1.2954, decode.d2.loss_cls: 0.0145, decode.d2.loss_mask: 1.1210, decode.d2.loss_dice: 1.2695, decode.d3.loss_cls: 0.0103, decode.d3.loss_mask: 1.1140, decode.d3.loss_dice: 1.2652, decode.d4.loss_cls: 0.0108, decode.d4.loss_mask: 1.1073, decode.d4.loss_dice: 1.2667, decode.d5.loss_cls: 0.0098, decode.d5.loss_mask: 1.1187, decode.d5.loss_dice: 1.2571, decode.d6.loss_cls: 0.0096, decode.d6.loss_mask: 1.1089, decode.d6.loss_dice: 1.2699, decode.d7.loss_cls: 0.0093, decode.d7.loss_mask: 1.1103, decode.d7.loss_dice: 1.2693, decode.d8.loss_cls: 0.0097, decode.d8.loss_mask: 1.1266, decode.d8.loss_dice: 1.2618, loss: 26.3631, grad_norm: 519.3488
2023-08-29 00:08:30,869 - mmseg - INFO - Iter [1750/160000]	lr: 1.665e-06, eta: 1 day, 8:12:01, time: 0.735, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0095, decode.loss_mask: 1.0605, decode.loss_dice: 1.2130, decode.d0.loss_cls: 2.2165, decode.d0.loss_mask: 1.1419, decode.d0.loss_dice: 1.3829, decode.d1.loss_cls: 0.0340, decode.d1.loss_mask: 1.0747, decode.d1.loss_dice: 1.2541, decode.d2.loss_cls: 0.0137, decode.d2.loss_mask: 1.0601, decode.d2.loss_dice: 1.2217, decode.d3.loss_cls: 0.0102, decode.d3.loss_mask: 1.0624, decode.d3.loss_dice: 1.2162, decode.d4.loss_cls: 0.0105, decode.d4.loss_mask: 1.0651, decode.d4.loss_dice: 1.2101, decode.d5.loss_cls: 0.0099, decode.d5.loss_mask: 1.0612, decode.d5.loss_dice: 1.2050, decode.d6.loss_cls: 0.0097, decode.d6.loss_mask: 1.0531, decode.d6.loss_dice: 1.2124, decode.d7.loss_cls: 0.0086, decode.d7.loss_mask: 1.0604, decode.d7.loss_dice: 1.2065, decode.d8.loss_cls: 0.0087, decode.d8.loss_mask: 1.0577, decode.d8.loss_dice: 1.2106, loss: 25.3606, grad_norm: 551.2350
2023-08-29 00:09:08,375 - mmseg - INFO - Iter [1800/160000]	lr: 1.664e-06, eta: 1 day, 8:12:41, time: 0.750, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0079, decode.loss_mask: 1.0451, decode.loss_dice: 1.2699, decode.d0.loss_cls: 2.2106, decode.d0.loss_mask: 1.1345, decode.d0.loss_dice: 1.4280, decode.d1.loss_cls: 0.0337, decode.d1.loss_mask: 1.0665, decode.d1.loss_dice: 1.2909, decode.d2.loss_cls: 0.0129, decode.d2.loss_mask: 1.0501, decode.d2.loss_dice: 1.2757, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 1.0446, decode.d3.loss_dice: 1.2603, decode.d4.loss_cls: 0.0092, decode.d4.loss_mask: 1.0476, decode.d4.loss_dice: 1.2555, decode.d5.loss_cls: 0.0084, decode.d5.loss_mask: 1.0451, decode.d5.loss_dice: 1.2562, decode.d6.loss_cls: 0.0077, decode.d6.loss_mask: 1.0498, decode.d6.loss_dice: 1.2494, decode.d7.loss_cls: 0.0078, decode.d7.loss_mask: 1.0510, decode.d7.loss_dice: 1.2528, decode.d8.loss_cls: 0.0073, decode.d8.loss_mask: 1.0530, decode.d8.loss_dice: 1.2598, loss: 25.7003, grad_norm: 586.2989
2023-08-29 00:09:45,958 - mmseg - INFO - Iter [1850/160000]	lr: 1.664e-06, eta: 1 day, 8:13:25, time: 0.752, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0239, decode.loss_mask: 1.0666, decode.loss_dice: 1.2075, decode.d0.loss_cls: 2.2077, decode.d0.loss_mask: 1.0966, decode.d0.loss_dice: 1.3536, decode.d1.loss_cls: 0.0409, decode.d1.loss_mask: 1.0694, decode.d1.loss_dice: 1.2282, decode.d2.loss_cls: 0.0248, decode.d2.loss_mask: 1.0663, decode.d2.loss_dice: 1.2042, decode.d3.loss_cls: 0.0225, decode.d3.loss_mask: 1.0657, decode.d3.loss_dice: 1.2020, decode.d4.loss_cls: 0.0239, decode.d4.loss_mask: 1.0695, decode.d4.loss_dice: 1.2027, decode.d5.loss_cls: 0.0231, decode.d5.loss_mask: 1.0660, decode.d5.loss_dice: 1.1988, decode.d6.loss_cls: 0.0230, decode.d6.loss_mask: 1.0605, decode.d6.loss_dice: 1.1998, decode.d7.loss_cls: 0.0238, decode.d7.loss_mask: 1.0637, decode.d7.loss_dice: 1.1991, decode.d8.loss_cls: 0.0232, decode.d8.loss_mask: 1.0725, decode.d8.loss_dice: 1.2034, loss: 25.3328, grad_norm: 529.8241
2023-08-29 00:10:21,426 - mmseg - INFO - Iter [1900/160000]	lr: 1.663e-06, eta: 1 day, 8:11:07, time: 0.709, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0271, decode.loss_mask: 1.0214, decode.loss_dice: 1.1319, decode.d0.loss_cls: 2.1995, decode.d0.loss_mask: 1.0624, decode.d0.loss_dice: 1.2802, decode.d1.loss_cls: 0.0398, decode.d1.loss_mask: 1.0281, decode.d1.loss_dice: 1.1584, decode.d2.loss_cls: 0.0234, decode.d2.loss_mask: 1.0195, decode.d2.loss_dice: 1.1389, decode.d3.loss_cls: 0.0201, decode.d3.loss_mask: 1.0205, decode.d3.loss_dice: 1.1275, decode.d4.loss_cls: 0.0222, decode.d4.loss_mask: 1.0235, decode.d4.loss_dice: 1.1278, decode.d5.loss_cls: 0.0218, decode.d5.loss_mask: 1.0247, decode.d5.loss_dice: 1.1268, decode.d6.loss_cls: 0.0239, decode.d6.loss_mask: 1.0209, decode.d6.loss_dice: 1.1279, decode.d7.loss_cls: 0.0256, decode.d7.loss_mask: 1.0205, decode.d7.loss_dice: 1.1246, decode.d8.loss_cls: 0.0244, decode.d8.loss_mask: 1.0204, decode.d8.loss_dice: 1.1325, loss: 24.1660, grad_norm: 507.4420
2023-08-29 00:10:58,226 - mmseg - INFO - Iter [1950/160000]	lr: 1.663e-06, eta: 1 day, 8:10:43, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0367, decode.loss_mask: 1.0779, decode.loss_dice: 1.2118, decode.d0.loss_cls: 2.1956, decode.d0.loss_mask: 1.1505, decode.d0.loss_dice: 1.3608, decode.d1.loss_cls: 0.0519, decode.d1.loss_mask: 1.0929, decode.d1.loss_dice: 1.2410, decode.d2.loss_cls: 0.0335, decode.d2.loss_mask: 1.0766, decode.d2.loss_dice: 1.2181, decode.d3.loss_cls: 0.0322, decode.d3.loss_mask: 1.0697, decode.d3.loss_dice: 1.2128, decode.d4.loss_cls: 0.0369, decode.d4.loss_mask: 1.0643, decode.d4.loss_dice: 1.2102, decode.d5.loss_cls: 0.0384, decode.d5.loss_mask: 1.0690, decode.d5.loss_dice: 1.2009, decode.d6.loss_cls: 0.0410, decode.d6.loss_mask: 1.0611, decode.d6.loss_dice: 1.2048, decode.d7.loss_cls: 0.0498, decode.d7.loss_mask: 1.0576, decode.d7.loss_dice: 1.2077, decode.d8.loss_cls: 0.0424, decode.d8.loss_mask: 1.0705, decode.d8.loss_dice: 1.2072, loss: 25.6238, grad_norm: 496.8682
2023-08-29 00:11:35,495 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-08-29 00:11:37,947 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 00:11:37,947 - mmseg - INFO - Iter [2000/160000]	lr: 1.662e-06, eta: 1 day, 8:14:10, time: 0.795, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0261, decode.loss_mask: 1.0488, decode.loss_dice: 1.1784, decode.d0.loss_cls: 2.1889, decode.d0.loss_mask: 1.0664, decode.d0.loss_dice: 1.2933, decode.d1.loss_cls: 0.0341, decode.d1.loss_mask: 1.0369, decode.d1.loss_dice: 1.1840, decode.d2.loss_cls: 0.0183, decode.d2.loss_mask: 1.0391, decode.d2.loss_dice: 1.1714, decode.d3.loss_cls: 0.0164, decode.d3.loss_mask: 1.0453, decode.d3.loss_dice: 1.1661, decode.d4.loss_cls: 0.0182, decode.d4.loss_mask: 1.0386, decode.d4.loss_dice: 1.1739, decode.d5.loss_cls: 0.0178, decode.d5.loss_mask: 1.0491, decode.d5.loss_dice: 1.1771, decode.d6.loss_cls: 0.0197, decode.d6.loss_mask: 1.0512, decode.d6.loss_dice: 1.1727, decode.d7.loss_cls: 0.0210, decode.d7.loss_mask: 1.0559, decode.d7.loss_dice: 1.1754, decode.d8.loss_cls: 0.0213, decode.d8.loss_mask: 1.0601, decode.d8.loss_dice: 1.1695, loss: 24.7349, grad_norm: 540.5629
2023-08-29 00:12:16,036 - mmseg - INFO - Iter [2050/160000]	lr: 1.662e-06, eta: 1 day, 8:15:18, time: 0.762, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0102, decode.loss_mask: 0.9735, decode.loss_dice: 1.0935, decode.d0.loss_cls: 2.1846, decode.d0.loss_mask: 1.0402, decode.d0.loss_dice: 1.2445, decode.d1.loss_cls: 0.0286, decode.d1.loss_mask: 0.9832, decode.d1.loss_dice: 1.1249, decode.d2.loss_cls: 0.0124, decode.d2.loss_mask: 0.9725, decode.d2.loss_dice: 1.1000, decode.d3.loss_cls: 0.0098, decode.d3.loss_mask: 0.9679, decode.d3.loss_dice: 1.0940, decode.d4.loss_cls: 0.0106, decode.d4.loss_mask: 0.9648, decode.d4.loss_dice: 1.0926, decode.d5.loss_cls: 0.0093, decode.d5.loss_mask: 0.9666, decode.d5.loss_dice: 1.0885, decode.d6.loss_cls: 0.0097, decode.d6.loss_mask: 0.9772, decode.d6.loss_dice: 1.0878, decode.d7.loss_cls: 0.0097, decode.d7.loss_mask: 0.9728, decode.d7.loss_dice: 1.0935, decode.d8.loss_cls: 0.0096, decode.d8.loss_mask: 0.9784, decode.d8.loss_dice: 1.0925, loss: 23.2034, grad_norm: 565.0177
2023-08-29 00:12:50,903 - mmseg - INFO - Iter [2100/160000]	lr: 1.661e-06, eta: 1 day, 8:12:19, time: 0.697, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0068, decode.loss_mask: 1.0061, decode.loss_dice: 1.1786, decode.d0.loss_cls: 2.1763, decode.d0.loss_mask: 1.1103, decode.d0.loss_dice: 1.3102, decode.d1.loss_cls: 0.0249, decode.d1.loss_mask: 1.0048, decode.d1.loss_dice: 1.1879, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 1.0004, decode.d2.loss_dice: 1.1760, decode.d3.loss_cls: 0.0075, decode.d3.loss_mask: 0.9970, decode.d3.loss_dice: 1.1740, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 1.0015, decode.d4.loss_dice: 1.1772, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 1.0095, decode.d5.loss_dice: 1.1710, decode.d6.loss_cls: 0.0073, decode.d6.loss_mask: 1.0011, decode.d6.loss_dice: 1.1784, decode.d7.loss_cls: 0.0068, decode.d7.loss_mask: 1.0054, decode.d7.loss_dice: 1.1718, decode.d8.loss_cls: 0.0068, decode.d8.loss_mask: 1.0085, decode.d8.loss_dice: 1.1758, loss: 24.3069, grad_norm: 540.6880
2023-08-29 00:13:27,753 - mmseg - INFO - Iter [2150/160000]	lr: 1.661e-06, eta: 1 day, 8:11:52, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0220, decode.loss_mask: 1.0150, decode.loss_dice: 1.0924, decode.d0.loss_cls: 2.1738, decode.d0.loss_mask: 1.0509, decode.d0.loss_dice: 1.2094, decode.d1.loss_cls: 0.0352, decode.d1.loss_mask: 1.0042, decode.d1.loss_dice: 1.1011, decode.d2.loss_cls: 0.0218, decode.d2.loss_mask: 1.0070, decode.d2.loss_dice: 1.0865, decode.d3.loss_cls: 0.0200, decode.d3.loss_mask: 1.0071, decode.d3.loss_dice: 1.0729, decode.d4.loss_cls: 0.0198, decode.d4.loss_mask: 1.0111, decode.d4.loss_dice: 1.0744, decode.d5.loss_cls: 0.0207, decode.d5.loss_mask: 1.0122, decode.d5.loss_dice: 1.0746, decode.d6.loss_cls: 0.0221, decode.d6.loss_mask: 1.0083, decode.d6.loss_dice: 1.0778, decode.d7.loss_cls: 0.0222, decode.d7.loss_mask: 1.0134, decode.d7.loss_dice: 1.0848, decode.d8.loss_cls: 0.0213, decode.d8.loss_mask: 1.0065, decode.d8.loss_dice: 1.0949, loss: 23.4835, grad_norm: 596.2971
2023-08-29 00:14:05,099 - mmseg - INFO - Iter [2200/160000]	lr: 1.660e-06, eta: 1 day, 8:12:01, time: 0.747, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0074, decode.loss_mask: 0.9799, decode.loss_dice: 1.1052, decode.d0.loss_cls: 2.1671, decode.d0.loss_mask: 1.0725, decode.d0.loss_dice: 1.2436, decode.d1.loss_cls: 0.0258, decode.d1.loss_mask: 0.9821, decode.d1.loss_dice: 1.1115, decode.d2.loss_cls: 0.0113, decode.d2.loss_mask: 0.9712, decode.d2.loss_dice: 1.0958, decode.d3.loss_cls: 0.0090, decode.d3.loss_mask: 0.9729, decode.d3.loss_dice: 1.0892, decode.d4.loss_cls: 0.0088, decode.d4.loss_mask: 0.9695, decode.d4.loss_dice: 1.0971, decode.d5.loss_cls: 0.0082, decode.d5.loss_mask: 0.9720, decode.d5.loss_dice: 1.0962, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 0.9766, decode.d6.loss_dice: 1.0957, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.9872, decode.d7.loss_dice: 1.1005, decode.d8.loss_cls: 0.0074, decode.d8.loss_mask: 0.9801, decode.d8.loss_dice: 1.1055, loss: 23.2646, grad_norm: 525.8943
2023-08-29 00:14:42,906 - mmseg - INFO - Iter [2250/160000]	lr: 1.660e-06, eta: 1 day, 8:12:40, time: 0.756, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0073, decode.loss_mask: 0.9306, decode.loss_dice: 1.0315, decode.d0.loss_cls: 2.1604, decode.d0.loss_mask: 0.9891, decode.d0.loss_dice: 1.2029, decode.d1.loss_cls: 0.0242, decode.d1.loss_mask: 0.9381, decode.d1.loss_dice: 1.0619, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.9273, decode.d2.loss_dice: 1.0452, decode.d3.loss_cls: 0.0087, decode.d3.loss_mask: 0.9260, decode.d3.loss_dice: 1.0339, decode.d4.loss_cls: 0.0091, decode.d4.loss_mask: 0.9302, decode.d4.loss_dice: 1.0294, decode.d5.loss_cls: 0.0083, decode.d5.loss_mask: 0.9292, decode.d5.loss_dice: 1.0206, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 0.9287, decode.d6.loss_dice: 1.0214, decode.d7.loss_cls: 0.0076, decode.d7.loss_mask: 0.9317, decode.d7.loss_dice: 1.0238, decode.d8.loss_cls: 0.0073, decode.d8.loss_mask: 0.9306, decode.d8.loss_dice: 1.0303, loss: 22.1136, grad_norm: 537.1765
2023-08-29 00:15:18,308 - mmseg - INFO - Iter [2300/160000]	lr: 1.659e-06, eta: 1 day, 8:10:30, time: 0.708, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0173, decode.loss_mask: 0.9829, decode.loss_dice: 1.1103, decode.d0.loss_cls: 2.1523, decode.d0.loss_mask: 1.0313, decode.d0.loss_dice: 1.2463, decode.d1.loss_cls: 0.0297, decode.d1.loss_mask: 0.9935, decode.d1.loss_dice: 1.1244, decode.d2.loss_cls: 0.0187, decode.d2.loss_mask: 0.9877, decode.d2.loss_dice: 1.1090, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.9868, decode.d3.loss_dice: 1.1074, decode.d4.loss_cls: 0.0176, decode.d4.loss_mask: 0.9818, decode.d4.loss_dice: 1.1079, decode.d5.loss_cls: 0.0170, decode.d5.loss_mask: 0.9747, decode.d5.loss_dice: 1.1066, decode.d6.loss_cls: 0.0178, decode.d6.loss_mask: 0.9713, decode.d6.loss_dice: 1.1023, decode.d7.loss_cls: 0.0190, decode.d7.loss_mask: 0.9786, decode.d7.loss_dice: 1.1110, decode.d8.loss_cls: 0.0172, decode.d8.loss_mask: 0.9792, decode.d8.loss_dice: 1.1102, loss: 23.4274, grad_norm: 554.3252
2023-08-29 00:15:55,081 - mmseg - INFO - Iter [2350/160000]	lr: 1.659e-06, eta: 1 day, 8:09:56, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.9310, decode.loss_dice: 1.0521, decode.d0.loss_cls: 2.1461, decode.d0.loss_mask: 1.0143, decode.d0.loss_dice: 1.2126, decode.d1.loss_cls: 0.0205, decode.d1.loss_mask: 0.9323, decode.d1.loss_dice: 1.0689, decode.d2.loss_cls: 0.0082, decode.d2.loss_mask: 0.9232, decode.d2.loss_dice: 1.0559, decode.d3.loss_cls: 0.0063, decode.d3.loss_mask: 0.9177, decode.d3.loss_dice: 1.0437, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.9182, decode.d4.loss_dice: 1.0426, decode.d5.loss_cls: 0.0056, decode.d5.loss_mask: 0.9181, decode.d5.loss_dice: 1.0446, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.9159, decode.d6.loss_dice: 1.0416, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.9160, decode.d7.loss_dice: 1.0448, decode.d8.loss_cls: 0.0044, decode.d8.loss_mask: 0.9222, decode.d8.loss_dice: 1.0532, loss: 22.1807, grad_norm: 561.6579
2023-08-29 00:16:32,318 - mmseg - INFO - Iter [2400/160000]	lr: 1.658e-06, eta: 1 day, 8:09:54, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0196, decode.loss_mask: 0.9547, decode.loss_dice: 1.0364, decode.d0.loss_cls: 2.1406, decode.d0.loss_mask: 1.0095, decode.d0.loss_dice: 1.1833, decode.d1.loss_cls: 0.0293, decode.d1.loss_mask: 0.9562, decode.d1.loss_dice: 1.0611, decode.d2.loss_cls: 0.0198, decode.d2.loss_mask: 0.9443, decode.d2.loss_dice: 1.0454, decode.d3.loss_cls: 0.0187, decode.d3.loss_mask: 0.9412, decode.d3.loss_dice: 1.0421, decode.d4.loss_cls: 0.0193, decode.d4.loss_mask: 0.9407, decode.d4.loss_dice: 1.0367, decode.d5.loss_cls: 0.0191, decode.d5.loss_mask: 0.9433, decode.d5.loss_dice: 1.0328, decode.d6.loss_cls: 0.0195, decode.d6.loss_mask: 0.9379, decode.d6.loss_dice: 1.0340, decode.d7.loss_cls: 0.0200, decode.d7.loss_mask: 0.9517, decode.d7.loss_dice: 1.0361, decode.d8.loss_cls: 0.0193, decode.d8.loss_mask: 0.9581, decode.d8.loss_dice: 1.0439, loss: 22.4146, grad_norm: 577.9703
2023-08-29 00:17:09,790 - mmseg - INFO - Iter [2450/160000]	lr: 1.657e-06, eta: 1 day, 8:10:04, time: 0.749, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0253, decode.loss_mask: 1.0096, decode.loss_dice: 1.1574, decode.d0.loss_cls: 2.1348, decode.d0.loss_mask: 1.0728, decode.d0.loss_dice: 1.2758, decode.d1.loss_cls: 0.0299, decode.d1.loss_mask: 1.0120, decode.d1.loss_dice: 1.1434, decode.d2.loss_cls: 0.0196, decode.d2.loss_mask: 0.9984, decode.d2.loss_dice: 1.1318, decode.d3.loss_cls: 0.0196, decode.d3.loss_mask: 0.9991, decode.d3.loss_dice: 1.1309, decode.d4.loss_cls: 0.0197, decode.d4.loss_mask: 0.9934, decode.d4.loss_dice: 1.1338, decode.d5.loss_cls: 0.0197, decode.d5.loss_mask: 0.9970, decode.d5.loss_dice: 1.1314, decode.d6.loss_cls: 0.0206, decode.d6.loss_mask: 0.9938, decode.d6.loss_dice: 1.1384, decode.d7.loss_cls: 0.0223, decode.d7.loss_mask: 1.0037, decode.d7.loss_dice: 1.1407, decode.d8.loss_cls: 0.0223, decode.d8.loss_mask: 1.0111, decode.d8.loss_dice: 1.1478, loss: 23.9561, grad_norm: 613.6566
2023-08-29 00:17:45,086 - mmseg - INFO - Iter [2500/160000]	lr: 1.657e-06, eta: 1 day, 8:07:55, time: 0.706, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0049, decode.loss_mask: 0.8480, decode.loss_dice: 0.9672, decode.d0.loss_cls: 2.1278, decode.d0.loss_mask: 0.8947, decode.d0.loss_dice: 1.1145, decode.d1.loss_cls: 0.0187, decode.d1.loss_mask: 0.8358, decode.d1.loss_dice: 0.9774, decode.d2.loss_cls: 0.0078, decode.d2.loss_mask: 0.8384, decode.d2.loss_dice: 0.9661, decode.d3.loss_cls: 0.0058, decode.d3.loss_mask: 0.8379, decode.d3.loss_dice: 0.9590, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.8393, decode.d4.loss_dice: 0.9526, decode.d5.loss_cls: 0.0050, decode.d5.loss_mask: 0.8444, decode.d5.loss_dice: 0.9497, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.8379, decode.d6.loss_dice: 0.9543, decode.d7.loss_cls: 0.0051, decode.d7.loss_mask: 0.8413, decode.d7.loss_dice: 0.9583, decode.d8.loss_cls: 0.0051, decode.d8.loss_mask: 0.8484, decode.d8.loss_dice: 0.9613, loss: 20.4176, grad_norm: 489.6412
2023-08-29 00:18:21,897 - mmseg - INFO - Iter [2550/160000]	lr: 1.656e-06, eta: 1 day, 8:07:23, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0064, decode.loss_mask: 0.8654, decode.loss_dice: 0.9782, decode.d0.loss_cls: 2.1234, decode.d0.loss_mask: 0.9248, decode.d0.loss_dice: 1.1406, decode.d1.loss_cls: 0.0198, decode.d1.loss_mask: 0.8744, decode.d1.loss_dice: 1.0063, decode.d2.loss_cls: 0.0091, decode.d2.loss_mask: 0.8625, decode.d2.loss_dice: 0.9899, decode.d3.loss_cls: 0.0073, decode.d3.loss_mask: 0.8580, decode.d3.loss_dice: 0.9816, decode.d4.loss_cls: 0.0077, decode.d4.loss_mask: 0.8536, decode.d4.loss_dice: 0.9866, decode.d5.loss_cls: 0.0067, decode.d5.loss_mask: 0.8610, decode.d5.loss_dice: 0.9785, decode.d6.loss_cls: 0.0063, decode.d6.loss_mask: 0.8619, decode.d6.loss_dice: 0.9726, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.8643, decode.d7.loss_dice: 0.9748, decode.d8.loss_cls: 0.0063, decode.d8.loss_mask: 0.8664, decode.d8.loss_dice: 0.9798, loss: 20.8804, grad_norm: 592.3944
2023-08-29 00:18:59,057 - mmseg - INFO - Iter [2600/160000]	lr: 1.656e-06, eta: 1 day, 8:07:14, time: 0.743, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0069, decode.loss_mask: 0.8341, decode.loss_dice: 0.9322, decode.d0.loss_cls: 2.1167, decode.d0.loss_mask: 0.9142, decode.d0.loss_dice: 1.1039, decode.d1.loss_cls: 0.0190, decode.d1.loss_mask: 0.8443, decode.d1.loss_dice: 0.9578, decode.d2.loss_cls: 0.0092, decode.d2.loss_mask: 0.8345, decode.d2.loss_dice: 0.9414, decode.d3.loss_cls: 0.0077, decode.d3.loss_mask: 0.8365, decode.d3.loss_dice: 0.9391, decode.d4.loss_cls: 0.0078, decode.d4.loss_mask: 0.8408, decode.d4.loss_dice: 0.9335, decode.d5.loss_cls: 0.0073, decode.d5.loss_mask: 0.8404, decode.d5.loss_dice: 0.9311, decode.d6.loss_cls: 0.0073, decode.d6.loss_mask: 0.8381, decode.d6.loss_dice: 0.9248, decode.d7.loss_cls: 0.0068, decode.d7.loss_mask: 0.8347, decode.d7.loss_dice: 0.9268, decode.d8.loss_cls: 0.0067, decode.d8.loss_mask: 0.8324, decode.d8.loss_dice: 0.9296, loss: 20.1657, grad_norm: 525.4702
2023-08-29 00:19:36,638 - mmseg - INFO - Iter [2650/160000]	lr: 1.655e-06, eta: 1 day, 8:07:27, time: 0.752, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0182, decode.loss_mask: 0.9173, decode.loss_dice: 0.9869, decode.d0.loss_cls: 2.1085, decode.d0.loss_mask: 0.9427, decode.d0.loss_dice: 1.1244, decode.d1.loss_cls: 0.0288, decode.d1.loss_mask: 0.9198, decode.d1.loss_dice: 1.0048, decode.d2.loss_cls: 0.0194, decode.d2.loss_mask: 0.9182, decode.d2.loss_dice: 0.9923, decode.d3.loss_cls: 0.0188, decode.d3.loss_mask: 0.9141, decode.d3.loss_dice: 0.9798, decode.d4.loss_cls: 0.0183, decode.d4.loss_mask: 0.9123, decode.d4.loss_dice: 0.9786, decode.d5.loss_cls: 0.0188, decode.d5.loss_mask: 0.9091, decode.d5.loss_dice: 0.9736, decode.d6.loss_cls: 0.0190, decode.d6.loss_mask: 0.9107, decode.d6.loss_dice: 0.9753, decode.d7.loss_cls: 0.0183, decode.d7.loss_mask: 0.9048, decode.d7.loss_dice: 0.9815, decode.d8.loss_cls: 0.0174, decode.d8.loss_mask: 0.9123, decode.d8.loss_dice: 0.9868, loss: 21.4308, grad_norm: 545.8944
2023-08-29 00:20:11,973 - mmseg - INFO - Iter [2700/160000]	lr: 1.655e-06, eta: 1 day, 8:05:28, time: 0.707, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.8996, decode.loss_dice: 0.9691, decode.d0.loss_cls: 2.1029, decode.d0.loss_mask: 0.9185, decode.d0.loss_dice: 1.0822, decode.d1.loss_cls: 0.0175, decode.d1.loss_mask: 0.8907, decode.d1.loss_dice: 0.9852, decode.d2.loss_cls: 0.0078, decode.d2.loss_mask: 0.8862, decode.d2.loss_dice: 0.9706, decode.d3.loss_cls: 0.0060, decode.d3.loss_mask: 0.8816, decode.d3.loss_dice: 0.9675, decode.d4.loss_cls: 0.0061, decode.d4.loss_mask: 0.8864, decode.d4.loss_dice: 0.9702, decode.d5.loss_cls: 0.0055, decode.d5.loss_mask: 0.8905, decode.d5.loss_dice: 0.9628, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.8918, decode.d6.loss_dice: 0.9599, decode.d7.loss_cls: 0.0051, decode.d7.loss_mask: 0.9008, decode.d7.loss_dice: 0.9648, decode.d8.loss_cls: 0.0050, decode.d8.loss_mask: 0.9024, decode.d8.loss_dice: 0.9708, loss: 20.9183, grad_norm: 522.2165
2023-08-29 00:20:49,161 - mmseg - INFO - Iter [2750/160000]	lr: 1.654e-06, eta: 1 day, 8:05:18, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.8262, decode.loss_dice: 0.9124, decode.d0.loss_cls: 2.0955, decode.d0.loss_mask: 0.8757, decode.d0.loss_dice: 1.0380, decode.d1.loss_cls: 0.0164, decode.d1.loss_mask: 0.8393, decode.d1.loss_dice: 0.9359, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.8355, decode.d2.loss_dice: 0.9190, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.8315, decode.d3.loss_dice: 0.9157, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.8375, decode.d4.loss_dice: 0.9153, decode.d5.loss_cls: 0.0054, decode.d5.loss_mask: 0.8393, decode.d5.loss_dice: 0.9118, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.8348, decode.d6.loss_dice: 0.9092, decode.d7.loss_cls: 0.0051, decode.d7.loss_mask: 0.8342, decode.d7.loss_dice: 0.9046, decode.d8.loss_cls: 0.0049, decode.d8.loss_mask: 0.8374, decode.d8.loss_dice: 0.9069, loss: 19.8184, grad_norm: 550.6225
2023-08-29 00:21:25,844 - mmseg - INFO - Iter [2800/160000]	lr: 1.654e-06, eta: 1 day, 8:04:39, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.8803, decode.loss_dice: 0.9459, decode.d0.loss_cls: 2.0884, decode.d0.loss_mask: 0.9121, decode.d0.loss_dice: 1.0892, decode.d1.loss_cls: 0.0163, decode.d1.loss_mask: 0.8664, decode.d1.loss_dice: 0.9583, decode.d2.loss_cls: 0.0078, decode.d2.loss_mask: 0.8713, decode.d2.loss_dice: 0.9503, decode.d3.loss_cls: 0.0064, decode.d3.loss_mask: 0.8716, decode.d3.loss_dice: 0.9385, decode.d4.loss_cls: 0.0063, decode.d4.loss_mask: 0.8754, decode.d4.loss_dice: 0.9396, decode.d5.loss_cls: 0.0058, decode.d5.loss_mask: 0.8810, decode.d5.loss_dice: 0.9407, decode.d6.loss_cls: 0.0058, decode.d6.loss_mask: 0.8776, decode.d6.loss_dice: 0.9380, decode.d7.loss_cls: 0.0053, decode.d7.loss_mask: 0.8844, decode.d7.loss_dice: 0.9370, decode.d8.loss_cls: 0.0051, decode.d8.loss_mask: 0.8806, decode.d8.loss_dice: 0.9445, loss: 20.5351, grad_norm: 645.5661
2023-08-29 00:22:03,338 - mmseg - INFO - Iter [2850/160000]	lr: 1.653e-06, eta: 1 day, 8:04:44, time: 0.750, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0045, decode.loss_mask: 0.8552, decode.loss_dice: 0.9147, decode.d0.loss_cls: 2.0817, decode.d0.loss_mask: 0.9118, decode.d0.loss_dice: 1.0436, decode.d1.loss_cls: 0.0161, decode.d1.loss_mask: 0.8512, decode.d1.loss_dice: 0.9225, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.8478, decode.d2.loss_dice: 0.9161, decode.d3.loss_cls: 0.0057, decode.d3.loss_mask: 0.8558, decode.d3.loss_dice: 0.9066, decode.d4.loss_cls: 0.0057, decode.d4.loss_mask: 0.8525, decode.d4.loss_dice: 0.9076, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.8524, decode.d5.loss_dice: 0.9110, decode.d6.loss_cls: 0.0049, decode.d6.loss_mask: 0.8539, decode.d6.loss_dice: 0.9045, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.8612, decode.d7.loss_dice: 0.9068, decode.d8.loss_cls: 0.0042, decode.d8.loss_mask: 0.8550, decode.d8.loss_dice: 0.9132, loss: 19.9827, grad_norm: 538.7087
2023-08-29 00:22:38,643 - mmseg - INFO - Iter [2900/160000]	lr: 1.653e-06, eta: 1 day, 8:02:49, time: 0.706, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0047, decode.loss_mask: 0.8675, decode.loss_dice: 0.9222, decode.d0.loss_cls: 2.0761, decode.d0.loss_mask: 0.9336, decode.d0.loss_dice: 1.0468, decode.d1.loss_cls: 0.0154, decode.d1.loss_mask: 0.8851, decode.d1.loss_dice: 0.9456, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.8743, decode.d2.loss_dice: 0.9334, decode.d3.loss_cls: 0.0058, decode.d3.loss_mask: 0.8695, decode.d3.loss_dice: 0.9283, decode.d4.loss_cls: 0.0058, decode.d4.loss_mask: 0.8720, decode.d4.loss_dice: 0.9272, decode.d5.loss_cls: 0.0050, decode.d5.loss_mask: 0.8723, decode.d5.loss_dice: 0.9237, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.8625, decode.d6.loss_dice: 0.9233, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.8632, decode.d7.loss_dice: 0.9217, decode.d8.loss_cls: 0.0046, decode.d8.loss_mask: 0.8690, decode.d8.loss_dice: 0.9244, loss: 20.3002, grad_norm: 516.8398
2023-08-29 00:23:15,474 - mmseg - INFO - Iter [2950/160000]	lr: 1.652e-06, eta: 1 day, 8:02:18, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0062, decode.loss_mask: 0.8248, decode.loss_dice: 0.8520, decode.d0.loss_cls: 2.0684, decode.d0.loss_mask: 0.8525, decode.d0.loss_dice: 1.0044, decode.d1.loss_cls: 0.0156, decode.d1.loss_mask: 0.8155, decode.d1.loss_dice: 0.8770, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.8064, decode.d2.loss_dice: 0.8670, decode.d3.loss_cls: 0.0069, decode.d3.loss_mask: 0.8093, decode.d3.loss_dice: 0.8562, decode.d4.loss_cls: 0.0070, decode.d4.loss_mask: 0.8091, decode.d4.loss_dice: 0.8531, decode.d5.loss_cls: 0.0062, decode.d5.loss_mask: 0.8097, decode.d5.loss_dice: 0.8538, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.8173, decode.d6.loss_dice: 0.8511, decode.d7.loss_cls: 0.0062, decode.d7.loss_mask: 0.8185, decode.d7.loss_dice: 0.8549, decode.d8.loss_cls: 0.0058, decode.d8.loss_mask: 0.8186, decode.d8.loss_dice: 0.8537, loss: 19.0417, grad_norm: 603.2762
2023-08-29 00:23:52,454 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-08-29 00:23:54,852 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 00:23:54,852 - mmseg - INFO - Iter [3000/160000]	lr: 1.652e-06, eta: 1 day, 8:04:01, time: 0.788, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0184, decode.loss_mask: 0.8838, decode.loss_dice: 0.9438, decode.d0.loss_cls: 2.0598, decode.d0.loss_mask: 0.9024, decode.d0.loss_dice: 1.0393, decode.d1.loss_cls: 0.0251, decode.d1.loss_mask: 0.8799, decode.d1.loss_dice: 0.9529, decode.d2.loss_cls: 0.0183, decode.d2.loss_mask: 0.8786, decode.d2.loss_dice: 0.9404, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.8721, decode.d3.loss_dice: 0.9353, decode.d4.loss_cls: 0.0171, decode.d4.loss_mask: 0.8700, decode.d4.loss_dice: 0.9409, decode.d5.loss_cls: 0.0181, decode.d5.loss_mask: 0.8763, decode.d5.loss_dice: 0.9386, decode.d6.loss_cls: 0.0180, decode.d6.loss_mask: 0.8709, decode.d6.loss_dice: 0.9330, decode.d7.loss_cls: 0.0185, decode.d7.loss_mask: 0.8754, decode.d7.loss_dice: 0.9385, decode.d8.loss_cls: 0.0183, decode.d8.loss_mask: 0.8790, decode.d8.loss_dice: 0.9397, loss: 20.5197, grad_norm: 569.3159
2023-08-29 00:24:32,554 - mmseg - INFO - Iter [3050/160000]	lr: 1.651e-06, eta: 1 day, 8:04:12, time: 0.754, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0056, decode.loss_mask: 0.8168, decode.loss_dice: 0.8807, decode.d0.loss_cls: 2.0536, decode.d0.loss_mask: 0.8352, decode.d0.loss_dice: 0.9899, decode.d1.loss_cls: 0.0152, decode.d1.loss_mask: 0.7988, decode.d1.loss_dice: 0.8823, decode.d2.loss_cls: 0.0077, decode.d2.loss_mask: 0.7942, decode.d2.loss_dice: 0.8693, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.7954, decode.d3.loss_dice: 0.8658, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.7964, decode.d4.loss_dice: 0.8681, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.8077, decode.d5.loss_dice: 0.8719, decode.d6.loss_cls: 0.0063, decode.d6.loss_mask: 0.8099, decode.d6.loss_dice: 0.8686, decode.d7.loss_cls: 0.0059, decode.d7.loss_mask: 0.8097, decode.d7.loss_dice: 0.8685, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.8143, decode.d8.loss_dice: 0.8739, loss: 19.0371, grad_norm: 536.0161
2023-08-29 00:25:07,915 - mmseg - INFO - Iter [3100/160000]	lr: 1.651e-06, eta: 1 day, 8:02:24, time: 0.707, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.7464, decode.loss_dice: 0.8128, decode.d0.loss_cls: 2.0450, decode.d0.loss_mask: 0.8346, decode.d0.loss_dice: 0.9590, decode.d1.loss_cls: 0.0137, decode.d1.loss_mask: 0.7536, decode.d1.loss_dice: 0.8334, decode.d2.loss_cls: 0.0072, decode.d2.loss_mask: 0.7491, decode.d2.loss_dice: 0.8198, decode.d3.loss_cls: 0.0061, decode.d3.loss_mask: 0.7377, decode.d3.loss_dice: 0.8128, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.7385, decode.d4.loss_dice: 0.8143, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.7443, decode.d5.loss_dice: 0.8135, decode.d6.loss_cls: 0.0058, decode.d6.loss_mask: 0.7473, decode.d6.loss_dice: 0.8123, decode.d7.loss_cls: 0.0053, decode.d7.loss_mask: 0.7463, decode.d7.loss_dice: 0.8099, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.7488, decode.d8.loss_dice: 0.8117, loss: 17.9500, grad_norm: 573.7722
2023-08-29 00:25:44,842 - mmseg - INFO - Iter [3150/160000]	lr: 1.650e-06, eta: 1 day, 8:01:55, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.7887, decode.loss_dice: 0.8587, decode.d0.loss_cls: 2.0395, decode.d0.loss_mask: 0.8130, decode.d0.loss_dice: 0.9723, decode.d1.loss_cls: 0.0139, decode.d1.loss_mask: 0.7710, decode.d1.loss_dice: 0.8659, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.7656, decode.d2.loss_dice: 0.8539, decode.d3.loss_cls: 0.0058, decode.d3.loss_mask: 0.7759, decode.d3.loss_dice: 0.8538, decode.d4.loss_cls: 0.0057, decode.d4.loss_mask: 0.7776, decode.d4.loss_dice: 0.8554, decode.d5.loss_cls: 0.0049, decode.d5.loss_mask: 0.7814, decode.d5.loss_dice: 0.8537, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.7824, decode.d6.loss_dice: 0.8568, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.7835, decode.d7.loss_dice: 0.8608, decode.d8.loss_cls: 0.0045, decode.d8.loss_mask: 0.7863, decode.d8.loss_dice: 0.8593, loss: 18.6117, grad_norm: 542.4448
2023-08-29 00:26:21,555 - mmseg - INFO - Iter [3200/160000]	lr: 1.650e-06, eta: 1 day, 8:01:16, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0048, decode.loss_mask: 0.7460, decode.loss_dice: 0.8122, decode.d0.loss_cls: 2.0310, decode.d0.loss_mask: 0.7899, decode.d0.loss_dice: 0.9283, decode.d1.loss_cls: 0.0189, decode.d1.loss_mask: 0.7412, decode.d1.loss_dice: 0.8175, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.7484, decode.d2.loss_dice: 0.8102, decode.d3.loss_cls: 0.0059, decode.d3.loss_mask: 0.7436, decode.d3.loss_dice: 0.8058, decode.d4.loss_cls: 0.0058, decode.d4.loss_mask: 0.7424, decode.d4.loss_dice: 0.8107, decode.d5.loss_cls: 0.0052, decode.d5.loss_mask: 0.7408, decode.d5.loss_dice: 0.8065, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.7442, decode.d6.loss_dice: 0.8075, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.7494, decode.d7.loss_dice: 0.8089, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.7492, decode.d8.loss_dice: 0.8079, loss: 17.8045, grad_norm: 567.6900
2023-08-29 00:26:59,174 - mmseg - INFO - Iter [3250/160000]	lr: 1.649e-06, eta: 1 day, 8:01:21, time: 0.752, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0059, decode.loss_mask: 0.8118, decode.loss_dice: 0.8677, decode.d0.loss_cls: 2.0248, decode.d0.loss_mask: 0.8859, decode.d0.loss_dice: 1.0122, decode.d1.loss_cls: 0.0139, decode.d1.loss_mask: 0.8115, decode.d1.loss_dice: 0.8870, decode.d2.loss_cls: 0.0077, decode.d2.loss_mask: 0.8044, decode.d2.loss_dice: 0.8749, decode.d3.loss_cls: 0.0068, decode.d3.loss_mask: 0.8054, decode.d3.loss_dice: 0.8739, decode.d4.loss_cls: 0.0071, decode.d4.loss_mask: 0.7984, decode.d4.loss_dice: 0.8686, decode.d5.loss_cls: 0.0062, decode.d5.loss_mask: 0.8085, decode.d5.loss_dice: 0.8678, decode.d6.loss_cls: 0.0067, decode.d6.loss_mask: 0.8071, decode.d6.loss_dice: 0.8600, decode.d7.loss_cls: 0.0064, decode.d7.loss_mask: 0.8106, decode.d7.loss_dice: 0.8655, decode.d8.loss_cls: 0.0060, decode.d8.loss_mask: 0.8103, decode.d8.loss_dice: 0.8668, loss: 19.0900, grad_norm: 692.5594
2023-08-29 00:27:34,541 - mmseg - INFO - Iter [3300/160000]	lr: 1.649e-06, eta: 1 day, 7:59:38, time: 0.707, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.6914, decode.loss_dice: 0.7454, decode.d0.loss_cls: 2.0172, decode.d0.loss_mask: 0.7602, decode.d0.loss_dice: 0.8951, decode.d1.loss_cls: 0.0127, decode.d1.loss_mask: 0.7018, decode.d1.loss_dice: 0.7697, decode.d2.loss_cls: 0.0068, decode.d2.loss_mask: 0.6955, decode.d2.loss_dice: 0.7528, decode.d3.loss_cls: 0.0060, decode.d3.loss_mask: 0.6917, decode.d3.loss_dice: 0.7432, decode.d4.loss_cls: 0.0060, decode.d4.loss_mask: 0.6931, decode.d4.loss_dice: 0.7410, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.6852, decode.d5.loss_dice: 0.7442, decode.d6.loss_cls: 0.0056, decode.d6.loss_mask: 0.6890, decode.d6.loss_dice: 0.7401, decode.d7.loss_cls: 0.0052, decode.d7.loss_mask: 0.6881, decode.d7.loss_dice: 0.7428, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.6917, decode.d8.loss_dice: 0.7420, loss: 16.6784, grad_norm: 569.8431
2023-08-29 00:28:11,596 - mmseg - INFO - Iter [3350/160000]	lr: 1.648e-06, eta: 1 day, 7:59:15, time: 0.741, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.7589, decode.loss_dice: 0.7983, decode.d0.loss_cls: 2.0076, decode.d0.loss_mask: 0.8000, decode.d0.loss_dice: 0.9353, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.7620, decode.d1.loss_dice: 0.8118, decode.d2.loss_cls: 0.0052, decode.d2.loss_mask: 0.7624, decode.d2.loss_dice: 0.7993, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.7578, decode.d3.loss_dice: 0.7988, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.7547, decode.d4.loss_dice: 0.7961, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.7506, decode.d5.loss_dice: 0.7966, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.7500, decode.d6.loss_dice: 0.7921, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.7508, decode.d7.loss_dice: 0.7963, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.7629, decode.d8.loss_dice: 0.7977, loss: 17.7815, grad_norm: 638.8816
2023-08-29 00:28:48,428 - mmseg - INFO - Iter [3400/160000]	lr: 1.647e-06, eta: 1 day, 7:58:42, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0109, decode.loss_mask: 0.7691, decode.loss_dice: 0.8149, decode.d0.loss_cls: 2.0024, decode.d0.loss_mask: 0.8153, decode.d0.loss_dice: 0.9570, decode.d1.loss_cls: 0.0180, decode.d1.loss_mask: 0.7711, decode.d1.loss_dice: 0.8360, decode.d2.loss_cls: 0.0125, decode.d2.loss_mask: 0.7706, decode.d2.loss_dice: 0.8264, decode.d3.loss_cls: 0.0118, decode.d3.loss_mask: 0.7675, decode.d3.loss_dice: 0.8244, decode.d4.loss_cls: 0.0119, decode.d4.loss_mask: 0.7649, decode.d4.loss_dice: 0.8220, decode.d5.loss_cls: 0.0117, decode.d5.loss_mask: 0.7715, decode.d5.loss_dice: 0.8182, decode.d6.loss_cls: 0.0119, decode.d6.loss_mask: 0.7745, decode.d6.loss_dice: 0.8148, decode.d7.loss_cls: 0.0113, decode.d7.loss_mask: 0.7735, decode.d7.loss_dice: 0.8182, decode.d8.loss_cls: 0.0107, decode.d8.loss_mask: 0.7692, decode.d8.loss_dice: 0.8178, loss: 18.2099, grad_norm: 598.1201
2023-08-29 00:29:25,738 - mmseg - INFO - Iter [3450/160000]	lr: 1.647e-06, eta: 1 day, 7:58:30, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.7705, decode.loss_dice: 0.7935, decode.d0.loss_cls: 1.9957, decode.d0.loss_mask: 0.7947, decode.d0.loss_dice: 0.9119, decode.d1.loss_cls: 0.0171, decode.d1.loss_mask: 0.7506, decode.d1.loss_dice: 0.8112, decode.d2.loss_cls: 0.0062, decode.d2.loss_mask: 0.7601, decode.d2.loss_dice: 0.8084, decode.d3.loss_cls: 0.0056, decode.d3.loss_mask: 0.7629, decode.d3.loss_dice: 0.8008, decode.d4.loss_cls: 0.0054, decode.d4.loss_mask: 0.7573, decode.d4.loss_dice: 0.7982, decode.d5.loss_cls: 0.0049, decode.d5.loss_mask: 0.7630, decode.d5.loss_dice: 0.7945, decode.d6.loss_cls: 0.0054, decode.d6.loss_mask: 0.7677, decode.d6.loss_dice: 0.7932, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.7640, decode.d7.loss_dice: 0.7951, decode.d8.loss_cls: 0.0042, decode.d8.loss_mask: 0.7636, decode.d8.loss_dice: 0.7969, loss: 17.8115, grad_norm: 581.2471
2023-08-29 00:30:03,142 - mmseg - INFO - Iter [3500/160000]	lr: 1.646e-06, eta: 1 day, 7:58:22, time: 0.748, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.7307, decode.loss_dice: 0.7933, decode.d0.loss_cls: 1.9879, decode.d0.loss_mask: 0.7688, decode.d0.loss_dice: 0.8993, decode.d1.loss_cls: 0.0114, decode.d1.loss_mask: 0.7480, decode.d1.loss_dice: 0.8137, decode.d2.loss_cls: 0.0064, decode.d2.loss_mask: 0.7372, decode.d2.loss_dice: 0.7955, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.7371, decode.d3.loss_dice: 0.7885, decode.d4.loss_cls: 0.0056, decode.d4.loss_mask: 0.7376, decode.d4.loss_dice: 0.7919, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.7329, decode.d5.loss_dice: 0.7871, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.7415, decode.d6.loss_dice: 0.7867, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.7343, decode.d7.loss_dice: 0.7869, decode.d8.loss_cls: 0.0044, decode.d8.loss_mask: 0.7362, decode.d8.loss_dice: 0.7888, loss: 17.4768, grad_norm: 562.6202
2023-08-29 00:30:38,182 - mmseg - INFO - Iter [3550/160000]	lr: 1.646e-06, eta: 1 day, 7:56:29, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.6913, decode.loss_dice: 0.7363, decode.d0.loss_cls: 1.9802, decode.d0.loss_mask: 0.7512, decode.d0.loss_dice: 0.8677, decode.d1.loss_cls: 0.0110, decode.d1.loss_mask: 0.7024, decode.d1.loss_dice: 0.7584, decode.d2.loss_cls: 0.0055, decode.d2.loss_mask: 0.6965, decode.d2.loss_dice: 0.7504, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.6935, decode.d3.loss_dice: 0.7406, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.6819, decode.d4.loss_dice: 0.7398, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.6799, decode.d5.loss_dice: 0.7351, decode.d6.loss_cls: 0.0044, decode.d6.loss_mask: 0.6857, decode.d6.loss_dice: 0.7307, decode.d7.loss_cls: 0.0039, decode.d7.loss_mask: 0.6847, decode.d7.loss_dice: 0.7340, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.6831, decode.d8.loss_dice: 0.7410, loss: 16.5102, grad_norm: 592.2757
2023-08-29 00:31:14,762 - mmseg - INFO - Iter [3600/160000]	lr: 1.645e-06, eta: 1 day, 7:55:45, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.7389, decode.loss_dice: 0.8110, decode.d0.loss_cls: 1.9703, decode.d0.loss_mask: 0.7820, decode.d0.loss_dice: 0.9122, decode.d1.loss_cls: 0.0104, decode.d1.loss_mask: 0.7641, decode.d1.loss_dice: 0.8253, decode.d2.loss_cls: 0.0055, decode.d2.loss_mask: 0.7499, decode.d2.loss_dice: 0.8144, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.7458, decode.d3.loss_dice: 0.8090, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.7469, decode.d4.loss_dice: 0.8120, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.7464, decode.d5.loss_dice: 0.8119, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.7389, decode.d6.loss_dice: 0.8126, decode.d7.loss_cls: 0.0040, decode.d7.loss_mask: 0.7425, decode.d7.loss_dice: 0.8107, decode.d8.loss_cls: 0.0038, decode.d8.loss_mask: 0.7448, decode.d8.loss_dice: 0.8092, loss: 17.7451, grad_norm: 618.2690
2023-08-29 00:31:52,112 - mmseg - INFO - Iter [3650/160000]	lr: 1.645e-06, eta: 1 day, 7:55:34, time: 0.747, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0322, decode.loss_mask: 0.6826, decode.loss_dice: 0.7335, decode.d0.loss_cls: 1.9624, decode.d0.loss_mask: 0.7335, decode.d0.loss_dice: 0.8357, decode.d1.loss_cls: 0.0336, decode.d1.loss_mask: 0.6871, decode.d1.loss_dice: 0.7419, decode.d2.loss_cls: 0.0318, decode.d2.loss_mask: 0.6776, decode.d2.loss_dice: 0.7351, decode.d3.loss_cls: 0.0316, decode.d3.loss_mask: 0.6767, decode.d3.loss_dice: 0.7295, decode.d4.loss_cls: 0.0311, decode.d4.loss_mask: 0.6729, decode.d4.loss_dice: 0.7318, decode.d5.loss_cls: 0.0316, decode.d5.loss_mask: 0.6755, decode.d5.loss_dice: 0.7318, decode.d6.loss_cls: 0.0318, decode.d6.loss_mask: 0.6753, decode.d6.loss_dice: 0.7296, decode.d7.loss_cls: 0.0337, decode.d7.loss_mask: 0.6826, decode.d7.loss_dice: 0.7327, decode.d8.loss_cls: 0.0318, decode.d8.loss_mask: 0.6859, decode.d8.loss_dice: 0.7345, loss: 16.5373, grad_norm: 586.7978
2023-08-29 00:32:29,596 - mmseg - INFO - Iter [3700/160000]	lr: 1.644e-06, eta: 1 day, 7:55:28, time: 0.750, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0335, decode.loss_mask: 0.7504, decode.loss_dice: 0.7538, decode.d0.loss_cls: 1.9589, decode.d0.loss_mask: 0.7725, decode.d0.loss_dice: 0.8403, decode.d1.loss_cls: 0.0344, decode.d1.loss_mask: 0.7320, decode.d1.loss_dice: 0.7538, decode.d2.loss_cls: 0.0306, decode.d2.loss_mask: 0.7291, decode.d2.loss_dice: 0.7444, decode.d3.loss_cls: 0.0342, decode.d3.loss_mask: 0.7378, decode.d3.loss_dice: 0.7391, decode.d4.loss_cls: 0.0327, decode.d4.loss_mask: 0.7386, decode.d4.loss_dice: 0.7434, decode.d5.loss_cls: 0.0270, decode.d5.loss_mask: 0.7607, decode.d5.loss_dice: 0.7397, decode.d6.loss_cls: 0.0273, decode.d6.loss_mask: 0.7641, decode.d6.loss_dice: 0.7421, decode.d7.loss_cls: 0.0363, decode.d7.loss_mask: 0.7516, decode.d7.loss_dice: 0.7471, decode.d8.loss_cls: 0.0357, decode.d8.loss_mask: 0.7565, decode.d8.loss_dice: 0.7478, loss: 17.2957, grad_norm: 593.1609
2023-08-29 00:33:04,554 - mmseg - INFO - Iter [3750/160000]	lr: 1.644e-06, eta: 1 day, 7:53:36, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0208, decode.loss_mask: 0.7271, decode.loss_dice: 0.7733, decode.d0.loss_cls: 1.9492, decode.d0.loss_mask: 0.7741, decode.d0.loss_dice: 0.8795, decode.d1.loss_cls: 0.0223, decode.d1.loss_mask: 0.7379, decode.d1.loss_dice: 0.7914, decode.d2.loss_cls: 0.0186, decode.d2.loss_mask: 0.7325, decode.d2.loss_dice: 0.7794, decode.d3.loss_cls: 0.0178, decode.d3.loss_mask: 0.7292, decode.d3.loss_dice: 0.7779, decode.d4.loss_cls: 0.0189, decode.d4.loss_mask: 0.7260, decode.d4.loss_dice: 0.7799, decode.d5.loss_cls: 0.0186, decode.d5.loss_mask: 0.7233, decode.d5.loss_dice: 0.7740, decode.d6.loss_cls: 0.0194, decode.d6.loss_mask: 0.7229, decode.d6.loss_dice: 0.7775, decode.d7.loss_cls: 0.0205, decode.d7.loss_mask: 0.7307, decode.d7.loss_dice: 0.7701, decode.d8.loss_cls: 0.0199, decode.d8.loss_mask: 0.7284, decode.d8.loss_dice: 0.7686, loss: 17.3297, grad_norm: 657.3491
2023-08-29 00:33:41,254 - mmseg - INFO - Iter [3800/160000]	lr: 1.643e-06, eta: 1 day, 7:52:57, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0204, decode.loss_mask: 0.7051, decode.loss_dice: 0.7700, decode.d0.loss_cls: 1.9434, decode.d0.loss_mask: 0.7365, decode.d0.loss_dice: 0.8676, decode.d1.loss_cls: 0.0217, decode.d1.loss_mask: 0.7084, decode.d1.loss_dice: 0.7748, decode.d2.loss_cls: 0.0179, decode.d2.loss_mask: 0.6989, decode.d2.loss_dice: 0.7564, decode.d3.loss_cls: 0.0183, decode.d3.loss_mask: 0.6954, decode.d3.loss_dice: 0.7587, decode.d4.loss_cls: 0.0182, decode.d4.loss_mask: 0.6952, decode.d4.loss_dice: 0.7554, decode.d5.loss_cls: 0.0185, decode.d5.loss_mask: 0.6999, decode.d5.loss_dice: 0.7538, decode.d6.loss_cls: 0.0196, decode.d6.loss_mask: 0.6999, decode.d6.loss_dice: 0.7553, decode.d7.loss_cls: 0.0192, decode.d7.loss_mask: 0.7005, decode.d7.loss_dice: 0.7618, decode.d8.loss_cls: 0.0189, decode.d8.loss_mask: 0.6978, decode.d8.loss_dice: 0.7613, loss: 16.8690, grad_norm: 523.5678
2023-08-29 00:34:18,508 - mmseg - INFO - Iter [3850/160000]	lr: 1.643e-06, eta: 1 day, 7:52:41, time: 0.745, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0055, decode.loss_mask: 0.6571, decode.loss_dice: 0.7161, decode.d0.loss_cls: 1.9319, decode.d0.loss_mask: 0.7069, decode.d0.loss_dice: 0.8308, decode.d1.loss_cls: 0.0103, decode.d1.loss_mask: 0.6589, decode.d1.loss_dice: 0.7286, decode.d2.loss_cls: 0.0058, decode.d2.loss_mask: 0.6534, decode.d2.loss_dice: 0.7147, decode.d3.loss_cls: 0.0051, decode.d3.loss_mask: 0.6586, decode.d3.loss_dice: 0.7170, decode.d4.loss_cls: 0.0057, decode.d4.loss_mask: 0.6538, decode.d4.loss_dice: 0.7149, decode.d5.loss_cls: 0.0049, decode.d5.loss_mask: 0.6535, decode.d5.loss_dice: 0.7145, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.6557, decode.d6.loss_dice: 0.7119, decode.d7.loss_cls: 0.0051, decode.d7.loss_mask: 0.6597, decode.d7.loss_dice: 0.7176, decode.d8.loss_cls: 0.0050, decode.d8.loss_mask: 0.6588, decode.d8.loss_dice: 0.7201, loss: 15.8874, grad_norm: 580.0188
2023-08-29 00:34:56,328 - mmseg - INFO - Iter [3900/160000]	lr: 1.642e-06, eta: 1 day, 7:52:47, time: 0.756, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0178, decode.loss_mask: 0.6924, decode.loss_dice: 0.7379, decode.d0.loss_cls: 1.9251, decode.d0.loss_mask: 0.7211, decode.d0.loss_dice: 0.8547, decode.d1.loss_cls: 0.0206, decode.d1.loss_mask: 0.6978, decode.d1.loss_dice: 0.7477, decode.d2.loss_cls: 0.0171, decode.d2.loss_mask: 0.6950, decode.d2.loss_dice: 0.7411, decode.d3.loss_cls: 0.0169, decode.d3.loss_mask: 0.6881, decode.d3.loss_dice: 0.7400, decode.d4.loss_cls: 0.0168, decode.d4.loss_mask: 0.6899, decode.d4.loss_dice: 0.7383, decode.d5.loss_cls: 0.0160, decode.d5.loss_mask: 0.6872, decode.d5.loss_dice: 0.7389, decode.d6.loss_cls: 0.0160, decode.d6.loss_mask: 0.6850, decode.d6.loss_dice: 0.7355, decode.d7.loss_cls: 0.0167, decode.d7.loss_mask: 0.6896, decode.d7.loss_dice: 0.7378, decode.d8.loss_cls: 0.0170, decode.d8.loss_mask: 0.6903, decode.d8.loss_dice: 0.7379, loss: 16.5263, grad_norm: 614.0137
2023-08-29 00:35:31,680 - mmseg - INFO - Iter [3950/160000]	lr: 1.642e-06, eta: 1 day, 7:51:15, time: 0.707, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.6538, decode.loss_dice: 0.7010, decode.d0.loss_cls: 1.9158, decode.d0.loss_mask: 0.6901, decode.d0.loss_dice: 0.8113, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.6583, decode.d1.loss_dice: 0.7138, decode.d2.loss_cls: 0.0048, decode.d2.loss_mask: 0.6547, decode.d2.loss_dice: 0.7011, decode.d3.loss_cls: 0.0041, decode.d3.loss_mask: 0.6545, decode.d3.loss_dice: 0.7018, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.6549, decode.d4.loss_dice: 0.6980, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.6528, decode.d5.loss_dice: 0.6965, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.6478, decode.d6.loss_dice: 0.6940, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.6497, decode.d7.loss_dice: 0.6964, decode.d8.loss_cls: 0.0032, decode.d8.loss_mask: 0.6522, decode.d8.loss_dice: 0.7028, loss: 15.6416, grad_norm: 550.9505
2023-08-29 00:36:08,421 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-08-29 00:36:11,570 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 00:36:11,571 - mmseg - INFO - Iter [4000/160000]	lr: 1.641e-06, eta: 1 day, 7:52:41, time: 0.798, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0040, decode.loss_mask: 0.6682, decode.loss_dice: 0.7336, decode.d0.loss_cls: 1.9104, decode.d0.loss_mask: 0.6787, decode.d0.loss_dice: 0.8161, decode.d1.loss_cls: 0.0099, decode.d1.loss_mask: 0.6809, decode.d1.loss_dice: 0.7416, decode.d2.loss_cls: 0.0056, decode.d2.loss_mask: 0.6723, decode.d2.loss_dice: 0.7338, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.6641, decode.d3.loss_dice: 0.7350, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.6685, decode.d4.loss_dice: 0.7312, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.6694, decode.d5.loss_dice: 0.7366, decode.d6.loss_cls: 0.0044, decode.d6.loss_mask: 0.6629, decode.d6.loss_dice: 0.7283, decode.d7.loss_cls: 0.0041, decode.d7.loss_mask: 0.6732, decode.d7.loss_dice: 0.7328, decode.d8.loss_cls: 0.0039, decode.d8.loss_mask: 0.6671, decode.d8.loss_dice: 0.7327, loss: 16.0835, grad_norm: 576.4323
2023-08-29 00:36:48,826 - mmseg - INFO - Iter [4050/160000]	lr: 1.641e-06, eta: 1 day, 7:52:22, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0061, decode.loss_mask: 0.6757, decode.loss_dice: 0.7125, decode.d0.loss_cls: 1.9029, decode.d0.loss_mask: 0.6945, decode.d0.loss_dice: 0.8205, decode.d1.loss_cls: 0.0109, decode.d1.loss_mask: 0.6867, decode.d1.loss_dice: 0.7307, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.6805, decode.d2.loss_dice: 0.7171, decode.d3.loss_cls: 0.0065, decode.d3.loss_mask: 0.6771, decode.d3.loss_dice: 0.7149, decode.d4.loss_cls: 0.0067, decode.d4.loss_mask: 0.6781, decode.d4.loss_dice: 0.7136, decode.d5.loss_cls: 0.0065, decode.d5.loss_mask: 0.6722, decode.d5.loss_dice: 0.7099, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.6693, decode.d6.loss_dice: 0.7101, decode.d7.loss_cls: 0.0061, decode.d7.loss_mask: 0.6773, decode.d7.loss_dice: 0.7125, decode.d8.loss_cls: 0.0059, decode.d8.loss_mask: 0.6734, decode.d8.loss_dice: 0.7132, loss: 16.0050, grad_norm: 554.1220
2023-08-29 00:37:26,576 - mmseg - INFO - Iter [4100/160000]	lr: 1.640e-06, eta: 1 day, 7:52:22, time: 0.755, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0043, decode.loss_mask: 0.6613, decode.loss_dice: 0.7107, decode.d0.loss_cls: 1.8921, decode.d0.loss_mask: 0.7164, decode.d0.loss_dice: 0.8005, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.6788, decode.d1.loss_dice: 0.7141, decode.d2.loss_cls: 0.0056, decode.d2.loss_mask: 0.6677, decode.d2.loss_dice: 0.7099, decode.d3.loss_cls: 0.0050, decode.d3.loss_mask: 0.6752, decode.d3.loss_dice: 0.7050, decode.d4.loss_cls: 0.0052, decode.d4.loss_mask: 0.6667, decode.d4.loss_dice: 0.7047, decode.d5.loss_cls: 0.0047, decode.d5.loss_mask: 0.6659, decode.d5.loss_dice: 0.7026, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.6652, decode.d6.loss_dice: 0.7056, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.6649, decode.d7.loss_dice: 0.7098, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.6669, decode.d8.loss_dice: 0.7095, loss: 15.8412, grad_norm: 546.4279
2023-08-29 00:38:01,600 - mmseg - INFO - Iter [4150/160000]	lr: 1.640e-06, eta: 1 day, 7:50:39, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0186, decode.loss_mask: 0.6511, decode.loss_dice: 0.6692, decode.d0.loss_cls: 1.8840, decode.d0.loss_mask: 0.7029, decode.d0.loss_dice: 0.7791, decode.d1.loss_cls: 0.0159, decode.d1.loss_mask: 0.6606, decode.d1.loss_dice: 0.6867, decode.d2.loss_cls: 0.0062, decode.d2.loss_mask: 0.6634, decode.d2.loss_dice: 0.6841, decode.d3.loss_cls: 0.0127, decode.d3.loss_mask: 0.6530, decode.d3.loss_dice: 0.6808, decode.d4.loss_cls: 0.0118, decode.d4.loss_mask: 0.6497, decode.d4.loss_dice: 0.6766, decode.d5.loss_cls: 0.0051, decode.d5.loss_mask: 0.6651, decode.d5.loss_dice: 0.6768, decode.d6.loss_cls: 0.0056, decode.d6.loss_mask: 0.6613, decode.d6.loss_dice: 0.6777, decode.d7.loss_cls: 0.0129, decode.d7.loss_mask: 0.6537, decode.d7.loss_dice: 0.6731, decode.d8.loss_cls: 0.0117, decode.d8.loss_mask: 0.6536, decode.d8.loss_dice: 0.6760, loss: 15.4792, grad_norm: 497.2019
2023-08-29 00:38:38,514 - mmseg - INFO - Iter [4200/160000]	lr: 1.639e-06, eta: 1 day, 7:50:06, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.7038, decode.loss_dice: 0.7168, decode.d0.loss_cls: 1.8725, decode.d0.loss_mask: 0.7189, decode.d0.loss_dice: 0.8289, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.7030, decode.d1.loss_dice: 0.7259, decode.d2.loss_cls: 0.0043, decode.d2.loss_mask: 0.7015, decode.d2.loss_dice: 0.7232, decode.d3.loss_cls: 0.0039, decode.d3.loss_mask: 0.6989, decode.d3.loss_dice: 0.7195, decode.d4.loss_cls: 0.0045, decode.d4.loss_mask: 0.6963, decode.d4.loss_dice: 0.7232, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.7017, decode.d5.loss_dice: 0.7214, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.7046, decode.d6.loss_dice: 0.7170, decode.d7.loss_cls: 0.0039, decode.d7.loss_mask: 0.7019, decode.d7.loss_dice: 0.7176, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.7070, decode.d8.loss_dice: 0.7184, loss: 16.2615, grad_norm: 534.9827
2023-08-29 00:39:15,537 - mmseg - INFO - Iter [4250/160000]	lr: 1.639e-06, eta: 1 day, 7:49:39, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.6953, decode.loss_dice: 0.7082, decode.d0.loss_cls: 1.8625, decode.d0.loss_mask: 0.7263, decode.d0.loss_dice: 0.7790, decode.d1.loss_cls: 0.0075, decode.d1.loss_mask: 0.6929, decode.d1.loss_dice: 0.7166, decode.d2.loss_cls: 0.0037, decode.d2.loss_mask: 0.6902, decode.d2.loss_dice: 0.7067, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.6852, decode.d3.loss_dice: 0.7070, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.6801, decode.d4.loss_dice: 0.7041, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.6861, decode.d5.loss_dice: 0.7027, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.6883, decode.d6.loss_dice: 0.7006, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.6890, decode.d7.loss_dice: 0.7088, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.6894, decode.d8.loss_dice: 0.7061, loss: 15.9583, grad_norm: 501.1040
2023-08-29 00:39:53,048 - mmseg - INFO - Iter [4300/160000]	lr: 1.638e-06, eta: 1 day, 7:49:29, time: 0.750, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0112, decode.loss_mask: 0.6242, decode.loss_dice: 0.6447, decode.d0.loss_cls: 1.8539, decode.d0.loss_mask: 0.6660, decode.d0.loss_dice: 0.7319, decode.d1.loss_cls: 0.0088, decode.d1.loss_mask: 0.6357, decode.d1.loss_dice: 0.6552, decode.d2.loss_cls: 0.0052, decode.d2.loss_mask: 0.6304, decode.d2.loss_dice: 0.6488, decode.d3.loss_cls: 0.0116, decode.d3.loss_mask: 0.6302, decode.d3.loss_dice: 0.6434, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.6337, decode.d4.loss_dice: 0.6477, decode.d5.loss_cls: 0.0044, decode.d5.loss_mask: 0.6313, decode.d5.loss_dice: 0.6485, decode.d6.loss_cls: 0.0120, decode.d6.loss_mask: 0.6294, decode.d6.loss_dice: 0.6426, decode.d7.loss_cls: 0.0115, decode.d7.loss_mask: 0.6268, decode.d7.loss_dice: 0.6441, decode.d8.loss_cls: 0.0113, decode.d8.loss_mask: 0.6269, decode.d8.loss_dice: 0.6484, loss: 14.8248, grad_norm: 469.7147
2023-08-29 00:40:28,333 - mmseg - INFO - Iter [4350/160000]	lr: 1.637e-06, eta: 1 day, 7:47:58, time: 0.706, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0106, decode.loss_mask: 0.5994, decode.loss_dice: 0.6171, decode.d0.loss_cls: 1.8469, decode.d0.loss_mask: 0.6733, decode.d0.loss_dice: 0.7402, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.6123, decode.d1.loss_dice: 0.6384, decode.d2.loss_cls: 0.0116, decode.d2.loss_mask: 0.6013, decode.d2.loss_dice: 0.6232, decode.d3.loss_cls: 0.0116, decode.d3.loss_mask: 0.6026, decode.d3.loss_dice: 0.6184, decode.d4.loss_cls: 0.0112, decode.d4.loss_mask: 0.6017, decode.d4.loss_dice: 0.6146, decode.d5.loss_cls: 0.0114, decode.d5.loss_mask: 0.6017, decode.d5.loss_dice: 0.6128, decode.d6.loss_cls: 0.0114, decode.d6.loss_mask: 0.5986, decode.d6.loss_dice: 0.6137, decode.d7.loss_cls: 0.0111, decode.d7.loss_mask: 0.5975, decode.d7.loss_dice: 0.6160, decode.d8.loss_cls: 0.0108, decode.d8.loss_mask: 0.5966, decode.d8.loss_dice: 0.6174, loss: 14.3422, grad_norm: 495.7832
2023-08-29 00:41:05,043 - mmseg - INFO - Iter [4400/160000]	lr: 1.637e-06, eta: 1 day, 7:47:18, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0100, decode.loss_mask: 0.6249, decode.loss_dice: 0.6604, decode.d0.loss_cls: 1.8376, decode.d0.loss_mask: 0.6754, decode.d0.loss_dice: 0.7490, decode.d1.loss_cls: 0.0139, decode.d1.loss_mask: 0.6446, decode.d1.loss_dice: 0.6728, decode.d2.loss_cls: 0.0104, decode.d2.loss_mask: 0.6387, decode.d2.loss_dice: 0.6678, decode.d3.loss_cls: 0.0101, decode.d3.loss_mask: 0.6347, decode.d3.loss_dice: 0.6648, decode.d4.loss_cls: 0.0101, decode.d4.loss_mask: 0.6340, decode.d4.loss_dice: 0.6673, decode.d5.loss_cls: 0.0099, decode.d5.loss_mask: 0.6311, decode.d5.loss_dice: 0.6643, decode.d6.loss_cls: 0.0101, decode.d6.loss_mask: 0.6293, decode.d6.loss_dice: 0.6624, decode.d7.loss_cls: 0.0097, decode.d7.loss_mask: 0.6260, decode.d7.loss_dice: 0.6628, decode.d8.loss_cls: 0.0097, decode.d8.loss_mask: 0.6267, decode.d8.loss_dice: 0.6611, loss: 15.0297, grad_norm: 559.1555
2023-08-29 00:41:42,301 - mmseg - INFO - Iter [4450/160000]	lr: 1.636e-06, eta: 1 day, 7:46:59, time: 0.745, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0097, decode.loss_mask: 0.6719, decode.loss_dice: 0.6711, decode.d0.loss_cls: 1.8288, decode.d0.loss_mask: 0.6935, decode.d0.loss_dice: 0.7668, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.6650, decode.d1.loss_dice: 0.6826, decode.d2.loss_cls: 0.0100, decode.d2.loss_mask: 0.6648, decode.d2.loss_dice: 0.6779, decode.d3.loss_cls: 0.0108, decode.d3.loss_mask: 0.6667, decode.d3.loss_dice: 0.6760, decode.d4.loss_cls: 0.0103, decode.d4.loss_mask: 0.6685, decode.d4.loss_dice: 0.6743, decode.d5.loss_cls: 0.0097, decode.d5.loss_mask: 0.6687, decode.d5.loss_dice: 0.6732, decode.d6.loss_cls: 0.0102, decode.d6.loss_mask: 0.6677, decode.d6.loss_dice: 0.6659, decode.d7.loss_cls: 0.0102, decode.d7.loss_mask: 0.6690, decode.d7.loss_dice: 0.6688, decode.d8.loss_cls: 0.0101, decode.d8.loss_mask: 0.6707, decode.d8.loss_dice: 0.6682, loss: 15.4486, grad_norm: 596.4291
2023-08-29 00:42:19,866 - mmseg - INFO - Iter [4500/160000]	lr: 1.636e-06, eta: 1 day, 7:46:49, time: 0.751, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0045, decode.loss_mask: 0.6661, decode.loss_dice: 0.6955, decode.d0.loss_cls: 1.8208, decode.d0.loss_mask: 0.6853, decode.d0.loss_dice: 0.7664, decode.d1.loss_cls: 0.0075, decode.d1.loss_mask: 0.6733, decode.d1.loss_dice: 0.6955, decode.d2.loss_cls: 0.0109, decode.d2.loss_mask: 0.6595, decode.d2.loss_dice: 0.6865, decode.d3.loss_cls: 0.0103, decode.d3.loss_mask: 0.6606, decode.d3.loss_dice: 0.6851, decode.d4.loss_cls: 0.0111, decode.d4.loss_mask: 0.6591, decode.d4.loss_dice: 0.6873, decode.d5.loss_cls: 0.0101, decode.d5.loss_mask: 0.6556, decode.d5.loss_dice: 0.6898, decode.d6.loss_cls: 0.0112, decode.d6.loss_mask: 0.6603, decode.d6.loss_dice: 0.6857, decode.d7.loss_cls: 0.0113, decode.d7.loss_mask: 0.6638, decode.d7.loss_dice: 0.6897, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 0.6586, decode.d8.loss_dice: 0.6882, loss: 15.5190, grad_norm: 563.8234
2023-08-29 00:42:55,055 - mmseg - INFO - Iter [4550/160000]	lr: 1.635e-06, eta: 1 day, 7:45:18, time: 0.704, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0112, decode.loss_mask: 0.7056, decode.loss_dice: 0.7207, decode.d0.loss_cls: 1.8144, decode.d0.loss_mask: 0.7028, decode.d0.loss_dice: 0.7727, decode.d1.loss_cls: 0.0132, decode.d1.loss_mask: 0.7126, decode.d1.loss_dice: 0.7204, decode.d2.loss_cls: 0.0043, decode.d2.loss_mask: 0.7103, decode.d2.loss_dice: 0.7086, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.7089, decode.d3.loss_dice: 0.7146, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.7119, decode.d4.loss_dice: 0.7224, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.7057, decode.d5.loss_dice: 0.7222, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.7082, decode.d6.loss_dice: 0.7205, decode.d7.loss_cls: 0.0126, decode.d7.loss_mask: 0.7005, decode.d7.loss_dice: 0.7217, decode.d8.loss_cls: 0.0110, decode.d8.loss_mask: 0.7044, decode.d8.loss_dice: 0.7215, loss: 16.1998, grad_norm: 553.4104
