2023-08-29 00:43:30,562 - mmseg - INFO - Multi-processing start method is `None`
2023-08-29 00:43:30,562 - mmseg - INFO - OpenCV num_threads is `12
2023-08-29 00:43:30,562 - mmseg - INFO - OMP num threads is 1
2023-08-29 00:43:30,586 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce GTX 1080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 12.1, V12.1.66
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+cefb275
------------------------------------------------------------

2023-08-29 00:43:30,586 - mmseg - INFO - Distributed training: True
2023-08-29 00:43:31,566 - mmseg - INFO - Config:
num_things_classes = 0
num_stuff_classes = 2
num_classes = 2
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoderMask2Former',
    pretrained=None,
    backbone=dict(
        type='InternImage',
        core_op='DCNv3',
        channels=112,
        depths=[4, 4, 21, 4],
        groups=[7, 14, 28, 56],
        mlp_ratio=4.0,
        drop_path_rate=0.4,
        norm_layer='LN',
        layer_scale=1.0,
        offset_scale=1.0,
        post_norm=True,
        with_cp=False,
        out_indices=(0, 1, 2, 3),
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
        )),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[112, 224, 448, 896],
        feat_channels=256,
        out_channels=256,
        in_index=[0, 1, 2, 3],
        num_things_classes=0,
        num_stuff_classes=2,
        num_queries=100,
        num_transformer_feat_level=3,
        pixel_decoder=dict(
            type='MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        num_heads=8,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=False,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True),
                        with_cp=True),
                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),
                init_cfg=None),
            positional_encoding=dict(
                type='SinePositionalEncoding', num_feats=128, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(
            type='SinePositionalEncoding', num_feats=128, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=256,
                    num_heads=8,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=256,
                    feedforward_channels=2048,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True,
                    with_cp=True),
                feedforward_channels=2048,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[1.0, 1.0, 0.1]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0)),
    train_cfg=dict(
        num_points=12544,
        oversample_ratio=3.0,
        importance_sample_ratio=0.75,
        assigner=dict(
            type='MaskHungarianAssigner',
            cls_cost=dict(type='ClassificationCost', weight=2.0),
            mask_cost=dict(
                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
            dice_cost=dict(
                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
        sampler=dict(type='MaskPseudoSampler')),
    test_cfg=dict(
        panoptic_on=True,
        semantic_on=False,
        instance_on=True,
        max_per_image=100,
        iou_thr=0.8,
        filter_low_score=True,
        mode='slide',
        crop_size=(200, 664),
        stride=(341, 341)),
    init_cfg=None)
dataset_type = 'UPBDataset'
data_root = '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation'
img_norm_cfg = dict(
    mean=[89.497, 93.675, 92.645], std=[76.422, 78.611, 80.487], to_rgb=True)
crop_size = (200, 664)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=False),
    dict(type='LoadCategory'),
    dict(type='Resize', img_scale=(664, 200), ratio_range=None),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[89.497, 93.675, 92.645],
        std=[76.422, 78.611, 80.487],
        to_rgb=True),
    dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
    dict(type='ToMask'),
    dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels', 'category'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(200, 664),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir='self_supervised_labels_30',
        split='splits/val_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=False),
            dict(type='LoadCategory'),
            dict(type='Resize', img_scale=(664, 200), ratio_range=None),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
            dict(type='ToMask'),
            dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=[
                    'img', 'gt_semantic_seg', 'gt_masks', 'gt_labels',
                    'category'
                ])
        ]),
    val=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    constructor='CustomLayerDecayOptimizerConstructor',
    paramwise_cfg=dict(
        num_layers=39,
        layer_decay_rate=0.94,
        depths=[5, 5, 24, 5],
        offset_lr_scale=1.0))
optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
evaluation = dict(
    interval=16000, metric='mIoU', pre_eval=True, save_best='mIoU')
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
work_dir = 'work_dirs/mask2former_internimage_b_kitti'
gpu_ids = range(0, 2)
auto_resume = False

2023-08-29 00:43:33,447 - mmseg - INFO - Set random seed to 738961762, deterministic: False
2023-08-29 00:43:33,447 - mmseg - INFO - using core type: DCNv3
2023-08-29 00:43:33,447 - mmseg - INFO - using activation layer: GELU
2023-08-29 00:43:33,447 - mmseg - INFO - using main norm layer: LN
2023-08-29 00:43:33,447 - mmseg - INFO - using dpr: linear, 0.4
2023-08-29 00:43:33,447 - mmseg - INFO - level2_post_norm: False
2023-08-29 00:43:33,447 - mmseg - INFO - level2_post_norm_block_ids: None
2023-08-29 00:43:33,447 - mmseg - INFO - res_post_norm: False
2023-08-29 00:43:34,899 - mmseg - INFO - load checkpoint from http path: https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth
2023-08-29 00:43:35,174 - mmseg - INFO - _IncompatibleKeys(missing_keys=[], unexpected_keys=['conv_head.0.weight', 'conv_head.1.0.weight', 'conv_head.1.0.bias', 'conv_head.1.0.running_mean', 'conv_head.1.0.running_var', 'conv_head.1.0.num_batches_tracked', 'head.weight', 'head.bias'])
Name of parameter - Initialization information

backbone.patch_embed.conv1.weight - torch.Size([56, 3, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.weight - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.weight - torch.Size([112, 56, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.conv.weight - torch.Size([224, 112, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.conv.weight - torch.Size([448, 224, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.conv.weight - torch.Size([896, 448, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 896, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 448, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 224, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 112, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  
2023-08-29 00:43:35,415 - mmseg - INFO - Loaded 20598 images
2023-08-29 00:43:48,268 - mmseg - INFO - {'num_layers': 39, 'layer_decay_rate': 0.94, 'depths': [5, 5, 24, 5], 'offset_lr_scale': 1.0}
2023-08-29 00:43:48,268 - mmseg - INFO - Build CustomLayerDecayOptimizerConstructor 0.940000 - 41
2023-08-29 00:43:48,274 - mmseg - INFO - Param groups = {
  "layer_0_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.weight",
      "backbone.patch_embed.conv2.weight",
      "decode_head.query_embed.weight",
      "decode_head.query_feat.weight",
      "decode_head.level_embed.weight",
      "decode_head.cls_embed.weight",
      "decode_head.mask_embed.0.weight",
      "decode_head.mask_embed.2.weight",
      "decode_head.mask_embed.4.weight"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.05
  },
  "layer_0_no_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.bias",
      "backbone.patch_embed.norm1.1.weight",
      "backbone.patch_embed.norm1.1.bias",
      "backbone.patch_embed.conv2.bias",
      "backbone.patch_embed.norm2.1.weight",
      "backbone.patch_embed.norm2.1.bias",
      "decode_head.cls_embed.bias",
      "decode_head.mask_embed.0.bias",
      "decode_head.mask_embed.2.bias",
      "decode_head.mask_embed.4.bias"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.0
  },
  "layer_1_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.gamma1",
      "backbone.levels.0.blocks.0.gamma2",
      "backbone.levels.0.blocks.0.norm1.0.weight",
      "backbone.levels.0.blocks.0.norm1.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.0.dcn.offset.bias",
      "backbone.levels.0.blocks.0.dcn.mask.bias",
      "backbone.levels.0.blocks.0.dcn.input_proj.bias",
      "backbone.levels.0.blocks.0.dcn.output_proj.bias",
      "backbone.levels.0.blocks.0.norm2.0.weight",
      "backbone.levels.0.blocks.0.norm2.0.bias",
      "backbone.levels.0.blocks.0.mlp.fc1.bias",
      "backbone.levels.0.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.0
  },
  "layer_1_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.0.dcn.offset.weight",
      "backbone.levels.0.blocks.0.dcn.mask.weight",
      "backbone.levels.0.blocks.0.dcn.input_proj.weight",
      "backbone.levels.0.blocks.0.dcn.output_proj.weight",
      "backbone.levels.0.blocks.0.mlp.fc1.weight",
      "backbone.levels.0.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.05
  },
  "layer_2_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.gamma1",
      "backbone.levels.0.blocks.1.gamma2",
      "backbone.levels.0.blocks.1.norm1.0.weight",
      "backbone.levels.0.blocks.1.norm1.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.1.dcn.offset.bias",
      "backbone.levels.0.blocks.1.dcn.mask.bias",
      "backbone.levels.0.blocks.1.dcn.input_proj.bias",
      "backbone.levels.0.blocks.1.dcn.output_proj.bias",
      "backbone.levels.0.blocks.1.norm2.0.weight",
      "backbone.levels.0.blocks.1.norm2.0.bias",
      "backbone.levels.0.blocks.1.mlp.fc1.bias",
      "backbone.levels.0.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.0
  },
  "layer_2_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.1.dcn.offset.weight",
      "backbone.levels.0.blocks.1.dcn.mask.weight",
      "backbone.levels.0.blocks.1.dcn.input_proj.weight",
      "backbone.levels.0.blocks.1.dcn.output_proj.weight",
      "backbone.levels.0.blocks.1.mlp.fc1.weight",
      "backbone.levels.0.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.05
  },
  "layer_3_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.gamma1",
      "backbone.levels.0.blocks.2.gamma2",
      "backbone.levels.0.blocks.2.norm1.0.weight",
      "backbone.levels.0.blocks.2.norm1.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.2.dcn.offset.bias",
      "backbone.levels.0.blocks.2.dcn.mask.bias",
      "backbone.levels.0.blocks.2.dcn.input_proj.bias",
      "backbone.levels.0.blocks.2.dcn.output_proj.bias",
      "backbone.levels.0.blocks.2.norm2.0.weight",
      "backbone.levels.0.blocks.2.norm2.0.bias",
      "backbone.levels.0.blocks.2.mlp.fc1.bias",
      "backbone.levels.0.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.0
  },
  "layer_3_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.2.dcn.offset.weight",
      "backbone.levels.0.blocks.2.dcn.mask.weight",
      "backbone.levels.0.blocks.2.dcn.input_proj.weight",
      "backbone.levels.0.blocks.2.dcn.output_proj.weight",
      "backbone.levels.0.blocks.2.mlp.fc1.weight",
      "backbone.levels.0.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.05
  },
  "layer_4_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.gamma1",
      "backbone.levels.0.blocks.3.gamma2",
      "backbone.levels.0.blocks.3.norm1.0.weight",
      "backbone.levels.0.blocks.3.norm1.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.3.dcn.offset.bias",
      "backbone.levels.0.blocks.3.dcn.mask.bias",
      "backbone.levels.0.blocks.3.dcn.input_proj.bias",
      "backbone.levels.0.blocks.3.dcn.output_proj.bias",
      "backbone.levels.0.blocks.3.norm2.0.weight",
      "backbone.levels.0.blocks.3.norm2.0.bias",
      "backbone.levels.0.blocks.3.mlp.fc1.bias",
      "backbone.levels.0.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.0
  },
  "layer_4_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.3.dcn.offset.weight",
      "backbone.levels.0.blocks.3.dcn.mask.weight",
      "backbone.levels.0.blocks.3.dcn.input_proj.weight",
      "backbone.levels.0.blocks.3.dcn.output_proj.weight",
      "backbone.levels.0.blocks.3.mlp.fc1.weight",
      "backbone.levels.0.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.05
  },
  "layer_6_decay": {
    "param_names": [
      "backbone.levels.0.downsample.conv.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.0.dcn.offset.weight",
      "backbone.levels.1.blocks.0.dcn.mask.weight",
      "backbone.levels.1.blocks.0.dcn.input_proj.weight",
      "backbone.levels.1.blocks.0.dcn.output_proj.weight",
      "backbone.levels.1.blocks.0.mlp.fc1.weight",
      "backbone.levels.1.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.05
  },
  "layer_6_no_decay": {
    "param_names": [
      "backbone.levels.0.downsample.norm.1.weight",
      "backbone.levels.0.downsample.norm.1.bias",
      "backbone.levels.1.blocks.0.gamma1",
      "backbone.levels.1.blocks.0.gamma2",
      "backbone.levels.1.blocks.0.norm1.0.weight",
      "backbone.levels.1.blocks.0.norm1.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.0.dcn.offset.bias",
      "backbone.levels.1.blocks.0.dcn.mask.bias",
      "backbone.levels.1.blocks.0.dcn.input_proj.bias",
      "backbone.levels.1.blocks.0.dcn.output_proj.bias",
      "backbone.levels.1.blocks.0.norm2.0.weight",
      "backbone.levels.1.blocks.0.norm2.0.bias",
      "backbone.levels.1.blocks.0.mlp.fc1.bias",
      "backbone.levels.1.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.0
  },
  "layer_7_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.gamma1",
      "backbone.levels.1.blocks.1.gamma2",
      "backbone.levels.1.blocks.1.norm1.0.weight",
      "backbone.levels.1.blocks.1.norm1.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.1.dcn.offset.bias",
      "backbone.levels.1.blocks.1.dcn.mask.bias",
      "backbone.levels.1.blocks.1.dcn.input_proj.bias",
      "backbone.levels.1.blocks.1.dcn.output_proj.bias",
      "backbone.levels.1.blocks.1.norm2.0.weight",
      "backbone.levels.1.blocks.1.norm2.0.bias",
      "backbone.levels.1.blocks.1.mlp.fc1.bias",
      "backbone.levels.1.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.0
  },
  "layer_7_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.1.dcn.offset.weight",
      "backbone.levels.1.blocks.1.dcn.mask.weight",
      "backbone.levels.1.blocks.1.dcn.input_proj.weight",
      "backbone.levels.1.blocks.1.dcn.output_proj.weight",
      "backbone.levels.1.blocks.1.mlp.fc1.weight",
      "backbone.levels.1.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.05
  },
  "layer_8_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.gamma1",
      "backbone.levels.1.blocks.2.gamma2",
      "backbone.levels.1.blocks.2.norm1.0.weight",
      "backbone.levels.1.blocks.2.norm1.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.2.dcn.offset.bias",
      "backbone.levels.1.blocks.2.dcn.mask.bias",
      "backbone.levels.1.blocks.2.dcn.input_proj.bias",
      "backbone.levels.1.blocks.2.dcn.output_proj.bias",
      "backbone.levels.1.blocks.2.norm2.0.weight",
      "backbone.levels.1.blocks.2.norm2.0.bias",
      "backbone.levels.1.blocks.2.mlp.fc1.bias",
      "backbone.levels.1.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.0
  },
  "layer_8_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.2.dcn.offset.weight",
      "backbone.levels.1.blocks.2.dcn.mask.weight",
      "backbone.levels.1.blocks.2.dcn.input_proj.weight",
      "backbone.levels.1.blocks.2.dcn.output_proj.weight",
      "backbone.levels.1.blocks.2.mlp.fc1.weight",
      "backbone.levels.1.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.05
  },
  "layer_9_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.gamma1",
      "backbone.levels.1.blocks.3.gamma2",
      "backbone.levels.1.blocks.3.norm1.0.weight",
      "backbone.levels.1.blocks.3.norm1.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.3.dcn.offset.bias",
      "backbone.levels.1.blocks.3.dcn.mask.bias",
      "backbone.levels.1.blocks.3.dcn.input_proj.bias",
      "backbone.levels.1.blocks.3.dcn.output_proj.bias",
      "backbone.levels.1.blocks.3.norm2.0.weight",
      "backbone.levels.1.blocks.3.norm2.0.bias",
      "backbone.levels.1.blocks.3.mlp.fc1.bias",
      "backbone.levels.1.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.0
  },
  "layer_9_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.3.dcn.offset.weight",
      "backbone.levels.1.blocks.3.dcn.mask.weight",
      "backbone.levels.1.blocks.3.dcn.input_proj.weight",
      "backbone.levels.1.blocks.3.dcn.output_proj.weight",
      "backbone.levels.1.blocks.3.mlp.fc1.weight",
      "backbone.levels.1.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.05
  },
  "layer_11_decay": {
    "param_names": [
      "backbone.levels.1.downsample.conv.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.0.dcn.offset.weight",
      "backbone.levels.2.blocks.0.dcn.mask.weight",
      "backbone.levels.2.blocks.0.dcn.input_proj.weight",
      "backbone.levels.2.blocks.0.dcn.output_proj.weight",
      "backbone.levels.2.blocks.0.mlp.fc1.weight",
      "backbone.levels.2.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.05
  },
  "layer_11_no_decay": {
    "param_names": [
      "backbone.levels.1.downsample.norm.1.weight",
      "backbone.levels.1.downsample.norm.1.bias",
      "backbone.levels.2.blocks.0.gamma1",
      "backbone.levels.2.blocks.0.gamma2",
      "backbone.levels.2.blocks.0.norm1.0.weight",
      "backbone.levels.2.blocks.0.norm1.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.0.dcn.offset.bias",
      "backbone.levels.2.blocks.0.dcn.mask.bias",
      "backbone.levels.2.blocks.0.dcn.input_proj.bias",
      "backbone.levels.2.blocks.0.dcn.output_proj.bias",
      "backbone.levels.2.blocks.0.norm2.0.weight",
      "backbone.levels.2.blocks.0.norm2.0.bias",
      "backbone.levels.2.blocks.0.mlp.fc1.bias",
      "backbone.levels.2.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.0
  },
  "layer_12_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.gamma1",
      "backbone.levels.2.blocks.1.gamma2",
      "backbone.levels.2.blocks.1.norm1.0.weight",
      "backbone.levels.2.blocks.1.norm1.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.1.dcn.offset.bias",
      "backbone.levels.2.blocks.1.dcn.mask.bias",
      "backbone.levels.2.blocks.1.dcn.input_proj.bias",
      "backbone.levels.2.blocks.1.dcn.output_proj.bias",
      "backbone.levels.2.blocks.1.norm2.0.weight",
      "backbone.levels.2.blocks.1.norm2.0.bias",
      "backbone.levels.2.blocks.1.mlp.fc1.bias",
      "backbone.levels.2.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.0
  },
  "layer_12_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.1.dcn.offset.weight",
      "backbone.levels.2.blocks.1.dcn.mask.weight",
      "backbone.levels.2.blocks.1.dcn.input_proj.weight",
      "backbone.levels.2.blocks.1.dcn.output_proj.weight",
      "backbone.levels.2.blocks.1.mlp.fc1.weight",
      "backbone.levels.2.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.05
  },
  "layer_13_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.gamma1",
      "backbone.levels.2.blocks.2.gamma2",
      "backbone.levels.2.blocks.2.norm1.0.weight",
      "backbone.levels.2.blocks.2.norm1.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.2.dcn.offset.bias",
      "backbone.levels.2.blocks.2.dcn.mask.bias",
      "backbone.levels.2.blocks.2.dcn.input_proj.bias",
      "backbone.levels.2.blocks.2.dcn.output_proj.bias",
      "backbone.levels.2.blocks.2.norm2.0.weight",
      "backbone.levels.2.blocks.2.norm2.0.bias",
      "backbone.levels.2.blocks.2.mlp.fc1.bias",
      "backbone.levels.2.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.0
  },
  "layer_13_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.2.dcn.offset.weight",
      "backbone.levels.2.blocks.2.dcn.mask.weight",
      "backbone.levels.2.blocks.2.dcn.input_proj.weight",
      "backbone.levels.2.blocks.2.dcn.output_proj.weight",
      "backbone.levels.2.blocks.2.mlp.fc1.weight",
      "backbone.levels.2.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.05
  },
  "layer_14_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.gamma1",
      "backbone.levels.2.blocks.3.gamma2",
      "backbone.levels.2.blocks.3.norm1.0.weight",
      "backbone.levels.2.blocks.3.norm1.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.3.dcn.offset.bias",
      "backbone.levels.2.blocks.3.dcn.mask.bias",
      "backbone.levels.2.blocks.3.dcn.input_proj.bias",
      "backbone.levels.2.blocks.3.dcn.output_proj.bias",
      "backbone.levels.2.blocks.3.norm2.0.weight",
      "backbone.levels.2.blocks.3.norm2.0.bias",
      "backbone.levels.2.blocks.3.mlp.fc1.bias",
      "backbone.levels.2.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.0
  },
  "layer_14_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.3.dcn.offset.weight",
      "backbone.levels.2.blocks.3.dcn.mask.weight",
      "backbone.levels.2.blocks.3.dcn.input_proj.weight",
      "backbone.levels.2.blocks.3.dcn.output_proj.weight",
      "backbone.levels.2.blocks.3.mlp.fc1.weight",
      "backbone.levels.2.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.05
  },
  "layer_15_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.gamma1",
      "backbone.levels.2.blocks.4.gamma2",
      "backbone.levels.2.blocks.4.norm1.0.weight",
      "backbone.levels.2.blocks.4.norm1.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.4.dcn.offset.bias",
      "backbone.levels.2.blocks.4.dcn.mask.bias",
      "backbone.levels.2.blocks.4.dcn.input_proj.bias",
      "backbone.levels.2.blocks.4.dcn.output_proj.bias",
      "backbone.levels.2.blocks.4.norm2.0.weight",
      "backbone.levels.2.blocks.4.norm2.0.bias",
      "backbone.levels.2.blocks.4.mlp.fc1.bias",
      "backbone.levels.2.blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.0
  },
  "layer_15_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.4.dcn.offset.weight",
      "backbone.levels.2.blocks.4.dcn.mask.weight",
      "backbone.levels.2.blocks.4.dcn.input_proj.weight",
      "backbone.levels.2.blocks.4.dcn.output_proj.weight",
      "backbone.levels.2.blocks.4.mlp.fc1.weight",
      "backbone.levels.2.blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.05
  },
  "layer_16_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.gamma1",
      "backbone.levels.2.blocks.5.gamma2",
      "backbone.levels.2.blocks.5.norm1.0.weight",
      "backbone.levels.2.blocks.5.norm1.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.5.dcn.offset.bias",
      "backbone.levels.2.blocks.5.dcn.mask.bias",
      "backbone.levels.2.blocks.5.dcn.input_proj.bias",
      "backbone.levels.2.blocks.5.dcn.output_proj.bias",
      "backbone.levels.2.blocks.5.norm2.0.weight",
      "backbone.levels.2.blocks.5.norm2.0.bias",
      "backbone.levels.2.blocks.5.mlp.fc1.bias",
      "backbone.levels.2.blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.0
  },
  "layer_16_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.5.dcn.offset.weight",
      "backbone.levels.2.blocks.5.dcn.mask.weight",
      "backbone.levels.2.blocks.5.dcn.input_proj.weight",
      "backbone.levels.2.blocks.5.dcn.output_proj.weight",
      "backbone.levels.2.blocks.5.mlp.fc1.weight",
      "backbone.levels.2.blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.05
  },
  "layer_17_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.gamma1",
      "backbone.levels.2.blocks.6.gamma2",
      "backbone.levels.2.blocks.6.norm1.0.weight",
      "backbone.levels.2.blocks.6.norm1.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.6.dcn.offset.bias",
      "backbone.levels.2.blocks.6.dcn.mask.bias",
      "backbone.levels.2.blocks.6.dcn.input_proj.bias",
      "backbone.levels.2.blocks.6.dcn.output_proj.bias",
      "backbone.levels.2.blocks.6.norm2.0.weight",
      "backbone.levels.2.blocks.6.norm2.0.bias",
      "backbone.levels.2.blocks.6.mlp.fc1.bias",
      "backbone.levels.2.blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.0
  },
  "layer_17_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.6.dcn.offset.weight",
      "backbone.levels.2.blocks.6.dcn.mask.weight",
      "backbone.levels.2.blocks.6.dcn.input_proj.weight",
      "backbone.levels.2.blocks.6.dcn.output_proj.weight",
      "backbone.levels.2.blocks.6.mlp.fc1.weight",
      "backbone.levels.2.blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.05
  },
  "layer_18_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.gamma1",
      "backbone.levels.2.blocks.7.gamma2",
      "backbone.levels.2.blocks.7.norm1.0.weight",
      "backbone.levels.2.blocks.7.norm1.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.7.dcn.offset.bias",
      "backbone.levels.2.blocks.7.dcn.mask.bias",
      "backbone.levels.2.blocks.7.dcn.input_proj.bias",
      "backbone.levels.2.blocks.7.dcn.output_proj.bias",
      "backbone.levels.2.blocks.7.norm2.0.weight",
      "backbone.levels.2.blocks.7.norm2.0.bias",
      "backbone.levels.2.blocks.7.mlp.fc1.bias",
      "backbone.levels.2.blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.0
  },
  "layer_18_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.7.dcn.offset.weight",
      "backbone.levels.2.blocks.7.dcn.mask.weight",
      "backbone.levels.2.blocks.7.dcn.input_proj.weight",
      "backbone.levels.2.blocks.7.dcn.output_proj.weight",
      "backbone.levels.2.blocks.7.mlp.fc1.weight",
      "backbone.levels.2.blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.05
  },
  "layer_19_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.gamma1",
      "backbone.levels.2.blocks.8.gamma2",
      "backbone.levels.2.blocks.8.norm1.0.weight",
      "backbone.levels.2.blocks.8.norm1.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.8.dcn.offset.bias",
      "backbone.levels.2.blocks.8.dcn.mask.bias",
      "backbone.levels.2.blocks.8.dcn.input_proj.bias",
      "backbone.levels.2.blocks.8.dcn.output_proj.bias",
      "backbone.levels.2.blocks.8.norm2.0.weight",
      "backbone.levels.2.blocks.8.norm2.0.bias",
      "backbone.levels.2.blocks.8.mlp.fc1.bias",
      "backbone.levels.2.blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.0
  },
  "layer_19_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.8.dcn.offset.weight",
      "backbone.levels.2.blocks.8.dcn.mask.weight",
      "backbone.levels.2.blocks.8.dcn.input_proj.weight",
      "backbone.levels.2.blocks.8.dcn.output_proj.weight",
      "backbone.levels.2.blocks.8.mlp.fc1.weight",
      "backbone.levels.2.blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.05
  },
  "layer_20_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.gamma1",
      "backbone.levels.2.blocks.9.gamma2",
      "backbone.levels.2.blocks.9.norm1.0.weight",
      "backbone.levels.2.blocks.9.norm1.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.9.dcn.offset.bias",
      "backbone.levels.2.blocks.9.dcn.mask.bias",
      "backbone.levels.2.blocks.9.dcn.input_proj.bias",
      "backbone.levels.2.blocks.9.dcn.output_proj.bias",
      "backbone.levels.2.blocks.9.norm2.0.weight",
      "backbone.levels.2.blocks.9.norm2.0.bias",
      "backbone.levels.2.blocks.9.mlp.fc1.bias",
      "backbone.levels.2.blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.0
  },
  "layer_20_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.9.dcn.offset.weight",
      "backbone.levels.2.blocks.9.dcn.mask.weight",
      "backbone.levels.2.blocks.9.dcn.input_proj.weight",
      "backbone.levels.2.blocks.9.dcn.output_proj.weight",
      "backbone.levels.2.blocks.9.mlp.fc1.weight",
      "backbone.levels.2.blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.05
  },
  "layer_21_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.gamma1",
      "backbone.levels.2.blocks.10.gamma2",
      "backbone.levels.2.blocks.10.norm1.0.weight",
      "backbone.levels.2.blocks.10.norm1.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.10.dcn.offset.bias",
      "backbone.levels.2.blocks.10.dcn.mask.bias",
      "backbone.levels.2.blocks.10.dcn.input_proj.bias",
      "backbone.levels.2.blocks.10.dcn.output_proj.bias",
      "backbone.levels.2.blocks.10.norm2.0.weight",
      "backbone.levels.2.blocks.10.norm2.0.bias",
      "backbone.levels.2.blocks.10.mlp.fc1.bias",
      "backbone.levels.2.blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.0
  },
  "layer_21_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.10.dcn.offset.weight",
      "backbone.levels.2.blocks.10.dcn.mask.weight",
      "backbone.levels.2.blocks.10.dcn.input_proj.weight",
      "backbone.levels.2.blocks.10.dcn.output_proj.weight",
      "backbone.levels.2.blocks.10.mlp.fc1.weight",
      "backbone.levels.2.blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.05
  },
  "layer_22_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.gamma1",
      "backbone.levels.2.blocks.11.gamma2",
      "backbone.levels.2.blocks.11.norm1.0.weight",
      "backbone.levels.2.blocks.11.norm1.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.11.dcn.offset.bias",
      "backbone.levels.2.blocks.11.dcn.mask.bias",
      "backbone.levels.2.blocks.11.dcn.input_proj.bias",
      "backbone.levels.2.blocks.11.dcn.output_proj.bias",
      "backbone.levels.2.blocks.11.norm2.0.weight",
      "backbone.levels.2.blocks.11.norm2.0.bias",
      "backbone.levels.2.blocks.11.mlp.fc1.bias",
      "backbone.levels.2.blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.0
  },
  "layer_22_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.11.dcn.offset.weight",
      "backbone.levels.2.blocks.11.dcn.mask.weight",
      "backbone.levels.2.blocks.11.dcn.input_proj.weight",
      "backbone.levels.2.blocks.11.dcn.output_proj.weight",
      "backbone.levels.2.blocks.11.mlp.fc1.weight",
      "backbone.levels.2.blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.05
  },
  "layer_23_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.gamma1",
      "backbone.levels.2.blocks.12.gamma2",
      "backbone.levels.2.blocks.12.norm1.0.weight",
      "backbone.levels.2.blocks.12.norm1.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.12.dcn.offset.bias",
      "backbone.levels.2.blocks.12.dcn.mask.bias",
      "backbone.levels.2.blocks.12.dcn.input_proj.bias",
      "backbone.levels.2.blocks.12.dcn.output_proj.bias",
      "backbone.levels.2.blocks.12.norm2.0.weight",
      "backbone.levels.2.blocks.12.norm2.0.bias",
      "backbone.levels.2.blocks.12.mlp.fc1.bias",
      "backbone.levels.2.blocks.12.mlp.fc2.bias"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.0
  },
  "layer_23_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.12.dcn.offset.weight",
      "backbone.levels.2.blocks.12.dcn.mask.weight",
      "backbone.levels.2.blocks.12.dcn.input_proj.weight",
      "backbone.levels.2.blocks.12.dcn.output_proj.weight",
      "backbone.levels.2.blocks.12.mlp.fc1.weight",
      "backbone.levels.2.blocks.12.mlp.fc2.weight"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.05
  },
  "layer_24_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.gamma1",
      "backbone.levels.2.blocks.13.gamma2",
      "backbone.levels.2.blocks.13.norm1.0.weight",
      "backbone.levels.2.blocks.13.norm1.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.13.dcn.offset.bias",
      "backbone.levels.2.blocks.13.dcn.mask.bias",
      "backbone.levels.2.blocks.13.dcn.input_proj.bias",
      "backbone.levels.2.blocks.13.dcn.output_proj.bias",
      "backbone.levels.2.blocks.13.norm2.0.weight",
      "backbone.levels.2.blocks.13.norm2.0.bias",
      "backbone.levels.2.blocks.13.mlp.fc1.bias",
      "backbone.levels.2.blocks.13.mlp.fc2.bias"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.0
  },
  "layer_24_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.13.dcn.offset.weight",
      "backbone.levels.2.blocks.13.dcn.mask.weight",
      "backbone.levels.2.blocks.13.dcn.input_proj.weight",
      "backbone.levels.2.blocks.13.dcn.output_proj.weight",
      "backbone.levels.2.blocks.13.mlp.fc1.weight",
      "backbone.levels.2.blocks.13.mlp.fc2.weight"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.05
  },
  "layer_25_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.gamma1",
      "backbone.levels.2.blocks.14.gamma2",
      "backbone.levels.2.blocks.14.norm1.0.weight",
      "backbone.levels.2.blocks.14.norm1.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.14.dcn.offset.bias",
      "backbone.levels.2.blocks.14.dcn.mask.bias",
      "backbone.levels.2.blocks.14.dcn.input_proj.bias",
      "backbone.levels.2.blocks.14.dcn.output_proj.bias",
      "backbone.levels.2.blocks.14.norm2.0.weight",
      "backbone.levels.2.blocks.14.norm2.0.bias",
      "backbone.levels.2.blocks.14.mlp.fc1.bias",
      "backbone.levels.2.blocks.14.mlp.fc2.bias"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.0
  },
  "layer_25_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.14.dcn.offset.weight",
      "backbone.levels.2.blocks.14.dcn.mask.weight",
      "backbone.levels.2.blocks.14.dcn.input_proj.weight",
      "backbone.levels.2.blocks.14.dcn.output_proj.weight",
      "backbone.levels.2.blocks.14.mlp.fc1.weight",
      "backbone.levels.2.blocks.14.mlp.fc2.weight"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.05
  },
  "layer_26_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.gamma1",
      "backbone.levels.2.blocks.15.gamma2",
      "backbone.levels.2.blocks.15.norm1.0.weight",
      "backbone.levels.2.blocks.15.norm1.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.15.dcn.offset.bias",
      "backbone.levels.2.blocks.15.dcn.mask.bias",
      "backbone.levels.2.blocks.15.dcn.input_proj.bias",
      "backbone.levels.2.blocks.15.dcn.output_proj.bias",
      "backbone.levels.2.blocks.15.norm2.0.weight",
      "backbone.levels.2.blocks.15.norm2.0.bias",
      "backbone.levels.2.blocks.15.mlp.fc1.bias",
      "backbone.levels.2.blocks.15.mlp.fc2.bias"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.0
  },
  "layer_26_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.15.dcn.offset.weight",
      "backbone.levels.2.blocks.15.dcn.mask.weight",
      "backbone.levels.2.blocks.15.dcn.input_proj.weight",
      "backbone.levels.2.blocks.15.dcn.output_proj.weight",
      "backbone.levels.2.blocks.15.mlp.fc1.weight",
      "backbone.levels.2.blocks.15.mlp.fc2.weight"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.05
  },
  "layer_27_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.gamma1",
      "backbone.levels.2.blocks.16.gamma2",
      "backbone.levels.2.blocks.16.norm1.0.weight",
      "backbone.levels.2.blocks.16.norm1.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.16.dcn.offset.bias",
      "backbone.levels.2.blocks.16.dcn.mask.bias",
      "backbone.levels.2.blocks.16.dcn.input_proj.bias",
      "backbone.levels.2.blocks.16.dcn.output_proj.bias",
      "backbone.levels.2.blocks.16.norm2.0.weight",
      "backbone.levels.2.blocks.16.norm2.0.bias",
      "backbone.levels.2.blocks.16.mlp.fc1.bias",
      "backbone.levels.2.blocks.16.mlp.fc2.bias"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.0
  },
  "layer_27_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.16.dcn.offset.weight",
      "backbone.levels.2.blocks.16.dcn.mask.weight",
      "backbone.levels.2.blocks.16.dcn.input_proj.weight",
      "backbone.levels.2.blocks.16.dcn.output_proj.weight",
      "backbone.levels.2.blocks.16.mlp.fc1.weight",
      "backbone.levels.2.blocks.16.mlp.fc2.weight"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.05
  },
  "layer_28_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.gamma1",
      "backbone.levels.2.blocks.17.gamma2",
      "backbone.levels.2.blocks.17.norm1.0.weight",
      "backbone.levels.2.blocks.17.norm1.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.17.dcn.offset.bias",
      "backbone.levels.2.blocks.17.dcn.mask.bias",
      "backbone.levels.2.blocks.17.dcn.input_proj.bias",
      "backbone.levels.2.blocks.17.dcn.output_proj.bias",
      "backbone.levels.2.blocks.17.norm2.0.weight",
      "backbone.levels.2.blocks.17.norm2.0.bias",
      "backbone.levels.2.blocks.17.mlp.fc1.bias",
      "backbone.levels.2.blocks.17.mlp.fc2.bias"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.0
  },
  "layer_28_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.17.dcn.offset.weight",
      "backbone.levels.2.blocks.17.dcn.mask.weight",
      "backbone.levels.2.blocks.17.dcn.input_proj.weight",
      "backbone.levels.2.blocks.17.dcn.output_proj.weight",
      "backbone.levels.2.blocks.17.mlp.fc1.weight",
      "backbone.levels.2.blocks.17.mlp.fc2.weight"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.05
  },
  "layer_29_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.gamma1",
      "backbone.levels.2.blocks.18.gamma2",
      "backbone.levels.2.blocks.18.norm1.0.weight",
      "backbone.levels.2.blocks.18.norm1.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.18.dcn.offset.bias",
      "backbone.levels.2.blocks.18.dcn.mask.bias",
      "backbone.levels.2.blocks.18.dcn.input_proj.bias",
      "backbone.levels.2.blocks.18.dcn.output_proj.bias",
      "backbone.levels.2.blocks.18.norm2.0.weight",
      "backbone.levels.2.blocks.18.norm2.0.bias",
      "backbone.levels.2.blocks.18.mlp.fc1.bias",
      "backbone.levels.2.blocks.18.mlp.fc2.bias"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.0
  },
  "layer_29_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.18.dcn.offset.weight",
      "backbone.levels.2.blocks.18.dcn.mask.weight",
      "backbone.levels.2.blocks.18.dcn.input_proj.weight",
      "backbone.levels.2.blocks.18.dcn.output_proj.weight",
      "backbone.levels.2.blocks.18.mlp.fc1.weight",
      "backbone.levels.2.blocks.18.mlp.fc2.weight"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.05
  },
  "layer_30_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.gamma1",
      "backbone.levels.2.blocks.19.gamma2",
      "backbone.levels.2.blocks.19.norm1.0.weight",
      "backbone.levels.2.blocks.19.norm1.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.19.dcn.offset.bias",
      "backbone.levels.2.blocks.19.dcn.mask.bias",
      "backbone.levels.2.blocks.19.dcn.input_proj.bias",
      "backbone.levels.2.blocks.19.dcn.output_proj.bias",
      "backbone.levels.2.blocks.19.norm2.0.weight",
      "backbone.levels.2.blocks.19.norm2.0.bias",
      "backbone.levels.2.blocks.19.mlp.fc1.bias",
      "backbone.levels.2.blocks.19.mlp.fc2.bias"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.0
  },
  "layer_30_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.19.dcn.offset.weight",
      "backbone.levels.2.blocks.19.dcn.mask.weight",
      "backbone.levels.2.blocks.19.dcn.input_proj.weight",
      "backbone.levels.2.blocks.19.dcn.output_proj.weight",
      "backbone.levels.2.blocks.19.mlp.fc1.weight",
      "backbone.levels.2.blocks.19.mlp.fc2.weight"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.05
  },
  "layer_31_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.gamma1",
      "backbone.levels.2.blocks.20.gamma2",
      "backbone.levels.2.blocks.20.norm1.0.weight",
      "backbone.levels.2.blocks.20.norm1.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.20.dcn.offset.bias",
      "backbone.levels.2.blocks.20.dcn.mask.bias",
      "backbone.levels.2.blocks.20.dcn.input_proj.bias",
      "backbone.levels.2.blocks.20.dcn.output_proj.bias",
      "backbone.levels.2.blocks.20.norm2.0.weight",
      "backbone.levels.2.blocks.20.norm2.0.bias",
      "backbone.levels.2.blocks.20.mlp.fc1.bias",
      "backbone.levels.2.blocks.20.mlp.fc2.bias"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.0
  },
  "layer_31_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.20.dcn.offset.weight",
      "backbone.levels.2.blocks.20.dcn.mask.weight",
      "backbone.levels.2.blocks.20.dcn.input_proj.weight",
      "backbone.levels.2.blocks.20.dcn.output_proj.weight",
      "backbone.levels.2.blocks.20.mlp.fc1.weight",
      "backbone.levels.2.blocks.20.mlp.fc2.weight"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.05
  },
  "layer_35_decay": {
    "param_names": [
      "backbone.levels.2.downsample.conv.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.0.dcn.offset.weight",
      "backbone.levels.3.blocks.0.dcn.mask.weight",
      "backbone.levels.3.blocks.0.dcn.input_proj.weight",
      "backbone.levels.3.blocks.0.dcn.output_proj.weight",
      "backbone.levels.3.blocks.0.mlp.fc1.weight",
      "backbone.levels.3.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.05
  },
  "layer_35_no_decay": {
    "param_names": [
      "backbone.levels.2.downsample.norm.1.weight",
      "backbone.levels.2.downsample.norm.1.bias",
      "backbone.levels.3.blocks.0.gamma1",
      "backbone.levels.3.blocks.0.gamma2",
      "backbone.levels.3.blocks.0.norm1.0.weight",
      "backbone.levels.3.blocks.0.norm1.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.0.dcn.offset.bias",
      "backbone.levels.3.blocks.0.dcn.mask.bias",
      "backbone.levels.3.blocks.0.dcn.input_proj.bias",
      "backbone.levels.3.blocks.0.dcn.output_proj.bias",
      "backbone.levels.3.blocks.0.norm2.0.weight",
      "backbone.levels.3.blocks.0.norm2.0.bias",
      "backbone.levels.3.blocks.0.mlp.fc1.bias",
      "backbone.levels.3.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.0
  },
  "layer_36_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.gamma1",
      "backbone.levels.3.blocks.1.gamma2",
      "backbone.levels.3.blocks.1.norm1.0.weight",
      "backbone.levels.3.blocks.1.norm1.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.1.dcn.offset.bias",
      "backbone.levels.3.blocks.1.dcn.mask.bias",
      "backbone.levels.3.blocks.1.dcn.input_proj.bias",
      "backbone.levels.3.blocks.1.dcn.output_proj.bias",
      "backbone.levels.3.blocks.1.norm2.0.weight",
      "backbone.levels.3.blocks.1.norm2.0.bias",
      "backbone.levels.3.blocks.1.mlp.fc1.bias",
      "backbone.levels.3.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.0
  },
  "layer_36_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.1.dcn.offset.weight",
      "backbone.levels.3.blocks.1.dcn.mask.weight",
      "backbone.levels.3.blocks.1.dcn.input_proj.weight",
      "backbone.levels.3.blocks.1.dcn.output_proj.weight",
      "backbone.levels.3.blocks.1.mlp.fc1.weight",
      "backbone.levels.3.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.05
  },
  "layer_37_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.gamma1",
      "backbone.levels.3.blocks.2.gamma2",
      "backbone.levels.3.blocks.2.norm1.0.weight",
      "backbone.levels.3.blocks.2.norm1.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.2.dcn.offset.bias",
      "backbone.levels.3.blocks.2.dcn.mask.bias",
      "backbone.levels.3.blocks.2.dcn.input_proj.bias",
      "backbone.levels.3.blocks.2.dcn.output_proj.bias",
      "backbone.levels.3.blocks.2.norm2.0.weight",
      "backbone.levels.3.blocks.2.norm2.0.bias",
      "backbone.levels.3.blocks.2.mlp.fc1.bias",
      "backbone.levels.3.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.0
  },
  "layer_37_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.2.dcn.offset.weight",
      "backbone.levels.3.blocks.2.dcn.mask.weight",
      "backbone.levels.3.blocks.2.dcn.input_proj.weight",
      "backbone.levels.3.blocks.2.dcn.output_proj.weight",
      "backbone.levels.3.blocks.2.mlp.fc1.weight",
      "backbone.levels.3.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.05
  },
  "layer_38_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.gamma1",
      "backbone.levels.3.blocks.3.gamma2",
      "backbone.levels.3.blocks.3.norm1.0.weight",
      "backbone.levels.3.blocks.3.norm1.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.3.dcn.offset.bias",
      "backbone.levels.3.blocks.3.dcn.mask.bias",
      "backbone.levels.3.blocks.3.dcn.input_proj.bias",
      "backbone.levels.3.blocks.3.dcn.output_proj.bias",
      "backbone.levels.3.blocks.3.norm2.0.weight",
      "backbone.levels.3.blocks.3.norm2.0.bias",
      "backbone.levels.3.blocks.3.mlp.fc1.bias",
      "backbone.levels.3.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.0
  },
  "layer_38_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.3.dcn.offset.weight",
      "backbone.levels.3.blocks.3.dcn.mask.weight",
      "backbone.levels.3.blocks.3.dcn.input_proj.weight",
      "backbone.levels.3.blocks.3.dcn.output_proj.weight",
      "backbone.levels.3.blocks.3.mlp.fc1.weight",
      "backbone.levels.3.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.05
  },
  "layer_40_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.weight",
      "decode_head.pixel_decoder.input_convs.1.conv.weight",
      "decode_head.pixel_decoder.input_convs.2.conv.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.level_encoding.weight",
      "decode_head.pixel_decoder.lateral_convs.0.conv.weight",
      "decode_head.pixel_decoder.output_convs.0.conv.weight",
      "decode_head.pixel_decoder.mask_feature.weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.05
  },
  "layer_40_no_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.bias",
      "decode_head.pixel_decoder.input_convs.0.gn.weight",
      "decode_head.pixel_decoder.input_convs.0.gn.bias",
      "decode_head.pixel_decoder.input_convs.1.conv.bias",
      "decode_head.pixel_decoder.input_convs.1.gn.weight",
      "decode_head.pixel_decoder.input_convs.1.gn.bias",
      "decode_head.pixel_decoder.input_convs.2.conv.bias",
      "decode_head.pixel_decoder.input_convs.2.gn.weight",
      "decode_head.pixel_decoder.input_convs.2.gn.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.bias",
      "decode_head.pixel_decoder.lateral_convs.0.gn.weight",
      "decode_head.pixel_decoder.lateral_convs.0.gn.bias",
      "decode_head.pixel_decoder.output_convs.0.gn.weight",
      "decode_head.pixel_decoder.output_convs.0.gn.bias",
      "decode_head.pixel_decoder.mask_feature.bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.0.weight",
      "decode_head.transformer_decoder.layers.0.norms.0.bias",
      "decode_head.transformer_decoder.layers.0.norms.1.weight",
      "decode_head.transformer_decoder.layers.0.norms.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.2.weight",
      "decode_head.transformer_decoder.layers.0.norms.2.bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.0.weight",
      "decode_head.transformer_decoder.layers.1.norms.0.bias",
      "decode_head.transformer_decoder.layers.1.norms.1.weight",
      "decode_head.transformer_decoder.layers.1.norms.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.2.weight",
      "decode_head.transformer_decoder.layers.1.norms.2.bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.0.weight",
      "decode_head.transformer_decoder.layers.2.norms.0.bias",
      "decode_head.transformer_decoder.layers.2.norms.1.weight",
      "decode_head.transformer_decoder.layers.2.norms.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.2.weight",
      "decode_head.transformer_decoder.layers.2.norms.2.bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.0.weight",
      "decode_head.transformer_decoder.layers.3.norms.0.bias",
      "decode_head.transformer_decoder.layers.3.norms.1.weight",
      "decode_head.transformer_decoder.layers.3.norms.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.2.weight",
      "decode_head.transformer_decoder.layers.3.norms.2.bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.0.weight",
      "decode_head.transformer_decoder.layers.4.norms.0.bias",
      "decode_head.transformer_decoder.layers.4.norms.1.weight",
      "decode_head.transformer_decoder.layers.4.norms.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.2.weight",
      "decode_head.transformer_decoder.layers.4.norms.2.bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.0.weight",
      "decode_head.transformer_decoder.layers.5.norms.0.bias",
      "decode_head.transformer_decoder.layers.5.norms.1.weight",
      "decode_head.transformer_decoder.layers.5.norms.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.2.weight",
      "decode_head.transformer_decoder.layers.5.norms.2.bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.0.weight",
      "decode_head.transformer_decoder.layers.6.norms.0.bias",
      "decode_head.transformer_decoder.layers.6.norms.1.weight",
      "decode_head.transformer_decoder.layers.6.norms.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.2.weight",
      "decode_head.transformer_decoder.layers.6.norms.2.bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.0.weight",
      "decode_head.transformer_decoder.layers.7.norms.0.bias",
      "decode_head.transformer_decoder.layers.7.norms.1.weight",
      "decode_head.transformer_decoder.layers.7.norms.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.2.weight",
      "decode_head.transformer_decoder.layers.7.norms.2.bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.0.weight",
      "decode_head.transformer_decoder.layers.8.norms.0.bias",
      "decode_head.transformer_decoder.layers.8.norms.1.weight",
      "decode_head.transformer_decoder.layers.8.norms.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.2.weight",
      "decode_head.transformer_decoder.layers.8.norms.2.bias",
      "decode_head.transformer_decoder.post_norm.weight",
      "decode_head.transformer_decoder.post_norm.bias"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.0
  }
}
2023-08-29 00:43:48,306 - mmseg - INFO - Loaded 6861 images
2023-08-29 00:43:48,326 - mmseg - INFO - Start running, host: nemodrive@nemodrive0, work_dir: /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti
2023-08-29 00:43:48,326 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-08-29 00:43:48,326 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-08-29 00:43:48,327 - mmseg - INFO - Checkpoints will be saved to /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti by HardDiskBackend.
2023-08-29 00:44:24,260 - mmseg - INFO - Iter [50/160000]	lr: 5.497e-08, eta: 1 day, 7:54:53, time: 0.718, data_time: 0.008, memory: 6584, decode.loss_cls: 3.3624, decode.loss_mask: 3.5062, decode.loss_dice: 3.1488, decode.d0.loss_cls: 2.1382, decode.d0.loss_mask: 2.7102, decode.d0.loss_dice: 2.8116, decode.d1.loss_cls: 1.7243, decode.d1.loss_mask: 2.6879, decode.d1.loss_dice: 2.9181, decode.d2.loss_cls: 2.1899, decode.d2.loss_mask: 3.0437, decode.d2.loss_dice: 2.9344, decode.d3.loss_cls: 1.5201, decode.d3.loss_mask: 3.2854, decode.d3.loss_dice: 3.0736, decode.d4.loss_cls: 1.8177, decode.d4.loss_mask: 3.3621, decode.d4.loss_dice: 3.1218, decode.d5.loss_cls: 1.8304, decode.d5.loss_mask: 3.4405, decode.d5.loss_dice: 3.1394, decode.d6.loss_cls: 1.3795, decode.d6.loss_mask: 3.4683, decode.d6.loss_dice: 3.1238, decode.d7.loss_cls: 1.6882, decode.d7.loss_mask: 3.5854, decode.d7.loss_dice: 3.0156, decode.d8.loss_cls: 3.0594, decode.d8.loss_mask: 3.5311, decode.d8.loss_dice: 3.1003, loss: 83.7185, grad_norm: 267.2102
2023-08-29 00:45:00,701 - mmseg - INFO - Iter [100/160000]	lr: 1.110e-07, eta: 1 day, 8:08:25, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 1.8913, decode.loss_mask: 3.5440, decode.loss_dice: 3.0285, decode.d0.loss_cls: 2.2092, decode.d0.loss_mask: 2.3580, decode.d0.loss_dice: 2.6764, decode.d1.loss_cls: 1.4724, decode.d1.loss_mask: 2.1787, decode.d1.loss_dice: 2.7365, decode.d2.loss_cls: 1.7048, decode.d2.loss_mask: 2.6891, decode.d2.loss_dice: 2.7610, decode.d3.loss_cls: 1.2759, decode.d3.loss_mask: 3.0452, decode.d3.loss_dice: 2.9361, decode.d4.loss_cls: 1.3592, decode.d4.loss_mask: 3.1922, decode.d4.loss_dice: 2.9852, decode.d5.loss_cls: 1.3768, decode.d5.loss_mask: 3.3694, decode.d5.loss_dice: 3.0278, decode.d6.loss_cls: 1.1843, decode.d6.loss_mask: 3.4462, decode.d6.loss_dice: 3.0455, decode.d7.loss_cls: 1.2504, decode.d7.loss_mask: 3.6370, decode.d7.loss_dice: 2.9120, decode.d8.loss_cls: 1.7507, decode.d8.loss_mask: 3.5918, decode.d8.loss_dice: 2.9652, loss: 75.6008, grad_norm: 166.8499
2023-08-29 00:45:37,674 - mmseg - INFO - Iter [150/160000]	lr: 1.670e-07, eta: 1 day, 8:21:55, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 1.1696, decode.loss_mask: 3.4296, decode.loss_dice: 2.9861, decode.d0.loss_cls: 2.2569, decode.d0.loss_mask: 1.6874, decode.d0.loss_dice: 2.5820, decode.d1.loss_cls: 1.2932, decode.d1.loss_mask: 1.4193, decode.d1.loss_dice: 2.4827, decode.d2.loss_cls: 1.3183, decode.d2.loss_mask: 1.7049, decode.d2.loss_dice: 2.5171, decode.d3.loss_cls: 1.1460, decode.d3.loss_mask: 2.1394, decode.d3.loss_dice: 2.6424, decode.d4.loss_cls: 1.1886, decode.d4.loss_mask: 2.4819, decode.d4.loss_dice: 2.7105, decode.d5.loss_cls: 1.1784, decode.d5.loss_mask: 2.9506, decode.d5.loss_dice: 2.8823, decode.d6.loss_cls: 1.1621, decode.d6.loss_mask: 3.1824, decode.d6.loss_dice: 2.9564, decode.d7.loss_cls: 1.1538, decode.d7.loss_mask: 3.2985, decode.d7.loss_dice: 2.9518, decode.d8.loss_cls: 1.1677, decode.d8.loss_mask: 3.4206, decode.d8.loss_dice: 2.9588, loss: 66.4192, grad_norm: 132.3214
2023-08-29 00:46:14,598 - mmseg - INFO - Iter [200/160000]	lr: 2.230e-07, eta: 1 day, 8:27:40, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 1.1282, decode.loss_mask: 2.7364, decode.loss_dice: 2.7776, decode.d0.loss_cls: 2.2570, decode.d0.loss_mask: 1.3492, decode.d0.loss_dice: 2.3758, decode.d1.loss_cls: 1.1768, decode.d1.loss_mask: 1.2071, decode.d1.loss_dice: 2.3030, decode.d2.loss_cls: 1.1202, decode.d2.loss_mask: 1.2934, decode.d2.loss_dice: 2.2998, decode.d3.loss_cls: 1.1220, decode.d3.loss_mask: 1.3048, decode.d3.loss_dice: 2.3619, decode.d4.loss_cls: 1.1638, decode.d4.loss_mask: 1.4006, decode.d4.loss_dice: 2.3640, decode.d5.loss_cls: 1.1188, decode.d5.loss_mask: 1.8065, decode.d5.loss_dice: 2.3578, decode.d6.loss_cls: 1.1572, decode.d6.loss_mask: 2.0026, decode.d6.loss_dice: 2.5003, decode.d7.loss_cls: 1.1560, decode.d7.loss_mask: 2.1618, decode.d7.loss_dice: 2.5550, decode.d8.loss_cls: 1.1441, decode.d8.loss_mask: 2.4451, decode.d8.loss_dice: 2.6742, loss: 54.8210, grad_norm: 155.1630
2023-08-29 00:46:49,718 - mmseg - INFO - Iter [250/160000]	lr: 2.790e-07, eta: 1 day, 8:11:36, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 1.0201, decode.loss_mask: 1.5033, decode.loss_dice: 2.2189, decode.d0.loss_cls: 2.2560, decode.d0.loss_mask: 1.3715, decode.d0.loss_dice: 2.2341, decode.d1.loss_cls: 1.0350, decode.d1.loss_mask: 1.3760, decode.d1.loss_dice: 2.1861, decode.d2.loss_cls: 0.8292, decode.d2.loss_mask: 1.4371, decode.d2.loss_dice: 2.2242, decode.d3.loss_cls: 0.9157, decode.d3.loss_mask: 1.4298, decode.d3.loss_dice: 2.2448, decode.d4.loss_cls: 0.9567, decode.d4.loss_mask: 1.4765, decode.d4.loss_dice: 2.2387, decode.d5.loss_cls: 0.9479, decode.d5.loss_mask: 1.4835, decode.d5.loss_dice: 2.1833, decode.d6.loss_cls: 1.0406, decode.d6.loss_mask: 1.5038, decode.d6.loss_dice: 2.2244, decode.d7.loss_cls: 1.0058, decode.d7.loss_mask: 1.4504, decode.d7.loss_dice: 2.1975, decode.d8.loss_cls: 1.0259, decode.d8.loss_mask: 1.5090, decode.d8.loss_dice: 2.2446, loss: 47.7706, grad_norm: 118.8879
2023-08-29 00:47:25,995 - mmseg - INFO - Iter [300/160000]	lr: 3.349e-07, eta: 1 day, 8:11:05, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.6929, decode.loss_mask: 1.6051, decode.loss_dice: 2.1350, decode.d0.loss_cls: 2.2547, decode.d0.loss_mask: 1.5257, decode.d0.loss_dice: 2.1921, decode.d1.loss_cls: 0.8978, decode.d1.loss_mask: 1.5230, decode.d1.loss_dice: 2.1808, decode.d2.loss_cls: 0.5276, decode.d2.loss_mask: 1.5968, decode.d2.loss_dice: 2.1911, decode.d3.loss_cls: 0.4939, decode.d3.loss_mask: 1.5990, decode.d3.loss_dice: 2.1456, decode.d4.loss_cls: 0.4701, decode.d4.loss_mask: 1.6094, decode.d4.loss_dice: 2.1523, decode.d5.loss_cls: 0.4903, decode.d5.loss_mask: 1.6173, decode.d5.loss_dice: 2.1215, decode.d6.loss_cls: 0.6249, decode.d6.loss_mask: 1.6120, decode.d6.loss_dice: 2.1417, decode.d7.loss_cls: 0.5819, decode.d7.loss_mask: 1.6248, decode.d7.loss_dice: 2.1403, decode.d8.loss_cls: 0.6470, decode.d8.loss_mask: 1.6186, decode.d8.loss_dice: 2.1453, loss: 45.1584, grad_norm: 150.3455
2023-08-29 00:48:03,185 - mmseg - INFO - Iter [350/160000]	lr: 3.908e-07, eta: 1 day, 8:17:24, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.3615, decode.loss_mask: 1.6022, decode.loss_dice: 2.0789, decode.d0.loss_cls: 2.2536, decode.d0.loss_mask: 1.5703, decode.d0.loss_dice: 2.1710, decode.d1.loss_cls: 0.7973, decode.d1.loss_mask: 1.5600, decode.d1.loss_dice: 2.1597, decode.d2.loss_cls: 0.3211, decode.d2.loss_mask: 1.5906, decode.d2.loss_dice: 2.1409, decode.d3.loss_cls: 0.2395, decode.d3.loss_mask: 1.6151, decode.d3.loss_dice: 2.0704, decode.d4.loss_cls: 0.1824, decode.d4.loss_mask: 1.6019, decode.d4.loss_dice: 2.0956, decode.d5.loss_cls: 0.1947, decode.d5.loss_mask: 1.6155, decode.d5.loss_dice: 2.0629, decode.d6.loss_cls: 0.2647, decode.d6.loss_mask: 1.6094, decode.d6.loss_dice: 2.0681, decode.d7.loss_cls: 0.2663, decode.d7.loss_mask: 1.6022, decode.d7.loss_dice: 2.0771, decode.d8.loss_cls: 0.3119, decode.d8.loss_mask: 1.6209, decode.d8.loss_dice: 2.0637, loss: 42.1694, grad_norm: 205.5462
2023-08-29 00:48:40,584 - mmseg - INFO - Iter [400/160000]	lr: 4.466e-07, eta: 1 day, 8:23:23, time: 0.748, data_time: 0.048, memory: 6584, decode.loss_cls: 0.1997, decode.loss_mask: 1.5640, decode.loss_dice: 2.0225, decode.d0.loss_cls: 2.2508, decode.d0.loss_mask: 1.5548, decode.d0.loss_dice: 2.1220, decode.d1.loss_cls: 0.7128, decode.d1.loss_mask: 1.5478, decode.d1.loss_dice: 2.1042, decode.d2.loss_cls: 0.2331, decode.d2.loss_mask: 1.5476, decode.d2.loss_dice: 2.0679, decode.d3.loss_cls: 0.1512, decode.d3.loss_mask: 1.5764, decode.d3.loss_dice: 1.9992, decode.d4.loss_cls: 0.1054, decode.d4.loss_mask: 1.5534, decode.d4.loss_dice: 2.0243, decode.d5.loss_cls: 0.1100, decode.d5.loss_mask: 1.5568, decode.d5.loss_dice: 2.0044, decode.d6.loss_cls: 0.1431, decode.d6.loss_mask: 1.5586, decode.d6.loss_dice: 2.0036, decode.d7.loss_cls: 0.1614, decode.d7.loss_mask: 1.5725, decode.d7.loss_dice: 2.0118, decode.d8.loss_cls: 0.1779, decode.d8.loss_mask: 1.5822, decode.d8.loss_dice: 2.0021, loss: 40.2216, grad_norm: 242.6810
2023-08-29 00:49:15,593 - mmseg - INFO - Iter [450/160000]	lr: 5.024e-07, eta: 1 day, 8:13:50, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.1186, decode.loss_mask: 1.5578, decode.loss_dice: 1.9875, decode.d0.loss_cls: 2.2510, decode.d0.loss_mask: 1.5699, decode.d0.loss_dice: 2.0929, decode.d1.loss_cls: 0.6363, decode.d1.loss_mask: 1.5672, decode.d1.loss_dice: 2.0631, decode.d2.loss_cls: 0.1771, decode.d2.loss_mask: 1.5540, decode.d2.loss_dice: 2.0271, decode.d3.loss_cls: 0.1021, decode.d3.loss_mask: 1.5833, decode.d3.loss_dice: 1.9633, decode.d4.loss_cls: 0.0660, decode.d4.loss_mask: 1.5523, decode.d4.loss_dice: 1.9867, decode.d5.loss_cls: 0.0672, decode.d5.loss_mask: 1.5612, decode.d5.loss_dice: 1.9674, decode.d6.loss_cls: 0.0913, decode.d6.loss_mask: 1.5574, decode.d6.loss_dice: 1.9702, decode.d7.loss_cls: 0.1108, decode.d7.loss_mask: 1.5690, decode.d7.loss_dice: 1.9695, decode.d8.loss_cls: 0.1104, decode.d8.loss_mask: 1.5855, decode.d8.loss_dice: 1.9648, loss: 39.3808, grad_norm: 283.1897
2023-08-29 00:49:52,045 - mmseg - INFO - Iter [500/160000]	lr: 5.582e-07, eta: 1 day, 8:13:44, time: 0.729, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0744, decode.loss_mask: 1.5631, decode.loss_dice: 1.9257, decode.d0.loss_cls: 2.2496, decode.d0.loss_mask: 1.5902, decode.d0.loss_dice: 2.0581, decode.d1.loss_cls: 0.5622, decode.d1.loss_mask: 1.5700, decode.d1.loss_dice: 2.0085, decode.d2.loss_cls: 0.1465, decode.d2.loss_mask: 1.5500, decode.d2.loss_dice: 1.9696, decode.d3.loss_cls: 0.0795, decode.d3.loss_mask: 1.5751, decode.d3.loss_dice: 1.9175, decode.d4.loss_cls: 0.0493, decode.d4.loss_mask: 1.5512, decode.d4.loss_dice: 1.9413, decode.d5.loss_cls: 0.0506, decode.d5.loss_mask: 1.5566, decode.d5.loss_dice: 1.9202, decode.d6.loss_cls: 0.0711, decode.d6.loss_mask: 1.5649, decode.d6.loss_dice: 1.9211, decode.d7.loss_cls: 0.0845, decode.d7.loss_mask: 1.5556, decode.d7.loss_dice: 1.9233, decode.d8.loss_cls: 0.0752, decode.d8.loss_mask: 1.5625, decode.d8.loss_dice: 1.9037, loss: 38.5711, grad_norm: 293.0653
2023-08-29 00:50:29,249 - mmseg - INFO - Iter [550/160000]	lr: 6.140e-07, eta: 1 day, 8:17:05, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0573, decode.loss_mask: 1.5083, decode.loss_dice: 1.9414, decode.d0.loss_cls: 2.2482, decode.d0.loss_mask: 1.5250, decode.d0.loss_dice: 2.0718, decode.d1.loss_cls: 0.4930, decode.d1.loss_mask: 1.5318, decode.d1.loss_dice: 2.0075, decode.d2.loss_cls: 0.1278, decode.d2.loss_mask: 1.5063, decode.d2.loss_dice: 1.9802, decode.d3.loss_cls: 0.0669, decode.d3.loss_mask: 1.5205, decode.d3.loss_dice: 1.9439, decode.d4.loss_cls: 0.0413, decode.d4.loss_mask: 1.5010, decode.d4.loss_dice: 1.9462, decode.d5.loss_cls: 0.0415, decode.d5.loss_mask: 1.5042, decode.d5.loss_dice: 1.9360, decode.d6.loss_cls: 0.0617, decode.d6.loss_mask: 1.5014, decode.d6.loss_dice: 1.9433, decode.d7.loss_cls: 0.0743, decode.d7.loss_mask: 1.5088, decode.d7.loss_dice: 1.9325, decode.d8.loss_cls: 0.0606, decode.d8.loss_mask: 1.5241, decode.d8.loss_dice: 1.9204, loss: 38.0276, grad_norm: 340.0360
2023-08-29 00:51:06,497 - mmseg - INFO - Iter [600/160000]	lr: 6.697e-07, eta: 1 day, 8:20:03, time: 0.745, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0571, decode.loss_mask: 1.5100, decode.loss_dice: 1.8273, decode.d0.loss_cls: 2.2461, decode.d0.loss_mask: 1.5479, decode.d0.loss_dice: 1.9809, decode.d1.loss_cls: 0.4377, decode.d1.loss_mask: 1.5356, decode.d1.loss_dice: 1.8962, decode.d2.loss_cls: 0.1184, decode.d2.loss_mask: 1.5074, decode.d2.loss_dice: 1.8695, decode.d3.loss_cls: 0.0649, decode.d3.loss_mask: 1.5228, decode.d3.loss_dice: 1.8329, decode.d4.loss_cls: 0.0465, decode.d4.loss_mask: 1.4920, decode.d4.loss_dice: 1.8567, decode.d5.loss_cls: 0.0470, decode.d5.loss_mask: 1.4971, decode.d5.loss_dice: 1.8287, decode.d6.loss_cls: 0.0636, decode.d6.loss_mask: 1.5033, decode.d6.loss_dice: 1.8340, decode.d7.loss_cls: 0.0762, decode.d7.loss_mask: 1.5003, decode.d7.loss_dice: 1.8287, decode.d8.loss_cls: 0.0612, decode.d8.loss_mask: 1.5128, decode.d8.loss_dice: 1.8173, loss: 36.9201, grad_norm: 409.7767
2023-08-29 00:51:41,572 - mmseg - INFO - Iter [650/160000]	lr: 7.253e-07, eta: 1 day, 8:13:32, time: 0.701, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0414, decode.loss_mask: 1.5110, decode.loss_dice: 1.8079, decode.d0.loss_cls: 2.2452, decode.d0.loss_mask: 1.5480, decode.d0.loss_dice: 1.9614, decode.d1.loss_cls: 0.3853, decode.d1.loss_mask: 1.5171, decode.d1.loss_dice: 1.8560, decode.d2.loss_cls: 0.0999, decode.d2.loss_mask: 1.5101, decode.d2.loss_dice: 1.8347, decode.d3.loss_cls: 0.0516, decode.d3.loss_mask: 1.5205, decode.d3.loss_dice: 1.7992, decode.d4.loss_cls: 0.0335, decode.d4.loss_mask: 1.4921, decode.d4.loss_dice: 1.8157, decode.d5.loss_cls: 0.0345, decode.d5.loss_mask: 1.4990, decode.d5.loss_dice: 1.8010, decode.d6.loss_cls: 0.0517, decode.d6.loss_mask: 1.5146, decode.d6.loss_dice: 1.7926, decode.d7.loss_cls: 0.0623, decode.d7.loss_mask: 1.5115, decode.d7.loss_dice: 1.8018, decode.d8.loss_cls: 0.0459, decode.d8.loss_mask: 1.5206, decode.d8.loss_dice: 1.7888, loss: 36.4552, grad_norm: 423.3523
2023-08-29 00:52:17,799 - mmseg - INFO - Iter [700/160000]	lr: 7.810e-07, eta: 1 day, 8:12:17, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0356, decode.loss_mask: 1.4395, decode.loss_dice: 1.7563, decode.d0.loss_cls: 2.2441, decode.d0.loss_mask: 1.5074, decode.d0.loss_dice: 1.9265, decode.d1.loss_cls: 0.3468, decode.d1.loss_mask: 1.4581, decode.d1.loss_dice: 1.8200, decode.d2.loss_cls: 0.0896, decode.d2.loss_mask: 1.4485, decode.d2.loss_dice: 1.7913, decode.d3.loss_cls: 0.0440, decode.d3.loss_mask: 1.4571, decode.d3.loss_dice: 1.7594, decode.d4.loss_cls: 0.0279, decode.d4.loss_mask: 1.4317, decode.d4.loss_dice: 1.7619, decode.d5.loss_cls: 0.0287, decode.d5.loss_mask: 1.4414, decode.d5.loss_dice: 1.7488, decode.d6.loss_cls: 0.0462, decode.d6.loss_mask: 1.4382, decode.d6.loss_dice: 1.7498, decode.d7.loss_cls: 0.0568, decode.d7.loss_mask: 1.4364, decode.d7.loss_dice: 1.7525, decode.d8.loss_cls: 0.0416, decode.d8.loss_mask: 1.4434, decode.d8.loss_dice: 1.7433, loss: 35.2728, grad_norm: 439.8364
2023-08-29 00:52:54,662 - mmseg - INFO - Iter [750/160000]	lr: 8.366e-07, eta: 1 day, 8:13:22, time: 0.737, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0367, decode.loss_mask: 1.4916, decode.loss_dice: 1.7547, decode.d0.loss_cls: 2.2413, decode.d0.loss_mask: 1.5262, decode.d0.loss_dice: 1.9126, decode.d1.loss_cls: 0.3195, decode.d1.loss_mask: 1.4773, decode.d1.loss_dice: 1.7992, decode.d2.loss_cls: 0.0896, decode.d2.loss_mask: 1.5004, decode.d2.loss_dice: 1.7905, decode.d3.loss_cls: 0.0484, decode.d3.loss_mask: 1.5043, decode.d3.loss_dice: 1.7609, decode.d4.loss_cls: 0.0361, decode.d4.loss_mask: 1.4751, decode.d4.loss_dice: 1.7729, decode.d5.loss_cls: 0.0390, decode.d5.loss_mask: 1.4895, decode.d5.loss_dice: 1.7548, decode.d6.loss_cls: 0.0551, decode.d6.loss_mask: 1.4880, decode.d6.loss_dice: 1.7566, decode.d7.loss_cls: 0.0599, decode.d7.loss_mask: 1.4953, decode.d7.loss_dice: 1.7575, decode.d8.loss_cls: 0.0427, decode.d8.loss_mask: 1.4974, decode.d8.loss_dice: 1.7428, loss: 35.7157, grad_norm: 453.0170
2023-08-29 00:53:31,796 - mmseg - INFO - Iter [800/160000]	lr: 8.921e-07, eta: 1 day, 8:15:07, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0250, decode.loss_mask: 1.3941, decode.loss_dice: 1.7048, decode.d0.loss_cls: 2.2406, decode.d0.loss_mask: 1.4434, decode.d0.loss_dice: 1.8861, decode.d1.loss_cls: 0.2913, decode.d1.loss_mask: 1.3845, decode.d1.loss_dice: 1.7709, decode.d2.loss_cls: 0.0739, decode.d2.loss_mask: 1.4035, decode.d2.loss_dice: 1.7363, decode.d3.loss_cls: 0.0365, decode.d3.loss_mask: 1.4111, decode.d3.loss_dice: 1.7117, decode.d4.loss_cls: 0.0232, decode.d4.loss_mask: 1.3898, decode.d4.loss_dice: 1.7141, decode.d5.loss_cls: 0.0247, decode.d5.loss_mask: 1.4014, decode.d5.loss_dice: 1.6975, decode.d6.loss_cls: 0.0421, decode.d6.loss_mask: 1.3990, decode.d6.loss_dice: 1.6981, decode.d7.loss_cls: 0.0468, decode.d7.loss_mask: 1.4013, decode.d7.loss_dice: 1.7019, decode.d8.loss_cls: 0.0308, decode.d8.loss_mask: 1.4104, decode.d8.loss_dice: 1.6856, loss: 34.1804, grad_norm: 528.7576
2023-08-29 00:54:06,674 - mmseg - INFO - Iter [850/160000]	lr: 9.477e-07, eta: 1 day, 8:09:33, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0364, decode.loss_mask: 1.3675, decode.loss_dice: 1.6364, decode.d0.loss_cls: 2.2385, decode.d0.loss_mask: 1.4272, decode.d0.loss_dice: 1.8225, decode.d1.loss_cls: 0.2742, decode.d1.loss_mask: 1.3536, decode.d1.loss_dice: 1.6910, decode.d2.loss_cls: 0.0764, decode.d2.loss_mask: 1.3942, decode.d2.loss_dice: 1.6647, decode.d3.loss_cls: 0.0418, decode.d3.loss_mask: 1.3990, decode.d3.loss_dice: 1.6360, decode.d4.loss_cls: 0.0310, decode.d4.loss_mask: 1.3716, decode.d4.loss_dice: 1.6471, decode.d5.loss_cls: 0.0343, decode.d5.loss_mask: 1.3756, decode.d5.loss_dice: 1.6380, decode.d6.loss_cls: 0.0506, decode.d6.loss_mask: 1.3719, decode.d6.loss_dice: 1.6327, decode.d7.loss_cls: 0.0510, decode.d7.loss_mask: 1.3732, decode.d7.loss_dice: 1.6385, decode.d8.loss_cls: 0.0374, decode.d8.loss_mask: 1.3796, decode.d8.loss_dice: 1.6235, loss: 33.3156, grad_norm: 480.6355
2023-08-29 00:54:42,983 - mmseg - INFO - Iter [900/160000]	lr: 1.003e-06, eta: 1 day, 8:08:45, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0237, decode.loss_mask: 1.3871, decode.loss_dice: 1.6820, decode.d0.loss_cls: 2.2369, decode.d0.loss_mask: 1.4220, decode.d0.loss_dice: 1.8332, decode.d1.loss_cls: 0.2488, decode.d1.loss_mask: 1.3717, decode.d1.loss_dice: 1.7128, decode.d2.loss_cls: 0.0621, decode.d2.loss_mask: 1.4111, decode.d2.loss_dice: 1.7093, decode.d3.loss_cls: 0.0305, decode.d3.loss_mask: 1.4134, decode.d3.loss_dice: 1.6892, decode.d4.loss_cls: 0.0207, decode.d4.loss_mask: 1.3940, decode.d4.loss_dice: 1.6970, decode.d5.loss_cls: 0.0219, decode.d5.loss_mask: 1.3933, decode.d5.loss_dice: 1.6818, decode.d6.loss_cls: 0.0374, decode.d6.loss_mask: 1.3911, decode.d6.loss_dice: 1.6822, decode.d7.loss_cls: 0.0446, decode.d7.loss_mask: 1.3909, decode.d7.loss_dice: 1.6837, decode.d8.loss_cls: 0.0287, decode.d8.loss_mask: 1.3920, decode.d8.loss_dice: 1.6722, loss: 33.7651, grad_norm: 548.1057
2023-08-29 00:55:19,814 - mmseg - INFO - Iter [950/160000]	lr: 1.059e-06, eta: 1 day, 8:09:27, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0320, decode.loss_mask: 1.3709, decode.loss_dice: 1.6010, decode.d0.loss_cls: 2.2339, decode.d0.loss_mask: 1.4108, decode.d0.loss_dice: 1.7645, decode.d1.loss_cls: 0.2367, decode.d1.loss_mask: 1.3711, decode.d1.loss_dice: 1.6449, decode.d2.loss_cls: 0.0672, decode.d2.loss_mask: 1.3906, decode.d2.loss_dice: 1.6286, decode.d3.loss_cls: 0.0380, decode.d3.loss_mask: 1.3826, decode.d3.loss_dice: 1.6173, decode.d4.loss_cls: 0.0277, decode.d4.loss_mask: 1.3658, decode.d4.loss_dice: 1.6190, decode.d5.loss_cls: 0.0317, decode.d5.loss_mask: 1.3693, decode.d5.loss_dice: 1.6035, decode.d6.loss_cls: 0.0476, decode.d6.loss_mask: 1.3771, decode.d6.loss_dice: 1.6050, decode.d7.loss_cls: 0.0476, decode.d7.loss_mask: 1.3734, decode.d7.loss_dice: 1.6068, decode.d8.loss_cls: 0.0350, decode.d8.loss_mask: 1.3813, decode.d8.loss_dice: 1.5974, loss: 32.8783, grad_norm: 541.7596
2023-08-29 00:55:57,140 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-08-29 00:55:59,417 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 00:55:59,418 - mmseg - INFO - Iter [1000/160000]	lr: 1.114e-06, eta: 1 day, 8:17:21, time: 0.792, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0177, decode.loss_mask: 1.3184, decode.loss_dice: 1.5659, decode.d0.loss_cls: 2.2327, decode.d0.loss_mask: 1.3977, decode.d0.loss_dice: 1.7515, decode.d1.loss_cls: 0.2208, decode.d1.loss_mask: 1.3307, decode.d1.loss_dice: 1.6081, decode.d2.loss_cls: 0.0517, decode.d2.loss_mask: 1.3468, decode.d2.loss_dice: 1.6033, decode.d3.loss_cls: 0.0253, decode.d3.loss_mask: 1.3263, decode.d3.loss_dice: 1.5842, decode.d4.loss_cls: 0.0169, decode.d4.loss_mask: 1.3127, decode.d4.loss_dice: 1.5769, decode.d5.loss_cls: 0.0173, decode.d5.loss_mask: 1.3175, decode.d5.loss_dice: 1.5643, decode.d6.loss_cls: 0.0324, decode.d6.loss_mask: 1.3158, decode.d6.loss_dice: 1.5716, decode.d7.loss_cls: 0.0367, decode.d7.loss_mask: 1.3189, decode.d7.loss_dice: 1.5693, decode.d8.loss_cls: 0.0227, decode.d8.loss_mask: 1.3222, decode.d8.loss_dice: 1.5616, loss: 31.9379, grad_norm: 540.7440
2023-08-29 00:56:34,507 - mmseg - INFO - Iter [1050/160000]	lr: 1.169e-06, eta: 1 day, 8:13:02, time: 0.702, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0190, decode.loss_mask: 1.2854, decode.loss_dice: 1.5347, decode.d0.loss_cls: 2.2297, decode.d0.loss_mask: 1.3232, decode.d0.loss_dice: 1.7047, decode.d1.loss_cls: 0.2048, decode.d1.loss_mask: 1.2781, decode.d1.loss_dice: 1.5760, decode.d2.loss_cls: 0.0489, decode.d2.loss_mask: 1.2993, decode.d2.loss_dice: 1.5677, decode.d3.loss_cls: 0.0243, decode.d3.loss_mask: 1.2875, decode.d3.loss_dice: 1.5473, decode.d4.loss_cls: 0.0171, decode.d4.loss_mask: 1.2807, decode.d4.loss_dice: 1.5410, decode.d5.loss_cls: 0.0185, decode.d5.loss_mask: 1.2819, decode.d5.loss_dice: 1.5277, decode.d6.loss_cls: 0.0333, decode.d6.loss_mask: 1.2906, decode.d6.loss_dice: 1.5263, decode.d7.loss_cls: 0.0358, decode.d7.loss_mask: 1.3001, decode.d7.loss_dice: 1.5297, decode.d8.loss_cls: 0.0231, decode.d8.loss_mask: 1.2963, decode.d8.loss_dice: 1.5272, loss: 31.1599, grad_norm: 537.3472
2023-08-29 00:57:11,332 - mmseg - INFO - Iter [1100/160000]	lr: 1.225e-06, eta: 1 day, 8:13:14, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0177, decode.loss_mask: 1.2729, decode.loss_dice: 1.4377, decode.d0.loss_cls: 2.2271, decode.d0.loss_mask: 1.3128, decode.d0.loss_dice: 1.6248, decode.d1.loss_cls: 0.1917, decode.d1.loss_mask: 1.2733, decode.d1.loss_dice: 1.4931, decode.d2.loss_cls: 0.0468, decode.d2.loss_mask: 1.3016, decode.d2.loss_dice: 1.4681, decode.d3.loss_cls: 0.0234, decode.d3.loss_mask: 1.2837, decode.d3.loss_dice: 1.4431, decode.d4.loss_cls: 0.0166, decode.d4.loss_mask: 1.2756, decode.d4.loss_dice: 1.4392, decode.d5.loss_cls: 0.0173, decode.d5.loss_mask: 1.2800, decode.d5.loss_dice: 1.4366, decode.d6.loss_cls: 0.0317, decode.d6.loss_mask: 1.2857, decode.d6.loss_dice: 1.4307, decode.d7.loss_cls: 0.0343, decode.d7.loss_mask: 1.2845, decode.d7.loss_dice: 1.4429, decode.d8.loss_cls: 0.0221, decode.d8.loss_mask: 1.2791, decode.d8.loss_dice: 1.4371, loss: 30.1311, grad_norm: 634.1724
2023-08-29 00:57:48,165 - mmseg - INFO - Iter [1150/160000]	lr: 1.280e-06, eta: 1 day, 8:13:25, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0152, decode.loss_mask: 1.2601, decode.loss_dice: 1.4683, decode.d0.loss_cls: 2.2242, decode.d0.loss_mask: 1.3006, decode.d0.loss_dice: 1.6326, decode.d1.loss_cls: 0.1798, decode.d1.loss_mask: 1.2669, decode.d1.loss_dice: 1.5074, decode.d2.loss_cls: 0.0425, decode.d2.loss_mask: 1.2756, decode.d2.loss_dice: 1.5000, decode.d3.loss_cls: 0.0203, decode.d3.loss_mask: 1.2561, decode.d3.loss_dice: 1.4803, decode.d4.loss_cls: 0.0147, decode.d4.loss_mask: 1.2484, decode.d4.loss_dice: 1.4761, decode.d5.loss_cls: 0.0158, decode.d5.loss_mask: 1.2629, decode.d5.loss_dice: 1.4605, decode.d6.loss_cls: 0.0291, decode.d6.loss_mask: 1.2602, decode.d6.loss_dice: 1.4626, decode.d7.loss_cls: 0.0293, decode.d7.loss_mask: 1.2719, decode.d7.loss_dice: 1.4689, decode.d8.loss_cls: 0.0192, decode.d8.loss_mask: 1.2628, decode.d8.loss_dice: 1.4580, loss: 30.1703, grad_norm: 528.5198
2023-08-29 00:58:25,236 - mmseg - INFO - Iter [1200/160000]	lr: 1.335e-06, eta: 1 day, 8:14:02, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0175, decode.loss_mask: 1.2691, decode.loss_dice: 1.4977, decode.d0.loss_cls: 2.2208, decode.d0.loss_mask: 1.2865, decode.d0.loss_dice: 1.6462, decode.d1.loss_cls: 0.1667, decode.d1.loss_mask: 1.2632, decode.d1.loss_dice: 1.5371, decode.d2.loss_cls: 0.0396, decode.d2.loss_mask: 1.2727, decode.d2.loss_dice: 1.5224, decode.d3.loss_cls: 0.0197, decode.d3.loss_mask: 1.2676, decode.d3.loss_dice: 1.5019, decode.d4.loss_cls: 0.0144, decode.d4.loss_mask: 1.2659, decode.d4.loss_dice: 1.4907, decode.d5.loss_cls: 0.0153, decode.d5.loss_mask: 1.2741, decode.d5.loss_dice: 1.4913, decode.d6.loss_cls: 0.0276, decode.d6.loss_mask: 1.2787, decode.d6.loss_dice: 1.4948, decode.d7.loss_cls: 0.0320, decode.d7.loss_mask: 1.2763, decode.d7.loss_dice: 1.4949, decode.d8.loss_cls: 0.0209, decode.d8.loss_mask: 1.2763, decode.d8.loss_dice: 1.4938, loss: 30.4753, grad_norm: 588.8729
2023-08-29 00:59:00,290 - mmseg - INFO - Iter [1250/160000]	lr: 1.391e-06, eta: 1 day, 8:10:17, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0235, decode.loss_mask: 1.1833, decode.loss_dice: 1.4274, decode.d0.loss_cls: 2.2157, decode.d0.loss_mask: 1.2466, decode.d0.loss_dice: 1.6006, decode.d1.loss_cls: 0.1631, decode.d1.loss_mask: 1.1936, decode.d1.loss_dice: 1.4877, decode.d2.loss_cls: 0.0469, decode.d2.loss_mask: 1.1842, decode.d2.loss_dice: 1.4541, decode.d3.loss_cls: 0.0283, decode.d3.loss_mask: 1.1798, decode.d3.loss_dice: 1.4295, decode.d4.loss_cls: 0.0288, decode.d4.loss_mask: 1.1833, decode.d4.loss_dice: 1.4217, decode.d5.loss_cls: 0.0242, decode.d5.loss_mask: 1.1784, decode.d5.loss_dice: 1.4152, decode.d6.loss_cls: 0.0363, decode.d6.loss_mask: 1.1896, decode.d6.loss_dice: 1.4207, decode.d7.loss_cls: 0.0370, decode.d7.loss_mask: 1.1939, decode.d7.loss_dice: 1.4219, decode.d8.loss_cls: 0.0263, decode.d8.loss_mask: 1.1864, decode.d8.loss_dice: 1.4225, loss: 29.0504, grad_norm: 548.0428
2023-08-29 00:59:37,003 - mmseg - INFO - Iter [1300/160000]	lr: 1.446e-06, eta: 1 day, 8:10:08, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0248, decode.loss_mask: 1.1989, decode.loss_dice: 1.4200, decode.d0.loss_cls: 2.2108, decode.d0.loss_mask: 1.2412, decode.d0.loss_dice: 1.5903, decode.d1.loss_cls: 0.1561, decode.d1.loss_mask: 1.1977, decode.d1.loss_dice: 1.4737, decode.d2.loss_cls: 0.0456, decode.d2.loss_mask: 1.2039, decode.d2.loss_dice: 1.4402, decode.d3.loss_cls: 0.0294, decode.d3.loss_mask: 1.1876, decode.d3.loss_dice: 1.4257, decode.d4.loss_cls: 0.0257, decode.d4.loss_mask: 1.1948, decode.d4.loss_dice: 1.4159, decode.d5.loss_cls: 0.0261, decode.d5.loss_mask: 1.1987, decode.d5.loss_dice: 1.4155, decode.d6.loss_cls: 0.0367, decode.d6.loss_mask: 1.1989, decode.d6.loss_dice: 1.4212, decode.d7.loss_cls: 0.0374, decode.d7.loss_mask: 1.1952, decode.d7.loss_dice: 1.4290, decode.d8.loss_cls: 0.0274, decode.d8.loss_mask: 1.2005, decode.d8.loss_dice: 1.4201, loss: 29.0889, grad_norm: 637.8372
2023-08-29 01:00:13,278 - mmseg - INFO - Iter [1350/160000]	lr: 1.501e-06, eta: 1 day, 8:09:08, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0211, decode.loss_mask: 1.2406, decode.loss_dice: 1.4259, decode.d0.loss_cls: 2.2098, decode.d0.loss_mask: 1.2768, decode.d0.loss_dice: 1.5779, decode.d1.loss_cls: 0.1309, decode.d1.loss_mask: 1.2437, decode.d1.loss_dice: 1.4920, decode.d2.loss_cls: 0.0329, decode.d2.loss_mask: 1.2347, decode.d2.loss_dice: 1.4340, decode.d3.loss_cls: 0.0182, decode.d3.loss_mask: 1.2283, decode.d3.loss_dice: 1.4213, decode.d4.loss_cls: 0.0141, decode.d4.loss_mask: 1.2227, decode.d4.loss_dice: 1.4178, decode.d5.loss_cls: 0.0168, decode.d5.loss_mask: 1.2239, decode.d5.loss_dice: 1.4216, decode.d6.loss_cls: 0.0288, decode.d6.loss_mask: 1.2327, decode.d6.loss_dice: 1.4219, decode.d7.loss_cls: 0.0336, decode.d7.loss_mask: 1.2513, decode.d7.loss_dice: 1.4181, decode.d8.loss_cls: 0.0250, decode.d8.loss_mask: 1.2337, decode.d8.loss_dice: 1.4250, loss: 29.3754, grad_norm: 579.9183
2023-08-29 01:00:50,375 - mmseg - INFO - Iter [1400/160000]	lr: 1.556e-06, eta: 1 day, 8:09:41, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0130, decode.loss_mask: 1.2184, decode.loss_dice: 1.4201, decode.d0.loss_cls: 2.2037, decode.d0.loss_mask: 1.2418, decode.d0.loss_dice: 1.5488, decode.d1.loss_cls: 0.1150, decode.d1.loss_mask: 1.2051, decode.d1.loss_dice: 1.4822, decode.d2.loss_cls: 0.0309, decode.d2.loss_mask: 1.2046, decode.d2.loss_dice: 1.4240, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 1.2056, decode.d3.loss_dice: 1.4153, decode.d4.loss_cls: 0.0127, decode.d4.loss_mask: 1.2157, decode.d4.loss_dice: 1.4112, decode.d5.loss_cls: 0.0139, decode.d5.loss_mask: 1.2143, decode.d5.loss_dice: 1.4140, decode.d6.loss_cls: 0.0250, decode.d6.loss_mask: 1.2128, decode.d6.loss_dice: 1.4007, decode.d7.loss_cls: 0.0261, decode.d7.loss_mask: 1.2127, decode.d7.loss_dice: 1.4171, decode.d8.loss_cls: 0.0160, decode.d8.loss_mask: 1.2172, decode.d8.loss_dice: 1.4134, loss: 28.9690, grad_norm: 651.9173
2023-08-29 01:01:25,459 - mmseg - INFO - Iter [1450/160000]	lr: 1.611e-06, eta: 1 day, 8:06:29, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0261, decode.loss_mask: 1.1694, decode.loss_dice: 1.3878, decode.d0.loss_cls: 2.1992, decode.d0.loss_mask: 1.2219, decode.d0.loss_dice: 1.5398, decode.d1.loss_cls: 0.1107, decode.d1.loss_mask: 1.1921, decode.d1.loss_dice: 1.4520, decode.d2.loss_cls: 0.0434, decode.d2.loss_mask: 1.1767, decode.d2.loss_dice: 1.3973, decode.d3.loss_cls: 0.0319, decode.d3.loss_mask: 1.1679, decode.d3.loss_dice: 1.3860, decode.d4.loss_cls: 0.0287, decode.d4.loss_mask: 1.1629, decode.d4.loss_dice: 1.3886, decode.d5.loss_cls: 0.0276, decode.d5.loss_mask: 1.1699, decode.d5.loss_dice: 1.3792, decode.d6.loss_cls: 0.0386, decode.d6.loss_mask: 1.1678, decode.d6.loss_dice: 1.3854, decode.d7.loss_cls: 0.0352, decode.d7.loss_mask: 1.1670, decode.d7.loss_dice: 1.3821, decode.d8.loss_cls: 0.0235, decode.d8.loss_mask: 1.1727, decode.d8.loss_dice: 1.3925, loss: 28.4240, grad_norm: 519.8385
2023-08-29 01:02:02,321 - mmseg - INFO - Iter [1500/160000]	lr: 1.666e-06, eta: 1 day, 8:06:36, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0125, decode.loss_mask: 1.1989, decode.loss_dice: 1.3265, decode.d0.loss_cls: 2.1941, decode.d0.loss_mask: 1.2130, decode.d0.loss_dice: 1.4839, decode.d1.loss_cls: 0.0880, decode.d1.loss_mask: 1.1971, decode.d1.loss_dice: 1.3894, decode.d2.loss_cls: 0.0283, decode.d2.loss_mask: 1.1781, decode.d2.loss_dice: 1.3348, decode.d3.loss_cls: 0.0172, decode.d3.loss_mask: 1.1808, decode.d3.loss_dice: 1.3149, decode.d4.loss_cls: 0.0122, decode.d4.loss_mask: 1.1882, decode.d4.loss_dice: 1.3119, decode.d5.loss_cls: 0.0125, decode.d5.loss_mask: 1.1923, decode.d5.loss_dice: 1.3084, decode.d6.loss_cls: 0.0226, decode.d6.loss_mask: 1.1896, decode.d6.loss_dice: 1.3173, decode.d7.loss_cls: 0.0253, decode.d7.loss_mask: 1.1956, decode.d7.loss_dice: 1.3239, decode.d8.loss_cls: 0.0154, decode.d8.loss_mask: 1.1932, decode.d8.loss_dice: 1.3210, loss: 27.7869, grad_norm: 553.1803
2023-08-29 01:02:38,854 - mmseg - INFO - Iter [1550/160000]	lr: 1.667e-06, eta: 1 day, 8:06:06, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0228, decode.loss_mask: 1.1146, decode.loss_dice: 1.3009, decode.d0.loss_cls: 2.1904, decode.d0.loss_mask: 1.1786, decode.d0.loss_dice: 1.4560, decode.d1.loss_cls: 0.0879, decode.d1.loss_mask: 1.1536, decode.d1.loss_dice: 1.3560, decode.d2.loss_cls: 0.0346, decode.d2.loss_mask: 1.1276, decode.d2.loss_dice: 1.3073, decode.d3.loss_cls: 0.0257, decode.d3.loss_mask: 1.1125, decode.d3.loss_dice: 1.2945, decode.d4.loss_cls: 0.0220, decode.d4.loss_mask: 1.1173, decode.d4.loss_dice: 1.2951, decode.d5.loss_cls: 0.0224, decode.d5.loss_mask: 1.1138, decode.d5.loss_dice: 1.2926, decode.d6.loss_cls: 0.0333, decode.d6.loss_mask: 1.1148, decode.d6.loss_dice: 1.2976, decode.d7.loss_cls: 0.0321, decode.d7.loss_mask: 1.1181, decode.d7.loss_dice: 1.3029, decode.d8.loss_cls: 0.0244, decode.d8.loss_mask: 1.1075, decode.d8.loss_dice: 1.3065, loss: 26.9637, grad_norm: 621.0432
2023-08-29 01:03:15,736 - mmseg - INFO - Iter [1600/160000]	lr: 1.666e-06, eta: 1 day, 8:06:11, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0337, decode.loss_mask: 1.1172, decode.loss_dice: 1.2296, decode.d0.loss_cls: 2.1866, decode.d0.loss_mask: 1.1593, decode.d0.loss_dice: 1.3805, decode.d1.loss_cls: 0.0835, decode.d1.loss_mask: 1.1268, decode.d1.loss_dice: 1.2780, decode.d2.loss_cls: 0.0421, decode.d2.loss_mask: 1.1146, decode.d2.loss_dice: 1.2393, decode.d3.loss_cls: 0.0320, decode.d3.loss_mask: 1.1250, decode.d3.loss_dice: 1.2220, decode.d4.loss_cls: 0.0341, decode.d4.loss_mask: 1.1190, decode.d4.loss_dice: 1.2192, decode.d5.loss_cls: 0.0328, decode.d5.loss_mask: 1.1183, decode.d5.loss_dice: 1.2252, decode.d6.loss_cls: 0.0415, decode.d6.loss_mask: 1.1108, decode.d6.loss_dice: 1.2316, decode.d7.loss_cls: 0.0356, decode.d7.loss_mask: 1.1193, decode.d7.loss_dice: 1.2378, decode.d8.loss_cls: 0.0293, decode.d8.loss_mask: 1.1162, decode.d8.loss_dice: 1.2379, loss: 26.2790, grad_norm: 507.5729
2023-08-29 01:03:50,752 - mmseg - INFO - Iter [1650/160000]	lr: 1.666e-06, eta: 1 day, 8:03:14, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0294, decode.loss_mask: 1.0638, decode.loss_dice: 1.1685, decode.d0.loss_cls: 2.1822, decode.d0.loss_mask: 1.0986, decode.d0.loss_dice: 1.3440, decode.d1.loss_cls: 0.0784, decode.d1.loss_mask: 1.0515, decode.d1.loss_dice: 1.2257, decode.d2.loss_cls: 0.0344, decode.d2.loss_mask: 1.0463, decode.d2.loss_dice: 1.1826, decode.d3.loss_cls: 0.0254, decode.d3.loss_mask: 1.0602, decode.d3.loss_dice: 1.1661, decode.d4.loss_cls: 0.0260, decode.d4.loss_mask: 1.0573, decode.d4.loss_dice: 1.1650, decode.d5.loss_cls: 0.0277, decode.d5.loss_mask: 1.0611, decode.d5.loss_dice: 1.1569, decode.d6.loss_cls: 0.0352, decode.d6.loss_mask: 1.0664, decode.d6.loss_dice: 1.1618, decode.d7.loss_cls: 0.0359, decode.d7.loss_mask: 1.0742, decode.d7.loss_dice: 1.1725, decode.d8.loss_cls: 0.0310, decode.d8.loss_mask: 1.0655, decode.d8.loss_dice: 1.1638, loss: 25.0577, grad_norm: 538.7545
2023-08-29 01:04:27,753 - mmseg - INFO - Iter [1700/160000]	lr: 1.665e-06, eta: 1 day, 8:03:30, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0115, decode.loss_mask: 1.0904, decode.loss_dice: 1.2444, decode.d0.loss_cls: 2.1765, decode.d0.loss_mask: 1.0965, decode.d0.loss_dice: 1.3781, decode.d1.loss_cls: 0.0641, decode.d1.loss_mask: 1.0732, decode.d1.loss_dice: 1.2709, decode.d2.loss_cls: 0.0212, decode.d2.loss_mask: 1.0878, decode.d2.loss_dice: 1.2472, decode.d3.loss_cls: 0.0132, decode.d3.loss_mask: 1.0916, decode.d3.loss_dice: 1.2432, decode.d4.loss_cls: 0.0102, decode.d4.loss_mask: 1.0772, decode.d4.loss_dice: 1.2449, decode.d5.loss_cls: 0.0112, decode.d5.loss_mask: 1.0795, decode.d5.loss_dice: 1.2375, decode.d6.loss_cls: 0.0198, decode.d6.loss_mask: 1.0710, decode.d6.loss_dice: 1.2512, decode.d7.loss_cls: 0.0183, decode.d7.loss_mask: 1.0753, decode.d7.loss_dice: 1.2486, decode.d8.loss_cls: 0.0126, decode.d8.loss_mask: 1.0816, decode.d8.loss_dice: 1.2496, loss: 25.7985, grad_norm: 553.1660
2023-08-29 01:05:04,783 - mmseg - INFO - Iter [1750/160000]	lr: 1.665e-06, eta: 1 day, 8:03:46, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0228, decode.loss_mask: 1.0634, decode.loss_dice: 1.2156, decode.d0.loss_cls: 2.1735, decode.d0.loss_mask: 1.1097, decode.d0.loss_dice: 1.3543, decode.d1.loss_cls: 0.0659, decode.d1.loss_mask: 1.0743, decode.d1.loss_dice: 1.2428, decode.d2.loss_cls: 0.0312, decode.d2.loss_mask: 1.0707, decode.d2.loss_dice: 1.2176, decode.d3.loss_cls: 0.0254, decode.d3.loss_mask: 1.0663, decode.d3.loss_dice: 1.2134, decode.d4.loss_cls: 0.0223, decode.d4.loss_mask: 1.0638, decode.d4.loss_dice: 1.2098, decode.d5.loss_cls: 0.0238, decode.d5.loss_mask: 1.0696, decode.d5.loss_dice: 1.2103, decode.d6.loss_cls: 0.0314, decode.d6.loss_mask: 1.0561, decode.d6.loss_dice: 1.2175, decode.d7.loss_cls: 0.0287, decode.d7.loss_mask: 1.0709, decode.d7.loss_dice: 1.2202, decode.d8.loss_cls: 0.0243, decode.d8.loss_mask: 1.0711, decode.d8.loss_dice: 1.2248, loss: 25.4917, grad_norm: 507.2010
2023-08-29 01:05:41,497 - mmseg - INFO - Iter [1800/160000]	lr: 1.664e-06, eta: 1 day, 8:03:30, time: 0.734, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0073, decode.loss_mask: 1.1077, decode.loss_dice: 1.2278, decode.d0.loss_cls: 2.1657, decode.d0.loss_mask: 1.1644, decode.d0.loss_dice: 1.3686, decode.d1.loss_cls: 0.0522, decode.d1.loss_mask: 1.1024, decode.d1.loss_dice: 1.2782, decode.d2.loss_cls: 0.0190, decode.d2.loss_mask: 1.0907, decode.d2.loss_dice: 1.2431, decode.d3.loss_cls: 0.0116, decode.d3.loss_mask: 1.0982, decode.d3.loss_dice: 1.2274, decode.d4.loss_cls: 0.0088, decode.d4.loss_mask: 1.0954, decode.d4.loss_dice: 1.2305, decode.d5.loss_cls: 0.0090, decode.d5.loss_mask: 1.0953, decode.d5.loss_dice: 1.2233, decode.d6.loss_cls: 0.0155, decode.d6.loss_mask: 1.0956, decode.d6.loss_dice: 1.2261, decode.d7.loss_cls: 0.0149, decode.d7.loss_mask: 1.1066, decode.d7.loss_dice: 1.2273, decode.d8.loss_cls: 0.0090, decode.d8.loss_mask: 1.1067, decode.d8.loss_dice: 1.2312, loss: 25.8595, grad_norm: 669.8828
2023-08-29 01:06:18,771 - mmseg - INFO - Iter [1850/160000]	lr: 1.664e-06, eta: 1 day, 8:04:03, time: 0.746, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0086, decode.loss_mask: 1.0595, decode.loss_dice: 1.2128, decode.d0.loss_cls: 2.1608, decode.d0.loss_mask: 1.1280, decode.d0.loss_dice: 1.3434, decode.d1.loss_cls: 0.0496, decode.d1.loss_mask: 1.0398, decode.d1.loss_dice: 1.2345, decode.d2.loss_cls: 0.0183, decode.d2.loss_mask: 1.0416, decode.d2.loss_dice: 1.2043, decode.d3.loss_cls: 0.0109, decode.d3.loss_mask: 1.0511, decode.d3.loss_dice: 1.2006, decode.d4.loss_cls: 0.0088, decode.d4.loss_mask: 1.0469, decode.d4.loss_dice: 1.2065, decode.d5.loss_cls: 0.0096, decode.d5.loss_mask: 1.0498, decode.d5.loss_dice: 1.2038, decode.d6.loss_cls: 0.0148, decode.d6.loss_mask: 1.0463, decode.d6.loss_dice: 1.2079, decode.d7.loss_cls: 0.0136, decode.d7.loss_mask: 1.0607, decode.d7.loss_dice: 1.2122, decode.d8.loss_cls: 0.0089, decode.d8.loss_mask: 1.0666, decode.d8.loss_dice: 1.2135, loss: 25.1337, grad_norm: 583.3179
2023-08-29 01:06:53,575 - mmseg - INFO - Iter [1900/160000]	lr: 1.663e-06, eta: 1 day, 8:01:05, time: 0.696, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0077, decode.loss_mask: 1.1089, decode.loss_dice: 1.2515, decode.d0.loss_cls: 2.1489, decode.d0.loss_mask: 1.1550, decode.d0.loss_dice: 1.3463, decode.d1.loss_cls: 0.0480, decode.d1.loss_mask: 1.0928, decode.d1.loss_dice: 1.2826, decode.d2.loss_cls: 0.0168, decode.d2.loss_mask: 1.1166, decode.d2.loss_dice: 1.2522, decode.d3.loss_cls: 0.0100, decode.d3.loss_mask: 1.1269, decode.d3.loss_dice: 1.2421, decode.d4.loss_cls: 0.0083, decode.d4.loss_mask: 1.1223, decode.d4.loss_dice: 1.2512, decode.d5.loss_cls: 0.0082, decode.d5.loss_mask: 1.1209, decode.d5.loss_dice: 1.2426, decode.d6.loss_cls: 0.0146, decode.d6.loss_mask: 1.1123, decode.d6.loss_dice: 1.2519, decode.d7.loss_cls: 0.0143, decode.d7.loss_mask: 1.1168, decode.d7.loss_dice: 1.2481, decode.d8.loss_cls: 0.0089, decode.d8.loss_mask: 1.1143, decode.d8.loss_dice: 1.2488, loss: 26.0898, grad_norm: 674.2449
2023-08-29 01:07:29,902 - mmseg - INFO - Iter [1950/160000]	lr: 1.663e-06, eta: 1 day, 8:00:18, time: 0.727, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0071, decode.loss_mask: 1.0403, decode.loss_dice: 1.2290, decode.d0.loss_cls: 2.1442, decode.d0.loss_mask: 1.0822, decode.d0.loss_dice: 1.3393, decode.d1.loss_cls: 0.0448, decode.d1.loss_mask: 1.0303, decode.d1.loss_dice: 1.2541, decode.d2.loss_cls: 0.0167, decode.d2.loss_mask: 1.0298, decode.d2.loss_dice: 1.2254, decode.d3.loss_cls: 0.0101, decode.d3.loss_mask: 1.0254, decode.d3.loss_dice: 1.2153, decode.d4.loss_cls: 0.0084, decode.d4.loss_mask: 1.0251, decode.d4.loss_dice: 1.2217, decode.d5.loss_cls: 0.0083, decode.d5.loss_mask: 1.0270, decode.d5.loss_dice: 1.2248, decode.d6.loss_cls: 0.0140, decode.d6.loss_mask: 1.0258, decode.d6.loss_dice: 1.2199, decode.d7.loss_cls: 0.0124, decode.d7.loss_mask: 1.0389, decode.d7.loss_dice: 1.2253, decode.d8.loss_cls: 0.0081, decode.d8.loss_mask: 1.0375, decode.d8.loss_dice: 1.2254, loss: 25.0165, grad_norm: 513.0130
2023-08-29 01:08:06,862 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-08-29 01:08:09,245 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 01:08:09,245 - mmseg - INFO - Iter [2000/160000]	lr: 1.662e-06, eta: 1 day, 8:03:31, time: 0.787, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0072, decode.loss_mask: 1.0385, decode.loss_dice: 1.1629, decode.d0.loss_cls: 2.1397, decode.d0.loss_mask: 1.0801, decode.d0.loss_dice: 1.2833, decode.d1.loss_cls: 0.0409, decode.d1.loss_mask: 1.0319, decode.d1.loss_dice: 1.1968, decode.d2.loss_cls: 0.0159, decode.d2.loss_mask: 1.0372, decode.d2.loss_dice: 1.1713, decode.d3.loss_cls: 0.0095, decode.d3.loss_mask: 1.0404, decode.d3.loss_dice: 1.1676, decode.d4.loss_cls: 0.0076, decode.d4.loss_mask: 1.0336, decode.d4.loss_dice: 1.1623, decode.d5.loss_cls: 0.0078, decode.d5.loss_mask: 1.0467, decode.d5.loss_dice: 1.1588, decode.d6.loss_cls: 0.0128, decode.d6.loss_mask: 1.0277, decode.d6.loss_dice: 1.1599, decode.d7.loss_cls: 0.0115, decode.d7.loss_mask: 1.0365, decode.d7.loss_dice: 1.1703, decode.d8.loss_cls: 0.0076, decode.d8.loss_mask: 1.0351, decode.d8.loss_dice: 1.1640, loss: 24.4654, grad_norm: 627.6790
2023-08-29 01:08:46,501 - mmseg - INFO - Iter [2050/160000]	lr: 1.662e-06, eta: 1 day, 8:03:50, time: 0.745, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0071, decode.loss_mask: 0.9624, decode.loss_dice: 1.1030, decode.d0.loss_cls: 2.1338, decode.d0.loss_mask: 1.0144, decode.d0.loss_dice: 1.2409, decode.d1.loss_cls: 0.0390, decode.d1.loss_mask: 0.9563, decode.d1.loss_dice: 1.1259, decode.d2.loss_cls: 0.0156, decode.d2.loss_mask: 0.9543, decode.d2.loss_dice: 1.1087, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 0.9526, decode.d3.loss_dice: 1.1025, decode.d4.loss_cls: 0.0075, decode.d4.loss_mask: 0.9507, decode.d4.loss_dice: 1.1021, decode.d5.loss_cls: 0.0079, decode.d5.loss_mask: 0.9531, decode.d5.loss_dice: 1.0958, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 0.9433, decode.d6.loss_dice: 1.1016, decode.d7.loss_cls: 0.0120, decode.d7.loss_mask: 0.9551, decode.d7.loss_dice: 1.1047, decode.d8.loss_cls: 0.0079, decode.d8.loss_mask: 0.9547, decode.d8.loss_dice: 1.1013, loss: 23.0365, grad_norm: 531.7264
2023-08-29 01:09:21,643 - mmseg - INFO - Iter [2100/160000]	lr: 1.661e-06, eta: 1 day, 8:01:29, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0078, decode.loss_mask: 0.9019, decode.loss_dice: 1.0500, decode.d0.loss_cls: 2.1298, decode.d0.loss_mask: 0.9616, decode.d0.loss_dice: 1.1881, decode.d1.loss_cls: 0.0374, decode.d1.loss_mask: 0.9002, decode.d1.loss_dice: 1.0840, decode.d2.loss_cls: 0.0152, decode.d2.loss_mask: 0.8993, decode.d2.loss_dice: 1.0600, decode.d3.loss_cls: 0.0090, decode.d3.loss_mask: 0.9009, decode.d3.loss_dice: 1.0475, decode.d4.loss_cls: 0.0072, decode.d4.loss_mask: 0.8932, decode.d4.loss_dice: 1.0555, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.9023, decode.d5.loss_dice: 1.0518, decode.d6.loss_cls: 0.0120, decode.d6.loss_mask: 0.9030, decode.d6.loss_dice: 1.0588, decode.d7.loss_cls: 0.0126, decode.d7.loss_mask: 0.9059, decode.d7.loss_dice: 1.0612, decode.d8.loss_cls: 0.0080, decode.d8.loss_mask: 0.9045, decode.d8.loss_dice: 1.0572, loss: 22.0330, grad_norm: 574.9415
2023-08-29 01:09:58,148 - mmseg - INFO - Iter [2150/160000]	lr: 1.661e-06, eta: 1 day, 8:00:52, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0057, decode.loss_mask: 0.9769, decode.loss_dice: 1.1062, decode.d0.loss_cls: 2.1215, decode.d0.loss_mask: 0.9926, decode.d0.loss_dice: 1.2169, decode.d1.loss_cls: 0.0359, decode.d1.loss_mask: 0.9759, decode.d1.loss_dice: 1.1183, decode.d2.loss_cls: 0.0149, decode.d2.loss_mask: 0.9772, decode.d2.loss_dice: 1.0965, decode.d3.loss_cls: 0.0083, decode.d3.loss_mask: 0.9771, decode.d3.loss_dice: 1.0909, decode.d4.loss_cls: 0.0067, decode.d4.loss_mask: 0.9740, decode.d4.loss_dice: 1.0964, decode.d5.loss_cls: 0.0069, decode.d5.loss_mask: 0.9670, decode.d5.loss_dice: 1.0952, decode.d6.loss_cls: 0.0119, decode.d6.loss_mask: 0.9688, decode.d6.loss_dice: 1.0918, decode.d7.loss_cls: 0.0097, decode.d7.loss_mask: 0.9614, decode.d7.loss_dice: 1.0965, decode.d8.loss_cls: 0.0062, decode.d8.loss_mask: 0.9742, decode.d8.loss_dice: 1.1068, loss: 23.0885, grad_norm: 570.1039
2023-08-29 01:10:35,372 - mmseg - INFO - Iter [2200/160000]	lr: 1.660e-06, eta: 1 day, 8:01:07, time: 0.745, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0067, decode.loss_mask: 0.8925, decode.loss_dice: 1.0077, decode.d0.loss_cls: 2.1145, decode.d0.loss_mask: 0.9647, decode.d0.loss_dice: 1.1578, decode.d1.loss_cls: 0.0353, decode.d1.loss_mask: 0.9034, decode.d1.loss_dice: 1.0341, decode.d2.loss_cls: 0.0152, decode.d2.loss_mask: 0.9033, decode.d2.loss_dice: 1.0151, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.8997, decode.d3.loss_dice: 1.0062, decode.d4.loss_cls: 0.0076, decode.d4.loss_mask: 0.8970, decode.d4.loss_dice: 1.0058, decode.d5.loss_cls: 0.0076, decode.d5.loss_mask: 0.9007, decode.d5.loss_dice: 1.0015, decode.d6.loss_cls: 0.0122, decode.d6.loss_mask: 0.9003, decode.d6.loss_dice: 1.0103, decode.d7.loss_cls: 0.0106, decode.d7.loss_mask: 0.8925, decode.d7.loss_dice: 1.0093, decode.d8.loss_cls: 0.0069, decode.d8.loss_mask: 0.8974, decode.d8.loss_dice: 1.0017, loss: 21.5266, grad_norm: 531.2040
2023-08-29 01:11:12,509 - mmseg - INFO - Iter [2250/160000]	lr: 1.660e-06, eta: 1 day, 8:01:13, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0062, decode.loss_mask: 0.9836, decode.loss_dice: 1.0503, decode.d0.loss_cls: 2.1108, decode.d0.loss_mask: 1.0335, decode.d0.loss_dice: 1.1629, decode.d1.loss_cls: 0.0341, decode.d1.loss_mask: 0.9974, decode.d1.loss_dice: 1.0686, decode.d2.loss_cls: 0.0146, decode.d2.loss_mask: 0.9951, decode.d2.loss_dice: 1.0559, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.9857, decode.d3.loss_dice: 1.0574, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.9881, decode.d4.loss_dice: 1.0497, decode.d5.loss_cls: 0.0076, decode.d5.loss_mask: 0.9901, decode.d5.loss_dice: 1.0521, decode.d6.loss_cls: 0.0114, decode.d6.loss_mask: 0.9889, decode.d6.loss_dice: 1.0503, decode.d7.loss_cls: 0.0101, decode.d7.loss_mask: 0.9882, decode.d7.loss_dice: 1.0444, decode.d8.loss_cls: 0.0068, decode.d8.loss_mask: 0.9820, decode.d8.loss_dice: 1.0529, loss: 22.7954, grad_norm: 577.7955
2023-08-29 01:11:47,207 - mmseg - INFO - Iter [2300/160000]	lr: 1.659e-06, eta: 1 day, 7:58:30, time: 0.694, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0194, decode.loss_mask: 1.0072, decode.loss_dice: 1.1635, decode.d0.loss_cls: 2.0896, decode.d0.loss_mask: 1.0165, decode.d0.loss_dice: 1.2598, decode.d1.loss_cls: 0.0382, decode.d1.loss_mask: 1.0162, decode.d1.loss_dice: 1.1764, decode.d2.loss_cls: 0.0325, decode.d2.loss_mask: 1.0201, decode.d2.loss_dice: 1.1658, decode.d3.loss_cls: 0.0192, decode.d3.loss_mask: 1.0208, decode.d3.loss_dice: 1.1644, decode.d4.loss_cls: 0.0204, decode.d4.loss_mask: 1.0051, decode.d4.loss_dice: 1.1664, decode.d5.loss_cls: 0.0194, decode.d5.loss_mask: 1.0057, decode.d5.loss_dice: 1.1651, decode.d6.loss_cls: 0.0241, decode.d6.loss_mask: 1.0061, decode.d6.loss_dice: 1.1695, decode.d7.loss_cls: 0.0202, decode.d7.loss_mask: 1.0122, decode.d7.loss_dice: 1.1662, decode.d8.loss_cls: 0.0204, decode.d8.loss_mask: 1.0111, decode.d8.loss_dice: 1.1733, loss: 24.1947, grad_norm: 575.7261
2023-08-29 01:12:23,614 - mmseg - INFO - Iter [2350/160000]	lr: 1.659e-06, eta: 1 day, 7:57:48, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.9213, decode.loss_dice: 0.9906, decode.d0.loss_cls: 2.0890, decode.d0.loss_mask: 0.9647, decode.d0.loss_dice: 1.1288, decode.d1.loss_cls: 0.0295, decode.d1.loss_mask: 0.9253, decode.d1.loss_dice: 1.0331, decode.d2.loss_cls: 0.0130, decode.d2.loss_mask: 0.9225, decode.d2.loss_dice: 1.0022, decode.d3.loss_cls: 0.0072, decode.d3.loss_mask: 0.9244, decode.d3.loss_dice: 0.9943, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.9277, decode.d4.loss_dice: 0.9878, decode.d5.loss_cls: 0.0054, decode.d5.loss_mask: 0.9310, decode.d5.loss_dice: 0.9817, decode.d6.loss_cls: 0.0089, decode.d6.loss_mask: 0.9238, decode.d6.loss_dice: 0.9839, decode.d7.loss_cls: 0.0088, decode.d7.loss_mask: 0.9309, decode.d7.loss_dice: 0.9853, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 0.9187, decode.d8.loss_dice: 0.9869, loss: 21.5425, grad_norm: 586.8970
2023-08-29 01:13:00,898 - mmseg - INFO - Iter [2400/160000]	lr: 1.658e-06, eta: 1 day, 7:58:03, time: 0.746, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0336, decode.loss_mask: 0.9155, decode.loss_dice: 1.0032, decode.d0.loss_cls: 2.0798, decode.d0.loss_mask: 0.9691, decode.d0.loss_dice: 1.1300, decode.d1.loss_cls: 0.0496, decode.d1.loss_mask: 0.9156, decode.d1.loss_dice: 1.0333, decode.d2.loss_cls: 0.0374, decode.d2.loss_mask: 0.9173, decode.d2.loss_dice: 1.0160, decode.d3.loss_cls: 0.0338, decode.d3.loss_mask: 0.9118, decode.d3.loss_dice: 1.0065, decode.d4.loss_cls: 0.0328, decode.d4.loss_mask: 0.9086, decode.d4.loss_dice: 1.0044, decode.d5.loss_cls: 0.0308, decode.d5.loss_mask: 0.9105, decode.d5.loss_dice: 0.9983, decode.d6.loss_cls: 0.0344, decode.d6.loss_mask: 0.9086, decode.d6.loss_dice: 1.0006, decode.d7.loss_cls: 0.0334, decode.d7.loss_mask: 0.9147, decode.d7.loss_dice: 0.9996, decode.d8.loss_cls: 0.0316, decode.d8.loss_mask: 0.9197, decode.d8.loss_dice: 0.9999, loss: 21.7801, grad_norm: 609.7072
2023-08-29 01:13:38,220 - mmseg - INFO - Iter [2450/160000]	lr: 1.657e-06, eta: 1 day, 7:58:19, time: 0.746, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0184, decode.loss_mask: 0.8983, decode.loss_dice: 0.9680, decode.d0.loss_cls: 2.0756, decode.d0.loss_mask: 0.9468, decode.d0.loss_dice: 1.0853, decode.d1.loss_cls: 0.0410, decode.d1.loss_mask: 0.8849, decode.d1.loss_dice: 0.9844, decode.d2.loss_cls: 0.0262, decode.d2.loss_mask: 0.8917, decode.d2.loss_dice: 0.9653, decode.d3.loss_cls: 0.0213, decode.d3.loss_mask: 0.9061, decode.d3.loss_dice: 0.9606, decode.d4.loss_cls: 0.0190, decode.d4.loss_mask: 0.8921, decode.d4.loss_dice: 0.9618, decode.d5.loss_cls: 0.0170, decode.d5.loss_mask: 0.8949, decode.d5.loss_dice: 0.9579, decode.d6.loss_cls: 0.0223, decode.d6.loss_mask: 0.8935, decode.d6.loss_dice: 0.9678, decode.d7.loss_cls: 0.0208, decode.d7.loss_mask: 0.9042, decode.d7.loss_dice: 0.9628, decode.d8.loss_cls: 0.0185, decode.d8.loss_mask: 0.9062, decode.d8.loss_dice: 0.9695, loss: 21.0819, grad_norm: 524.1161
2023-08-29 01:14:13,518 - mmseg - INFO - Iter [2500/160000]	lr: 1.657e-06, eta: 1 day, 7:56:25, time: 0.706, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0184, decode.loss_mask: 0.9497, decode.loss_dice: 1.0021, decode.d0.loss_cls: 2.0658, decode.d0.loss_mask: 0.9656, decode.d0.loss_dice: 1.1048, decode.d1.loss_cls: 0.0384, decode.d1.loss_mask: 0.9556, decode.d1.loss_dice: 1.0314, decode.d2.loss_cls: 0.0252, decode.d2.loss_mask: 0.9607, decode.d2.loss_dice: 1.0198, decode.d3.loss_cls: 0.0201, decode.d3.loss_mask: 0.9562, decode.d3.loss_dice: 1.0019, decode.d4.loss_cls: 0.0197, decode.d4.loss_mask: 0.9554, decode.d4.loss_dice: 1.0052, decode.d5.loss_cls: 0.0198, decode.d5.loss_mask: 0.9602, decode.d5.loss_dice: 1.0018, decode.d6.loss_cls: 0.0230, decode.d6.loss_mask: 0.9620, decode.d6.loss_dice: 0.9994, decode.d7.loss_cls: 0.0230, decode.d7.loss_mask: 0.9535, decode.d7.loss_dice: 1.0041, decode.d8.loss_cls: 0.0194, decode.d8.loss_mask: 0.9552, decode.d8.loss_dice: 1.0064, loss: 22.0238, grad_norm: 593.4676
2023-08-29 01:14:50,300 - mmseg - INFO - Iter [2550/160000]	lr: 1.656e-06, eta: 1 day, 7:56:05, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0075, decode.loss_mask: 0.8938, decode.loss_dice: 0.9897, decode.d0.loss_cls: 2.0547, decode.d0.loss_mask: 0.9489, decode.d0.loss_dice: 1.1012, decode.d1.loss_cls: 0.0328, decode.d1.loss_mask: 0.9009, decode.d1.loss_dice: 1.0049, decode.d2.loss_cls: 0.0187, decode.d2.loss_mask: 0.8904, decode.d2.loss_dice: 0.9918, decode.d3.loss_cls: 0.0136, decode.d3.loss_mask: 0.8948, decode.d3.loss_dice: 0.9905, decode.d4.loss_cls: 0.0131, decode.d4.loss_mask: 0.8919, decode.d4.loss_dice: 0.9911, decode.d5.loss_cls: 0.0135, decode.d5.loss_mask: 0.8896, decode.d5.loss_dice: 0.9861, decode.d6.loss_cls: 0.0165, decode.d6.loss_mask: 0.8942, decode.d6.loss_dice: 0.9875, decode.d7.loss_cls: 0.0146, decode.d7.loss_mask: 0.8907, decode.d7.loss_dice: 0.9860, decode.d8.loss_cls: 0.0111, decode.d8.loss_mask: 0.8927, decode.d8.loss_dice: 0.9840, loss: 21.1967, grad_norm: 542.3593
2023-08-29 01:15:27,007 - mmseg - INFO - Iter [2600/160000]	lr: 1.656e-06, eta: 1 day, 7:55:41, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0181, decode.loss_mask: 0.8906, decode.loss_dice: 0.9685, decode.d0.loss_cls: 2.0452, decode.d0.loss_mask: 0.8936, decode.d0.loss_dice: 1.0902, decode.d1.loss_cls: 0.0322, decode.d1.loss_mask: 0.8930, decode.d1.loss_dice: 0.9945, decode.d2.loss_cls: 0.0242, decode.d2.loss_mask: 0.8989, decode.d2.loss_dice: 0.9738, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.8926, decode.d3.loss_dice: 0.9664, decode.d4.loss_cls: 0.0180, decode.d4.loss_mask: 0.9057, decode.d4.loss_dice: 0.9666, decode.d5.loss_cls: 0.0169, decode.d5.loss_mask: 0.9001, decode.d5.loss_dice: 0.9709, decode.d6.loss_cls: 0.0222, decode.d6.loss_mask: 0.8944, decode.d6.loss_dice: 0.9577, decode.d7.loss_cls: 0.0208, decode.d7.loss_mask: 0.8947, decode.d7.loss_dice: 0.9633, decode.d8.loss_cls: 0.0177, decode.d8.loss_mask: 0.8879, decode.d8.loss_dice: 0.9660, loss: 21.0021, grad_norm: 568.5461
2023-08-29 01:16:04,178 - mmseg - INFO - Iter [2650/160000]	lr: 1.655e-06, eta: 1 day, 7:55:44, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0166, decode.loss_mask: 0.8772, decode.loss_dice: 0.9159, decode.d0.loss_cls: 2.0418, decode.d0.loss_mask: 0.8903, decode.d0.loss_dice: 1.0256, decode.d1.loss_cls: 0.0368, decode.d1.loss_mask: 0.8684, decode.d1.loss_dice: 0.9427, decode.d2.loss_cls: 0.0253, decode.d2.loss_mask: 0.8661, decode.d2.loss_dice: 0.9246, decode.d3.loss_cls: 0.0217, decode.d3.loss_mask: 0.8689, decode.d3.loss_dice: 0.9180, decode.d4.loss_cls: 0.0209, decode.d4.loss_mask: 0.8611, decode.d4.loss_dice: 0.9161, decode.d5.loss_cls: 0.0190, decode.d5.loss_mask: 0.8650, decode.d5.loss_dice: 0.9228, decode.d6.loss_cls: 0.0233, decode.d6.loss_mask: 0.8651, decode.d6.loss_dice: 0.9164, decode.d7.loss_cls: 0.0219, decode.d7.loss_mask: 0.8661, decode.d7.loss_dice: 0.9196, decode.d8.loss_cls: 0.0172, decode.d8.loss_mask: 0.8691, decode.d8.loss_dice: 0.9207, loss: 20.2642, grad_norm: 576.4472
2023-08-29 01:16:39,213 - mmseg - INFO - Iter [2700/160000]	lr: 1.655e-06, eta: 1 day, 7:53:40, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0063, decode.loss_mask: 0.8619, decode.loss_dice: 0.9613, decode.d0.loss_cls: 2.0254, decode.d0.loss_mask: 0.9186, decode.d0.loss_dice: 1.1029, decode.d1.loss_cls: 0.0248, decode.d1.loss_mask: 0.8650, decode.d1.loss_dice: 0.9881, decode.d2.loss_cls: 0.0122, decode.d2.loss_mask: 0.8603, decode.d2.loss_dice: 0.9704, decode.d3.loss_cls: 0.0074, decode.d3.loss_mask: 0.8606, decode.d3.loss_dice: 0.9635, decode.d4.loss_cls: 0.0066, decode.d4.loss_mask: 0.8675, decode.d4.loss_dice: 0.9604, decode.d5.loss_cls: 0.0063, decode.d5.loss_mask: 0.8730, decode.d5.loss_dice: 0.9550, decode.d6.loss_cls: 0.0102, decode.d6.loss_mask: 0.8704, decode.d6.loss_dice: 0.9536, decode.d7.loss_cls: 0.0095, decode.d7.loss_mask: 0.8611, decode.d7.loss_dice: 0.9555, decode.d8.loss_cls: 0.0068, decode.d8.loss_mask: 0.8650, decode.d8.loss_dice: 0.9597, loss: 20.5894, grad_norm: 582.1480
2023-08-29 01:17:15,572 - mmseg - INFO - Iter [2750/160000]	lr: 1.654e-06, eta: 1 day, 7:52:56, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.8921, decode.loss_dice: 0.9059, decode.d0.loss_cls: 2.0222, decode.d0.loss_mask: 0.8901, decode.d0.loss_dice: 1.0294, decode.d1.loss_cls: 0.0242, decode.d1.loss_mask: 0.8809, decode.d1.loss_dice: 0.9317, decode.d2.loss_cls: 0.0111, decode.d2.loss_mask: 0.8883, decode.d2.loss_dice: 0.9114, decode.d3.loss_cls: 0.0065, decode.d3.loss_mask: 0.8905, decode.d3.loss_dice: 0.9026, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.8914, decode.d4.loss_dice: 0.9030, decode.d5.loss_cls: 0.0056, decode.d5.loss_mask: 0.8961, decode.d5.loss_dice: 0.9067, decode.d6.loss_cls: 0.0084, decode.d6.loss_mask: 0.8909, decode.d6.loss_dice: 0.9000, decode.d7.loss_cls: 0.0079, decode.d7.loss_mask: 0.8888, decode.d7.loss_dice: 0.9031, decode.d8.loss_cls: 0.0053, decode.d8.loss_mask: 0.8884, decode.d8.loss_dice: 0.9020, loss: 20.1956, grad_norm: 570.8143
2023-08-29 01:17:52,623 - mmseg - INFO - Iter [2800/160000]	lr: 1.654e-06, eta: 1 day, 7:52:51, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0049, decode.loss_mask: 0.8248, decode.loss_dice: 0.8813, decode.d0.loss_cls: 2.0057, decode.d0.loss_mask: 0.8592, decode.d0.loss_dice: 1.0153, decode.d1.loss_cls: 0.0226, decode.d1.loss_mask: 0.8245, decode.d1.loss_dice: 0.8936, decode.d2.loss_cls: 0.0106, decode.d2.loss_mask: 0.8293, decode.d2.loss_dice: 0.8788, decode.d3.loss_cls: 0.0064, decode.d3.loss_mask: 0.8251, decode.d3.loss_dice: 0.8749, decode.d4.loss_cls: 0.0056, decode.d4.loss_mask: 0.8229, decode.d4.loss_dice: 0.8698, decode.d5.loss_cls: 0.0054, decode.d5.loss_mask: 0.8200, decode.d5.loss_dice: 0.8715, decode.d6.loss_cls: 0.0081, decode.d6.loss_mask: 0.8189, decode.d6.loss_dice: 0.8742, decode.d7.loss_cls: 0.0076, decode.d7.loss_mask: 0.8163, decode.d7.loss_dice: 0.8810, decode.d8.loss_cls: 0.0049, decode.d8.loss_mask: 0.8190, decode.d8.loss_dice: 0.8754, loss: 19.2576, grad_norm: 557.7714
2023-08-29 01:18:29,926 - mmseg - INFO - Iter [2850/160000]	lr: 1.653e-06, eta: 1 day, 7:52:58, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0056, decode.loss_mask: 0.8267, decode.loss_dice: 0.8806, decode.d0.loss_cls: 1.9810, decode.d0.loss_mask: 0.8633, decode.d0.loss_dice: 1.0486, decode.d1.loss_cls: 0.0230, decode.d1.loss_mask: 0.8336, decode.d1.loss_dice: 0.9053, decode.d2.loss_cls: 0.0111, decode.d2.loss_mask: 0.8277, decode.d2.loss_dice: 0.8847, decode.d3.loss_cls: 0.0071, decode.d3.loss_mask: 0.8239, decode.d3.loss_dice: 0.8799, decode.d4.loss_cls: 0.0062, decode.d4.loss_mask: 0.8263, decode.d4.loss_dice: 0.8775, decode.d5.loss_cls: 0.0058, decode.d5.loss_mask: 0.8168, decode.d5.loss_dice: 0.8762, decode.d6.loss_cls: 0.0089, decode.d6.loss_mask: 0.8202, decode.d6.loss_dice: 0.8750, decode.d7.loss_cls: 0.0087, decode.d7.loss_mask: 0.8211, decode.d7.loss_dice: 0.8784, decode.d8.loss_cls: 0.0055, decode.d8.loss_mask: 0.8259, decode.d8.loss_dice: 0.8791, loss: 19.3336, grad_norm: 542.3690
2023-08-29 01:19:05,070 - mmseg - INFO - Iter [2900/160000]	lr: 1.653e-06, eta: 1 day, 7:51:07, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0179, decode.loss_mask: 0.8418, decode.loss_dice: 0.9214, decode.d0.loss_cls: 1.9640, decode.d0.loss_mask: 0.8819, decode.d0.loss_dice: 1.1009, decode.d1.loss_cls: 0.0284, decode.d1.loss_mask: 0.8433, decode.d1.loss_dice: 0.9449, decode.d2.loss_cls: 0.0290, decode.d2.loss_mask: 0.8400, decode.d2.loss_dice: 0.9261, decode.d3.loss_cls: 0.0201, decode.d3.loss_mask: 0.8466, decode.d3.loss_dice: 0.9192, decode.d4.loss_cls: 0.0191, decode.d4.loss_mask: 0.8436, decode.d4.loss_dice: 0.9157, decode.d5.loss_cls: 0.0142, decode.d5.loss_mask: 0.8429, decode.d5.loss_dice: 0.9204, decode.d6.loss_cls: 0.0200, decode.d6.loss_mask: 0.8421, decode.d6.loss_dice: 0.9168, decode.d7.loss_cls: 0.0173, decode.d7.loss_mask: 0.8438, decode.d7.loss_dice: 0.9134, decode.d8.loss_cls: 0.0190, decode.d8.loss_mask: 0.8413, decode.d8.loss_dice: 0.9208, loss: 20.0161, grad_norm: 542.0376
2023-08-29 01:19:41,561 - mmseg - INFO - Iter [2950/160000]	lr: 1.652e-06, eta: 1 day, 7:50:29, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0050, decode.loss_mask: 0.8082, decode.loss_dice: 0.8827, decode.d0.loss_cls: 1.9422, decode.d0.loss_mask: 0.8513, decode.d0.loss_dice: 1.0824, decode.d1.loss_cls: 0.0215, decode.d1.loss_mask: 0.8063, decode.d1.loss_dice: 0.9112, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.8059, decode.d2.loss_dice: 0.8937, decode.d3.loss_cls: 0.0065, decode.d3.loss_mask: 0.8019, decode.d3.loss_dice: 0.8880, decode.d4.loss_cls: 0.0060, decode.d4.loss_mask: 0.8016, decode.d4.loss_dice: 0.8857, decode.d5.loss_cls: 0.0059, decode.d5.loss_mask: 0.8016, decode.d5.loss_dice: 0.8869, decode.d6.loss_cls: 0.0088, decode.d6.loss_mask: 0.8080, decode.d6.loss_dice: 0.8874, decode.d7.loss_cls: 0.0077, decode.d7.loss_mask: 0.8009, decode.d7.loss_dice: 0.8916, decode.d8.loss_cls: 0.0048, decode.d8.loss_mask: 0.8024, decode.d8.loss_dice: 0.8877, loss: 19.2045, grad_norm: 573.3535
2023-08-29 01:20:18,232 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-08-29 01:20:20,619 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 01:20:20,619 - mmseg - INFO - Iter [3000/160000]	lr: 1.652e-06, eta: 1 day, 7:52:08, time: 0.782, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0059, decode.loss_mask: 0.8172, decode.loss_dice: 0.8782, decode.d0.loss_cls: 1.9271, decode.d0.loss_mask: 0.8679, decode.d0.loss_dice: 1.0691, decode.d1.loss_cls: 0.0217, decode.d1.loss_mask: 0.8423, decode.d1.loss_dice: 0.8994, decode.d2.loss_cls: 0.0108, decode.d2.loss_mask: 0.8396, decode.d2.loss_dice: 0.8811, decode.d3.loss_cls: 0.0073, decode.d3.loss_mask: 0.8321, decode.d3.loss_dice: 0.8783, decode.d4.loss_cls: 0.0065, decode.d4.loss_mask: 0.8338, decode.d4.loss_dice: 0.8663, decode.d5.loss_cls: 0.0062, decode.d5.loss_mask: 0.8236, decode.d5.loss_dice: 0.8763, decode.d6.loss_cls: 0.0087, decode.d6.loss_mask: 0.8212, decode.d6.loss_dice: 0.8814, decode.d7.loss_cls: 0.0092, decode.d7.loss_mask: 0.8212, decode.d7.loss_dice: 0.8823, decode.d8.loss_cls: 0.0063, decode.d8.loss_mask: 0.8220, decode.d8.loss_dice: 0.8794, loss: 19.3222, grad_norm: 613.9537
2023-08-29 01:20:57,976 - mmseg - INFO - Iter [3050/160000]	lr: 1.651e-06, eta: 1 day, 7:52:14, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.7321, decode.loss_dice: 0.7778, decode.d0.loss_cls: 1.9222, decode.d0.loss_mask: 0.8109, decode.d0.loss_dice: 0.9918, decode.d1.loss_cls: 0.0190, decode.d1.loss_mask: 0.7511, decode.d1.loss_dice: 0.8222, decode.d2.loss_cls: 0.0089, decode.d2.loss_mask: 0.7446, decode.d2.loss_dice: 0.8002, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.7401, decode.d3.loss_dice: 0.7888, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.7399, decode.d4.loss_dice: 0.7869, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.7388, decode.d5.loss_dice: 0.7853, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.7360, decode.d6.loss_dice: 0.7753, decode.d7.loss_cls: 0.0062, decode.d7.loss_mask: 0.7349, decode.d7.loss_dice: 0.7813, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.7350, decode.d8.loss_dice: 0.7796, loss: 17.5375, grad_norm: 573.4332
2023-08-29 01:21:33,039 - mmseg - INFO - Iter [3100/160000]	lr: 1.651e-06, eta: 1 day, 7:50:22, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0040, decode.loss_mask: 0.8470, decode.loss_dice: 0.9052, decode.d0.loss_cls: 1.9157, decode.d0.loss_mask: 0.8925, decode.d0.loss_dice: 1.0685, decode.d1.loss_cls: 0.0184, decode.d1.loss_mask: 0.8813, decode.d1.loss_dice: 0.9329, decode.d2.loss_cls: 0.0085, decode.d2.loss_mask: 0.8566, decode.d2.loss_dice: 0.9136, decode.d3.loss_cls: 0.0052, decode.d3.loss_mask: 0.8565, decode.d3.loss_dice: 0.9089, decode.d4.loss_cls: 0.0046, decode.d4.loss_mask: 0.8512, decode.d4.loss_dice: 0.9124, decode.d5.loss_cls: 0.0046, decode.d5.loss_mask: 0.8423, decode.d5.loss_dice: 0.9102, decode.d6.loss_cls: 0.0069, decode.d6.loss_mask: 0.8452, decode.d6.loss_dice: 0.9106, decode.d7.loss_cls: 0.0064, decode.d7.loss_mask: 0.8426, decode.d7.loss_dice: 0.9098, decode.d8.loss_cls: 0.0039, decode.d8.loss_mask: 0.8415, decode.d8.loss_dice: 0.9092, loss: 19.8162, grad_norm: 664.3936
2023-08-29 01:22:09,725 - mmseg - INFO - Iter [3150/160000]	lr: 1.650e-06, eta: 1 day, 7:49:53, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0043, decode.loss_mask: 0.7645, decode.loss_dice: 0.8242, decode.d0.loss_cls: 1.9065, decode.d0.loss_mask: 0.8486, decode.d0.loss_dice: 0.9982, decode.d1.loss_cls: 0.0184, decode.d1.loss_mask: 0.7662, decode.d1.loss_dice: 0.8598, decode.d2.loss_cls: 0.0083, decode.d2.loss_mask: 0.7601, decode.d2.loss_dice: 0.8428, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.7591, decode.d3.loss_dice: 0.8339, decode.d4.loss_cls: 0.0045, decode.d4.loss_mask: 0.7682, decode.d4.loss_dice: 0.8307, decode.d5.loss_cls: 0.0044, decode.d5.loss_mask: 0.7635, decode.d5.loss_dice: 0.8250, decode.d6.loss_cls: 0.0068, decode.d6.loss_mask: 0.7597, decode.d6.loss_dice: 0.8189, decode.d7.loss_cls: 0.0066, decode.d7.loss_mask: 0.7577, decode.d7.loss_dice: 0.8241, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.7674, decode.d8.loss_dice: 0.8236, loss: 18.1655, grad_norm: 528.5589
2023-08-29 01:22:46,334 - mmseg - INFO - Iter [3200/160000]	lr: 1.650e-06, eta: 1 day, 7:49:20, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.8216, decode.loss_dice: 0.8724, decode.d0.loss_cls: 1.8958, decode.d0.loss_mask: 0.8840, decode.d0.loss_dice: 1.0406, decode.d1.loss_cls: 0.0176, decode.d1.loss_mask: 0.8297, decode.d1.loss_dice: 0.8989, decode.d2.loss_cls: 0.0083, decode.d2.loss_mask: 0.8243, decode.d2.loss_dice: 0.8840, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.8183, decode.d3.loss_dice: 0.8773, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.8226, decode.d4.loss_dice: 0.8739, decode.d5.loss_cls: 0.0051, decode.d5.loss_mask: 0.8210, decode.d5.loss_dice: 0.8703, decode.d6.loss_cls: 0.0070, decode.d6.loss_mask: 0.8208, decode.d6.loss_dice: 0.8746, decode.d7.loss_cls: 0.0072, decode.d7.loss_mask: 0.8232, decode.d7.loss_dice: 0.8737, decode.d8.loss_cls: 0.0047, decode.d8.loss_mask: 0.8181, decode.d8.loss_dice: 0.8735, loss: 19.1833, grad_norm: 499.3533
2023-08-29 01:23:23,501 - mmseg - INFO - Iter [3250/160000]	lr: 1.649e-06, eta: 1 day, 7:49:15, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0166, decode.loss_mask: 0.7276, decode.loss_dice: 0.7739, decode.d0.loss_cls: 1.8867, decode.d0.loss_mask: 0.7802, decode.d0.loss_dice: 0.9405, decode.d1.loss_cls: 0.0239, decode.d1.loss_mask: 0.7286, decode.d1.loss_dice: 0.7891, decode.d2.loss_cls: 0.0203, decode.d2.loss_mask: 0.7199, decode.d2.loss_dice: 0.7724, decode.d3.loss_cls: 0.0165, decode.d3.loss_mask: 0.7196, decode.d3.loss_dice: 0.7717, decode.d4.loss_cls: 0.0179, decode.d4.loss_mask: 0.7208, decode.d4.loss_dice: 0.7720, decode.d5.loss_cls: 0.0185, decode.d5.loss_mask: 0.7137, decode.d5.loss_dice: 0.7649, decode.d6.loss_cls: 0.0188, decode.d6.loss_mask: 0.7151, decode.d6.loss_dice: 0.7653, decode.d7.loss_cls: 0.0172, decode.d7.loss_mask: 0.7216, decode.d7.loss_dice: 0.7661, decode.d8.loss_cls: 0.0172, decode.d8.loss_mask: 0.7224, decode.d8.loss_dice: 0.7694, loss: 17.2084, grad_norm: 532.3579
2023-08-29 01:23:58,761 - mmseg - INFO - Iter [3300/160000]	lr: 1.649e-06, eta: 1 day, 7:47:37, time: 0.705, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.7732, decode.loss_dice: 0.8546, decode.d0.loss_cls: 1.8784, decode.d0.loss_mask: 0.8297, decode.d0.loss_dice: 0.9887, decode.d1.loss_cls: 0.0160, decode.d1.loss_mask: 0.7787, decode.d1.loss_dice: 0.8759, decode.d2.loss_cls: 0.0077, decode.d2.loss_mask: 0.7686, decode.d2.loss_dice: 0.8565, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.7676, decode.d3.loss_dice: 0.8560, decode.d4.loss_cls: 0.0041, decode.d4.loss_mask: 0.7714, decode.d4.loss_dice: 0.8553, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.7694, decode.d5.loss_dice: 0.8534, decode.d6.loss_cls: 0.0061, decode.d6.loss_mask: 0.7752, decode.d6.loss_dice: 0.8478, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.7749, decode.d7.loss_dice: 0.8538, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.7733, decode.d8.loss_dice: 0.8552, loss: 18.4127, grad_norm: 530.8309
2023-08-29 01:24:35,628 - mmseg - INFO - Iter [3350/160000]	lr: 1.648e-06, eta: 1 day, 7:47:17, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.7313, decode.loss_dice: 0.7952, decode.d0.loss_cls: 1.8735, decode.d0.loss_mask: 0.7569, decode.d0.loss_dice: 0.9259, decode.d1.loss_cls: 0.0159, decode.d1.loss_mask: 0.7274, decode.d1.loss_dice: 0.8224, decode.d2.loss_cls: 0.0072, decode.d2.loss_mask: 0.7326, decode.d2.loss_dice: 0.7984, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.7351, decode.d3.loss_dice: 0.7960, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.7376, decode.d4.loss_dice: 0.7922, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.7380, decode.d5.loss_dice: 0.7949, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.7403, decode.d6.loss_dice: 0.7944, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.7320, decode.d7.loss_dice: 0.7928, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.7288, decode.d8.loss_dice: 0.7893, loss: 17.3908, grad_norm: 555.4584
2023-08-29 01:25:12,172 - mmseg - INFO - Iter [3400/160000]	lr: 1.647e-06, eta: 1 day, 7:46:41, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.6969, decode.loss_dice: 0.7315, decode.d0.loss_cls: 1.8645, decode.d0.loss_mask: 0.7492, decode.d0.loss_dice: 0.8801, decode.d1.loss_cls: 0.0155, decode.d1.loss_mask: 0.7155, decode.d1.loss_dice: 0.7615, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.7029, decode.d2.loss_dice: 0.7410, decode.d3.loss_cls: 0.0050, decode.d3.loss_mask: 0.6944, decode.d3.loss_dice: 0.7384, decode.d4.loss_cls: 0.0045, decode.d4.loss_mask: 0.6968, decode.d4.loss_dice: 0.7290, decode.d5.loss_cls: 0.0044, decode.d5.loss_mask: 0.6934, decode.d5.loss_dice: 0.7279, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.6913, decode.d6.loss_dice: 0.7281, decode.d7.loss_cls: 0.0061, decode.d7.loss_mask: 0.6952, decode.d7.loss_dice: 0.7291, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.6918, decode.d8.loss_dice: 0.7315, loss: 16.4478, grad_norm: 541.2596
2023-08-29 01:25:49,241 - mmseg - INFO - Iter [3450/160000]	lr: 1.647e-06, eta: 1 day, 7:46:29, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0095, decode.loss_mask: 0.7705, decode.loss_dice: 0.8042, decode.d0.loss_cls: 1.8593, decode.d0.loss_mask: 0.8319, decode.d0.loss_dice: 0.9334, decode.d1.loss_cls: 0.0222, decode.d1.loss_mask: 0.7824, decode.d1.loss_dice: 0.8292, decode.d2.loss_cls: 0.0136, decode.d2.loss_mask: 0.7753, decode.d2.loss_dice: 0.8077, decode.d3.loss_cls: 0.0120, decode.d3.loss_mask: 0.7751, decode.d3.loss_dice: 0.8052, decode.d4.loss_cls: 0.0105, decode.d4.loss_mask: 0.7749, decode.d4.loss_dice: 0.8051, decode.d5.loss_cls: 0.0115, decode.d5.loss_mask: 0.7701, decode.d5.loss_dice: 0.7979, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 0.7674, decode.d6.loss_dice: 0.7981, decode.d7.loss_cls: 0.0117, decode.d7.loss_mask: 0.7724, decode.d7.loss_dice: 0.7965, decode.d8.loss_cls: 0.0100, decode.d8.loss_mask: 0.7673, decode.d8.loss_dice: 0.7957, loss: 17.9333, grad_norm: 510.9370
2023-08-29 01:26:26,446 - mmseg - INFO - Iter [3500/160000]	lr: 1.646e-06, eta: 1 day, 7:46:23, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0042, decode.loss_mask: 0.7364, decode.loss_dice: 0.7744, decode.d0.loss_cls: 1.8485, decode.d0.loss_mask: 0.7749, decode.d0.loss_dice: 0.9251, decode.d1.loss_cls: 0.0148, decode.d1.loss_mask: 0.7438, decode.d1.loss_dice: 0.8079, decode.d2.loss_cls: 0.0078, decode.d2.loss_mask: 0.7468, decode.d2.loss_dice: 0.7871, decode.d3.loss_cls: 0.0053, decode.d3.loss_mask: 0.7377, decode.d3.loss_dice: 0.7787, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.7381, decode.d4.loss_dice: 0.7806, decode.d5.loss_cls: 0.0045, decode.d5.loss_mask: 0.7354, decode.d5.loss_dice: 0.7770, decode.d6.loss_cls: 0.0068, decode.d6.loss_mask: 0.7359, decode.d6.loss_dice: 0.7759, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.7465, decode.d7.loss_dice: 0.7845, decode.d8.loss_cls: 0.0045, decode.d8.loss_mask: 0.7357, decode.d8.loss_dice: 0.7708, loss: 17.3007, grad_norm: 551.1524
2023-08-29 01:27:01,467 - mmseg - INFO - Iter [3550/160000]	lr: 1.646e-06, eta: 1 day, 7:44:39, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.7225, decode.loss_dice: 0.7617, decode.d0.loss_cls: 1.8429, decode.d0.loss_mask: 0.7836, decode.d0.loss_dice: 0.8874, decode.d1.loss_cls: 0.0139, decode.d1.loss_mask: 0.7321, decode.d1.loss_dice: 0.7858, decode.d2.loss_cls: 0.0067, decode.d2.loss_mask: 0.7280, decode.d2.loss_dice: 0.7629, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.7228, decode.d3.loss_dice: 0.7557, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.7266, decode.d4.loss_dice: 0.7537, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.7317, decode.d5.loss_dice: 0.7544, decode.d6.loss_cls: 0.0064, decode.d6.loss_mask: 0.7268, decode.d6.loss_dice: 0.7528, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.7279, decode.d7.loss_dice: 0.7569, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.7274, decode.d8.loss_dice: 0.7594, loss: 16.9567, grad_norm: 500.8973
2023-08-29 01:27:37,871 - mmseg - INFO - Iter [3600/160000]	lr: 1.645e-06, eta: 1 day, 7:43:57, time: 0.728, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.7665, decode.loss_dice: 0.7860, decode.d0.loss_cls: 1.8360, decode.d0.loss_mask: 0.8228, decode.d0.loss_dice: 0.9363, decode.d1.loss_cls: 0.0142, decode.d1.loss_mask: 0.7749, decode.d1.loss_dice: 0.8152, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.7666, decode.d2.loss_dice: 0.7932, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.7630, decode.d3.loss_dice: 0.7898, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.7609, decode.d4.loss_dice: 0.7841, decode.d5.loss_cls: 0.0050, decode.d5.loss_mask: 0.7624, decode.d5.loss_dice: 0.7886, decode.d6.loss_cls: 0.0073, decode.d6.loss_mask: 0.7588, decode.d6.loss_dice: 0.7839, decode.d7.loss_cls: 0.0057, decode.d7.loss_mask: 0.7685, decode.d7.loss_dice: 0.7865, decode.d8.loss_cls: 0.0042, decode.d8.loss_mask: 0.7700, decode.d8.loss_dice: 0.7859, loss: 17.6582, grad_norm: 602.1963
2023-08-29 01:28:14,836 - mmseg - INFO - Iter [3650/160000]	lr: 1.645e-06, eta: 1 day, 7:43:40, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.7061, decode.loss_dice: 0.7548, decode.d0.loss_cls: 1.8270, decode.d0.loss_mask: 0.7504, decode.d0.loss_dice: 0.8900, decode.d1.loss_cls: 0.0143, decode.d1.loss_mask: 0.7162, decode.d1.loss_dice: 0.7867, decode.d2.loss_cls: 0.0074, decode.d2.loss_mask: 0.7031, decode.d2.loss_dice: 0.7518, decode.d3.loss_cls: 0.0054, decode.d3.loss_mask: 0.7018, decode.d3.loss_dice: 0.7522, decode.d4.loss_cls: 0.0047, decode.d4.loss_mask: 0.6981, decode.d4.loss_dice: 0.7482, decode.d5.loss_cls: 0.0046, decode.d5.loss_mask: 0.6994, decode.d5.loss_dice: 0.7508, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.6994, decode.d6.loss_dice: 0.7549, decode.d7.loss_cls: 0.0055, decode.d7.loss_mask: 0.7049, decode.d7.loss_dice: 0.7583, decode.d8.loss_cls: 0.0038, decode.d8.loss_mask: 0.7039, decode.d8.loss_dice: 0.7528, loss: 16.6670, grad_norm: 596.2603
2023-08-29 01:28:51,799 - mmseg - INFO - Iter [3700/160000]	lr: 1.644e-06, eta: 1 day, 7:43:22, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.6931, decode.loss_dice: 0.7486, decode.d0.loss_cls: 1.8189, decode.d0.loss_mask: 0.7203, decode.d0.loss_dice: 0.8701, decode.d1.loss_cls: 0.0137, decode.d1.loss_mask: 0.6969, decode.d1.loss_dice: 0.7741, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.6906, decode.d2.loss_dice: 0.7557, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.6907, decode.d3.loss_dice: 0.7483, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.6881, decode.d4.loss_dice: 0.7489, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.6879, decode.d5.loss_dice: 0.7448, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.6877, decode.d6.loss_dice: 0.7458, decode.d7.loss_cls: 0.0055, decode.d7.loss_mask: 0.6911, decode.d7.loss_dice: 0.7428, decode.d8.loss_cls: 0.0038, decode.d8.loss_mask: 0.6924, decode.d8.loss_dice: 0.7447, loss: 16.4343, grad_norm: 599.5449
2023-08-29 01:29:26,684 - mmseg - INFO - Iter [3750/160000]	lr: 1.644e-06, eta: 1 day, 7:41:36, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0179, decode.loss_mask: 0.6710, decode.loss_dice: 0.7075, decode.d0.loss_cls: 1.8118, decode.d0.loss_mask: 0.7443, decode.d0.loss_dice: 0.8531, decode.d1.loss_cls: 0.0217, decode.d1.loss_mask: 0.6847, decode.d1.loss_dice: 0.7387, decode.d2.loss_cls: 0.0201, decode.d2.loss_mask: 0.6705, decode.d2.loss_dice: 0.7121, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.6672, decode.d3.loss_dice: 0.7044, decode.d4.loss_cls: 0.0194, decode.d4.loss_mask: 0.6721, decode.d4.loss_dice: 0.7004, decode.d5.loss_cls: 0.0187, decode.d5.loss_mask: 0.6677, decode.d5.loss_dice: 0.7001, decode.d6.loss_cls: 0.0201, decode.d6.loss_mask: 0.6694, decode.d6.loss_dice: 0.7043, decode.d7.loss_cls: 0.0208, decode.d7.loss_mask: 0.6721, decode.d7.loss_dice: 0.7057, decode.d8.loss_cls: 0.0200, decode.d8.loss_mask: 0.6706, decode.d8.loss_dice: 0.7081, loss: 16.0124, grad_norm: 536.2084
2023-08-29 01:30:03,147 - mmseg - INFO - Iter [3800/160000]	lr: 1.643e-06, eta: 1 day, 7:40:58, time: 0.729, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0030, decode.loss_mask: 0.7221, decode.loss_dice: 0.7368, decode.d0.loss_cls: 1.8030, decode.d0.loss_mask: 0.7540, decode.d0.loss_dice: 0.8453, decode.d1.loss_cls: 0.0123, decode.d1.loss_mask: 0.7224, decode.d1.loss_dice: 0.7419, decode.d2.loss_cls: 0.0063, decode.d2.loss_mask: 0.7177, decode.d2.loss_dice: 0.7229, decode.d3.loss_cls: 0.0046, decode.d3.loss_mask: 0.7131, decode.d3.loss_dice: 0.7211, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.7194, decode.d4.loss_dice: 0.7228, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.7194, decode.d5.loss_dice: 0.7219, decode.d6.loss_cls: 0.0052, decode.d6.loss_mask: 0.7174, decode.d6.loss_dice: 0.7285, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.7215, decode.d7.loss_dice: 0.7309, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.7171, decode.d8.loss_dice: 0.7344, loss: 16.4808, grad_norm: 543.9131
2023-08-29 01:30:40,256 - mmseg - INFO - Iter [3850/160000]	lr: 1.643e-06, eta: 1 day, 7:40:46, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0151, decode.loss_mask: 0.6718, decode.loss_dice: 0.6928, decode.d0.loss_cls: 1.7968, decode.d0.loss_mask: 0.6946, decode.d0.loss_dice: 0.7977, decode.d1.loss_cls: 0.0214, decode.d1.loss_mask: 0.6704, decode.d1.loss_dice: 0.7186, decode.d2.loss_cls: 0.0186, decode.d2.loss_mask: 0.6662, decode.d2.loss_dice: 0.6971, decode.d3.loss_cls: 0.0189, decode.d3.loss_mask: 0.6626, decode.d3.loss_dice: 0.6867, decode.d4.loss_cls: 0.0175, decode.d4.loss_mask: 0.6676, decode.d4.loss_dice: 0.6928, decode.d5.loss_cls: 0.0193, decode.d5.loss_mask: 0.6679, decode.d5.loss_dice: 0.6888, decode.d6.loss_cls: 0.0193, decode.d6.loss_mask: 0.6655, decode.d6.loss_dice: 0.6875, decode.d7.loss_cls: 0.0167, decode.d7.loss_mask: 0.6634, decode.d7.loss_dice: 0.6852, decode.d8.loss_cls: 0.0157, decode.d8.loss_mask: 0.6712, decode.d8.loss_dice: 0.6900, loss: 15.6980, grad_norm: 512.9092
2023-08-29 01:31:17,481 - mmseg - INFO - Iter [3900/160000]	lr: 1.642e-06, eta: 1 day, 7:40:37, time: 0.744, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0243, decode.loss_mask: 0.7462, decode.loss_dice: 0.7567, decode.d0.loss_cls: 1.7863, decode.d0.loss_mask: 0.7891, decode.d0.loss_dice: 0.8709, decode.d1.loss_cls: 0.0291, decode.d1.loss_mask: 0.7508, decode.d1.loss_dice: 0.7690, decode.d2.loss_cls: 0.0320, decode.d2.loss_mask: 0.7362, decode.d2.loss_dice: 0.7509, decode.d3.loss_cls: 0.0293, decode.d3.loss_mask: 0.7336, decode.d3.loss_dice: 0.7520, decode.d4.loss_cls: 0.0304, decode.d4.loss_mask: 0.7307, decode.d4.loss_dice: 0.7506, decode.d5.loss_cls: 0.0295, decode.d5.loss_mask: 0.7323, decode.d5.loss_dice: 0.7510, decode.d6.loss_cls: 0.0308, decode.d6.loss_mask: 0.7430, decode.d6.loss_dice: 0.7516, decode.d7.loss_cls: 0.0258, decode.d7.loss_mask: 0.7435, decode.d7.loss_dice: 0.7604, decode.d8.loss_cls: 0.0245, decode.d8.loss_mask: 0.7507, decode.d8.loss_dice: 0.7547, loss: 17.1658, grad_norm: 525.4309
2023-08-29 01:31:52,489 - mmseg - INFO - Iter [3950/160000]	lr: 1.642e-06, eta: 1 day, 7:39:01, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0083, decode.loss_mask: 0.6959, decode.loss_dice: 0.7055, decode.d0.loss_cls: 1.7783, decode.d0.loss_mask: 0.7313, decode.d0.loss_dice: 0.8175, decode.d1.loss_cls: 0.0127, decode.d1.loss_mask: 0.6964, decode.d1.loss_dice: 0.7190, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.6905, decode.d2.loss_dice: 0.7037, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.6943, decode.d3.loss_dice: 0.6946, decode.d4.loss_cls: 0.0053, decode.d4.loss_mask: 0.6916, decode.d4.loss_dice: 0.6985, decode.d5.loss_cls: 0.0054, decode.d5.loss_mask: 0.6885, decode.d5.loss_dice: 0.7019, decode.d6.loss_cls: 0.0079, decode.d6.loss_mask: 0.6950, decode.d6.loss_dice: 0.7003, decode.d7.loss_cls: 0.0060, decode.d7.loss_mask: 0.6946, decode.d7.loss_dice: 0.6985, decode.d8.loss_cls: 0.0067, decode.d8.loss_mask: 0.6948, decode.d8.loss_dice: 0.7003, loss: 15.9562, grad_norm: 610.5405
2023-08-29 01:32:28,979 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-08-29 01:32:35,354 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 01:32:35,354 - mmseg - INFO - Iter [4000/160000]	lr: 1.641e-06, eta: 1 day, 7:42:33, time: 0.858, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0036, decode.loss_mask: 0.6598, decode.loss_dice: 0.7194, decode.d0.loss_cls: 1.7686, decode.d0.loss_mask: 0.6986, decode.d0.loss_dice: 0.8280, decode.d1.loss_cls: 0.0116, decode.d1.loss_mask: 0.6542, decode.d1.loss_dice: 0.7297, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.6464, decode.d2.loss_dice: 0.7151, decode.d3.loss_cls: 0.0046, decode.d3.loss_mask: 0.6494, decode.d3.loss_dice: 0.7063, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.6492, decode.d4.loss_dice: 0.7140, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.6465, decode.d5.loss_dice: 0.7096, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.6527, decode.d6.loss_dice: 0.7099, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.6588, decode.d7.loss_dice: 0.7081, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.6587, decode.d8.loss_dice: 0.7137, loss: 15.6456, grad_norm: 566.6498
2023-08-29 01:33:11,928 - mmseg - INFO - Iter [4050/160000]	lr: 1.641e-06, eta: 1 day, 7:41:55, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0196, decode.loss_mask: 0.7250, decode.loss_dice: 0.7253, decode.d0.loss_cls: 1.7620, decode.d0.loss_mask: 0.7563, decode.d0.loss_dice: 0.8219, decode.d1.loss_cls: 0.0228, decode.d1.loss_mask: 0.7093, decode.d1.loss_dice: 0.7433, decode.d2.loss_cls: 0.0191, decode.d2.loss_mask: 0.6973, decode.d2.loss_dice: 0.7259, decode.d3.loss_cls: 0.0170, decode.d3.loss_mask: 0.6917, decode.d3.loss_dice: 0.7151, decode.d4.loss_cls: 0.0178, decode.d4.loss_mask: 0.6932, decode.d4.loss_dice: 0.7163, decode.d5.loss_cls: 0.0177, decode.d5.loss_mask: 0.6956, decode.d5.loss_dice: 0.7101, decode.d6.loss_cls: 0.0208, decode.d6.loss_mask: 0.6913, decode.d6.loss_dice: 0.7124, decode.d7.loss_cls: 0.0188, decode.d7.loss_mask: 0.7047, decode.d7.loss_dice: 0.7156, decode.d8.loss_cls: 0.0185, decode.d8.loss_mask: 0.7138, decode.d8.loss_dice: 0.7238, loss: 16.3221, grad_norm: 542.0159
2023-08-29 01:33:49,088 - mmseg - INFO - Iter [4100/160000]	lr: 1.640e-06, eta: 1 day, 7:41:40, time: 0.743, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0194, decode.loss_mask: 0.7123, decode.loss_dice: 0.7042, decode.d0.loss_cls: 1.7535, decode.d0.loss_mask: 0.7427, decode.d0.loss_dice: 0.8156, decode.d1.loss_cls: 0.0304, decode.d1.loss_mask: 0.6931, decode.d1.loss_dice: 0.7247, decode.d2.loss_cls: 0.0314, decode.d2.loss_mask: 0.6913, decode.d2.loss_dice: 0.7019, decode.d3.loss_cls: 0.0308, decode.d3.loss_mask: 0.6906, decode.d3.loss_dice: 0.6935, decode.d4.loss_cls: 0.0312, decode.d4.loss_mask: 0.6872, decode.d4.loss_dice: 0.6967, decode.d5.loss_cls: 0.0320, decode.d5.loss_mask: 0.6878, decode.d5.loss_dice: 0.6886, decode.d6.loss_cls: 0.0282, decode.d6.loss_mask: 0.6862, decode.d6.loss_dice: 0.6907, decode.d7.loss_cls: 0.0253, decode.d7.loss_mask: 0.6896, decode.d7.loss_dice: 0.6920, decode.d8.loss_cls: 0.0181, decode.d8.loss_mask: 0.7169, decode.d8.loss_dice: 0.6941, loss: 16.0998, grad_norm: 488.7455
2023-08-29 01:34:23,920 - mmseg - INFO - Iter [4150/160000]	lr: 1.640e-06, eta: 1 day, 7:39:58, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0036, decode.loss_mask: 0.7214, decode.loss_dice: 0.7327, decode.d0.loss_cls: 1.7447, decode.d0.loss_mask: 0.7599, decode.d0.loss_dice: 0.8232, decode.d1.loss_cls: 0.0114, decode.d1.loss_mask: 0.7262, decode.d1.loss_dice: 0.7422, decode.d2.loss_cls: 0.0063, decode.d2.loss_mask: 0.7261, decode.d2.loss_dice: 0.7267, decode.d3.loss_cls: 0.0044, decode.d3.loss_mask: 0.7251, decode.d3.loss_dice: 0.7260, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.7232, decode.d4.loss_dice: 0.7322, decode.d5.loss_cls: 0.0042, decode.d5.loss_mask: 0.7249, decode.d5.loss_dice: 0.7337, decode.d6.loss_cls: 0.0065, decode.d6.loss_mask: 0.7278, decode.d6.loss_dice: 0.7339, decode.d7.loss_cls: 0.0059, decode.d7.loss_mask: 0.7271, decode.d7.loss_dice: 0.7353, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.7214, decode.d8.loss_dice: 0.7371, loss: 16.5010, grad_norm: 587.2379
2023-08-29 01:35:00,273 - mmseg - INFO - Iter [4200/160000]	lr: 1.639e-06, eta: 1 day, 7:39:13, time: 0.727, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.6134, decode.loss_dice: 0.6790, decode.d0.loss_cls: 1.7373, decode.d0.loss_mask: 0.6596, decode.d0.loss_dice: 0.7781, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.6188, decode.d1.loss_dice: 0.6925, decode.d2.loss_cls: 0.0058, decode.d2.loss_mask: 0.6091, decode.d2.loss_dice: 0.6708, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.6077, decode.d3.loss_dice: 0.6717, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.6111, decode.d4.loss_dice: 0.6707, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.6118, decode.d5.loss_dice: 0.6677, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.6114, decode.d6.loss_dice: 0.6717, decode.d7.loss_cls: 0.0042, decode.d7.loss_mask: 0.6131, decode.d7.loss_dice: 0.6736, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.6157, decode.d8.loss_dice: 0.6721, loss: 14.8013, grad_norm: 478.6227
2023-08-29 01:35:37,462 - mmseg - INFO - Iter [4250/160000]	lr: 1.639e-06, eta: 1 day, 7:38:59, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.6238, decode.loss_dice: 0.6849, decode.d0.loss_cls: 1.7288, decode.d0.loss_mask: 0.6751, decode.d0.loss_dice: 0.8054, decode.d1.loss_cls: 0.0179, decode.d1.loss_mask: 0.6132, decode.d1.loss_dice: 0.6981, decode.d2.loss_cls: 0.0066, decode.d2.loss_mask: 0.6307, decode.d2.loss_dice: 0.6798, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.6256, decode.d3.loss_dice: 0.6741, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.6270, decode.d4.loss_dice: 0.6821, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.6232, decode.d5.loss_dice: 0.6793, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.6246, decode.d6.loss_dice: 0.6803, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.6288, decode.d7.loss_dice: 0.6791, decode.d8.loss_cls: 0.0032, decode.d8.loss_mask: 0.6288, decode.d8.loss_dice: 0.6772, loss: 15.0232, grad_norm: 493.3368
2023-08-29 01:36:14,719 - mmseg - INFO - Iter [4300/160000]	lr: 1.638e-06, eta: 1 day, 7:38:47, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0347, decode.loss_mask: 0.6815, decode.loss_dice: 0.6995, decode.d0.loss_cls: 1.7211, decode.d0.loss_mask: 0.7296, decode.d0.loss_dice: 0.7813, decode.d1.loss_cls: 0.0334, decode.d1.loss_mask: 0.6797, decode.d1.loss_dice: 0.7016, decode.d2.loss_cls: 0.0300, decode.d2.loss_mask: 0.6845, decode.d2.loss_dice: 0.6885, decode.d3.loss_cls: 0.0305, decode.d3.loss_mask: 0.6870, decode.d3.loss_dice: 0.6842, decode.d4.loss_cls: 0.0310, decode.d4.loss_mask: 0.6977, decode.d4.loss_dice: 0.6828, decode.d5.loss_cls: 0.0329, decode.d5.loss_mask: 0.7007, decode.d5.loss_dice: 0.6896, decode.d6.loss_cls: 0.0352, decode.d6.loss_mask: 0.6970, decode.d6.loss_dice: 0.6920, decode.d7.loss_cls: 0.0361, decode.d7.loss_mask: 0.6933, decode.d7.loss_dice: 0.6882, decode.d8.loss_cls: 0.0381, decode.d8.loss_mask: 0.6848, decode.d8.loss_dice: 0.6877, loss: 15.9543, grad_norm: 523.0729
2023-08-29 01:36:49,699 - mmseg - INFO - Iter [4350/160000]	lr: 1.637e-06, eta: 1 day, 7:37:13, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.6502, decode.loss_dice: 0.6381, decode.d0.loss_cls: 1.7133, decode.d0.loss_mask: 0.6627, decode.d0.loss_dice: 0.7184, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.6435, decode.d1.loss_dice: 0.6465, decode.d2.loss_cls: 0.0073, decode.d2.loss_mask: 0.6430, decode.d2.loss_dice: 0.6362, decode.d3.loss_cls: 0.0056, decode.d3.loss_mask: 0.6442, decode.d3.loss_dice: 0.6285, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.6439, decode.d4.loss_dice: 0.6393, decode.d5.loss_cls: 0.0049, decode.d5.loss_mask: 0.6464, decode.d5.loss_dice: 0.6384, decode.d6.loss_cls: 0.0063, decode.d6.loss_mask: 0.6477, decode.d6.loss_dice: 0.6405, decode.d7.loss_cls: 0.0052, decode.d7.loss_mask: 0.6504, decode.d7.loss_dice: 0.6392, decode.d8.loss_cls: 0.0045, decode.d8.loss_mask: 0.6496, decode.d8.loss_dice: 0.6400, loss: 14.7145, grad_norm: 443.2157
2023-08-29 01:37:25,993 - mmseg - INFO - Iter [4400/160000]	lr: 1.637e-06, eta: 1 day, 7:36:27, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0100, decode.loss_mask: 0.6449, decode.loss_dice: 0.6854, decode.d0.loss_cls: 1.7013, decode.d0.loss_mask: 0.6610, decode.d0.loss_dice: 0.7900, decode.d1.loss_cls: 0.0223, decode.d1.loss_mask: 0.6428, decode.d1.loss_dice: 0.6975, decode.d2.loss_cls: 0.0174, decode.d2.loss_mask: 0.6404, decode.d2.loss_dice: 0.6809, decode.d3.loss_cls: 0.0099, decode.d3.loss_mask: 0.6419, decode.d3.loss_dice: 0.6818, decode.d4.loss_cls: 0.0093, decode.d4.loss_mask: 0.6413, decode.d4.loss_dice: 0.6831, decode.d5.loss_cls: 0.0180, decode.d5.loss_mask: 0.6337, decode.d5.loss_dice: 0.6847, decode.d6.loss_cls: 0.0190, decode.d6.loss_mask: 0.6383, decode.d6.loss_dice: 0.6818, decode.d7.loss_cls: 0.0090, decode.d7.loss_mask: 0.6395, decode.d7.loss_dice: 0.6765, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.6515, decode.d8.loss_dice: 0.6832, loss: 15.1987, grad_norm: 568.2899
2023-08-29 01:38:02,889 - mmseg - INFO - Iter [4450/160000]	lr: 1.636e-06, eta: 1 day, 7:36:02, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0324, decode.loss_mask: 0.6761, decode.loss_dice: 0.6958, decode.d0.loss_cls: 1.6955, decode.d0.loss_mask: 0.6919, decode.d0.loss_dice: 0.7940, decode.d1.loss_cls: 0.0321, decode.d1.loss_mask: 0.6604, decode.d1.loss_dice: 0.7126, decode.d2.loss_cls: 0.0312, decode.d2.loss_mask: 0.6563, decode.d2.loss_dice: 0.6947, decode.d3.loss_cls: 0.0301, decode.d3.loss_mask: 0.6606, decode.d3.loss_dice: 0.6934, decode.d4.loss_cls: 0.0251, decode.d4.loss_mask: 0.6854, decode.d4.loss_dice: 0.6922, decode.d5.loss_cls: 0.0264, decode.d5.loss_mask: 0.6801, decode.d5.loss_dice: 0.6927, decode.d6.loss_cls: 0.0357, decode.d6.loss_mask: 0.6621, decode.d6.loss_dice: 0.7015, decode.d7.loss_cls: 0.0273, decode.d7.loss_mask: 0.6889, decode.d7.loss_dice: 0.6975, decode.d8.loss_cls: 0.0271, decode.d8.loss_mask: 0.6884, decode.d8.loss_dice: 0.6941, loss: 15.7815, grad_norm: 489.1430
2023-08-29 01:38:40,190 - mmseg - INFO - Iter [4500/160000]	lr: 1.636e-06, eta: 1 day, 7:35:50, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0055, decode.loss_mask: 0.6327, decode.loss_dice: 0.6656, decode.d0.loss_cls: 1.6871, decode.d0.loss_mask: 0.6461, decode.d0.loss_dice: 0.7378, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.6269, decode.d1.loss_dice: 0.6759, decode.d2.loss_cls: 0.0067, decode.d2.loss_mask: 0.6235, decode.d2.loss_dice: 0.6602, decode.d3.loss_cls: 0.0058, decode.d3.loss_mask: 0.6209, decode.d3.loss_dice: 0.6579, decode.d4.loss_cls: 0.0057, decode.d4.loss_mask: 0.6222, decode.d4.loss_dice: 0.6660, decode.d5.loss_cls: 0.0059, decode.d5.loss_mask: 0.6280, decode.d5.loss_dice: 0.6622, decode.d6.loss_cls: 0.0074, decode.d6.loss_mask: 0.6287, decode.d6.loss_dice: 0.6689, decode.d7.loss_cls: 0.0081, decode.d7.loss_mask: 0.6296, decode.d7.loss_dice: 0.6762, decode.d8.loss_cls: 0.0055, decode.d8.loss_mask: 0.6318, decode.d8.loss_dice: 0.6765, loss: 14.7865, grad_norm: 510.1821
2023-08-29 01:39:15,300 - mmseg - INFO - Iter [4550/160000]	lr: 1.635e-06, eta: 1 day, 7:34:24, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.6641, decode.loss_dice: 0.6945, decode.d0.loss_cls: 1.6769, decode.d0.loss_mask: 0.6919, decode.d0.loss_dice: 0.7917, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.6649, decode.d1.loss_dice: 0.7090, decode.d2.loss_cls: 0.0049, decode.d2.loss_mask: 0.6648, decode.d2.loss_dice: 0.6941, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.6687, decode.d3.loss_dice: 0.6878, decode.d4.loss_cls: 0.0032, decode.d4.loss_mask: 0.6689, decode.d4.loss_dice: 0.6985, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.6627, decode.d5.loss_dice: 0.6888, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.6648, decode.d6.loss_dice: 0.6908, decode.d7.loss_cls: 0.0034, decode.d7.loss_mask: 0.6616, decode.d7.loss_dice: 0.6939, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.6627, decode.d8.loss_dice: 0.6927, loss: 15.4304, grad_norm: 549.3672
2023-08-29 01:39:51,847 - mmseg - INFO - Iter [4600/160000]	lr: 1.635e-06, eta: 1 day, 7:33:47, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.6222, decode.loss_dice: 0.6795, decode.d0.loss_cls: 1.6722, decode.d0.loss_mask: 0.6744, decode.d0.loss_dice: 0.7822, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.6350, decode.d1.loss_dice: 0.7019, decode.d2.loss_cls: 0.0051, decode.d2.loss_mask: 0.6281, decode.d2.loss_dice: 0.6809, decode.d3.loss_cls: 0.0036, decode.d3.loss_mask: 0.6255, decode.d3.loss_dice: 0.6763, decode.d4.loss_cls: 0.0032, decode.d4.loss_mask: 0.6248, decode.d4.loss_dice: 0.6768, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.6229, decode.d5.loss_dice: 0.6753, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.6239, decode.d6.loss_dice: 0.6737, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.6256, decode.d7.loss_dice: 0.6747, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.6214, decode.d8.loss_dice: 0.6793, loss: 14.9139, grad_norm: 548.7143
2023-08-29 01:40:28,566 - mmseg - INFO - Iter [4650/160000]	lr: 1.634e-06, eta: 1 day, 7:33:16, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0156, decode.loss_mask: 0.6369, decode.loss_dice: 0.6299, decode.d0.loss_cls: 1.6668, decode.d0.loss_mask: 0.6872, decode.d0.loss_dice: 0.7277, decode.d1.loss_cls: 0.0223, decode.d1.loss_mask: 0.6451, decode.d1.loss_dice: 0.6534, decode.d2.loss_cls: 0.0178, decode.d2.loss_mask: 0.6440, decode.d2.loss_dice: 0.6357, decode.d3.loss_cls: 0.0177, decode.d3.loss_mask: 0.6375, decode.d3.loss_dice: 0.6323, decode.d4.loss_cls: 0.0181, decode.d4.loss_mask: 0.6356, decode.d4.loss_dice: 0.6300, decode.d5.loss_cls: 0.0170, decode.d5.loss_mask: 0.6463, decode.d5.loss_dice: 0.6293, decode.d6.loss_cls: 0.0195, decode.d6.loss_mask: 0.6411, decode.d6.loss_dice: 0.6305, decode.d7.loss_cls: 0.0165, decode.d7.loss_mask: 0.6474, decode.d7.loss_dice: 0.6279, decode.d8.loss_cls: 0.0165, decode.d8.loss_mask: 0.6392, decode.d8.loss_dice: 0.6301, loss: 14.7148, grad_norm: 536.0436
2023-08-29 01:41:05,778 - mmseg - INFO - Iter [4700/160000]	lr: 1.634e-06, eta: 1 day, 7:33:01, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.5951, decode.loss_dice: 0.6203, decode.d0.loss_cls: 1.6508, decode.d0.loss_mask: 0.6230, decode.d0.loss_dice: 0.7042, decode.d1.loss_cls: 0.0091, decode.d1.loss_mask: 0.5989, decode.d1.loss_dice: 0.6352, decode.d2.loss_cls: 0.0051, decode.d2.loss_mask: 0.5920, decode.d2.loss_dice: 0.6193, decode.d3.loss_cls: 0.0036, decode.d3.loss_mask: 0.5908, decode.d3.loss_dice: 0.6166, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.5948, decode.d4.loss_dice: 0.6177, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.5931, decode.d5.loss_dice: 0.6208, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.5915, decode.d6.loss_dice: 0.6240, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.5892, decode.d7.loss_dice: 0.6247, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.5931, decode.d8.loss_dice: 0.6220, loss: 13.9541, grad_norm: 529.5188
2023-08-29 01:41:40,821 - mmseg - INFO - Iter [4750/160000]	lr: 1.633e-06, eta: 1 day, 7:31:34, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.6586, decode.loss_dice: 0.6697, decode.d0.loss_cls: 1.6417, decode.d0.loss_mask: 0.6771, decode.d0.loss_dice: 0.7479, decode.d1.loss_cls: 0.0088, decode.d1.loss_mask: 0.6674, decode.d1.loss_dice: 0.6876, decode.d2.loss_cls: 0.0046, decode.d2.loss_mask: 0.6600, decode.d2.loss_dice: 0.6712, decode.d3.loss_cls: 0.0032, decode.d3.loss_mask: 0.6577, decode.d3.loss_dice: 0.6665, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.6582, decode.d4.loss_dice: 0.6659, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.6562, decode.d5.loss_dice: 0.6628, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.6600, decode.d6.loss_dice: 0.6649, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.6547, decode.d7.loss_dice: 0.6678, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.6574, decode.d8.loss_dice: 0.6684, loss: 15.0554, grad_norm: 586.2181
2023-08-29 01:42:17,522 - mmseg - INFO - Iter [4800/160000]	lr: 1.633e-06, eta: 1 day, 7:31:02, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0051, decode.loss_mask: 0.6569, decode.loss_dice: 0.6858, decode.d0.loss_cls: 1.6392, decode.d0.loss_mask: 0.6949, decode.d0.loss_dice: 0.7682, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.6610, decode.d1.loss_dice: 0.7027, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.6522, decode.d2.loss_dice: 0.6871, decode.d3.loss_cls: 0.0060, decode.d3.loss_mask: 0.6541, decode.d3.loss_dice: 0.6794, decode.d4.loss_cls: 0.0055, decode.d4.loss_mask: 0.6566, decode.d4.loss_dice: 0.6853, decode.d5.loss_cls: 0.0056, decode.d5.loss_mask: 0.6530, decode.d5.loss_dice: 0.6813, decode.d6.loss_cls: 0.0061, decode.d6.loss_mask: 0.6548, decode.d6.loss_dice: 0.6850, decode.d7.loss_cls: 0.0063, decode.d7.loss_mask: 0.6544, decode.d7.loss_dice: 0.6819, decode.d8.loss_cls: 0.0053, decode.d8.loss_mask: 0.6551, decode.d8.loss_dice: 0.6796, loss: 15.2270, grad_norm: 505.8776
2023-08-29 01:42:53,822 - mmseg - INFO - Iter [4850/160000]	lr: 1.632e-06, eta: 1 day, 7:30:18, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.6033, decode.loss_dice: 0.6419, decode.d0.loss_cls: 1.6281, decode.d0.loss_mask: 0.6262, decode.d0.loss_dice: 0.7214, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.6115, decode.d1.loss_dice: 0.6637, decode.d2.loss_cls: 0.0041, decode.d2.loss_mask: 0.6016, decode.d2.loss_dice: 0.6473, decode.d3.loss_cls: 0.0027, decode.d3.loss_mask: 0.6047, decode.d3.loss_dice: 0.6425, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.6068, decode.d4.loss_dice: 0.6440, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.6055, decode.d5.loss_dice: 0.6436, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.6049, decode.d6.loss_dice: 0.6414, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.6052, decode.d7.loss_dice: 0.6401, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.6029, decode.d8.loss_dice: 0.6397, loss: 14.2552, grad_norm: 468.4214
2023-08-29 01:43:30,946 - mmseg - INFO - Iter [4900/160000]	lr: 1.632e-06, eta: 1 day, 7:29:59, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.6503, decode.loss_dice: 0.6395, decode.d0.loss_cls: 1.6183, decode.d0.loss_mask: 0.6812, decode.d0.loss_dice: 0.7275, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.6508, decode.d1.loss_dice: 0.6560, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.6532, decode.d2.loss_dice: 0.6407, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.6474, decode.d3.loss_dice: 0.6364, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.6490, decode.d4.loss_dice: 0.6367, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.6436, decode.d5.loss_dice: 0.6355, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.6533, decode.d6.loss_dice: 0.6384, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.6487, decode.d7.loss_dice: 0.6386, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.6485, decode.d8.loss_dice: 0.6355, loss: 14.6560, grad_norm: 594.8696
2023-08-29 01:44:06,023 - mmseg - INFO - Iter [4950/160000]	lr: 1.631e-06, eta: 1 day, 7:28:36, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.6439, decode.loss_dice: 0.6240, decode.d0.loss_cls: 1.6094, decode.d0.loss_mask: 0.6584, decode.d0.loss_dice: 0.7070, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.6374, decode.d1.loss_dice: 0.6420, decode.d2.loss_cls: 0.0055, decode.d2.loss_mask: 0.6405, decode.d2.loss_dice: 0.6311, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.6382, decode.d3.loss_dice: 0.6260, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.6377, decode.d4.loss_dice: 0.6260, decode.d5.loss_cls: 0.0040, decode.d5.loss_mask: 0.6368, decode.d5.loss_dice: 0.6269, decode.d6.loss_cls: 0.0045, decode.d6.loss_mask: 0.6336, decode.d6.loss_dice: 0.6246, decode.d7.loss_cls: 0.0040, decode.d7.loss_mask: 0.6397, decode.d7.loss_dice: 0.6253, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.6384, decode.d8.loss_dice: 0.6247, loss: 14.4138, grad_norm: 507.7174
2023-08-29 01:44:42,857 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-08-29 01:44:45,703 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 01:44:45,703 - mmseg - INFO - Iter [5000/160000]	lr: 1.631e-06, eta: 1 day, 7:29:37, time: 0.794, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0117, decode.loss_mask: 0.6185, decode.loss_dice: 0.6427, decode.d0.loss_cls: 1.6008, decode.d0.loss_mask: 0.6524, decode.d0.loss_dice: 0.7378, decode.d1.loss_cls: 0.0212, decode.d1.loss_mask: 0.6074, decode.d1.loss_dice: 0.6655, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.6072, decode.d2.loss_dice: 0.6545, decode.d3.loss_cls: 0.0187, decode.d3.loss_mask: 0.5997, decode.d3.loss_dice: 0.6447, decode.d4.loss_cls: 0.0178, decode.d4.loss_mask: 0.6078, decode.d4.loss_dice: 0.6503, decode.d5.loss_cls: 0.0202, decode.d5.loss_mask: 0.6080, decode.d5.loss_dice: 0.6482, decode.d6.loss_cls: 0.0191, decode.d6.loss_mask: 0.6001, decode.d6.loss_dice: 0.6514, decode.d7.loss_cls: 0.0046, decode.d7.loss_mask: 0.6232, decode.d7.loss_dice: 0.6482, decode.d8.loss_cls: 0.0118, decode.d8.loss_mask: 0.6162, decode.d8.loss_dice: 0.6478, loss: 14.4769, grad_norm: 474.1763
2023-08-29 01:45:22,348 - mmseg - INFO - Iter [5050/160000]	lr: 1.630e-06, eta: 1 day, 7:29:03, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0030, decode.loss_mask: 0.6058, decode.loss_dice: 0.6262, decode.d0.loss_cls: 1.5926, decode.d0.loss_mask: 0.6393, decode.d0.loss_dice: 0.7022, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.6178, decode.d1.loss_dice: 0.6446, decode.d2.loss_cls: 0.0049, decode.d2.loss_mask: 0.6101, decode.d2.loss_dice: 0.6301, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.6074, decode.d3.loss_dice: 0.6275, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.6051, decode.d4.loss_dice: 0.6307, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.6069, decode.d5.loss_dice: 0.6263, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.6067, decode.d6.loss_dice: 0.6252, decode.d7.loss_cls: 0.0037, decode.d7.loss_mask: 0.6055, decode.d7.loss_dice: 0.6269, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.6081, decode.d8.loss_dice: 0.6279, loss: 14.1106, grad_norm: 582.4526
2023-08-29 01:45:59,424 - mmseg - INFO - Iter [5100/160000]	lr: 1.630e-06, eta: 1 day, 7:28:41, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5976, decode.loss_dice: 0.6351, decode.d0.loss_cls: 1.5852, decode.d0.loss_mask: 0.6387, decode.d0.loss_dice: 0.7124, decode.d1.loss_cls: 0.0075, decode.d1.loss_mask: 0.6111, decode.d1.loss_dice: 0.6544, decode.d2.loss_cls: 0.0041, decode.d2.loss_mask: 0.6013, decode.d2.loss_dice: 0.6340, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.5976, decode.d3.loss_dice: 0.6299, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.5982, decode.d4.loss_dice: 0.6307, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.5954, decode.d5.loss_dice: 0.6329, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.5931, decode.d6.loss_dice: 0.6301, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.5985, decode.d7.loss_dice: 0.6350, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.5945, decode.d8.loss_dice: 0.6366, loss: 14.0709, grad_norm: 522.0167
2023-08-29 01:46:36,538 - mmseg - INFO - Iter [5150/160000]	lr: 1.629e-06, eta: 1 day, 7:28:21, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.6157, decode.loss_dice: 0.6129, decode.d0.loss_cls: 1.5770, decode.d0.loss_mask: 0.6213, decode.d0.loss_dice: 0.6882, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.6157, decode.d1.loss_dice: 0.6354, decode.d2.loss_cls: 0.0047, decode.d2.loss_mask: 0.6115, decode.d2.loss_dice: 0.6190, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.6151, decode.d3.loss_dice: 0.6208, decode.d4.loss_cls: 0.0030, decode.d4.loss_mask: 0.6111, decode.d4.loss_dice: 0.6185, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.6158, decode.d5.loss_dice: 0.6162, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.6124, decode.d6.loss_dice: 0.6200, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.6118, decode.d7.loss_dice: 0.6135, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.6142, decode.d8.loss_dice: 0.6118, loss: 14.0107, grad_norm: 526.4134
2023-08-29 01:47:11,221 - mmseg - INFO - Iter [5200/160000]	lr: 1.629e-06, eta: 1 day, 7:26:47, time: 0.693, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0186, decode.loss_mask: 0.5993, decode.loss_dice: 0.6027, decode.d0.loss_cls: 1.5686, decode.d0.loss_mask: 0.6370, decode.d0.loss_dice: 0.6773, decode.d1.loss_cls: 0.0199, decode.d1.loss_mask: 0.6010, decode.d1.loss_dice: 0.6175, decode.d2.loss_cls: 0.0180, decode.d2.loss_mask: 0.5980, decode.d2.loss_dice: 0.6035, decode.d3.loss_cls: 0.0186, decode.d3.loss_mask: 0.6000, decode.d3.loss_dice: 0.5991, decode.d4.loss_cls: 0.0191, decode.d4.loss_mask: 0.6041, decode.d4.loss_dice: 0.5987, decode.d5.loss_cls: 0.0183, decode.d5.loss_mask: 0.6013, decode.d5.loss_dice: 0.5973, decode.d6.loss_cls: 0.0200, decode.d6.loss_mask: 0.5939, decode.d6.loss_dice: 0.6014, decode.d7.loss_cls: 0.0191, decode.d7.loss_mask: 0.5907, decode.d7.loss_dice: 0.6017, decode.d8.loss_cls: 0.0193, decode.d8.loss_mask: 0.5967, decode.d8.loss_dice: 0.6008, loss: 13.8616, grad_norm: 538.7415
2023-08-29 01:47:47,798 - mmseg - INFO - Iter [5250/160000]	lr: 1.628e-06, eta: 1 day, 7:26:11, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0304, decode.loss_mask: 0.6258, decode.loss_dice: 0.6251, decode.d0.loss_cls: 1.5642, decode.d0.loss_mask: 0.6335, decode.d0.loss_dice: 0.6948, decode.d1.loss_cls: 0.0318, decode.d1.loss_mask: 0.6222, decode.d1.loss_dice: 0.6469, decode.d2.loss_cls: 0.0306, decode.d2.loss_mask: 0.6204, decode.d2.loss_dice: 0.6260, decode.d3.loss_cls: 0.0303, decode.d3.loss_mask: 0.6174, decode.d3.loss_dice: 0.6261, decode.d4.loss_cls: 0.0259, decode.d4.loss_mask: 0.6184, decode.d4.loss_dice: 0.6269, decode.d5.loss_cls: 0.0301, decode.d5.loss_mask: 0.6228, decode.d5.loss_dice: 0.6238, decode.d6.loss_cls: 0.0285, decode.d6.loss_mask: 0.6215, decode.d6.loss_dice: 0.6294, decode.d7.loss_cls: 0.0255, decode.d7.loss_mask: 0.6119, decode.d7.loss_dice: 0.6291, decode.d8.loss_cls: 0.0271, decode.d8.loss_mask: 0.6197, decode.d8.loss_dice: 0.6304, loss: 14.3963, grad_norm: 535.2654
2023-08-29 01:48:25,018 - mmseg - INFO - Iter [5300/160000]	lr: 1.627e-06, eta: 1 day, 7:25:54, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0334, decode.loss_mask: 0.6856, decode.loss_dice: 0.6854, decode.d0.loss_cls: 1.5531, decode.d0.loss_mask: 0.7225, decode.d0.loss_dice: 0.7498, decode.d1.loss_cls: 0.0325, decode.d1.loss_mask: 0.7038, decode.d1.loss_dice: 0.6991, decode.d2.loss_cls: 0.0376, decode.d2.loss_mask: 0.6715, decode.d2.loss_dice: 0.6788, decode.d3.loss_cls: 0.0374, decode.d3.loss_mask: 0.6700, decode.d3.loss_dice: 0.6813, decode.d4.loss_cls: 0.0256, decode.d4.loss_mask: 0.7045, decode.d4.loss_dice: 0.6849, decode.d5.loss_cls: 0.0263, decode.d5.loss_mask: 0.7034, decode.d5.loss_dice: 0.6811, decode.d6.loss_cls: 0.0357, decode.d6.loss_mask: 0.6867, decode.d6.loss_dice: 0.6896, decode.d7.loss_cls: 0.0243, decode.d7.loss_mask: 0.7081, decode.d7.loss_dice: 0.6809, decode.d8.loss_cls: 0.0279, decode.d8.loss_mask: 0.7036, decode.d8.loss_dice: 0.6800, loss: 15.7044, grad_norm: 506.2349
2023-08-29 01:49:02,143 - mmseg - INFO - Iter [5350/160000]	lr: 1.627e-06, eta: 1 day, 7:25:33, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0188, decode.loss_mask: 0.5994, decode.loss_dice: 0.5905, decode.d0.loss_cls: 1.5434, decode.d0.loss_mask: 0.6169, decode.d0.loss_dice: 0.6692, decode.d1.loss_cls: 0.0311, decode.d1.loss_mask: 0.5826, decode.d1.loss_dice: 0.5956, decode.d2.loss_cls: 0.0224, decode.d2.loss_mask: 0.5896, decode.d2.loss_dice: 0.5899, decode.d3.loss_cls: 0.0234, decode.d3.loss_mask: 0.5888, decode.d3.loss_dice: 0.5866, decode.d4.loss_cls: 0.0198, decode.d4.loss_mask: 0.5914, decode.d4.loss_dice: 0.5868, decode.d5.loss_cls: 0.0207, decode.d5.loss_mask: 0.5958, decode.d5.loss_dice: 0.5896, decode.d6.loss_cls: 0.0192, decode.d6.loss_mask: 0.5941, decode.d6.loss_dice: 0.5845, decode.d7.loss_cls: 0.0182, decode.d7.loss_mask: 0.5896, decode.d7.loss_dice: 0.5867, decode.d8.loss_cls: 0.0181, decode.d8.loss_mask: 0.5945, decode.d8.loss_dice: 0.5865, loss: 13.6436, grad_norm: 507.8598
2023-08-29 01:49:36,916 - mmseg - INFO - Iter [5400/160000]	lr: 1.626e-06, eta: 1 day, 7:24:05, time: 0.695, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.6164, decode.loss_dice: 0.5927, decode.d0.loss_cls: 1.5333, decode.d0.loss_mask: 0.6305, decode.d0.loss_dice: 0.6647, decode.d1.loss_cls: 0.0076, decode.d1.loss_mask: 0.6140, decode.d1.loss_dice: 0.6119, decode.d2.loss_cls: 0.0050, decode.d2.loss_mask: 0.6143, decode.d2.loss_dice: 0.5972, decode.d3.loss_cls: 0.0038, decode.d3.loss_mask: 0.6174, decode.d3.loss_dice: 0.5972, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.6166, decode.d4.loss_dice: 0.5993, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.6168, decode.d5.loss_dice: 0.5965, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.6163, decode.d6.loss_dice: 0.5946, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.6156, decode.d7.loss_dice: 0.5994, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.6150, decode.d8.loss_dice: 0.5972, loss: 13.7934, grad_norm: 486.0434
2023-08-29 01:50:13,540 - mmseg - INFO - Iter [5450/160000]	lr: 1.626e-06, eta: 1 day, 7:23:30, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0045, decode.loss_mask: 0.5598, decode.loss_dice: 0.6074, decode.d0.loss_cls: 1.5243, decode.d0.loss_mask: 0.6037, decode.d0.loss_dice: 0.6972, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.5694, decode.d1.loss_dice: 0.6170, decode.d2.loss_cls: 0.0058, decode.d2.loss_mask: 0.5614, decode.d2.loss_dice: 0.6115, decode.d3.loss_cls: 0.0047, decode.d3.loss_mask: 0.5628, decode.d3.loss_dice: 0.6010, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.5583, decode.d4.loss_dice: 0.5990, decode.d5.loss_cls: 0.0040, decode.d5.loss_mask: 0.5617, decode.d5.loss_dice: 0.6037, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.5622, decode.d6.loss_dice: 0.5986, decode.d7.loss_cls: 0.0053, decode.d7.loss_mask: 0.5620, decode.d7.loss_dice: 0.6055, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.5571, decode.d8.loss_dice: 0.6053, loss: 13.3750, grad_norm: 495.1645
2023-08-29 01:50:50,424 - mmseg - INFO - Iter [5500/160000]	lr: 1.625e-06, eta: 1 day, 7:23:03, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5492, decode.loss_dice: 0.5830, decode.d0.loss_cls: 1.5176, decode.d0.loss_mask: 0.5966, decode.d0.loss_dice: 0.6731, decode.d1.loss_cls: 0.0071, decode.d1.loss_mask: 0.5540, decode.d1.loss_dice: 0.6005, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.5510, decode.d2.loss_dice: 0.5828, decode.d3.loss_cls: 0.0027, decode.d3.loss_mask: 0.5541, decode.d3.loss_dice: 0.5774, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.5471, decode.d4.loss_dice: 0.5777, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.5432, decode.d5.loss_dice: 0.5778, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.5485, decode.d6.loss_dice: 0.5754, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.5506, decode.d7.loss_dice: 0.5776, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.5475, decode.d8.loss_dice: 0.5810, loss: 12.9930, grad_norm: 573.2480
2023-08-29 01:51:27,692 - mmseg - INFO - Iter [5550/160000]	lr: 1.625e-06, eta: 1 day, 7:22:46, time: 0.745, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0317, decode.loss_mask: 0.6269, decode.loss_dice: 0.5919, decode.d0.loss_cls: 1.5108, decode.d0.loss_mask: 0.6316, decode.d0.loss_dice: 0.6542, decode.d1.loss_cls: 0.0300, decode.d1.loss_mask: 0.6295, decode.d1.loss_dice: 0.6029, decode.d2.loss_cls: 0.0311, decode.d2.loss_mask: 0.6227, decode.d2.loss_dice: 0.5935, decode.d3.loss_cls: 0.0313, decode.d3.loss_mask: 0.6344, decode.d3.loss_dice: 0.5928, decode.d4.loss_cls: 0.0243, decode.d4.loss_mask: 0.6499, decode.d4.loss_dice: 0.5972, decode.d5.loss_cls: 0.0333, decode.d5.loss_mask: 0.6282, decode.d5.loss_dice: 0.5943, decode.d6.loss_cls: 0.0348, decode.d6.loss_mask: 0.6265, decode.d6.loss_dice: 0.5958, decode.d7.loss_cls: 0.0334, decode.d7.loss_mask: 0.6332, decode.d7.loss_dice: 0.5959, decode.d8.loss_cls: 0.0336, decode.d8.loss_mask: 0.6404, decode.d8.loss_dice: 0.5964, loss: 14.1327, grad_norm: 542.6760
2023-08-29 01:52:02,518 - mmseg - INFO - Iter [5600/160000]	lr: 1.624e-06, eta: 1 day, 7:21:21, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.5843, decode.loss_dice: 0.5986, decode.d0.loss_cls: 1.5000, decode.d0.loss_mask: 0.6247, decode.d0.loss_dice: 0.6767, decode.d1.loss_cls: 0.0073, decode.d1.loss_mask: 0.5997, decode.d1.loss_dice: 0.6196, decode.d2.loss_cls: 0.0045, decode.d2.loss_mask: 0.5888, decode.d2.loss_dice: 0.5992, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.5880, decode.d3.loss_dice: 0.5953, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.5859, decode.d4.loss_dice: 0.6064, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.5876, decode.d5.loss_dice: 0.5992, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.5936, decode.d6.loss_dice: 0.5951, decode.d7.loss_cls: 0.0041, decode.d7.loss_mask: 0.5880, decode.d7.loss_dice: 0.5982, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.5881, decode.d8.loss_dice: 0.5992, loss: 13.5529, grad_norm: 520.0003
2023-08-29 01:52:38,872 - mmseg - INFO - Iter [5650/160000]	lr: 1.624e-06, eta: 1 day, 7:20:39, time: 0.727, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5295, decode.loss_dice: 0.5629, decode.d0.loss_cls: 1.4883, decode.d0.loss_mask: 0.5676, decode.d0.loss_dice: 0.6439, decode.d1.loss_cls: 0.0063, decode.d1.loss_mask: 0.5310, decode.d1.loss_dice: 0.5773, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.5278, decode.d2.loss_dice: 0.5643, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.5322, decode.d3.loss_dice: 0.5625, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5313, decode.d4.loss_dice: 0.5675, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.5328, decode.d5.loss_dice: 0.5625, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.5346, decode.d6.loss_dice: 0.5617, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.5301, decode.d7.loss_dice: 0.5626, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.5271, decode.d8.loss_dice: 0.5603, loss: 12.5823, grad_norm: 522.8230
2023-08-29 01:53:15,879 - mmseg - INFO - Iter [5700/160000]	lr: 1.623e-06, eta: 1 day, 7:20:15, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.5834, decode.loss_dice: 0.5749, decode.d0.loss_cls: 1.4834, decode.d0.loss_mask: 0.5933, decode.d0.loss_dice: 0.6362, decode.d1.loss_cls: 0.0077, decode.d1.loss_mask: 0.5897, decode.d1.loss_dice: 0.5846, decode.d2.loss_cls: 0.0113, decode.d2.loss_mask: 0.5802, decode.d2.loss_dice: 0.5748, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.5896, decode.d3.loss_dice: 0.5751, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.5838, decode.d4.loss_dice: 0.5772, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.5815, decode.d5.loss_dice: 0.5744, decode.d6.loss_cls: 0.0042, decode.d6.loss_mask: 0.5871, decode.d6.loss_dice: 0.5768, decode.d7.loss_cls: 0.0037, decode.d7.loss_mask: 0.5791, decode.d7.loss_dice: 0.5743, decode.d8.loss_cls: 0.0032, decode.d8.loss_mask: 0.5813, decode.d8.loss_dice: 0.5729, loss: 13.1982, grad_norm: 473.5564
2023-08-29 01:53:53,151 - mmseg - INFO - Iter [5750/160000]	lr: 1.623e-06, eta: 1 day, 7:19:57, time: 0.745, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.5347, decode.loss_dice: 0.5396, decode.d0.loss_cls: 1.4765, decode.d0.loss_mask: 0.5724, decode.d0.loss_dice: 0.6139, decode.d1.loss_cls: 0.0135, decode.d1.loss_mask: 0.5184, decode.d1.loss_dice: 0.5571, decode.d2.loss_cls: 0.0125, decode.d2.loss_mask: 0.5169, decode.d2.loss_dice: 0.5440, decode.d3.loss_cls: 0.0040, decode.d3.loss_mask: 0.5318, decode.d3.loss_dice: 0.5358, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.5302, decode.d4.loss_dice: 0.5328, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.5327, decode.d5.loss_dice: 0.5340, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.5375, decode.d6.loss_dice: 0.5380, decode.d7.loss_cls: 0.0039, decode.d7.loss_mask: 0.5321, decode.d7.loss_dice: 0.5376, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.5335, decode.d8.loss_dice: 0.5357, loss: 12.3372, grad_norm: 490.1416
2023-08-29 01:54:28,207 - mmseg - INFO - Iter [5800/160000]	lr: 1.622e-06, eta: 1 day, 7:18:40, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.5815, decode.loss_dice: 0.5653, decode.d0.loss_cls: 1.4649, decode.d0.loss_mask: 0.5994, decode.d0.loss_dice: 0.6432, decode.d1.loss_cls: 0.0072, decode.d1.loss_mask: 0.5757, decode.d1.loss_dice: 0.5831, decode.d2.loss_cls: 0.0045, decode.d2.loss_mask: 0.5759, decode.d2.loss_dice: 0.5685, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.5794, decode.d3.loss_dice: 0.5647, decode.d4.loss_cls: 0.0032, decode.d4.loss_mask: 0.5756, decode.d4.loss_dice: 0.5676, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.5773, decode.d5.loss_dice: 0.5623, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.5756, decode.d6.loss_dice: 0.5663, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.5839, decode.d7.loss_dice: 0.5663, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.5833, decode.d8.loss_dice: 0.5731, loss: 13.0673, grad_norm: 531.6823
2023-08-29 01:55:04,916 - mmseg - INFO - Iter [5850/160000]	lr: 1.622e-06, eta: 1 day, 7:18:08, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.5452, decode.loss_dice: 0.5704, decode.d0.loss_cls: 1.4556, decode.d0.loss_mask: 0.5741, decode.d0.loss_dice: 0.6222, decode.d1.loss_cls: 0.0067, decode.d1.loss_mask: 0.5394, decode.d1.loss_dice: 0.5719, decode.d2.loss_cls: 0.0042, decode.d2.loss_mask: 0.5364, decode.d2.loss_dice: 0.5665, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.5389, decode.d3.loss_dice: 0.5696, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.5405, decode.d4.loss_dice: 0.5673, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.5395, decode.d5.loss_dice: 0.5676, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.5389, decode.d6.loss_dice: 0.5641, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.5462, decode.d7.loss_dice: 0.5677, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.5397, decode.d8.loss_dice: 0.5673, loss: 12.6600, grad_norm: 415.0846
2023-08-29 01:55:41,577 - mmseg - INFO - Iter [5900/160000]	lr: 1.621e-06, eta: 1 day, 7:17:35, time: 0.733, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.5684, decode.loss_dice: 0.5710, decode.d0.loss_cls: 1.4476, decode.d0.loss_mask: 0.5950, decode.d0.loss_dice: 0.6376, decode.d1.loss_cls: 0.0066, decode.d1.loss_mask: 0.5729, decode.d1.loss_dice: 0.5771, decode.d2.loss_cls: 0.0041, decode.d2.loss_mask: 0.5703, decode.d2.loss_dice: 0.5676, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.5685, decode.d3.loss_dice: 0.5642, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.5695, decode.d4.loss_dice: 0.5661, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.5681, decode.d5.loss_dice: 0.5657, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.5692, decode.d6.loss_dice: 0.5661, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.5725, decode.d7.loss_dice: 0.5709, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.5670, decode.d8.loss_dice: 0.5681, loss: 12.9541, grad_norm: 544.7599
2023-08-29 01:56:18,770 - mmseg - INFO - Iter [5950/160000]	lr: 1.621e-06, eta: 1 day, 7:17:15, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0193, decode.loss_mask: 0.6631, decode.loss_dice: 0.6373, decode.d0.loss_cls: 1.4390, decode.d0.loss_mask: 0.6820, decode.d0.loss_dice: 0.7020, decode.d1.loss_cls: 0.0252, decode.d1.loss_mask: 0.6287, decode.d1.loss_dice: 0.6454, decode.d2.loss_cls: 0.0242, decode.d2.loss_mask: 0.6217, decode.d2.loss_dice: 0.6368, decode.d3.loss_cls: 0.0184, decode.d3.loss_mask: 0.6329, decode.d3.loss_dice: 0.6341, decode.d4.loss_cls: 0.0188, decode.d4.loss_mask: 0.6567, decode.d4.loss_dice: 0.6331, decode.d5.loss_cls: 0.0197, decode.d5.loss_mask: 0.6372, decode.d5.loss_dice: 0.6379, decode.d6.loss_cls: 0.0203, decode.d6.loss_mask: 0.6335, decode.d6.loss_dice: 0.6342, decode.d7.loss_cls: 0.0197, decode.d7.loss_mask: 0.6568, decode.d7.loss_dice: 0.6345, decode.d8.loss_cls: 0.0196, decode.d8.loss_mask: 0.6550, decode.d8.loss_dice: 0.6341, loss: 14.5212, grad_norm: 512.6849
2023-08-29 01:56:53,594 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-08-29 01:56:56,086 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 01:56:56,087 - mmseg - INFO - Iter [6000/160000]	lr: 1.620e-06, eta: 1 day, 7:16:58, time: 0.746, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0149, decode.loss_mask: 0.5486, decode.loss_dice: 0.5778, decode.d0.loss_cls: 1.4319, decode.d0.loss_mask: 0.5630, decode.d0.loss_dice: 0.6532, decode.d1.loss_cls: 0.0171, decode.d1.loss_mask: 0.5462, decode.d1.loss_dice: 0.5925, decode.d2.loss_cls: 0.0170, decode.d2.loss_mask: 0.5389, decode.d2.loss_dice: 0.5742, decode.d3.loss_cls: 0.0165, decode.d3.loss_mask: 0.5397, decode.d3.loss_dice: 0.5679, decode.d4.loss_cls: 0.0168, decode.d4.loss_mask: 0.5421, decode.d4.loss_dice: 0.5781, decode.d5.loss_cls: 0.0176, decode.d5.loss_mask: 0.5459, decode.d5.loss_dice: 0.5781, decode.d6.loss_cls: 0.0185, decode.d6.loss_mask: 0.5457, decode.d6.loss_dice: 0.5732, decode.d7.loss_cls: 0.0163, decode.d7.loss_mask: 0.5506, decode.d7.loss_dice: 0.5806, decode.d8.loss_cls: 0.0173, decode.d8.loss_mask: 0.5478, decode.d8.loss_dice: 0.5780, loss: 12.9062, grad_norm: 565.5632
2023-08-29 01:57:33,057 - mmseg - INFO - Iter [6050/160000]	lr: 1.620e-06, eta: 1 day, 7:16:31, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.5350, decode.loss_dice: 0.5459, decode.d0.loss_cls: 1.4225, decode.d0.loss_mask: 0.5675, decode.d0.loss_dice: 0.6250, decode.d1.loss_cls: 0.0064, decode.d1.loss_mask: 0.5388, decode.d1.loss_dice: 0.5579, decode.d2.loss_cls: 0.0042, decode.d2.loss_mask: 0.5362, decode.d2.loss_dice: 0.5412, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.5335, decode.d3.loss_dice: 0.5416, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.5322, decode.d4.loss_dice: 0.5437, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.5332, decode.d5.loss_dice: 0.5438, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.5353, decode.d6.loss_dice: 0.5450, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.5329, decode.d7.loss_dice: 0.5497, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.5341, decode.d8.loss_dice: 0.5486, loss: 12.3759, grad_norm: 536.4779
2023-08-29 01:58:09,674 - mmseg - INFO - Iter [6100/160000]	lr: 1.619e-06, eta: 1 day, 7:15:56, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.5229, decode.loss_dice: 0.5280, decode.d0.loss_cls: 1.4143, decode.d0.loss_mask: 0.5618, decode.d0.loss_dice: 0.6150, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.5268, decode.d1.loss_dice: 0.5545, decode.d2.loss_cls: 0.0049, decode.d2.loss_mask: 0.5200, decode.d2.loss_dice: 0.5331, decode.d3.loss_cls: 0.0039, decode.d3.loss_mask: 0.5197, decode.d3.loss_dice: 0.5271, decode.d4.loss_cls: 0.0036, decode.d4.loss_mask: 0.5217, decode.d4.loss_dice: 0.5266, decode.d5.loss_cls: 0.0035, decode.d5.loss_mask: 0.5171, decode.d5.loss_dice: 0.5258, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.5215, decode.d6.loss_dice: 0.5257, decode.d7.loss_cls: 0.0037, decode.d7.loss_mask: 0.5209, decode.d7.loss_dice: 0.5278, decode.d8.loss_cls: 0.0032, decode.d8.loss_mask: 0.5195, decode.d8.loss_dice: 0.5245, loss: 12.0914, grad_norm: 455.6749
2023-08-29 01:58:46,779 - mmseg - INFO - Iter [6150/160000]	lr: 1.619e-06, eta: 1 day, 7:15:33, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0043, decode.loss_mask: 0.5038, decode.loss_dice: 0.5132, decode.d0.loss_cls: 1.4074, decode.d0.loss_mask: 0.5338, decode.d0.loss_dice: 0.5893, decode.d1.loss_cls: 0.0070, decode.d1.loss_mask: 0.5120, decode.d1.loss_dice: 0.5289, decode.d2.loss_cls: 0.0051, decode.d2.loss_mask: 0.5045, decode.d2.loss_dice: 0.5162, decode.d3.loss_cls: 0.0044, decode.d3.loss_mask: 0.5035, decode.d3.loss_dice: 0.5131, decode.d4.loss_cls: 0.0039, decode.d4.loss_mask: 0.5026, decode.d4.loss_dice: 0.5121, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.5013, decode.d5.loss_dice: 0.5103, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.4976, decode.d6.loss_dice: 0.5116, decode.d7.loss_cls: 0.0043, decode.d7.loss_mask: 0.5021, decode.d7.loss_dice: 0.5125, decode.d8.loss_cls: 0.0042, decode.d8.loss_mask: 0.5016, decode.d8.loss_dice: 0.5131, loss: 11.7326, grad_norm: 518.4684
2023-08-29 01:59:21,918 - mmseg - INFO - Iter [6200/160000]	lr: 1.618e-06, eta: 1 day, 7:14:21, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5360, decode.loss_dice: 0.5432, decode.d0.loss_cls: 1.3970, decode.d0.loss_mask: 0.5467, decode.d0.loss_dice: 0.6126, decode.d1.loss_cls: 0.0059, decode.d1.loss_mask: 0.5316, decode.d1.loss_dice: 0.5595, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.5339, decode.d2.loss_dice: 0.5451, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.5384, decode.d3.loss_dice: 0.5433, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.5406, decode.d4.loss_dice: 0.5479, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.5327, decode.d5.loss_dice: 0.5453, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.5360, decode.d6.loss_dice: 0.5451, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.5315, decode.d7.loss_dice: 0.5452, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.5311, decode.d8.loss_dice: 0.5464, loss: 12.3153, grad_norm: 563.0632
2023-08-29 01:59:58,754 - mmseg - INFO - Iter [6250/160000]	lr: 1.617e-06, eta: 1 day, 7:13:51, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.5139, decode.loss_dice: 0.5246, decode.d0.loss_cls: 1.3896, decode.d0.loss_mask: 0.5545, decode.d0.loss_dice: 0.6034, decode.d1.loss_cls: 0.0052, decode.d1.loss_mask: 0.5209, decode.d1.loss_dice: 0.5408, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.5149, decode.d2.loss_dice: 0.5218, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.5173, decode.d3.loss_dice: 0.5230, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5161, decode.d4.loss_dice: 0.5227, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.5167, decode.d5.loss_dice: 0.5208, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.5175, decode.d6.loss_dice: 0.5221, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.5186, decode.d7.loss_dice: 0.5219, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.5144, decode.d8.loss_dice: 0.5214, loss: 11.9394, grad_norm: 578.0287
2023-08-29 02:00:35,337 - mmseg - INFO - Iter [6300/160000]	lr: 1.617e-06, eta: 1 day, 7:13:15, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0011, decode.loss_mask: 0.5827, decode.loss_dice: 0.5778, decode.d0.loss_cls: 1.3794, decode.d0.loss_mask: 0.5929, decode.d0.loss_dice: 0.6420, decode.d1.loss_cls: 0.0048, decode.d1.loss_mask: 0.5886, decode.d1.loss_dice: 0.5870, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.5886, decode.d2.loss_dice: 0.5805, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.5873, decode.d3.loss_dice: 0.5763, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.5913, decode.d4.loss_dice: 0.5738, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.5886, decode.d5.loss_dice: 0.5773, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.5827, decode.d6.loss_dice: 0.5763, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.5863, decode.d7.loss_dice: 0.5783, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.5857, decode.d8.loss_dice: 0.5795, loss: 13.1220, grad_norm: 510.7440
2023-08-29 02:01:12,437 - mmseg - INFO - Iter [6350/160000]	lr: 1.616e-06, eta: 1 day, 7:12:51, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0175, decode.loss_mask: 0.5701, decode.loss_dice: 0.5592, decode.d0.loss_cls: 1.3725, decode.d0.loss_mask: 0.5816, decode.d0.loss_dice: 0.6238, decode.d1.loss_cls: 0.0176, decode.d1.loss_mask: 0.5677, decode.d1.loss_dice: 0.5699, decode.d2.loss_cls: 0.0152, decode.d2.loss_mask: 0.5563, decode.d2.loss_dice: 0.5550, decode.d3.loss_cls: 0.0163, decode.d3.loss_mask: 0.5588, decode.d3.loss_dice: 0.5538, decode.d4.loss_cls: 0.0170, decode.d4.loss_mask: 0.5644, decode.d4.loss_dice: 0.5582, decode.d5.loss_cls: 0.0173, decode.d5.loss_mask: 0.5607, decode.d5.loss_dice: 0.5615, decode.d6.loss_cls: 0.0187, decode.d6.loss_mask: 0.5615, decode.d6.loss_dice: 0.5569, decode.d7.loss_cls: 0.0101, decode.d7.loss_mask: 0.5826, decode.d7.loss_dice: 0.5585, decode.d8.loss_cls: 0.0103, decode.d8.loss_mask: 0.5816, decode.d8.loss_dice: 0.5594, loss: 12.8541, grad_norm: 444.3050
2023-08-29 02:01:47,350 - mmseg - INFO - Iter [6400/160000]	lr: 1.616e-06, eta: 1 day, 7:11:35, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0167, decode.loss_mask: 0.5472, decode.loss_dice: 0.5768, decode.d0.loss_cls: 1.3663, decode.d0.loss_mask: 0.5899, decode.d0.loss_dice: 0.6447, decode.d1.loss_cls: 0.0198, decode.d1.loss_mask: 0.5473, decode.d1.loss_dice: 0.5919, decode.d2.loss_cls: 0.0176, decode.d2.loss_mask: 0.5437, decode.d2.loss_dice: 0.5816, decode.d3.loss_cls: 0.0158, decode.d3.loss_mask: 0.5463, decode.d3.loss_dice: 0.5804, decode.d4.loss_cls: 0.0169, decode.d4.loss_mask: 0.5484, decode.d4.loss_dice: 0.5757, decode.d5.loss_cls: 0.0163, decode.d5.loss_mask: 0.5459, decode.d5.loss_dice: 0.5736, decode.d6.loss_cls: 0.0154, decode.d6.loss_mask: 0.5470, decode.d6.loss_dice: 0.5747, decode.d7.loss_cls: 0.0094, decode.d7.loss_mask: 0.5580, decode.d7.loss_dice: 0.5821, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 0.5565, decode.d8.loss_dice: 0.5795, loss: 12.8947, grad_norm: 454.4619
2023-08-29 02:02:23,950 - mmseg - INFO - Iter [6450/160000]	lr: 1.615e-06, eta: 1 day, 7:10:59, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0057, decode.loss_mask: 0.5383, decode.loss_dice: 0.5400, decode.d0.loss_cls: 1.3548, decode.d0.loss_mask: 0.5596, decode.d0.loss_dice: 0.6048, decode.d1.loss_cls: 0.0055, decode.d1.loss_mask: 0.5434, decode.d1.loss_dice: 0.5529, decode.d2.loss_cls: 0.0045, decode.d2.loss_mask: 0.5421, decode.d2.loss_dice: 0.5409, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.5403, decode.d3.loss_dice: 0.5345, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.5423, decode.d4.loss_dice: 0.5353, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.5341, decode.d5.loss_dice: 0.5328, decode.d6.loss_cls: 0.0057, decode.d6.loss_mask: 0.5348, decode.d6.loss_dice: 0.5421, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.5402, decode.d7.loss_dice: 0.5453, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 0.5395, decode.d8.loss_dice: 0.5440, loss: 12.2849, grad_norm: 527.0753
2023-08-29 02:03:00,537 - mmseg - INFO - Iter [6500/160000]	lr: 1.615e-06, eta: 1 day, 7:10:24, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5375, decode.loss_dice: 0.5403, decode.d0.loss_cls: 1.3456, decode.d0.loss_mask: 0.5490, decode.d0.loss_dice: 0.6012, decode.d1.loss_cls: 0.0050, decode.d1.loss_mask: 0.5340, decode.d1.loss_dice: 0.5495, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.5354, decode.d2.loss_dice: 0.5389, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.5383, decode.d3.loss_dice: 0.5377, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5352, decode.d4.loss_dice: 0.5382, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.5403, decode.d5.loss_dice: 0.5377, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.5423, decode.d6.loss_dice: 0.5407, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.5397, decode.d7.loss_dice: 0.5412, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.5392, decode.d8.loss_dice: 0.5416, loss: 12.2268, grad_norm: 483.8656
2023-08-29 02:03:37,634 - mmseg - INFO - Iter [6550/160000]	lr: 1.614e-06, eta: 1 day, 7:10:00, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0194, decode.loss_mask: 0.6150, decode.loss_dice: 0.5976, decode.d0.loss_cls: 1.3380, decode.d0.loss_mask: 0.5956, decode.d0.loss_dice: 0.6580, decode.d1.loss_cls: 0.0257, decode.d1.loss_mask: 0.5895, decode.d1.loss_dice: 0.6104, decode.d2.loss_cls: 0.0169, decode.d2.loss_mask: 0.5966, decode.d2.loss_dice: 0.6029, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.6017, decode.d3.loss_dice: 0.5996, decode.d4.loss_cls: 0.0183, decode.d4.loss_mask: 0.6090, decode.d4.loss_dice: 0.6009, decode.d5.loss_cls: 0.0167, decode.d5.loss_mask: 0.6099, decode.d5.loss_dice: 0.5998, decode.d6.loss_cls: 0.0177, decode.d6.loss_mask: 0.6188, decode.d6.loss_dice: 0.6033, decode.d7.loss_cls: 0.0144, decode.d7.loss_mask: 0.6399, decode.d7.loss_dice: 0.5986, decode.d8.loss_cls: 0.0186, decode.d8.loss_mask: 0.6274, decode.d8.loss_dice: 0.5977, loss: 13.6758, grad_norm: 503.1805
2023-08-29 02:04:12,828 - mmseg - INFO - Iter [6600/160000]	lr: 1.614e-06, eta: 1 day, 7:08:51, time: 0.704, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0137, decode.loss_mask: 0.5635, decode.loss_dice: 0.5613, decode.d0.loss_cls: 1.3295, decode.d0.loss_mask: 0.5573, decode.d0.loss_dice: 0.6105, decode.d1.loss_cls: 0.0158, decode.d1.loss_mask: 0.5559, decode.d1.loss_dice: 0.5661, decode.d2.loss_cls: 0.0160, decode.d2.loss_mask: 0.5537, decode.d2.loss_dice: 0.5602, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.5562, decode.d3.loss_dice: 0.5563, decode.d4.loss_cls: 0.0169, decode.d4.loss_mask: 0.5602, decode.d4.loss_dice: 0.5580, decode.d5.loss_cls: 0.0147, decode.d5.loss_mask: 0.5644, decode.d5.loss_dice: 0.5643, decode.d6.loss_cls: 0.0171, decode.d6.loss_mask: 0.5649, decode.d6.loss_dice: 0.5589, decode.d7.loss_cls: 0.0178, decode.d7.loss_mask: 0.5655, decode.d7.loss_dice: 0.5609, decode.d8.loss_cls: 0.0171, decode.d8.loss_mask: 0.5643, decode.d8.loss_dice: 0.5643, loss: 12.7427, grad_norm: 466.2806
2023-08-29 02:04:49,797 - mmseg - INFO - Iter [6650/160000]	lr: 1.613e-06, eta: 1 day, 7:08:25, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.4934, decode.loss_dice: 0.4924, decode.d0.loss_cls: 1.3182, decode.d0.loss_mask: 0.5111, decode.d0.loss_dice: 0.5554, decode.d1.loss_cls: 0.0051, decode.d1.loss_mask: 0.4939, decode.d1.loss_dice: 0.5010, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.4913, decode.d2.loss_dice: 0.4927, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.4901, decode.d3.loss_dice: 0.4873, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4943, decode.d4.loss_dice: 0.4893, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.4899, decode.d5.loss_dice: 0.4933, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.4906, decode.d6.loss_dice: 0.4904, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.4935, decode.d7.loss_dice: 0.4909, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.4917, decode.d8.loss_dice: 0.4923, loss: 11.2726, grad_norm: 436.7580
2023-08-29 02:05:26,146 - mmseg - INFO - Iter [6700/160000]	lr: 1.613e-06, eta: 1 day, 7:07:44, time: 0.727, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.5949, decode.loss_dice: 0.5511, decode.d0.loss_cls: 1.3118, decode.d0.loss_mask: 0.5998, decode.d0.loss_dice: 0.6046, decode.d1.loss_cls: 0.0057, decode.d1.loss_mask: 0.6013, decode.d1.loss_dice: 0.5548, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.5961, decode.d2.loss_dice: 0.5518, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.5943, decode.d3.loss_dice: 0.5501, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.5960, decode.d4.loss_dice: 0.5517, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.5923, decode.d5.loss_dice: 0.5534, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.5959, decode.d6.loss_dice: 0.5522, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.5952, decode.d7.loss_dice: 0.5488, decode.d8.loss_cls: 0.0028, decode.d8.loss_mask: 0.5979, decode.d8.loss_dice: 0.5510, loss: 12.8775, grad_norm: 536.5857
2023-08-29 02:06:03,361 - mmseg - INFO - Iter [6750/160000]	lr: 1.612e-06, eta: 1 day, 7:07:22, time: 0.744, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0165, decode.loss_mask: 0.5273, decode.loss_dice: 0.5411, decode.d0.loss_cls: 1.3040, decode.d0.loss_mask: 0.5363, decode.d0.loss_dice: 0.5939, decode.d1.loss_cls: 0.0159, decode.d1.loss_mask: 0.5353, decode.d1.loss_dice: 0.5467, decode.d2.loss_cls: 0.0148, decode.d2.loss_mask: 0.5319, decode.d2.loss_dice: 0.5388, decode.d3.loss_cls: 0.0142, decode.d3.loss_mask: 0.5302, decode.d3.loss_dice: 0.5376, decode.d4.loss_cls: 0.0153, decode.d4.loss_mask: 0.5278, decode.d4.loss_dice: 0.5394, decode.d5.loss_cls: 0.0084, decode.d5.loss_mask: 0.5463, decode.d5.loss_dice: 0.5348, decode.d6.loss_cls: 0.0099, decode.d6.loss_mask: 0.5563, decode.d6.loss_dice: 0.5347, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.5492, decode.d7.loss_dice: 0.5387, decode.d8.loss_cls: 0.0165, decode.d8.loss_mask: 0.5287, decode.d8.loss_dice: 0.5393, loss: 12.2373, grad_norm: 546.9732
2023-08-29 02:06:40,572 - mmseg - INFO - Iter [6800/160000]	lr: 1.612e-06, eta: 1 day, 7:07:00, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0091, decode.loss_mask: 0.5374, decode.loss_dice: 0.5397, decode.d0.loss_cls: 1.2968, decode.d0.loss_mask: 0.5486, decode.d0.loss_dice: 0.5904, decode.d1.loss_cls: 0.0153, decode.d1.loss_mask: 0.5367, decode.d1.loss_dice: 0.5442, decode.d2.loss_cls: 0.0083, decode.d2.loss_mask: 0.5368, decode.d2.loss_dice: 0.5376, decode.d3.loss_cls: 0.0074, decode.d3.loss_mask: 0.5353, decode.d3.loss_dice: 0.5339, decode.d4.loss_cls: 0.0058, decode.d4.loss_mask: 0.5353, decode.d4.loss_dice: 0.5389, decode.d5.loss_cls: 0.0112, decode.d5.loss_mask: 0.5270, decode.d5.loss_dice: 0.5418, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.5387, decode.d6.loss_dice: 0.5376, decode.d7.loss_cls: 0.0038, decode.d7.loss_mask: 0.5338, decode.d7.loss_dice: 0.5394, decode.d8.loss_cls: 0.0096, decode.d8.loss_mask: 0.5396, decode.d8.loss_dice: 0.5390, loss: 12.1834, grad_norm: 542.9899
2023-08-29 02:07:15,173 - mmseg - INFO - Iter [6850/160000]	lr: 1.611e-06, eta: 1 day, 7:05:40, time: 0.692, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.5049, decode.loss_dice: 0.5300, decode.d0.loss_cls: 1.2859, decode.d0.loss_mask: 0.5234, decode.d0.loss_dice: 0.5969, decode.d1.loss_cls: 0.0046, decode.d1.loss_mask: 0.5017, decode.d1.loss_dice: 0.5439, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.5011, decode.d2.loss_dice: 0.5359, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4983, decode.d3.loss_dice: 0.5303, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5025, decode.d4.loss_dice: 0.5334, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.5004, decode.d5.loss_dice: 0.5335, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.5006, decode.d6.loss_dice: 0.5280, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.5002, decode.d7.loss_dice: 0.5286, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.4975, decode.d8.loss_dice: 0.5286, loss: 11.7289, grad_norm: 462.4180
2023-08-29 02:07:51,619 - mmseg - INFO - Iter [6900/160000]	lr: 1.611e-06, eta: 1 day, 7:05:01, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.5001, decode.loss_dice: 0.5003, decode.d0.loss_cls: 1.2801, decode.d0.loss_mask: 0.4966, decode.d0.loss_dice: 0.5377, decode.d1.loss_cls: 0.0110, decode.d1.loss_mask: 0.4839, decode.d1.loss_dice: 0.4980, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.4824, decode.d2.loss_dice: 0.4904, decode.d3.loss_cls: 0.0096, decode.d3.loss_mask: 0.4857, decode.d3.loss_dice: 0.4954, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4970, decode.d4.loss_dice: 0.4995, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4984, decode.d5.loss_dice: 0.4996, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.4984, decode.d6.loss_dice: 0.5000, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.5022, decode.d7.loss_dice: 0.5028, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.4981, decode.d8.loss_dice: 0.5019, loss: 11.2918, grad_norm: 515.4386
2023-08-29 02:08:28,641 - mmseg - INFO - Iter [6950/160000]	lr: 1.610e-06, eta: 1 day, 7:04:35, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4837, decode.loss_dice: 0.4956, decode.d0.loss_cls: 1.2710, decode.d0.loss_mask: 0.5209, decode.d0.loss_dice: 0.5656, decode.d1.loss_cls: 0.0052, decode.d1.loss_mask: 0.4930, decode.d1.loss_dice: 0.5109, decode.d2.loss_cls: 0.0034, decode.d2.loss_mask: 0.4896, decode.d2.loss_dice: 0.5042, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.4878, decode.d3.loss_dice: 0.5004, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4881, decode.d4.loss_dice: 0.4982, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.4892, decode.d5.loss_dice: 0.5013, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.4887, decode.d6.loss_dice: 0.4917, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4861, decode.d7.loss_dice: 0.4950, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.4852, decode.d8.loss_dice: 0.4981, loss: 11.2696, grad_norm: 515.0075
2023-08-29 02:09:05,606 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-08-29 02:09:07,793 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 02:09:07,794 - mmseg - INFO - Iter [7000/160000]	lr: 1.610e-06, eta: 1 day, 7:04:56, time: 0.783, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0171, decode.loss_mask: 0.5313, decode.loss_dice: 0.5186, decode.d0.loss_cls: 1.2648, decode.d0.loss_mask: 0.5578, decode.d0.loss_dice: 0.5771, decode.d1.loss_cls: 0.0175, decode.d1.loss_mask: 0.5451, decode.d1.loss_dice: 0.5352, decode.d2.loss_cls: 0.0166, decode.d2.loss_mask: 0.5349, decode.d2.loss_dice: 0.5191, decode.d3.loss_cls: 0.0173, decode.d3.loss_mask: 0.5341, decode.d3.loss_dice: 0.5183, decode.d4.loss_cls: 0.0157, decode.d4.loss_mask: 0.5306, decode.d4.loss_dice: 0.5171, decode.d5.loss_cls: 0.0162, decode.d5.loss_mask: 0.5296, decode.d5.loss_dice: 0.5200, decode.d6.loss_cls: 0.0152, decode.d6.loss_mask: 0.5312, decode.d6.loss_dice: 0.5151, decode.d7.loss_cls: 0.0105, decode.d7.loss_mask: 0.5296, decode.d7.loss_dice: 0.5232, decode.d8.loss_cls: 0.0189, decode.d8.loss_mask: 0.5289, decode.d8.loss_dice: 0.5201, loss: 12.0268, grad_norm: 483.9649
2023-08-29 02:09:42,744 - mmseg - INFO - Iter [7050/160000]	lr: 1.609e-06, eta: 1 day, 7:03:44, time: 0.699, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0139, decode.loss_mask: 0.5068, decode.loss_dice: 0.5005, decode.d0.loss_cls: 1.2561, decode.d0.loss_mask: 0.5211, decode.d0.loss_dice: 0.5516, decode.d1.loss_cls: 0.0168, decode.d1.loss_mask: 0.4970, decode.d1.loss_dice: 0.5028, decode.d2.loss_cls: 0.0151, decode.d2.loss_mask: 0.4983, decode.d2.loss_dice: 0.5005, decode.d3.loss_cls: 0.0121, decode.d3.loss_mask: 0.5016, decode.d3.loss_dice: 0.4978, decode.d4.loss_cls: 0.0092, decode.d4.loss_mask: 0.5133, decode.d4.loss_dice: 0.4968, decode.d5.loss_cls: 0.0135, decode.d5.loss_mask: 0.5051, decode.d5.loss_dice: 0.5003, decode.d6.loss_cls: 0.0164, decode.d6.loss_mask: 0.5054, decode.d6.loss_dice: 0.4981, decode.d7.loss_cls: 0.0193, decode.d7.loss_mask: 0.5055, decode.d7.loss_dice: 0.5026, decode.d8.loss_cls: 0.0110, decode.d8.loss_mask: 0.5116, decode.d8.loss_dice: 0.5022, loss: 11.5021, grad_norm: 466.5375
2023-08-29 02:10:19,206 - mmseg - INFO - Iter [7100/160000]	lr: 1.609e-06, eta: 1 day, 7:03:05, time: 0.729, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.4936, decode.loss_dice: 0.5087, decode.d0.loss_cls: 1.2469, decode.d0.loss_mask: 0.5290, decode.d0.loss_dice: 0.5660, decode.d1.loss_cls: 0.0058, decode.d1.loss_mask: 0.5015, decode.d1.loss_dice: 0.5150, decode.d2.loss_cls: 0.0041, decode.d2.loss_mask: 0.4886, decode.d2.loss_dice: 0.5081, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.4889, decode.d3.loss_dice: 0.5071, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.4939, decode.d4.loss_dice: 0.5104, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.4927, decode.d5.loss_dice: 0.5089, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.4942, decode.d6.loss_dice: 0.5091, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.4930, decode.d7.loss_dice: 0.5090, decode.d8.loss_cls: 0.0032, decode.d8.loss_mask: 0.4908, decode.d8.loss_dice: 0.5085, loss: 11.3992, grad_norm: 443.1663
2023-08-29 02:10:56,373 - mmseg - INFO - Iter [7150/160000]	lr: 1.608e-06, eta: 1 day, 7:02:42, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.5242, decode.loss_dice: 0.5488, decode.d0.loss_cls: 1.2378, decode.d0.loss_mask: 0.5455, decode.d0.loss_dice: 0.5859, decode.d1.loss_cls: 0.0046, decode.d1.loss_mask: 0.5224, decode.d1.loss_dice: 0.5551, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.5199, decode.d2.loss_dice: 0.5494, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.5217, decode.d3.loss_dice: 0.5470, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.5180, decode.d4.loss_dice: 0.5441, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.5244, decode.d5.loss_dice: 0.5492, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.5262, decode.d6.loss_dice: 0.5516, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.5262, decode.d7.loss_dice: 0.5502, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.5246, decode.d8.loss_dice: 0.5496, loss: 12.0497, grad_norm: 463.7627
2023-08-29 02:11:33,735 - mmseg - INFO - Iter [7200/160000]	lr: 1.607e-06, eta: 1 day, 7:02:22, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0180, decode.loss_mask: 0.5041, decode.loss_dice: 0.4882, decode.d0.loss_cls: 1.2317, decode.d0.loss_mask: 0.5214, decode.d0.loss_dice: 0.5359, decode.d1.loss_cls: 0.0193, decode.d1.loss_mask: 0.5039, decode.d1.loss_dice: 0.4959, decode.d2.loss_cls: 0.0183, decode.d2.loss_mask: 0.5014, decode.d2.loss_dice: 0.4857, decode.d3.loss_cls: 0.0157, decode.d3.loss_mask: 0.5052, decode.d3.loss_dice: 0.4862, decode.d4.loss_cls: 0.0191, decode.d4.loss_mask: 0.5027, decode.d4.loss_dice: 0.4822, decode.d5.loss_cls: 0.0194, decode.d5.loss_mask: 0.5025, decode.d5.loss_dice: 0.4855, decode.d6.loss_cls: 0.0180, decode.d6.loss_mask: 0.5057, decode.d6.loss_dice: 0.4856, decode.d7.loss_cls: 0.0174, decode.d7.loss_mask: 0.5053, decode.d7.loss_dice: 0.4826, decode.d8.loss_cls: 0.0187, decode.d8.loss_mask: 0.5019, decode.d8.loss_dice: 0.4840, loss: 11.3618, grad_norm: 495.7939
2023-08-29 02:12:08,861 - mmseg - INFO - Iter [7250/160000]	lr: 1.607e-06, eta: 1 day, 7:01:15, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0239, decode.loss_mask: 0.5002, decode.loss_dice: 0.5309, decode.d0.loss_cls: 1.2253, decode.d0.loss_mask: 0.5196, decode.d0.loss_dice: 0.5809, decode.d1.loss_cls: 0.0185, decode.d1.loss_mask: 0.5045, decode.d1.loss_dice: 0.5298, decode.d2.loss_cls: 0.0148, decode.d2.loss_mask: 0.4988, decode.d2.loss_dice: 0.5216, decode.d3.loss_cls: 0.0141, decode.d3.loss_mask: 0.4940, decode.d3.loss_dice: 0.5155, decode.d4.loss_cls: 0.0161, decode.d4.loss_mask: 0.4936, decode.d4.loss_dice: 0.5178, decode.d5.loss_cls: 0.0124, decode.d5.loss_mask: 0.4957, decode.d5.loss_dice: 0.5220, decode.d6.loss_cls: 0.0141, decode.d6.loss_mask: 0.4933, decode.d6.loss_dice: 0.5221, decode.d7.loss_cls: 0.0150, decode.d7.loss_mask: 0.5000, decode.d7.loss_dice: 0.5259, decode.d8.loss_cls: 0.0188, decode.d8.loss_mask: 0.4946, decode.d8.loss_dice: 0.5240, loss: 11.6579, grad_norm: 542.3633
2023-08-29 02:12:45,271 - mmseg - INFO - Iter [7300/160000]	lr: 1.606e-06, eta: 1 day, 7:00:36, time: 0.728, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0044, decode.loss_mask: 0.4666, decode.loss_dice: 0.4597, decode.d0.loss_cls: 1.2169, decode.d0.loss_mask: 0.4842, decode.d0.loss_dice: 0.5181, decode.d1.loss_cls: 0.0054, decode.d1.loss_mask: 0.4647, decode.d1.loss_dice: 0.4728, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.4596, decode.d2.loss_dice: 0.4621, decode.d3.loss_cls: 0.0032, decode.d3.loss_mask: 0.4610, decode.d3.loss_dice: 0.4590, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.4592, decode.d4.loss_dice: 0.4628, decode.d5.loss_cls: 0.0031, decode.d5.loss_mask: 0.4590, decode.d5.loss_dice: 0.4604, decode.d6.loss_cls: 0.0038, decode.d6.loss_mask: 0.4596, decode.d6.loss_dice: 0.4609, decode.d7.loss_cls: 0.0039, decode.d7.loss_mask: 0.4686, decode.d7.loss_dice: 0.4602, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.4687, decode.d8.loss_dice: 0.4628, loss: 10.5807, grad_norm: 449.5313
2023-08-29 02:13:22,432 - mmseg - INFO - Iter [7350/160000]	lr: 1.606e-06, eta: 1 day, 7:00:12, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.4963, decode.loss_dice: 0.4797, decode.d0.loss_cls: 1.2074, decode.d0.loss_mask: 0.5144, decode.d0.loss_dice: 0.5272, decode.d1.loss_cls: 0.0048, decode.d1.loss_mask: 0.4982, decode.d1.loss_dice: 0.4904, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4944, decode.d2.loss_dice: 0.4819, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4959, decode.d3.loss_dice: 0.4801, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.4954, decode.d4.loss_dice: 0.4801, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4957, decode.d5.loss_dice: 0.4783, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.4955, decode.d6.loss_dice: 0.4820, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4964, decode.d7.loss_dice: 0.4798, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.4933, decode.d8.loss_dice: 0.4818, loss: 11.0686, grad_norm: 484.4268
2023-08-29 02:13:59,462 - mmseg - INFO - Iter [7400/160000]	lr: 1.605e-06, eta: 1 day, 6:59:45, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0029, decode.loss_mask: 0.5175, decode.loss_dice: 0.5206, decode.d0.loss_cls: 1.2006, decode.d0.loss_mask: 0.5489, decode.d0.loss_dice: 0.5663, decode.d1.loss_cls: 0.0057, decode.d1.loss_mask: 0.5183, decode.d1.loss_dice: 0.5231, decode.d2.loss_cls: 0.0040, decode.d2.loss_mask: 0.5128, decode.d2.loss_dice: 0.5124, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.5148, decode.d3.loss_dice: 0.5143, decode.d4.loss_cls: 0.0031, decode.d4.loss_mask: 0.5131, decode.d4.loss_dice: 0.5171, decode.d5.loss_cls: 0.0030, decode.d5.loss_mask: 0.5114, decode.d5.loss_dice: 0.5149, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.5123, decode.d6.loss_dice: 0.5176, decode.d7.loss_cls: 0.0034, decode.d7.loss_mask: 0.5165, decode.d7.loss_dice: 0.5236, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.5163, decode.d8.loss_dice: 0.5202, loss: 11.6447, grad_norm: 490.6457
2023-08-29 02:14:34,105 - mmseg - INFO - Iter [7450/160000]	lr: 1.605e-06, eta: 1 day, 6:58:29, time: 0.693, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.4877, decode.loss_dice: 0.5348, decode.d0.loss_cls: 1.1932, decode.d0.loss_mask: 0.5066, decode.d0.loss_dice: 0.5948, decode.d1.loss_cls: 0.0052, decode.d1.loss_mask: 0.4892, decode.d1.loss_dice: 0.5465, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.4874, decode.d2.loss_dice: 0.5397, decode.d3.loss_cls: 0.0029, decode.d3.loss_mask: 0.4876, decode.d3.loss_dice: 0.5341, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4876, decode.d4.loss_dice: 0.5378, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.4858, decode.d5.loss_dice: 0.5367, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.4850, decode.d6.loss_dice: 0.5358, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.4860, decode.d7.loss_dice: 0.5345, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.4833, decode.d8.loss_dice: 0.5314, loss: 11.5327, grad_norm: 465.5303
2023-08-29 02:15:10,571 - mmseg - INFO - Iter [7500/160000]	lr: 1.604e-06, eta: 1 day, 6:57:51, time: 0.729, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.5262, decode.loss_dice: 0.4975, decode.d0.loss_cls: 1.1835, decode.d0.loss_mask: 0.5243, decode.d0.loss_dice: 0.5298, decode.d1.loss_cls: 0.0045, decode.d1.loss_mask: 0.5256, decode.d1.loss_dice: 0.4980, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.5237, decode.d2.loss_dice: 0.4917, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.5241, decode.d3.loss_dice: 0.4924, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.5221, decode.d4.loss_dice: 0.4935, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.5262, decode.d5.loss_dice: 0.4926, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.5291, decode.d6.loss_dice: 0.4947, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.5266, decode.d7.loss_dice: 0.4953, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.5275, decode.d8.loss_dice: 0.4970, loss: 11.4421, grad_norm: 502.9596
2023-08-29 02:15:47,636 - mmseg - INFO - Iter [7550/160000]	lr: 1.604e-06, eta: 1 day, 6:57:25, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5035, decode.loss_dice: 0.5224, decode.d0.loss_cls: 1.1768, decode.d0.loss_mask: 0.5194, decode.d0.loss_dice: 0.5803, decode.d1.loss_cls: 0.0044, decode.d1.loss_mask: 0.5023, decode.d1.loss_dice: 0.5360, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.5031, decode.d2.loss_dice: 0.5245, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.5042, decode.d3.loss_dice: 0.5198, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5079, decode.d4.loss_dice: 0.5211, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.5043, decode.d5.loss_dice: 0.5217, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.5061, decode.d6.loss_dice: 0.5196, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.5085, decode.d7.loss_dice: 0.5188, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.5021, decode.d8.loss_dice: 0.5222, loss: 11.5464, grad_norm: 506.9706
2023-08-29 02:16:25,027 - mmseg - INFO - Iter [7600/160000]	lr: 1.603e-06, eta: 1 day, 6:57:05, time: 0.748, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0212, decode.loss_mask: 0.5313, decode.loss_dice: 0.5199, decode.d0.loss_cls: 1.1715, decode.d0.loss_mask: 0.5510, decode.d0.loss_dice: 0.5789, decode.d1.loss_cls: 0.0234, decode.d1.loss_mask: 0.5404, decode.d1.loss_dice: 0.5338, decode.d2.loss_cls: 0.0163, decode.d2.loss_mask: 0.5337, decode.d2.loss_dice: 0.5257, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.5338, decode.d3.loss_dice: 0.5210, decode.d4.loss_cls: 0.0168, decode.d4.loss_mask: 0.5375, decode.d4.loss_dice: 0.5239, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 0.5328, decode.d5.loss_dice: 0.5215, decode.d6.loss_cls: 0.0140, decode.d6.loss_mask: 0.5334, decode.d6.loss_dice: 0.5186, decode.d7.loss_cls: 0.0105, decode.d7.loss_mask: 0.5368, decode.d7.loss_dice: 0.5216, decode.d8.loss_cls: 0.0155, decode.d8.loss_mask: 0.5332, decode.d8.loss_dice: 0.5186, loss: 11.9681, grad_norm: 515.4614
2023-08-29 02:17:00,035 - mmseg - INFO - Iter [7650/160000]	lr: 1.603e-06, eta: 1 day, 6:55:58, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0226, decode.loss_mask: 0.5038, decode.loss_dice: 0.5132, decode.d0.loss_cls: 1.1619, decode.d0.loss_mask: 0.5369, decode.d0.loss_dice: 0.5686, decode.d1.loss_cls: 0.0201, decode.d1.loss_mask: 0.5076, decode.d1.loss_dice: 0.5237, decode.d2.loss_cls: 0.0189, decode.d2.loss_mask: 0.4958, decode.d2.loss_dice: 0.5049, decode.d3.loss_cls: 0.0183, decode.d3.loss_mask: 0.5014, decode.d3.loss_dice: 0.5057, decode.d4.loss_cls: 0.0192, decode.d4.loss_mask: 0.4966, decode.d4.loss_dice: 0.5030, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 0.5081, decode.d5.loss_dice: 0.5042, decode.d6.loss_cls: 0.0150, decode.d6.loss_mask: 0.5112, decode.d6.loss_dice: 0.5042, decode.d7.loss_cls: 0.0157, decode.d7.loss_mask: 0.5079, decode.d7.loss_dice: 0.5079, decode.d8.loss_cls: 0.0158, decode.d8.loss_mask: 0.5074, decode.d8.loss_dice: 0.5151, loss: 11.5487, grad_norm: 483.4333
2023-08-29 02:17:36,759 - mmseg - INFO - Iter [7700/160000]	lr: 1.602e-06, eta: 1 day, 6:55:24, time: 0.734, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0026, decode.loss_mask: 0.4340, decode.loss_dice: 0.4602, decode.d0.loss_cls: 1.1524, decode.d0.loss_mask: 0.4632, decode.d0.loss_dice: 0.5133, decode.d1.loss_cls: 0.0048, decode.d1.loss_mask: 0.4329, decode.d1.loss_dice: 0.4703, decode.d2.loss_cls: 0.0033, decode.d2.loss_mask: 0.4336, decode.d2.loss_dice: 0.4610, decode.d3.loss_cls: 0.0031, decode.d3.loss_mask: 0.4352, decode.d3.loss_dice: 0.4604, decode.d4.loss_cls: 0.0030, decode.d4.loss_mask: 0.4334, decode.d4.loss_dice: 0.4574, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4336, decode.d5.loss_dice: 0.4599, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.4340, decode.d6.loss_dice: 0.4583, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.4316, decode.d7.loss_dice: 0.4551, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.4317, decode.d8.loss_dice: 0.4599, loss: 10.1999, grad_norm: 476.6006
2023-08-29 02:18:13,625 - mmseg - INFO - Iter [7750/160000]	lr: 1.602e-06, eta: 1 day, 6:54:54, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0109, decode.loss_mask: 0.4641, decode.loss_dice: 0.4606, decode.d0.loss_cls: 1.1460, decode.d0.loss_mask: 0.4936, decode.d0.loss_dice: 0.5286, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.4651, decode.d1.loss_dice: 0.4762, decode.d2.loss_cls: 0.0114, decode.d2.loss_mask: 0.4601, decode.d2.loss_dice: 0.4620, decode.d3.loss_cls: 0.0108, decode.d3.loss_mask: 0.4611, decode.d3.loss_dice: 0.4549, decode.d4.loss_cls: 0.0101, decode.d4.loss_mask: 0.4620, decode.d4.loss_dice: 0.4570, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.4781, decode.d5.loss_dice: 0.4563, decode.d6.loss_cls: 0.0104, decode.d6.loss_mask: 0.4585, decode.d6.loss_dice: 0.4571, decode.d7.loss_cls: 0.0041, decode.d7.loss_mask: 0.4801, decode.d7.loss_dice: 0.4562, decode.d8.loss_cls: 0.0038, decode.d8.loss_mask: 0.4765, decode.d8.loss_dice: 0.4566, loss: 10.5874, grad_norm: 474.0240
2023-08-29 02:18:51,024 - mmseg - INFO - Iter [7800/160000]	lr: 1.601e-06, eta: 1 day, 6:54:34, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.4621, decode.loss_dice: 0.4809, decode.d0.loss_cls: 1.1368, decode.d0.loss_mask: 0.4832, decode.d0.loss_dice: 0.5340, decode.d1.loss_cls: 0.0040, decode.d1.loss_mask: 0.4720, decode.d1.loss_dice: 0.4811, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.4645, decode.d2.loss_dice: 0.4763, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.4660, decode.d3.loss_dice: 0.4790, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.4644, decode.d4.loss_dice: 0.4802, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.4631, decode.d5.loss_dice: 0.4809, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.4638, decode.d6.loss_dice: 0.4790, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.4625, decode.d7.loss_dice: 0.4789, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.4623, decode.d8.loss_dice: 0.4792, loss: 10.6694, grad_norm: 438.1443
2023-08-29 02:19:26,079 - mmseg - INFO - Iter [7850/160000]	lr: 1.601e-06, eta: 1 day, 6:53:29, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4912, decode.loss_dice: 0.5006, decode.d0.loss_cls: 1.1296, decode.d0.loss_mask: 0.5036, decode.d0.loss_dice: 0.5657, decode.d1.loss_cls: 0.0043, decode.d1.loss_mask: 0.4992, decode.d1.loss_dice: 0.5132, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.4947, decode.d2.loss_dice: 0.5017, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.4902, decode.d3.loss_dice: 0.4977, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4874, decode.d4.loss_dice: 0.5000, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4861, decode.d5.loss_dice: 0.5011, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.4886, decode.d6.loss_dice: 0.4997, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.4916, decode.d7.loss_dice: 0.4990, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.4928, decode.d8.loss_dice: 0.4981, loss: 11.1562, grad_norm: 523.7108
2023-08-29 02:20:02,942 - mmseg - INFO - Iter [7900/160000]	lr: 1.600e-06, eta: 1 day, 6:52:58, time: 0.737, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.4115, decode.loss_dice: 0.4194, decode.d0.loss_cls: 1.1233, decode.d0.loss_mask: 0.4425, decode.d0.loss_dice: 0.4677, decode.d1.loss_cls: 0.0056, decode.d1.loss_mask: 0.4218, decode.d1.loss_dice: 0.4281, decode.d2.loss_cls: 0.0043, decode.d2.loss_mask: 0.4142, decode.d2.loss_dice: 0.4190, decode.d3.loss_cls: 0.0039, decode.d3.loss_mask: 0.4142, decode.d3.loss_dice: 0.4164, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.4123, decode.d4.loss_dice: 0.4179, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.4138, decode.d5.loss_dice: 0.4163, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.4143, decode.d6.loss_dice: 0.4182, decode.d7.loss_cls: 0.0038, decode.d7.loss_mask: 0.4130, decode.d7.loss_dice: 0.4198, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.4117, decode.d8.loss_dice: 0.4177, loss: 9.5691, grad_norm: 430.6660
2023-08-29 02:20:39,651 - mmseg - INFO - Iter [7950/160000]	lr: 1.600e-06, eta: 1 day, 6:52:25, time: 0.734, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0261, decode.loss_mask: 0.5151, decode.loss_dice: 0.5138, decode.d0.loss_cls: 1.1186, decode.d0.loss_mask: 0.5336, decode.d0.loss_dice: 0.5674, decode.d1.loss_cls: 0.0240, decode.d1.loss_mask: 0.5177, decode.d1.loss_dice: 0.5222, decode.d2.loss_cls: 0.0153, decode.d2.loss_mask: 0.5253, decode.d2.loss_dice: 0.5153, decode.d3.loss_cls: 0.0152, decode.d3.loss_mask: 0.5248, decode.d3.loss_dice: 0.5141, decode.d4.loss_cls: 0.0144, decode.d4.loss_mask: 0.5242, decode.d4.loss_dice: 0.5155, decode.d5.loss_cls: 0.0086, decode.d5.loss_mask: 0.5309, decode.d5.loss_dice: 0.5199, decode.d6.loss_cls: 0.0090, decode.d6.loss_mask: 0.5344, decode.d6.loss_dice: 0.5188, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.5402, decode.d7.loss_dice: 0.5195, decode.d8.loss_cls: 0.0108, decode.d8.loss_mask: 0.5393, decode.d8.loss_dice: 0.5197, loss: 11.7565, grad_norm: 556.6889
2023-08-29 02:21:16,742 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-08-29 02:21:19,048 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 02:21:19,048 - mmseg - INFO - Iter [8000/160000]	lr: 1.599e-06, eta: 1 day, 6:52:42, time: 0.788, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.5124, decode.loss_dice: 0.4774, decode.d0.loss_cls: 1.1095, decode.d0.loss_mask: 0.5004, decode.d0.loss_dice: 0.5176, decode.d1.loss_cls: 0.0039, decode.d1.loss_mask: 0.5118, decode.d1.loss_dice: 0.4866, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.5058, decode.d2.loss_dice: 0.4742, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.5118, decode.d3.loss_dice: 0.4745, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.5145, decode.d4.loss_dice: 0.4752, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.5102, decode.d5.loss_dice: 0.4761, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.5102, decode.d6.loss_dice: 0.4779, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.5103, decode.d7.loss_dice: 0.4807, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.5094, decode.d8.loss_dice: 0.4825, loss: 11.0501, grad_norm: 548.5289
2023-08-29 02:21:54,461 - mmseg - INFO - Iter [8050/160000]	lr: 1.599e-06, eta: 1 day, 6:51:44, time: 0.708, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0105, decode.loss_mask: 0.5062, decode.loss_dice: 0.4972, decode.d0.loss_cls: 1.1009, decode.d0.loss_mask: 0.5235, decode.d0.loss_dice: 0.5389, decode.d1.loss_cls: 0.0118, decode.d1.loss_mask: 0.4981, decode.d1.loss_dice: 0.4980, decode.d2.loss_cls: 0.0093, decode.d2.loss_mask: 0.5028, decode.d2.loss_dice: 0.4962, decode.d3.loss_cls: 0.0088, decode.d3.loss_mask: 0.4993, decode.d3.loss_dice: 0.4998, decode.d4.loss_cls: 0.0091, decode.d4.loss_mask: 0.4994, decode.d4.loss_dice: 0.4967, decode.d5.loss_cls: 0.0085, decode.d5.loss_mask: 0.4976, decode.d5.loss_dice: 0.4999, decode.d6.loss_cls: 0.0100, decode.d6.loss_mask: 0.4994, decode.d6.loss_dice: 0.5018, decode.d7.loss_cls: 0.0089, decode.d7.loss_mask: 0.5018, decode.d7.loss_dice: 0.5016, decode.d8.loss_cls: 0.0092, decode.d8.loss_mask: 0.5007, decode.d8.loss_dice: 0.5009, loss: 11.2469, grad_norm: 438.6306
2023-08-29 02:22:31,266 - mmseg - INFO - Iter [8100/160000]	lr: 1.598e-06, eta: 1 day, 6:51:12, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4512, decode.loss_dice: 0.4497, decode.d0.loss_cls: 1.0937, decode.d0.loss_mask: 0.4595, decode.d0.loss_dice: 0.4993, decode.d1.loss_cls: 0.0041, decode.d1.loss_mask: 0.4517, decode.d1.loss_dice: 0.4564, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.4463, decode.d2.loss_dice: 0.4478, decode.d3.loss_cls: 0.0022, decode.d3.loss_mask: 0.4500, decode.d3.loss_dice: 0.4472, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4532, decode.d4.loss_dice: 0.4473, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4533, decode.d5.loss_dice: 0.4482, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4536, decode.d6.loss_dice: 0.4472, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.4519, decode.d7.loss_dice: 0.4498, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.4496, decode.d8.loss_dice: 0.4520, loss: 10.1809, grad_norm: 459.8586
2023-08-29 02:23:07,694 - mmseg - INFO - Iter [8150/160000]	lr: 1.598e-06, eta: 1 day, 6:50:33, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0303, decode.loss_mask: 0.4581, decode.loss_dice: 0.4623, decode.d0.loss_cls: 1.0884, decode.d0.loss_mask: 0.4871, decode.d0.loss_dice: 0.5122, decode.d1.loss_cls: 0.0271, decode.d1.loss_mask: 0.4591, decode.d1.loss_dice: 0.4643, decode.d2.loss_cls: 0.0253, decode.d2.loss_mask: 0.4543, decode.d2.loss_dice: 0.4562, decode.d3.loss_cls: 0.0274, decode.d3.loss_mask: 0.4553, decode.d3.loss_dice: 0.4541, decode.d4.loss_cls: 0.0267, decode.d4.loss_mask: 0.4613, decode.d4.loss_dice: 0.4569, decode.d5.loss_cls: 0.0200, decode.d5.loss_mask: 0.4662, decode.d5.loss_dice: 0.4531, decode.d6.loss_cls: 0.0168, decode.d6.loss_mask: 0.4781, decode.d6.loss_dice: 0.4562, decode.d7.loss_cls: 0.0182, decode.d7.loss_mask: 0.4772, decode.d7.loss_dice: 0.4558, decode.d8.loss_cls: 0.0265, decode.d8.loss_mask: 0.4594, decode.d8.loss_dice: 0.4565, loss: 10.5903, grad_norm: 475.1335
2023-08-29 02:23:45,069 - mmseg - INFO - Iter [8200/160000]	lr: 1.597e-06, eta: 1 day, 6:50:11, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0185, decode.loss_mask: 0.5233, decode.loss_dice: 0.4961, decode.d0.loss_cls: 1.0798, decode.d0.loss_mask: 0.5279, decode.d0.loss_dice: 0.5407, decode.d1.loss_cls: 0.0190, decode.d1.loss_mask: 0.5244, decode.d1.loss_dice: 0.5059, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.5308, decode.d2.loss_dice: 0.5034, decode.d3.loss_cls: 0.0177, decode.d3.loss_mask: 0.5270, decode.d3.loss_dice: 0.4989, decode.d4.loss_cls: 0.0172, decode.d4.loss_mask: 0.5258, decode.d4.loss_dice: 0.5008, decode.d5.loss_cls: 0.0101, decode.d5.loss_mask: 0.5325, decode.d5.loss_dice: 0.5032, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.5428, decode.d6.loss_dice: 0.5117, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.5439, decode.d7.loss_dice: 0.5077, decode.d8.loss_cls: 0.0188, decode.d8.loss_mask: 0.5198, decode.d8.loss_dice: 0.5030, loss: 11.5707, grad_norm: 493.6210
2023-08-29 02:24:20,026 - mmseg - INFO - Iter [8250/160000]	lr: 1.596e-06, eta: 1 day, 6:49:05, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.4509, decode.loss_dice: 0.4762, decode.d0.loss_cls: 1.0720, decode.d0.loss_mask: 0.4707, decode.d0.loss_dice: 0.5287, decode.d1.loss_cls: 0.0048, decode.d1.loss_mask: 0.4474, decode.d1.loss_dice: 0.4832, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.4457, decode.d2.loss_dice: 0.4786, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.4456, decode.d3.loss_dice: 0.4776, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.4538, decode.d4.loss_dice: 0.4775, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.4486, decode.d5.loss_dice: 0.4753, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.4434, decode.d6.loss_dice: 0.4754, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.4436, decode.d7.loss_dice: 0.4738, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.4503, decode.d8.loss_dice: 0.4772, loss: 10.4268, grad_norm: 502.0791
2023-08-29 02:24:57,267 - mmseg - INFO - Iter [8300/160000]	lr: 1.596e-06, eta: 1 day, 6:48:41, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0171, decode.loss_mask: 0.4594, decode.loss_dice: 0.4667, decode.d0.loss_cls: 1.0646, decode.d0.loss_mask: 0.4789, decode.d0.loss_dice: 0.5243, decode.d1.loss_cls: 0.0176, decode.d1.loss_mask: 0.4675, decode.d1.loss_dice: 0.4777, decode.d2.loss_cls: 0.0180, decode.d2.loss_mask: 0.4560, decode.d2.loss_dice: 0.4651, decode.d3.loss_cls: 0.0180, decode.d3.loss_mask: 0.4584, decode.d3.loss_dice: 0.4638, decode.d4.loss_cls: 0.0179, decode.d4.loss_mask: 0.4592, decode.d4.loss_dice: 0.4641, decode.d5.loss_cls: 0.0168, decode.d5.loss_mask: 0.4568, decode.d5.loss_dice: 0.4660, decode.d6.loss_cls: 0.0152, decode.d6.loss_mask: 0.4554, decode.d6.loss_dice: 0.4635, decode.d7.loss_cls: 0.0167, decode.d7.loss_mask: 0.4570, decode.d7.loss_dice: 0.4655, decode.d8.loss_cls: 0.0185, decode.d8.loss_mask: 0.4592, decode.d8.loss_dice: 0.4680, loss: 10.5530, grad_norm: 489.2668
2023-08-29 02:25:33,822 - mmseg - INFO - Iter [8350/160000]	lr: 1.595e-06, eta: 1 day, 6:48:05, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.5039, decode.loss_dice: 0.4896, decode.d0.loss_cls: 1.0576, decode.d0.loss_mask: 0.5150, decode.d0.loss_dice: 0.5426, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.5077, decode.d1.loss_dice: 0.5007, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.5034, decode.d2.loss_dice: 0.4903, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.5069, decode.d3.loss_dice: 0.4865, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.5041, decode.d4.loss_dice: 0.4861, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.5022, decode.d5.loss_dice: 0.4895, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.5029, decode.d6.loss_dice: 0.4888, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.5046, decode.d7.loss_dice: 0.4914, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.5001, decode.d8.loss_dice: 0.4917, loss: 11.0870, grad_norm: 514.7146
2023-08-29 02:26:10,972 - mmseg - INFO - Iter [8400/160000]	lr: 1.595e-06, eta: 1 day, 6:47:39, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4722, decode.loss_dice: 0.4849, decode.d0.loss_cls: 1.0513, decode.d0.loss_mask: 0.4955, decode.d0.loss_dice: 0.5236, decode.d1.loss_cls: 0.0039, decode.d1.loss_mask: 0.4745, decode.d1.loss_dice: 0.4844, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.4697, decode.d2.loss_dice: 0.4807, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4715, decode.d3.loss_dice: 0.4839, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.4741, decode.d4.loss_dice: 0.4851, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.4717, decode.d5.loss_dice: 0.4841, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.4741, decode.d6.loss_dice: 0.4871, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.4739, decode.d7.loss_dice: 0.4842, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.4743, decode.d8.loss_dice: 0.4868, loss: 10.7065, grad_norm: 442.7796
2023-08-29 02:26:48,123 - mmseg - INFO - Iter [8450/160000]	lr: 1.594e-06, eta: 1 day, 6:47:13, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.4417, decode.loss_dice: 0.4420, decode.d0.loss_cls: 1.0422, decode.d0.loss_mask: 0.4625, decode.d0.loss_dice: 0.4839, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.4412, decode.d1.loss_dice: 0.4463, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.4360, decode.d2.loss_dice: 0.4423, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4395, decode.d3.loss_dice: 0.4394, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4406, decode.d4.loss_dice: 0.4393, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4412, decode.d5.loss_dice: 0.4399, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.4444, decode.d6.loss_dice: 0.4368, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.4392, decode.d7.loss_dice: 0.4403, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4436, decode.d8.loss_dice: 0.4399, loss: 9.9442, grad_norm: 435.8396
2023-08-29 02:27:23,000 - mmseg - INFO - Iter [8500/160000]	lr: 1.594e-06, eta: 1 day, 6:46:06, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0259, decode.loss_mask: 0.4563, decode.loss_dice: 0.4604, decode.d0.loss_cls: 1.0367, decode.d0.loss_mask: 0.4736, decode.d0.loss_dice: 0.5058, decode.d1.loss_cls: 0.0253, decode.d1.loss_mask: 0.4613, decode.d1.loss_dice: 0.4770, decode.d2.loss_cls: 0.0230, decode.d2.loss_mask: 0.4534, decode.d2.loss_dice: 0.4677, decode.d3.loss_cls: 0.0151, decode.d3.loss_mask: 0.4688, decode.d3.loss_dice: 0.4657, decode.d4.loss_cls: 0.0170, decode.d4.loss_mask: 0.4706, decode.d4.loss_dice: 0.4686, decode.d5.loss_cls: 0.0165, decode.d5.loss_mask: 0.4700, decode.d5.loss_dice: 0.4672, decode.d6.loss_cls: 0.0164, decode.d6.loss_mask: 0.4712, decode.d6.loss_dice: 0.4658, decode.d7.loss_cls: 0.0182, decode.d7.loss_mask: 0.4670, decode.d7.loss_dice: 0.4612, decode.d8.loss_cls: 0.0257, decode.d8.loss_mask: 0.4578, decode.d8.loss_dice: 0.4623, loss: 10.5714, grad_norm: 463.8857
2023-08-29 02:27:59,259 - mmseg - INFO - Iter [8550/160000]	lr: 1.593e-06, eta: 1 day, 6:45:24, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.4431, decode.loss_dice: 0.4701, decode.d0.loss_cls: 1.0261, decode.d0.loss_mask: 0.4594, decode.d0.loss_dice: 0.5282, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.4385, decode.d1.loss_dice: 0.4822, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.4364, decode.d2.loss_dice: 0.4703, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.4427, decode.d3.loss_dice: 0.4645, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.4426, decode.d4.loss_dice: 0.4700, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.4414, decode.d5.loss_dice: 0.4720, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.4445, decode.d6.loss_dice: 0.4705, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.4421, decode.d7.loss_dice: 0.4723, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.4447, decode.d8.loss_dice: 0.4693, loss: 10.2464, grad_norm: 425.4990
2023-08-29 02:28:36,302 - mmseg - INFO - Iter [8600/160000]	lr: 1.593e-06, eta: 1 day, 6:44:56, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0091, decode.loss_mask: 0.3996, decode.loss_dice: 0.3943, decode.d0.loss_cls: 1.0201, decode.d0.loss_mask: 0.4087, decode.d0.loss_dice: 0.4508, decode.d1.loss_cls: 0.0105, decode.d1.loss_mask: 0.3947, decode.d1.loss_dice: 0.4048, decode.d2.loss_cls: 0.0089, decode.d2.loss_mask: 0.3935, decode.d2.loss_dice: 0.3958, decode.d3.loss_cls: 0.0089, decode.d3.loss_mask: 0.3929, decode.d3.loss_dice: 0.3916, decode.d4.loss_cls: 0.0076, decode.d4.loss_mask: 0.3974, decode.d4.loss_dice: 0.3983, decode.d5.loss_cls: 0.0071, decode.d5.loss_mask: 0.3983, decode.d5.loss_dice: 0.3966, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.4038, decode.d6.loss_dice: 0.3938, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.4049, decode.d7.loss_dice: 0.3967, decode.d8.loss_cls: 0.0070, decode.d8.loss_mask: 0.3986, decode.d8.loss_dice: 0.3964, loss: 9.0951, grad_norm: 385.4990
2023-08-29 02:29:13,528 - mmseg - INFO - Iter [8650/160000]	lr: 1.592e-06, eta: 1 day, 6:44:31, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.4886, decode.loss_dice: 0.4717, decode.d0.loss_cls: 1.0137, decode.d0.loss_mask: 0.5117, decode.d0.loss_dice: 0.5240, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4923, decode.d1.loss_dice: 0.4856, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.4828, decode.d2.loss_dice: 0.4740, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4819, decode.d3.loss_dice: 0.4722, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.4821, decode.d4.loss_dice: 0.4688, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.4836, decode.d5.loss_dice: 0.4700, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.4814, decode.d6.loss_dice: 0.4717, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.4854, decode.d7.loss_dice: 0.4752, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.4843, decode.d8.loss_dice: 0.4692, loss: 10.6879, grad_norm: 529.0345
2023-08-29 02:29:48,382 - mmseg - INFO - Iter [8700/160000]	lr: 1.592e-06, eta: 1 day, 6:43:25, time: 0.697, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.4550, decode.loss_dice: 0.4683, decode.d0.loss_cls: 1.0050, decode.d0.loss_mask: 0.4673, decode.d0.loss_dice: 0.5088, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4503, decode.d1.loss_dice: 0.4716, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.4510, decode.d2.loss_dice: 0.4664, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.4543, decode.d3.loss_dice: 0.4657, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.4504, decode.d4.loss_dice: 0.4635, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4522, decode.d5.loss_dice: 0.4647, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.4491, decode.d6.loss_dice: 0.4651, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.4538, decode.d7.loss_dice: 0.4626, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4527, decode.d8.loss_dice: 0.4650, loss: 10.2637, grad_norm: 455.5038
2023-08-29 02:30:24,971 - mmseg - INFO - Iter [8750/160000]	lr: 1.591e-06, eta: 1 day, 6:42:49, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.4166, decode.loss_dice: 0.4305, decode.d0.loss_cls: 0.9982, decode.d0.loss_mask: 0.4500, decode.d0.loss_dice: 0.4827, decode.d1.loss_cls: 0.0049, decode.d1.loss_mask: 0.4191, decode.d1.loss_dice: 0.4366, decode.d2.loss_cls: 0.0039, decode.d2.loss_mask: 0.4189, decode.d2.loss_dice: 0.4302, decode.d3.loss_cls: 0.0036, decode.d3.loss_mask: 0.4156, decode.d3.loss_dice: 0.4251, decode.d4.loss_cls: 0.0034, decode.d4.loss_mask: 0.4153, decode.d4.loss_dice: 0.4260, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.4164, decode.d5.loss_dice: 0.4274, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.4155, decode.d6.loss_dice: 0.4248, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.4183, decode.d7.loss_dice: 0.4279, decode.d8.loss_cls: 0.0032, decode.d8.loss_mask: 0.4189, decode.d8.loss_dice: 0.4279, loss: 9.5743, grad_norm: 460.9105
2023-08-29 02:31:02,220 - mmseg - INFO - Iter [8800/160000]	lr: 1.591e-06, eta: 1 day, 6:42:24, time: 0.745, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4335, decode.loss_dice: 0.4292, decode.d0.loss_cls: 0.9903, decode.d0.loss_mask: 0.4579, decode.d0.loss_dice: 0.4753, decode.d1.loss_cls: 0.0040, decode.d1.loss_mask: 0.4302, decode.d1.loss_dice: 0.4354, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.4305, decode.d2.loss_dice: 0.4286, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.4286, decode.d3.loss_dice: 0.4255, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4325, decode.d4.loss_dice: 0.4265, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4318, decode.d5.loss_dice: 0.4273, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.4339, decode.d6.loss_dice: 0.4267, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4332, decode.d7.loss_dice: 0.4273, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4363, decode.d8.loss_dice: 0.4286, loss: 9.6923, grad_norm: 422.1931
2023-08-29 02:31:39,595 - mmseg - INFO - Iter [8850/160000]	lr: 1.590e-06, eta: 1 day, 6:42:02, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.4505, decode.loss_dice: 0.4501, decode.d0.loss_cls: 0.9827, decode.d0.loss_mask: 0.4629, decode.d0.loss_dice: 0.5024, decode.d1.loss_cls: 0.0034, decode.d1.loss_mask: 0.4531, decode.d1.loss_dice: 0.4533, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.4566, decode.d2.loss_dice: 0.4526, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4514, decode.d3.loss_dice: 0.4478, decode.d4.loss_cls: 0.0087, decode.d4.loss_mask: 0.4499, decode.d4.loss_dice: 0.4466, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.4542, decode.d5.loss_dice: 0.4503, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.4558, decode.d6.loss_dice: 0.4491, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.4519, decode.d7.loss_dice: 0.4464, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.4522, decode.d8.loss_dice: 0.4534, loss: 10.0967, grad_norm: 501.1992
2023-08-29 02:32:14,682 - mmseg - INFO - Iter [8900/160000]	lr: 1.590e-06, eta: 1 day, 6:41:00, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0156, decode.loss_mask: 0.4531, decode.loss_dice: 0.4478, decode.d0.loss_cls: 0.9798, decode.d0.loss_mask: 0.4757, decode.d0.loss_dice: 0.4993, decode.d1.loss_cls: 0.0174, decode.d1.loss_mask: 0.4592, decode.d1.loss_dice: 0.4592, decode.d2.loss_cls: 0.0165, decode.d2.loss_mask: 0.4548, decode.d2.loss_dice: 0.4483, decode.d3.loss_cls: 0.0175, decode.d3.loss_mask: 0.4521, decode.d3.loss_dice: 0.4468, decode.d4.loss_cls: 0.0181, decode.d4.loss_mask: 0.4536, decode.d4.loss_dice: 0.4480, decode.d5.loss_cls: 0.0150, decode.d5.loss_mask: 0.4549, decode.d5.loss_dice: 0.4496, decode.d6.loss_cls: 0.0139, decode.d6.loss_mask: 0.4551, decode.d6.loss_dice: 0.4501, decode.d7.loss_cls: 0.0167, decode.d7.loss_mask: 0.4551, decode.d7.loss_dice: 0.4493, decode.d8.loss_cls: 0.0175, decode.d8.loss_mask: 0.4517, decode.d8.loss_dice: 0.4475, loss: 10.2396, grad_norm: 524.4630
2023-08-29 02:32:51,201 - mmseg - INFO - Iter [8950/160000]	lr: 1.589e-06, eta: 1 day, 6:40:23, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4917, decode.loss_dice: 0.4581, decode.d0.loss_cls: 0.9708, decode.d0.loss_mask: 0.5013, decode.d0.loss_dice: 0.4967, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.4980, decode.d1.loss_dice: 0.4692, decode.d2.loss_cls: 0.0084, decode.d2.loss_mask: 0.4783, decode.d2.loss_dice: 0.4560, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.4897, decode.d3.loss_dice: 0.4533, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.4860, decode.d4.loss_dice: 0.4520, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.4871, decode.d5.loss_dice: 0.4511, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.4884, decode.d6.loss_dice: 0.4519, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.4914, decode.d7.loss_dice: 0.4535, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4910, decode.d8.loss_dice: 0.4569, loss: 10.4993, grad_norm: 434.1730
2023-08-29 02:33:28,090 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-08-29 02:33:30,494 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 02:33:30,494 - mmseg - INFO - Iter [9000/160000]	lr: 1.589e-06, eta: 1 day, 6:40:33, time: 0.786, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.5152, decode.loss_dice: 0.4966, decode.d0.loss_cls: 0.9661, decode.d0.loss_mask: 0.5112, decode.d0.loss_dice: 0.5248, decode.d1.loss_cls: 0.0102, decode.d1.loss_mask: 0.5011, decode.d1.loss_dice: 0.4984, decode.d2.loss_cls: 0.0099, decode.d2.loss_mask: 0.5045, decode.d2.loss_dice: 0.4959, decode.d3.loss_cls: 0.0090, decode.d3.loss_mask: 0.5060, decode.d3.loss_dice: 0.4947, decode.d4.loss_cls: 0.0084, decode.d4.loss_mask: 0.5045, decode.d4.loss_dice: 0.4948, decode.d5.loss_cls: 0.0073, decode.d5.loss_mask: 0.5033, decode.d5.loss_dice: 0.4956, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.5114, decode.d6.loss_dice: 0.4955, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.5145, decode.d7.loss_dice: 0.4961, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.5143, decode.d8.loss_dice: 0.5002, loss: 11.0970, grad_norm: 584.6723
2023-08-29 02:34:07,774 - mmseg - INFO - Iter [9050/160000]	lr: 1.588e-06, eta: 1 day, 6:40:08, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0099, decode.loss_mask: 0.4448, decode.loss_dice: 0.4521, decode.d0.loss_cls: 0.9575, decode.d0.loss_mask: 0.4660, decode.d0.loss_dice: 0.4740, decode.d1.loss_cls: 0.0146, decode.d1.loss_mask: 0.4429, decode.d1.loss_dice: 0.4424, decode.d2.loss_cls: 0.0126, decode.d2.loss_mask: 0.4431, decode.d2.loss_dice: 0.4350, decode.d3.loss_cls: 0.0151, decode.d3.loss_mask: 0.4417, decode.d3.loss_dice: 0.4342, decode.d4.loss_cls: 0.0154, decode.d4.loss_mask: 0.4471, decode.d4.loss_dice: 0.4372, decode.d5.loss_cls: 0.0105, decode.d5.loss_mask: 0.4664, decode.d5.loss_dice: 0.4413, decode.d6.loss_cls: 0.0067, decode.d6.loss_mask: 0.4691, decode.d6.loss_dice: 0.4427, decode.d7.loss_cls: 0.0151, decode.d7.loss_mask: 0.4595, decode.d7.loss_dice: 0.4382, decode.d8.loss_cls: 0.0105, decode.d8.loss_mask: 0.4549, decode.d8.loss_dice: 0.4397, loss: 10.0399, grad_norm: 405.6813
2023-08-29 02:34:42,683 - mmseg - INFO - Iter [9100/160000]	lr: 1.588e-06, eta: 1 day, 6:39:04, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.4237, decode.loss_dice: 0.4295, decode.d0.loss_cls: 0.9511, decode.d0.loss_mask: 0.4361, decode.d0.loss_dice: 0.4826, decode.d1.loss_cls: 0.0111, decode.d1.loss_mask: 0.4146, decode.d1.loss_dice: 0.4368, decode.d2.loss_cls: 0.0097, decode.d2.loss_mask: 0.4084, decode.d2.loss_dice: 0.4282, decode.d3.loss_cls: 0.0100, decode.d3.loss_mask: 0.4083, decode.d3.loss_dice: 0.4236, decode.d4.loss_cls: 0.0106, decode.d4.loss_mask: 0.4074, decode.d4.loss_dice: 0.4210, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.4226, decode.d5.loss_dice: 0.4295, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.4173, decode.d6.loss_dice: 0.4320, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.4228, decode.d7.loss_dice: 0.4264, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4234, decode.d8.loss_dice: 0.4330, loss: 9.5304, grad_norm: 472.6304
2023-08-29 02:35:19,147 - mmseg - INFO - Iter [9150/160000]	lr: 1.587e-06, eta: 1 day, 6:38:26, time: 0.729, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4484, decode.loss_dice: 0.4426, decode.d0.loss_cls: 0.9422, decode.d0.loss_mask: 0.4680, decode.d0.loss_dice: 0.4889, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4483, decode.d1.loss_dice: 0.4509, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.4482, decode.d2.loss_dice: 0.4450, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.4471, decode.d3.loss_dice: 0.4409, decode.d4.loss_cls: 0.0028, decode.d4.loss_mask: 0.4477, decode.d4.loss_dice: 0.4390, decode.d5.loss_cls: 0.0029, decode.d5.loss_mask: 0.4467, decode.d5.loss_dice: 0.4438, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.4458, decode.d6.loss_dice: 0.4412, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.4473, decode.d7.loss_dice: 0.4433, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.4433, decode.d8.loss_dice: 0.4399, loss: 9.9333, grad_norm: 457.2771
2023-08-29 02:35:55,992 - mmseg - INFO - Iter [9200/160000]	lr: 1.586e-06, eta: 1 day, 6:37:54, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.4285, decode.loss_dice: 0.4393, decode.d0.loss_cls: 0.9367, decode.d0.loss_mask: 0.4433, decode.d0.loss_dice: 0.4680, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.4334, decode.d1.loss_dice: 0.4430, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.4356, decode.d2.loss_dice: 0.4395, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.4334, decode.d3.loss_dice: 0.4395, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.4334, decode.d4.loss_dice: 0.4415, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.4344, decode.d5.loss_dice: 0.4377, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.4321, decode.d6.loss_dice: 0.4406, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.4340, decode.d7.loss_dice: 0.4404, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.4322, decode.d8.loss_dice: 0.4436, loss: 9.7258, grad_norm: 443.6057
2023-08-29 02:36:33,384 - mmseg - INFO - Iter [9250/160000]	lr: 1.586e-06, eta: 1 day, 6:37:31, time: 0.748, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0178, decode.loss_mask: 0.4602, decode.loss_dice: 0.4753, decode.d0.loss_cls: 0.9324, decode.d0.loss_mask: 0.4845, decode.d0.loss_dice: 0.5262, decode.d1.loss_cls: 0.0177, decode.d1.loss_mask: 0.4630, decode.d1.loss_dice: 0.4863, decode.d2.loss_cls: 0.0148, decode.d2.loss_mask: 0.4573, decode.d2.loss_dice: 0.4738, decode.d3.loss_cls: 0.0170, decode.d3.loss_mask: 0.4577, decode.d3.loss_dice: 0.4752, decode.d4.loss_cls: 0.0221, decode.d4.loss_mask: 0.4467, decode.d4.loss_dice: 0.4725, decode.d5.loss_cls: 0.0145, decode.d5.loss_mask: 0.4578, decode.d5.loss_dice: 0.4743, decode.d6.loss_cls: 0.0077, decode.d6.loss_mask: 0.4640, decode.d6.loss_dice: 0.4730, decode.d7.loss_cls: 0.0166, decode.d7.loss_mask: 0.4589, decode.d7.loss_dice: 0.4694, decode.d8.loss_cls: 0.0106, decode.d8.loss_mask: 0.4797, decode.d8.loss_dice: 0.4746, loss: 10.5019, grad_norm: 478.0669
2023-08-29 02:37:08,277 - mmseg - INFO - Iter [9300/160000]	lr: 1.585e-06, eta: 1 day, 6:36:27, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0117, decode.loss_mask: 0.4387, decode.loss_dice: 0.4437, decode.d0.loss_cls: 0.9268, decode.d0.loss_mask: 0.4592, decode.d0.loss_dice: 0.4954, decode.d1.loss_cls: 0.0114, decode.d1.loss_mask: 0.4448, decode.d1.loss_dice: 0.4513, decode.d2.loss_cls: 0.0103, decode.d2.loss_mask: 0.4445, decode.d2.loss_dice: 0.4428, decode.d3.loss_cls: 0.0105, decode.d3.loss_mask: 0.4437, decode.d3.loss_dice: 0.4409, decode.d4.loss_cls: 0.0109, decode.d4.loss_mask: 0.4379, decode.d4.loss_dice: 0.4426, decode.d5.loss_cls: 0.0105, decode.d5.loss_mask: 0.4408, decode.d5.loss_dice: 0.4453, decode.d6.loss_cls: 0.0109, decode.d6.loss_mask: 0.4446, decode.d6.loss_dice: 0.4425, decode.d7.loss_cls: 0.0102, decode.d7.loss_mask: 0.4433, decode.d7.loss_dice: 0.4453, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.4568, decode.d8.loss_dice: 0.4484, loss: 9.9691, grad_norm: 431.3397
2023-08-29 02:37:44,695 - mmseg - INFO - Iter [9350/160000]	lr: 1.585e-06, eta: 1 day, 6:35:48, time: 0.728, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0101, decode.loss_mask: 0.4069, decode.loss_dice: 0.4233, decode.d0.loss_cls: 0.9195, decode.d0.loss_mask: 0.4072, decode.d0.loss_dice: 0.4562, decode.d1.loss_cls: 0.0156, decode.d1.loss_mask: 0.4020, decode.d1.loss_dice: 0.4274, decode.d2.loss_cls: 0.0131, decode.d2.loss_mask: 0.4006, decode.d2.loss_dice: 0.4227, decode.d3.loss_cls: 0.0062, decode.d3.loss_mask: 0.4079, decode.d3.loss_dice: 0.4204, decode.d4.loss_cls: 0.0128, decode.d4.loss_mask: 0.4019, decode.d4.loss_dice: 0.4260, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.4087, decode.d5.loss_dice: 0.4217, decode.d6.loss_cls: 0.0064, decode.d6.loss_mask: 0.4095, decode.d6.loss_dice: 0.4216, decode.d7.loss_cls: 0.0083, decode.d7.loss_mask: 0.4077, decode.d7.loss_dice: 0.4233, decode.d8.loss_cls: 0.0102, decode.d8.loss_mask: 0.4072, decode.d8.loss_dice: 0.4278, loss: 9.3383, grad_norm: 418.8865
2023-08-29 02:38:21,714 - mmseg - INFO - Iter [9400/160000]	lr: 1.584e-06, eta: 1 day, 6:35:19, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0084, decode.loss_mask: 0.4034, decode.loss_dice: 0.4023, decode.d0.loss_cls: 0.9104, decode.d0.loss_mask: 0.4287, decode.d0.loss_dice: 0.4643, decode.d1.loss_cls: 0.0165, decode.d1.loss_mask: 0.4012, decode.d1.loss_dice: 0.4161, decode.d2.loss_cls: 0.0084, decode.d2.loss_mask: 0.4011, decode.d2.loss_dice: 0.4037, decode.d3.loss_cls: 0.0084, decode.d3.loss_mask: 0.4019, decode.d3.loss_dice: 0.4008, decode.d4.loss_cls: 0.0075, decode.d4.loss_mask: 0.4017, decode.d4.loss_dice: 0.3983, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.4037, decode.d5.loss_dice: 0.4010, decode.d6.loss_cls: 0.0080, decode.d6.loss_mask: 0.4022, decode.d6.loss_dice: 0.4022, decode.d7.loss_cls: 0.0075, decode.d7.loss_mask: 0.4025, decode.d7.loss_dice: 0.4003, decode.d8.loss_cls: 0.0073, decode.d8.loss_mask: 0.4001, decode.d8.loss_dice: 0.4044, loss: 9.1292, grad_norm: 428.3119
2023-08-29 02:38:58,787 - mmseg - INFO - Iter [9450/160000]	lr: 1.584e-06, eta: 1 day, 6:34:51, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0145, decode.loss_mask: 0.4142, decode.loss_dice: 0.4258, decode.d0.loss_cls: 0.9040, decode.d0.loss_mask: 0.4333, decode.d0.loss_dice: 0.4689, decode.d1.loss_cls: 0.0103, decode.d1.loss_mask: 0.4268, decode.d1.loss_dice: 0.4355, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.4216, decode.d2.loss_dice: 0.4302, decode.d3.loss_cls: 0.0125, decode.d3.loss_mask: 0.4152, decode.d3.loss_dice: 0.4224, decode.d4.loss_cls: 0.0124, decode.d4.loss_mask: 0.4123, decode.d4.loss_dice: 0.4223, decode.d5.loss_cls: 0.0067, decode.d5.loss_mask: 0.4246, decode.d5.loss_dice: 0.4273, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.4296, decode.d6.loss_dice: 0.4312, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.4370, decode.d7.loss_dice: 0.4317, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4311, decode.d8.loss_dice: 0.4384, loss: 9.5539, grad_norm: 458.3998
2023-08-29 02:39:33,939 - mmseg - INFO - Iter [9500/160000]	lr: 1.583e-06, eta: 1 day, 6:33:52, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.4103, decode.loss_dice: 0.4455, decode.d0.loss_cls: 0.8962, decode.d0.loss_mask: 0.4327, decode.d0.loss_dice: 0.5084, decode.d1.loss_cls: 0.0046, decode.d1.loss_mask: 0.4150, decode.d1.loss_dice: 0.4679, decode.d2.loss_cls: 0.0037, decode.d2.loss_mask: 0.4103, decode.d2.loss_dice: 0.4536, decode.d3.loss_cls: 0.0034, decode.d3.loss_mask: 0.4088, decode.d3.loss_dice: 0.4466, decode.d4.loss_cls: 0.0033, decode.d4.loss_mask: 0.4113, decode.d4.loss_dice: 0.4475, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.4120, decode.d5.loss_dice: 0.4511, decode.d6.loss_cls: 0.0034, decode.d6.loss_mask: 0.4128, decode.d6.loss_dice: 0.4493, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.4108, decode.d7.loss_dice: 0.4483, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.4103, decode.d8.loss_dice: 0.4480, loss: 9.6276, grad_norm: 382.5047
2023-08-29 02:40:10,583 - mmseg - INFO - Iter [9550/160000]	lr: 1.583e-06, eta: 1 day, 6:33:16, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0101, decode.loss_mask: 0.4526, decode.loss_dice: 0.4330, decode.d0.loss_cls: 0.8890, decode.d0.loss_mask: 0.4650, decode.d0.loss_dice: 0.4636, decode.d1.loss_cls: 0.0104, decode.d1.loss_mask: 0.4608, decode.d1.loss_dice: 0.4340, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 0.4550, decode.d2.loss_dice: 0.4326, decode.d3.loss_cls: 0.0098, decode.d3.loss_mask: 0.4534, decode.d3.loss_dice: 0.4314, decode.d4.loss_cls: 0.0094, decode.d4.loss_mask: 0.4565, decode.d4.loss_dice: 0.4308, decode.d5.loss_cls: 0.0101, decode.d5.loss_mask: 0.4549, decode.d5.loss_dice: 0.4327, decode.d6.loss_cls: 0.0084, decode.d6.loss_mask: 0.4554, decode.d6.loss_dice: 0.4368, decode.d7.loss_cls: 0.0087, decode.d7.loss_mask: 0.4554, decode.d7.loss_dice: 0.4302, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4728, decode.d8.loss_dice: 0.4353, loss: 9.9100, grad_norm: 395.3310
2023-08-29 02:40:47,373 - mmseg - INFO - Iter [9600/160000]	lr: 1.582e-06, eta: 1 day, 6:32:44, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0158, decode.loss_mask: 0.4313, decode.loss_dice: 0.4364, decode.d0.loss_cls: 0.8828, decode.d0.loss_mask: 0.4492, decode.d0.loss_dice: 0.4809, decode.d1.loss_cls: 0.0098, decode.d1.loss_mask: 0.4468, decode.d1.loss_dice: 0.4512, decode.d2.loss_cls: 0.0088, decode.d2.loss_mask: 0.4392, decode.d2.loss_dice: 0.4478, decode.d3.loss_cls: 0.0159, decode.d3.loss_mask: 0.4273, decode.d3.loss_dice: 0.4408, decode.d4.loss_cls: 0.0150, decode.d4.loss_mask: 0.4287, decode.d4.loss_dice: 0.4402, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 0.4286, decode.d5.loss_dice: 0.4384, decode.d6.loss_cls: 0.0094, decode.d6.loss_mask: 0.4393, decode.d6.loss_dice: 0.4430, decode.d7.loss_cls: 0.0078, decode.d7.loss_mask: 0.4413, decode.d7.loss_dice: 0.4430, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.4557, decode.d8.loss_dice: 0.4473, loss: 9.8367, grad_norm: 457.5067
2023-08-29 02:41:24,666 - mmseg - INFO - Iter [9650/160000]	lr: 1.582e-06, eta: 1 day, 6:32:19, time: 0.746, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0150, decode.loss_mask: 0.4501, decode.loss_dice: 0.4321, decode.d0.loss_cls: 0.8788, decode.d0.loss_mask: 0.4664, decode.d0.loss_dice: 0.4657, decode.d1.loss_cls: 0.0158, decode.d1.loss_mask: 0.4460, decode.d1.loss_dice: 0.4322, decode.d2.loss_cls: 0.0164, decode.d2.loss_mask: 0.4444, decode.d2.loss_dice: 0.4317, decode.d3.loss_cls: 0.0166, decode.d3.loss_mask: 0.4454, decode.d3.loss_dice: 0.4303, decode.d4.loss_cls: 0.0156, decode.d4.loss_mask: 0.4466, decode.d4.loss_dice: 0.4305, decode.d5.loss_cls: 0.0154, decode.d5.loss_mask: 0.4446, decode.d5.loss_dice: 0.4306, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 0.4490, decode.d6.loss_dice: 0.4305, decode.d7.loss_cls: 0.0168, decode.d7.loss_mask: 0.4492, decode.d7.loss_dice: 0.4319, decode.d8.loss_cls: 0.0132, decode.d8.loss_mask: 0.4534, decode.d8.loss_dice: 0.4354, loss: 9.8627, grad_norm: 448.6499
2023-08-29 02:41:59,629 - mmseg - INFO - Iter [9700/160000]	lr: 1.581e-06, eta: 1 day, 6:31:17, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.4500, decode.loss_dice: 0.4257, decode.d0.loss_cls: 0.8708, decode.d0.loss_mask: 0.4782, decode.d0.loss_dice: 0.4683, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.4574, decode.d1.loss_dice: 0.4433, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.4480, decode.d2.loss_dice: 0.4329, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.4464, decode.d3.loss_dice: 0.4334, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.4468, decode.d4.loss_dice: 0.4334, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.4456, decode.d5.loss_dice: 0.4317, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.4477, decode.d6.loss_dice: 0.4322, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.4498, decode.d7.loss_dice: 0.4295, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.4521, decode.d8.loss_dice: 0.4299, loss: 9.7793, grad_norm: 466.0538
2023-08-29 02:42:36,545 - mmseg - INFO - Iter [9750/160000]	lr: 1.581e-06, eta: 1 day, 6:30:46, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0010, decode.loss_mask: 0.4045, decode.loss_dice: 0.4056, decode.d0.loss_cls: 0.8616, decode.d0.loss_mask: 0.4171, decode.d0.loss_dice: 0.4459, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.4002, decode.d1.loss_dice: 0.4112, decode.d2.loss_cls: 0.0015, decode.d2.loss_mask: 0.4017, decode.d2.loss_dice: 0.4058, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.4001, decode.d3.loss_dice: 0.4052, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.4024, decode.d4.loss_dice: 0.4071, decode.d5.loss_cls: 0.0011, decode.d5.loss_mask: 0.4012, decode.d5.loss_dice: 0.4039, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.4050, decode.d6.loss_dice: 0.4053, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.4040, decode.d7.loss_dice: 0.4042, decode.d8.loss_cls: 0.0011, decode.d8.loss_mask: 0.4031, decode.d8.loss_dice: 0.4052, loss: 9.0120, grad_norm: 386.1483
2023-08-29 02:43:13,049 - mmseg - INFO - Iter [9800/160000]	lr: 1.580e-06, eta: 1 day, 6:30:09, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0012, decode.loss_mask: 0.4122, decode.loss_dice: 0.4238, decode.d0.loss_cls: 0.8551, decode.d0.loss_mask: 0.4336, decode.d0.loss_dice: 0.4575, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.4086, decode.d1.loss_dice: 0.4298, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.4109, decode.d2.loss_dice: 0.4227, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.4127, decode.d3.loss_dice: 0.4229, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.4107, decode.d4.loss_dice: 0.4204, decode.d5.loss_cls: 0.0013, decode.d5.loss_mask: 0.4103, decode.d5.loss_dice: 0.4189, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.4096, decode.d6.loss_dice: 0.4202, decode.d7.loss_cls: 0.0012, decode.d7.loss_mask: 0.4118, decode.d7.loss_dice: 0.4199, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.4119, decode.d8.loss_dice: 0.4232, loss: 9.2601, grad_norm: 451.2350
2023-08-29 02:43:50,009 - mmseg - INFO - Iter [9850/160000]	lr: 1.580e-06, eta: 1 day, 6:29:39, time: 0.739, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.4276, decode.loss_dice: 0.4005, decode.d0.loss_cls: 0.8507, decode.d0.loss_mask: 0.4524, decode.d0.loss_dice: 0.4447, decode.d1.loss_cls: 0.0045, decode.d1.loss_mask: 0.4357, decode.d1.loss_dice: 0.4166, decode.d2.loss_cls: 0.0038, decode.d2.loss_mask: 0.4295, decode.d2.loss_dice: 0.4047, decode.d3.loss_cls: 0.0035, decode.d3.loss_mask: 0.4285, decode.d3.loss_dice: 0.4023, decode.d4.loss_cls: 0.0032, decode.d4.loss_mask: 0.4297, decode.d4.loss_dice: 0.4027, decode.d5.loss_cls: 0.0033, decode.d5.loss_mask: 0.4285, decode.d5.loss_dice: 0.4021, decode.d6.loss_cls: 0.0033, decode.d6.loss_mask: 0.4291, decode.d6.loss_dice: 0.4033, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.4284, decode.d7.loss_dice: 0.4037, decode.d8.loss_cls: 0.0029, decode.d8.loss_mask: 0.4276, decode.d8.loss_dice: 0.4002, loss: 9.2790, grad_norm: 433.4786
2023-08-29 02:44:25,019 - mmseg - INFO - Iter [9900/160000]	lr: 1.579e-06, eta: 1 day, 6:28:39, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3875, decode.loss_dice: 0.4082, decode.d0.loss_cls: 0.8427, decode.d0.loss_mask: 0.4084, decode.d0.loss_dice: 0.4384, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.3871, decode.d1.loss_dice: 0.4121, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3859, decode.d2.loss_dice: 0.4046, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.3859, decode.d3.loss_dice: 0.4085, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.3883, decode.d4.loss_dice: 0.4063, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.3858, decode.d5.loss_dice: 0.4055, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.3904, decode.d6.loss_dice: 0.4049, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3883, decode.d7.loss_dice: 0.4062, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3913, decode.d8.loss_dice: 0.4084, loss: 8.8621, grad_norm: 406.7515
2023-08-29 02:45:01,820 - mmseg - INFO - Iter [9950/160000]	lr: 1.579e-06, eta: 1 day, 6:28:06, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0195, decode.loss_mask: 0.4692, decode.loss_dice: 0.4564, decode.d0.loss_cls: 0.8428, decode.d0.loss_mask: 0.4939, decode.d0.loss_dice: 0.4946, decode.d1.loss_cls: 0.0221, decode.d1.loss_mask: 0.4793, decode.d1.loss_dice: 0.4641, decode.d2.loss_cls: 0.0224, decode.d2.loss_mask: 0.4729, decode.d2.loss_dice: 0.4565, decode.d3.loss_cls: 0.0191, decode.d3.loss_mask: 0.4719, decode.d3.loss_dice: 0.4527, decode.d4.loss_cls: 0.0161, decode.d4.loss_mask: 0.4731, decode.d4.loss_dice: 0.4546, decode.d5.loss_cls: 0.0166, decode.d5.loss_mask: 0.4703, decode.d5.loss_dice: 0.4556, decode.d6.loss_cls: 0.0114, decode.d6.loss_mask: 0.4842, decode.d6.loss_dice: 0.4583, decode.d7.loss_cls: 0.0156, decode.d7.loss_mask: 0.4837, decode.d7.loss_dice: 0.4600, decode.d8.loss_cls: 0.0161, decode.d8.loss_mask: 0.4810, decode.d8.loss_dice: 0.4579, loss: 10.3918, grad_norm: 458.8504
2023-08-29 02:45:38,341 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-08-29 02:45:40,951 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 02:45:40,951 - mmseg - INFO - Iter [10000/160000]	lr: 1.578e-06, eta: 1 day, 6:28:08, time: 0.783, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0092, decode.loss_mask: 0.4049, decode.loss_dice: 0.4266, decode.d0.loss_cls: 0.8323, decode.d0.loss_mask: 0.4272, decode.d0.loss_dice: 0.4668, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.4112, decode.d1.loss_dice: 0.4320, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.4101, decode.d2.loss_dice: 0.4322, decode.d3.loss_cls: 0.0066, decode.d3.loss_mask: 0.4085, decode.d3.loss_dice: 0.4271, decode.d4.loss_cls: 0.0075, decode.d4.loss_mask: 0.4047, decode.d4.loss_dice: 0.4266, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.4044, decode.d5.loss_dice: 0.4299, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.4124, decode.d6.loss_dice: 0.4278, decode.d7.loss_cls: 0.0072, decode.d7.loss_mask: 0.4042, decode.d7.loss_dice: 0.4264, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4145, decode.d8.loss_dice: 0.4295, loss: 9.3178, grad_norm: 450.7854
2023-08-29 02:46:18,385 - mmseg - INFO - Iter [10050/160000]	lr: 1.578e-06, eta: 1 day, 6:27:44, time: 0.749, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0119, decode.loss_mask: 0.4223, decode.loss_dice: 0.4290, decode.d0.loss_cls: 0.8297, decode.d0.loss_mask: 0.4376, decode.d0.loss_dice: 0.4723, decode.d1.loss_cls: 0.0096, decode.d1.loss_mask: 0.4192, decode.d1.loss_dice: 0.4380, decode.d2.loss_cls: 0.0059, decode.d2.loss_mask: 0.4189, decode.d2.loss_dice: 0.4322, decode.d3.loss_cls: 0.0081, decode.d3.loss_mask: 0.4195, decode.d3.loss_dice: 0.4303, decode.d4.loss_cls: 0.0084, decode.d4.loss_mask: 0.4243, decode.d4.loss_dice: 0.4320, decode.d5.loss_cls: 0.0060, decode.d5.loss_mask: 0.4215, decode.d5.loss_dice: 0.4307, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.4240, decode.d6.loss_dice: 0.4341, decode.d7.loss_cls: 0.0089, decode.d7.loss_mask: 0.4209, decode.d7.loss_dice: 0.4279, decode.d8.loss_cls: 0.0038, decode.d8.loss_mask: 0.4213, decode.d8.loss_dice: 0.4300, loss: 9.4830, grad_norm: 463.3174
2023-08-29 02:46:55,921 - mmseg - INFO - Iter [10100/160000]	lr: 1.577e-06, eta: 1 day, 6:27:22, time: 0.751, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0199, decode.loss_mask: 0.4491, decode.loss_dice: 0.4419, decode.d0.loss_cls: 0.8233, decode.d0.loss_mask: 0.4617, decode.d0.loss_dice: 0.4881, decode.d1.loss_cls: 0.0098, decode.d1.loss_mask: 0.4681, decode.d1.loss_dice: 0.4601, decode.d2.loss_cls: 0.0123, decode.d2.loss_mask: 0.4517, decode.d2.loss_dice: 0.4463, decode.d3.loss_cls: 0.0210, decode.d3.loss_mask: 0.4476, decode.d3.loss_dice: 0.4399, decode.d4.loss_cls: 0.0219, decode.d4.loss_mask: 0.4427, decode.d4.loss_dice: 0.4417, decode.d5.loss_cls: 0.0128, decode.d5.loss_mask: 0.4543, decode.d5.loss_dice: 0.4434, decode.d6.loss_cls: 0.0041, decode.d6.loss_mask: 0.4553, decode.d6.loss_dice: 0.4552, decode.d7.loss_cls: 0.0070, decode.d7.loss_mask: 0.4571, decode.d7.loss_dice: 0.4470, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.4621, decode.d8.loss_dice: 0.4497, loss: 9.9984, grad_norm: 452.9789
2023-08-29 02:47:30,488 - mmseg - INFO - Iter [10150/160000]	lr: 1.576e-06, eta: 1 day, 6:26:16, time: 0.691, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.4068, decode.loss_dice: 0.4182, decode.d0.loss_cls: 0.8141, decode.d0.loss_mask: 0.4303, decode.d0.loss_dice: 0.4577, decode.d1.loss_cls: 0.0037, decode.d1.loss_mask: 0.4051, decode.d1.loss_dice: 0.4215, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.4016, decode.d2.loss_dice: 0.4122, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.4057, decode.d3.loss_dice: 0.4144, decode.d4.loss_cls: 0.0026, decode.d4.loss_mask: 0.4037, decode.d4.loss_dice: 0.4147, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4015, decode.d5.loss_dice: 0.4142, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.4005, decode.d6.loss_dice: 0.4177, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.4031, decode.d7.loss_dice: 0.4158, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.4029, decode.d8.loss_dice: 0.4206, loss: 9.1063, grad_norm: 439.7706
2023-08-29 02:48:06,950 - mmseg - INFO - Iter [10200/160000]	lr: 1.576e-06, eta: 1 day, 6:25:38, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0014, decode.loss_mask: 0.4420, decode.loss_dice: 0.4485, decode.d0.loss_cls: 0.8092, decode.d0.loss_mask: 0.4698, decode.d0.loss_dice: 0.4990, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.4470, decode.d1.loss_dice: 0.4602, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.4373, decode.d2.loss_dice: 0.4491, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.4420, decode.d3.loss_dice: 0.4496, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.4442, decode.d4.loss_dice: 0.4527, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.4431, decode.d5.loss_dice: 0.4505, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.4417, decode.d6.loss_dice: 0.4518, decode.d7.loss_cls: 0.0013, decode.d7.loss_mask: 0.4420, decode.d7.loss_dice: 0.4502, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.4402, decode.d8.loss_dice: 0.4505, loss: 9.8359, grad_norm: 473.4456
2023-08-29 02:48:44,190 - mmseg - INFO - Iter [10250/160000]	lr: 1.575e-06, eta: 1 day, 6:25:11, time: 0.745, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0153, decode.loss_mask: 0.3857, decode.loss_dice: 0.3984, decode.d0.loss_cls: 0.8018, decode.d0.loss_mask: 0.4029, decode.d0.loss_dice: 0.4473, decode.d1.loss_cls: 0.0150, decode.d1.loss_mask: 0.3918, decode.d1.loss_dice: 0.4065, decode.d2.loss_cls: 0.0162, decode.d2.loss_mask: 0.3868, decode.d2.loss_dice: 0.3962, decode.d3.loss_cls: 0.0151, decode.d3.loss_mask: 0.3857, decode.d3.loss_dice: 0.3960, decode.d4.loss_cls: 0.0175, decode.d4.loss_mask: 0.3888, decode.d4.loss_dice: 0.3963, decode.d5.loss_cls: 0.0164, decode.d5.loss_mask: 0.3867, decode.d5.loss_dice: 0.3967, decode.d6.loss_cls: 0.0149, decode.d6.loss_mask: 0.3981, decode.d6.loss_dice: 0.3978, decode.d7.loss_cls: 0.0168, decode.d7.loss_mask: 0.3875, decode.d7.loss_dice: 0.3996, decode.d8.loss_cls: 0.0145, decode.d8.loss_mask: 0.3899, decode.d8.loss_dice: 0.4011, loss: 8.8831, grad_norm: 376.0325
2023-08-29 02:49:21,322 - mmseg - INFO - Iter [10300/160000]	lr: 1.575e-06, eta: 1 day, 6:24:43, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4037, decode.loss_dice: 0.4083, decode.d0.loss_cls: 0.7959, decode.d0.loss_mask: 0.4308, decode.d0.loss_dice: 0.4446, decode.d1.loss_cls: 0.0034, decode.d1.loss_mask: 0.4090, decode.d1.loss_dice: 0.4096, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.4068, decode.d2.loss_dice: 0.4062, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.4034, decode.d3.loss_dice: 0.4045, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.4039, decode.d4.loss_dice: 0.4034, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4023, decode.d5.loss_dice: 0.4050, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.4061, decode.d6.loss_dice: 0.4082, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.4059, decode.d7.loss_dice: 0.4086, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4028, decode.d8.loss_dice: 0.4083, loss: 8.9982, grad_norm: 413.8296
2023-08-29 02:49:56,159 - mmseg - INFO - Iter [10350/160000]	lr: 1.574e-06, eta: 1 day, 6:23:41, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.4213, decode.loss_dice: 0.4087, decode.d0.loss_cls: 0.7888, decode.d0.loss_mask: 0.4251, decode.d0.loss_dice: 0.4414, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.4203, decode.d1.loss_dice: 0.4127, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.4163, decode.d2.loss_dice: 0.4063, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.4180, decode.d3.loss_dice: 0.4080, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4192, decode.d4.loss_dice: 0.4041, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.4166, decode.d5.loss_dice: 0.4054, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.4169, decode.d6.loss_dice: 0.4059, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.4185, decode.d7.loss_dice: 0.4090, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.4191, decode.d8.loss_dice: 0.4059, loss: 9.1076, grad_norm: 456.0733
2023-08-29 02:50:32,625 - mmseg - INFO - Iter [10400/160000]	lr: 1.574e-06, eta: 1 day, 6:23:04, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3966, decode.loss_dice: 0.4006, decode.d0.loss_cls: 0.7828, decode.d0.loss_mask: 0.4073, decode.d0.loss_dice: 0.4257, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3928, decode.d1.loss_dice: 0.3977, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3933, decode.d2.loss_dice: 0.3981, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.3937, decode.d3.loss_dice: 0.3998, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3930, decode.d4.loss_dice: 0.4010, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3940, decode.d5.loss_dice: 0.4009, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3960, decode.d6.loss_dice: 0.3989, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.3951, decode.d7.loss_dice: 0.4020, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.3948, decode.d8.loss_dice: 0.3971, loss: 8.7769, grad_norm: 430.9405
2023-08-29 02:51:09,763 - mmseg - INFO - Iter [10450/160000]	lr: 1.573e-06, eta: 1 day, 6:22:35, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0131, decode.loss_mask: 0.4563, decode.loss_dice: 0.4487, decode.d0.loss_cls: 0.7826, decode.d0.loss_mask: 0.4835, decode.d0.loss_dice: 0.4844, decode.d1.loss_cls: 0.0182, decode.d1.loss_mask: 0.4690, decode.d1.loss_dice: 0.4613, decode.d2.loss_cls: 0.0144, decode.d2.loss_mask: 0.4533, decode.d2.loss_dice: 0.4542, decode.d3.loss_cls: 0.0153, decode.d3.loss_mask: 0.4575, decode.d3.loss_dice: 0.4555, decode.d4.loss_cls: 0.0122, decode.d4.loss_mask: 0.4558, decode.d4.loss_dice: 0.4504, decode.d5.loss_cls: 0.0137, decode.d5.loss_mask: 0.4530, decode.d5.loss_dice: 0.4507, decode.d6.loss_cls: 0.0055, decode.d6.loss_mask: 0.4588, decode.d6.loss_dice: 0.4528, decode.d7.loss_cls: 0.0113, decode.d7.loss_mask: 0.4525, decode.d7.loss_dice: 0.4522, decode.d8.loss_cls: 0.0051, decode.d8.loss_mask: 0.4642, decode.d8.loss_dice: 0.4545, loss: 10.0600, grad_norm: 493.0855
2023-08-29 02:51:47,229 - mmseg - INFO - Iter [10500/160000]	lr: 1.573e-06, eta: 1 day, 6:22:12, time: 0.749, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0091, decode.loss_mask: 0.4028, decode.loss_dice: 0.4192, decode.d0.loss_cls: 0.7727, decode.d0.loss_mask: 0.4245, decode.d0.loss_dice: 0.4569, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.4115, decode.d1.loss_dice: 0.4285, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.4037, decode.d2.loss_dice: 0.4217, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.4062, decode.d3.loss_dice: 0.4223, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.4097, decode.d4.loss_dice: 0.4210, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.4048, decode.d5.loss_dice: 0.4242, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.4064, decode.d6.loss_dice: 0.4254, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.4070, decode.d7.loss_dice: 0.4242, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.4105, decode.d8.loss_dice: 0.4246, loss: 9.1541, grad_norm: 464.6767
2023-08-29 02:52:22,143 - mmseg - INFO - Iter [10550/160000]	lr: 1.572e-06, eta: 1 day, 6:21:12, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0282, decode.loss_mask: 0.4275, decode.loss_dice: 0.4028, decode.d0.loss_cls: 0.7683, decode.d0.loss_mask: 0.4236, decode.d0.loss_dice: 0.4466, decode.d1.loss_cls: 0.0236, decode.d1.loss_mask: 0.4139, decode.d1.loss_dice: 0.4122, decode.d2.loss_cls: 0.0223, decode.d2.loss_mask: 0.4100, decode.d2.loss_dice: 0.3996, decode.d3.loss_cls: 0.0285, decode.d3.loss_mask: 0.4084, decode.d3.loss_dice: 0.3963, decode.d4.loss_cls: 0.0267, decode.d4.loss_mask: 0.4075, decode.d4.loss_dice: 0.3956, decode.d5.loss_cls: 0.0255, decode.d5.loss_mask: 0.4086, decode.d5.loss_dice: 0.3991, decode.d6.loss_cls: 0.0103, decode.d6.loss_mask: 0.4321, decode.d6.loss_dice: 0.4074, decode.d7.loss_cls: 0.0277, decode.d7.loss_mask: 0.4090, decode.d7.loss_dice: 0.3953, decode.d8.loss_cls: 0.0275, decode.d8.loss_mask: 0.4086, decode.d8.loss_dice: 0.3986, loss: 9.1914, grad_norm: 445.7760
2023-08-29 02:52:58,692 - mmseg - INFO - Iter [10600/160000]	lr: 1.572e-06, eta: 1 day, 6:20:35, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0043, decode.loss_mask: 0.4021, decode.loss_dice: 0.3856, decode.d0.loss_cls: 0.7605, decode.d0.loss_mask: 0.4111, decode.d0.loss_dice: 0.4135, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.4056, decode.d1.loss_dice: 0.3940, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.4011, decode.d2.loss_dice: 0.3885, decode.d3.loss_cls: 0.0066, decode.d3.loss_mask: 0.3984, decode.d3.loss_dice: 0.3842, decode.d4.loss_cls: 0.0050, decode.d4.loss_mask: 0.4005, decode.d4.loss_dice: 0.3866, decode.d5.loss_cls: 0.0052, decode.d5.loss_mask: 0.3999, decode.d5.loss_dice: 0.3861, decode.d6.loss_cls: 0.0054, decode.d6.loss_mask: 0.4031, decode.d6.loss_dice: 0.3865, decode.d7.loss_cls: 0.0043, decode.d7.loss_mask: 0.4019, decode.d7.loss_dice: 0.3873, decode.d8.loss_cls: 0.0042, decode.d8.loss_mask: 0.4013, decode.d8.loss_dice: 0.3853, loss: 8.7286, grad_norm: 418.0641
2023-08-29 02:53:35,610 - mmseg - INFO - Iter [10650/160000]	lr: 1.571e-06, eta: 1 day, 6:20:03, time: 0.739, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0073, decode.loss_mask: 0.4318, decode.loss_dice: 0.3970, decode.d0.loss_cls: 0.7544, decode.d0.loss_mask: 0.4484, decode.d0.loss_dice: 0.4370, decode.d1.loss_cls: 0.0154, decode.d1.loss_mask: 0.4351, decode.d1.loss_dice: 0.4045, decode.d2.loss_cls: 0.0120, decode.d2.loss_mask: 0.4291, decode.d2.loss_dice: 0.4008, decode.d3.loss_cls: 0.0109, decode.d3.loss_mask: 0.4308, decode.d3.loss_dice: 0.3984, decode.d4.loss_cls: 0.0111, decode.d4.loss_mask: 0.4289, decode.d4.loss_dice: 0.4013, decode.d5.loss_cls: 0.0111, decode.d5.loss_mask: 0.4283, decode.d5.loss_dice: 0.3990, decode.d6.loss_cls: 0.0091, decode.d6.loss_mask: 0.4322, decode.d6.loss_dice: 0.3994, decode.d7.loss_cls: 0.0076, decode.d7.loss_mask: 0.4309, decode.d7.loss_dice: 0.3968, decode.d8.loss_cls: 0.0064, decode.d8.loss_mask: 0.4288, decode.d8.loss_dice: 0.3962, loss: 9.1999, grad_norm: 436.5547
2023-08-29 02:54:12,955 - mmseg - INFO - Iter [10700/160000]	lr: 1.571e-06, eta: 1 day, 6:19:38, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.4306, decode.loss_dice: 0.4303, decode.d0.loss_cls: 0.7476, decode.d0.loss_mask: 0.4355, decode.d0.loss_dice: 0.4646, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.4263, decode.d1.loss_dice: 0.4321, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.4231, decode.d2.loss_dice: 0.4250, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.4195, decode.d3.loss_dice: 0.4248, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4224, decode.d4.loss_dice: 0.4260, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4233, decode.d5.loss_dice: 0.4246, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4277, decode.d6.loss_dice: 0.4266, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.4280, decode.d7.loss_dice: 0.4260, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4300, decode.d8.loss_dice: 0.4317, loss: 9.3484, grad_norm: 442.8597
2023-08-29 02:54:48,209 - mmseg - INFO - Iter [10750/160000]	lr: 1.570e-06, eta: 1 day, 6:18:43, time: 0.705, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.3440, decode.loss_dice: 0.3747, decode.d0.loss_cls: 0.7418, decode.d0.loss_mask: 0.3602, decode.d0.loss_dice: 0.4070, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.3422, decode.d1.loss_dice: 0.3817, decode.d2.loss_cls: 0.0026, decode.d2.loss_mask: 0.3430, decode.d2.loss_dice: 0.3735, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.3447, decode.d3.loss_dice: 0.3716, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.3436, decode.d4.loss_dice: 0.3725, decode.d5.loss_cls: 0.0022, decode.d5.loss_mask: 0.3433, decode.d5.loss_dice: 0.3730, decode.d6.loss_cls: 0.0022, decode.d6.loss_mask: 0.3455, decode.d6.loss_dice: 0.3682, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.3412, decode.d7.loss_dice: 0.3701, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3431, decode.d8.loss_dice: 0.3725, loss: 7.9784, grad_norm: 363.4201
2023-08-29 02:55:24,784 - mmseg - INFO - Iter [10800/160000]	lr: 1.570e-06, eta: 1 day, 6:18:07, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.3899, decode.loss_dice: 0.4059, decode.d0.loss_cls: 0.7345, decode.d0.loss_mask: 0.4093, decode.d0.loss_dice: 0.4416, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3889, decode.d1.loss_dice: 0.4070, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.3884, decode.d2.loss_dice: 0.4030, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.3899, decode.d3.loss_dice: 0.4063, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.3888, decode.d4.loss_dice: 0.4085, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.3895, decode.d5.loss_dice: 0.4060, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.3882, decode.d6.loss_dice: 0.4078, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.3887, decode.d7.loss_dice: 0.4112, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.3896, decode.d8.loss_dice: 0.4074, loss: 8.7608, grad_norm: 482.2124
2023-08-29 02:56:01,708 - mmseg - INFO - Iter [10850/160000]	lr: 1.569e-06, eta: 1 day, 6:17:35, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.3981, decode.loss_dice: 0.3888, decode.d0.loss_cls: 0.7303, decode.d0.loss_mask: 0.4222, decode.d0.loss_dice: 0.4203, decode.d1.loss_cls: 0.0032, decode.d1.loss_mask: 0.4054, decode.d1.loss_dice: 0.3932, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.3990, decode.d2.loss_dice: 0.3908, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.3994, decode.d3.loss_dice: 0.3879, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.4004, decode.d4.loss_dice: 0.3904, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.3977, decode.d5.loss_dice: 0.3880, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.3960, decode.d6.loss_dice: 0.3885, decode.d7.loss_cls: 0.0024, decode.d7.loss_mask: 0.3988, decode.d7.loss_dice: 0.3894, decode.d8.loss_cls: 0.0023, decode.d8.loss_mask: 0.3963, decode.d8.loss_dice: 0.3889, loss: 8.6929, grad_norm: 423.1442
2023-08-29 02:56:39,068 - mmseg - INFO - Iter [10900/160000]	lr: 1.569e-06, eta: 1 day, 6:17:10, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.3891, decode.loss_dice: 0.3736, decode.d0.loss_cls: 0.7263, decode.d0.loss_mask: 0.4066, decode.d0.loss_dice: 0.4023, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3914, decode.d1.loss_dice: 0.3796, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3860, decode.d2.loss_dice: 0.3725, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.3872, decode.d3.loss_dice: 0.3713, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.3896, decode.d4.loss_dice: 0.3727, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.3893, decode.d5.loss_dice: 0.3733, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3905, decode.d6.loss_dice: 0.3713, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3902, decode.d7.loss_dice: 0.3732, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3901, decode.d8.loss_dice: 0.3739, loss: 8.4181, grad_norm: 417.3274
2023-08-29 02:57:14,028 - mmseg - INFO - Iter [10950/160000]	lr: 1.568e-06, eta: 1 day, 6:16:11, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0233, decode.loss_mask: 0.4225, decode.loss_dice: 0.4195, decode.d0.loss_cls: 0.7224, decode.d0.loss_mask: 0.4319, decode.d0.loss_dice: 0.4530, decode.d1.loss_cls: 0.0246, decode.d1.loss_mask: 0.4276, decode.d1.loss_dice: 0.4253, decode.d2.loss_cls: 0.0166, decode.d2.loss_mask: 0.4220, decode.d2.loss_dice: 0.4185, decode.d3.loss_cls: 0.0260, decode.d3.loss_mask: 0.4158, decode.d3.loss_dice: 0.4128, decode.d4.loss_cls: 0.0243, decode.d4.loss_mask: 0.4200, decode.d4.loss_dice: 0.4146, decode.d5.loss_cls: 0.0243, decode.d5.loss_mask: 0.4151, decode.d5.loss_dice: 0.4174, decode.d6.loss_cls: 0.0180, decode.d6.loss_mask: 0.4184, decode.d6.loss_dice: 0.4219, decode.d7.loss_cls: 0.0170, decode.d7.loss_mask: 0.4189, decode.d7.loss_dice: 0.4184, decode.d8.loss_cls: 0.0151, decode.d8.loss_mask: 0.4193, decode.d8.loss_dice: 0.4162, loss: 9.3407, grad_norm: 399.8032
2023-08-29 02:57:50,785 - mmseg - INFO - Saving checkpoint at 11000 iterations
2023-08-29 02:57:53,824 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 02:57:53,824 - mmseg - INFO - Iter [11000/160000]	lr: 1.568e-06, eta: 1 day, 6:16:19, time: 0.796, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0091, decode.loss_mask: 0.3874, decode.loss_dice: 0.4087, decode.d0.loss_cls: 0.7153, decode.d0.loss_mask: 0.4070, decode.d0.loss_dice: 0.4424, decode.d1.loss_cls: 0.0143, decode.d1.loss_mask: 0.3828, decode.d1.loss_dice: 0.4102, decode.d2.loss_cls: 0.0123, decode.d2.loss_mask: 0.3797, decode.d2.loss_dice: 0.4019, decode.d3.loss_cls: 0.0132, decode.d3.loss_mask: 0.3787, decode.d3.loss_dice: 0.4026, decode.d4.loss_cls: 0.0125, decode.d4.loss_mask: 0.3792, decode.d4.loss_dice: 0.4033, decode.d5.loss_cls: 0.0125, decode.d5.loss_mask: 0.3790, decode.d5.loss_dice: 0.4031, decode.d6.loss_cls: 0.0100, decode.d6.loss_mask: 0.3784, decode.d6.loss_dice: 0.4059, decode.d7.loss_cls: 0.0119, decode.d7.loss_mask: 0.3785, decode.d7.loss_dice: 0.4025, decode.d8.loss_cls: 0.0146, decode.d8.loss_mask: 0.3798, decode.d8.loss_dice: 0.4078, loss: 8.7445, grad_norm: 414.9154
2023-08-29 02:58:30,465 - mmseg - INFO - Iter [11050/160000]	lr: 1.567e-06, eta: 1 day, 6:15:43, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0068, decode.loss_mask: 0.4220, decode.loss_dice: 0.3839, decode.d0.loss_cls: 0.7113, decode.d0.loss_mask: 0.4386, decode.d0.loss_dice: 0.4209, decode.d1.loss_cls: 0.0153, decode.d1.loss_mask: 0.4193, decode.d1.loss_dice: 0.3883, decode.d2.loss_cls: 0.0111, decode.d2.loss_mask: 0.4172, decode.d2.loss_dice: 0.3912, decode.d3.loss_cls: 0.0105, decode.d3.loss_mask: 0.4169, decode.d3.loss_dice: 0.3877, decode.d4.loss_cls: 0.0076, decode.d4.loss_mask: 0.4135, decode.d4.loss_dice: 0.3865, decode.d5.loss_cls: 0.0079, decode.d5.loss_mask: 0.4123, decode.d5.loss_dice: 0.3857, decode.d6.loss_cls: 0.0075, decode.d6.loss_mask: 0.4148, decode.d6.loss_dice: 0.3858, decode.d7.loss_cls: 0.0106, decode.d7.loss_mask: 0.4163, decode.d7.loss_dice: 0.3845, decode.d8.loss_cls: 0.0101, decode.d8.loss_mask: 0.4158, decode.d8.loss_dice: 0.3857, loss: 8.8854, grad_norm: 517.8718
2023-08-29 02:59:07,573 - mmseg - INFO - Iter [11100/160000]	lr: 1.566e-06, eta: 1 day, 6:15:14, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0027, decode.loss_mask: 0.4081, decode.loss_dice: 0.4120, decode.d0.loss_cls: 0.7041, decode.d0.loss_mask: 0.4299, decode.d0.loss_dice: 0.4523, decode.d1.loss_cls: 0.0035, decode.d1.loss_mask: 0.4129, decode.d1.loss_dice: 0.4190, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4088, decode.d2.loss_dice: 0.4102, decode.d3.loss_cls: 0.0030, decode.d3.loss_mask: 0.4072, decode.d3.loss_dice: 0.4083, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.4066, decode.d4.loss_dice: 0.4113, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.4075, decode.d5.loss_dice: 0.4108, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.4033, decode.d6.loss_dice: 0.4090, decode.d7.loss_cls: 0.0028, decode.d7.loss_mask: 0.4047, decode.d7.loss_dice: 0.4085, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.4066, decode.d8.loss_dice: 0.4098, loss: 8.9767, grad_norm: 417.2771
2023-08-29 02:59:42,438 - mmseg - INFO - Iter [11150/160000]	lr: 1.566e-06, eta: 1 day, 6:14:14, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.4305, decode.loss_dice: 0.4136, decode.d0.loss_cls: 0.6977, decode.d0.loss_mask: 0.4370, decode.d0.loss_dice: 0.4495, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.4298, decode.d1.loss_dice: 0.4120, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.4349, decode.d2.loss_dice: 0.4137, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.4335, decode.d3.loss_dice: 0.4144, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.4336, decode.d4.loss_dice: 0.4156, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.4307, decode.d5.loss_dice: 0.4157, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.4341, decode.d6.loss_dice: 0.4146, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.4307, decode.d7.loss_dice: 0.4151, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.4299, decode.d8.loss_dice: 0.4124, loss: 9.2215, grad_norm: 416.5034
2023-08-29 03:00:19,342 - mmseg - INFO - Iter [11200/160000]	lr: 1.565e-06, eta: 1 day, 6:13:42, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3773, decode.loss_dice: 0.3831, decode.d0.loss_cls: 0.6921, decode.d0.loss_mask: 0.4020, decode.d0.loss_dice: 0.4161, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3823, decode.d1.loss_dice: 0.3901, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3750, decode.d2.loss_dice: 0.3842, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3766, decode.d3.loss_dice: 0.3808, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.3781, decode.d4.loss_dice: 0.3788, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.3758, decode.d5.loss_dice: 0.3818, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.3781, decode.d6.loss_dice: 0.3850, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.3788, decode.d7.loss_dice: 0.3829, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3781, decode.d8.loss_dice: 0.3811, loss: 8.3753, grad_norm: 421.6996
2023-08-29 03:00:56,082 - mmseg - INFO - Iter [11250/160000]	lr: 1.565e-06, eta: 1 day, 6:13:08, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0174, decode.loss_mask: 0.4241, decode.loss_dice: 0.4258, decode.d0.loss_cls: 0.6897, decode.d0.loss_mask: 0.4377, decode.d0.loss_dice: 0.4709, decode.d1.loss_cls: 0.0141, decode.d1.loss_mask: 0.4281, decode.d1.loss_dice: 0.4320, decode.d2.loss_cls: 0.0117, decode.d2.loss_mask: 0.4222, decode.d2.loss_dice: 0.4344, decode.d3.loss_cls: 0.0096, decode.d3.loss_mask: 0.4397, decode.d3.loss_dice: 0.4323, decode.d4.loss_cls: 0.0121, decode.d4.loss_mask: 0.4292, decode.d4.loss_dice: 0.4320, decode.d5.loss_cls: 0.0089, decode.d5.loss_mask: 0.4385, decode.d5.loss_dice: 0.4350, decode.d6.loss_cls: 0.0026, decode.d6.loss_mask: 0.4569, decode.d6.loss_dice: 0.4348, decode.d7.loss_cls: 0.0071, decode.d7.loss_mask: 0.4405, decode.d7.loss_dice: 0.4318, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4492, decode.d8.loss_dice: 0.4357, loss: 9.5065, grad_norm: 416.3612
2023-08-29 03:01:33,247 - mmseg - INFO - Iter [11300/160000]	lr: 1.564e-06, eta: 1 day, 6:12:39, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.4239, decode.loss_dice: 0.4013, decode.d0.loss_cls: 0.6829, decode.d0.loss_mask: 0.4482, decode.d0.loss_dice: 0.4358, decode.d1.loss_cls: 0.0036, decode.d1.loss_mask: 0.4320, decode.d1.loss_dice: 0.4108, decode.d2.loss_cls: 0.0030, decode.d2.loss_mask: 0.4225, decode.d2.loss_dice: 0.4051, decode.d3.loss_cls: 0.0028, decode.d3.loss_mask: 0.4207, decode.d3.loss_dice: 0.4017, decode.d4.loss_cls: 0.0027, decode.d4.loss_mask: 0.4213, decode.d4.loss_dice: 0.4038, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.4230, decode.d5.loss_dice: 0.4047, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.4219, decode.d6.loss_dice: 0.4019, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.4254, decode.d7.loss_dice: 0.4053, decode.d8.loss_cls: 0.0025, decode.d8.loss_mask: 0.4214, decode.d8.loss_dice: 0.4062, loss: 9.0451, grad_norm: 393.9430
2023-08-29 03:02:08,476 - mmseg - INFO - Iter [11350/160000]	lr: 1.564e-06, eta: 1 day, 6:11:45, time: 0.705, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.3905, decode.loss_dice: 0.3917, decode.d0.loss_cls: 0.6773, decode.d0.loss_mask: 0.4075, decode.d0.loss_dice: 0.4345, decode.d1.loss_cls: 0.0029, decode.d1.loss_mask: 0.3939, decode.d1.loss_dice: 0.4047, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3883, decode.d2.loss_dice: 0.3933, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3847, decode.d3.loss_dice: 0.3895, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.3865, decode.d4.loss_dice: 0.3885, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.3878, decode.d5.loss_dice: 0.3919, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3875, decode.d6.loss_dice: 0.3877, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.3877, decode.d7.loss_dice: 0.3909, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3877, decode.d8.loss_dice: 0.3922, loss: 8.5630, grad_norm: 420.6752
2023-08-29 03:02:45,409 - mmseg - INFO - Iter [11400/160000]	lr: 1.563e-06, eta: 1 day, 6:11:13, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.4117, decode.loss_dice: 0.4076, decode.d0.loss_cls: 0.6720, decode.d0.loss_mask: 0.4307, decode.d0.loss_dice: 0.4405, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.4143, decode.d1.loss_dice: 0.4165, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.4133, decode.d2.loss_dice: 0.4130, decode.d3.loss_cls: 0.0023, decode.d3.loss_mask: 0.4135, decode.d3.loss_dice: 0.4128, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4143, decode.d4.loss_dice: 0.4130, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.4165, decode.d5.loss_dice: 0.4136, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.4130, decode.d6.loss_dice: 0.4132, decode.d7.loss_cls: 0.0026, decode.d7.loss_mask: 0.4139, decode.d7.loss_dice: 0.4114, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4146, decode.d8.loss_dice: 0.4102, loss: 9.0013, grad_norm: 394.0791
2023-08-29 03:03:21,750 - mmseg - INFO - Iter [11450/160000]	lr: 1.563e-06, eta: 1 day, 6:10:34, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0168, decode.loss_mask: 0.3703, decode.loss_dice: 0.3606, decode.d0.loss_cls: 0.6676, decode.d0.loss_mask: 0.3849, decode.d0.loss_dice: 0.3995, decode.d1.loss_cls: 0.0167, decode.d1.loss_mask: 0.3681, decode.d1.loss_dice: 0.3670, decode.d2.loss_cls: 0.0147, decode.d2.loss_mask: 0.3703, decode.d2.loss_dice: 0.3593, decode.d3.loss_cls: 0.0176, decode.d3.loss_mask: 0.3700, decode.d3.loss_dice: 0.3613, decode.d4.loss_cls: 0.0129, decode.d4.loss_mask: 0.3715, decode.d4.loss_dice: 0.3586, decode.d5.loss_cls: 0.0140, decode.d5.loss_mask: 0.3731, decode.d5.loss_dice: 0.3615, decode.d6.loss_cls: 0.0117, decode.d6.loss_mask: 0.3749, decode.d6.loss_dice: 0.3629, decode.d7.loss_cls: 0.0156, decode.d7.loss_mask: 0.3770, decode.d7.loss_dice: 0.3628, decode.d8.loss_cls: 0.0122, decode.d8.loss_mask: 0.3723, decode.d8.loss_dice: 0.3591, loss: 8.1848, grad_norm: 380.3757
2023-08-29 03:03:59,014 - mmseg - INFO - Iter [11500/160000]	lr: 1.562e-06, eta: 1 day, 6:10:06, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0012, decode.loss_mask: 0.3936, decode.loss_dice: 0.4002, decode.d0.loss_cls: 0.6604, decode.d0.loss_mask: 0.4080, decode.d0.loss_dice: 0.4434, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3960, decode.d1.loss_dice: 0.3967, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.3914, decode.d2.loss_dice: 0.3949, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.3924, decode.d3.loss_dice: 0.3974, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.3922, decode.d4.loss_dice: 0.3975, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.3926, decode.d5.loss_dice: 0.3951, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.3933, decode.d6.loss_dice: 0.4005, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.4025, decode.d7.loss_dice: 0.3963, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3976, decode.d8.loss_dice: 0.3960, loss: 8.6492, grad_norm: 445.5321
2023-08-29 03:04:34,101 - mmseg - INFO - Iter [11550/160000]	lr: 1.562e-06, eta: 1 day, 6:09:11, time: 0.702, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.4377, decode.loss_dice: 0.4268, decode.d0.loss_cls: 0.6580, decode.d0.loss_mask: 0.4736, decode.d0.loss_dice: 0.4741, decode.d1.loss_cls: 0.0030, decode.d1.loss_mask: 0.4437, decode.d1.loss_dice: 0.4367, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.4347, decode.d2.loss_dice: 0.4295, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4330, decode.d3.loss_dice: 0.4258, decode.d4.loss_cls: 0.0023, decode.d4.loss_mask: 0.4346, decode.d4.loss_dice: 0.4269, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.4355, decode.d5.loss_dice: 0.4328, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.4372, decode.d6.loss_dice: 0.4295, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.4363, decode.d7.loss_dice: 0.4233, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.4362, decode.d8.loss_dice: 0.4279, loss: 9.4152, grad_norm: 432.8218
2023-08-29 03:05:10,837 - mmseg - INFO - Iter [11600/160000]	lr: 1.561e-06, eta: 1 day, 6:08:36, time: 0.735, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.4041, decode.loss_dice: 0.4200, decode.d0.loss_cls: 0.6503, decode.d0.loss_mask: 0.4322, decode.d0.loss_dice: 0.4478, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.4033, decode.d1.loss_dice: 0.4215, decode.d2.loss_cls: 0.0028, decode.d2.loss_mask: 0.4016, decode.d2.loss_dice: 0.4213, decode.d3.loss_cls: 0.0025, decode.d3.loss_mask: 0.4071, decode.d3.loss_dice: 0.4160, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.4017, decode.d4.loss_dice: 0.4207, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.4067, decode.d5.loss_dice: 0.4223, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.4041, decode.d6.loss_dice: 0.4221, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.4037, decode.d7.loss_dice: 0.4221, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.4039, decode.d8.loss_dice: 0.4224, loss: 8.9779, grad_norm: 432.2402
2023-08-29 03:05:47,453 - mmseg - INFO - Iter [11650/160000]	lr: 1.561e-06, eta: 1 day, 6:08:00, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0159, decode.loss_mask: 0.4098, decode.loss_dice: 0.3951, decode.d0.loss_cls: 0.6472, decode.d0.loss_mask: 0.4179, decode.d0.loss_dice: 0.4249, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.4135, decode.d1.loss_dice: 0.3995, decode.d2.loss_cls: 0.0133, decode.d2.loss_mask: 0.4166, decode.d2.loss_dice: 0.3940, decode.d3.loss_cls: 0.0151, decode.d3.loss_mask: 0.4135, decode.d3.loss_dice: 0.3905, decode.d4.loss_cls: 0.0119, decode.d4.loss_mask: 0.4368, decode.d4.loss_dice: 0.3939, decode.d5.loss_cls: 0.0160, decode.d5.loss_mask: 0.4592, decode.d5.loss_dice: 0.3895, decode.d6.loss_cls: 0.0164, decode.d6.loss_mask: 0.4448, decode.d6.loss_dice: 0.3909, decode.d7.loss_cls: 0.0201, decode.d7.loss_mask: 0.4111, decode.d7.loss_dice: 0.3951, decode.d8.loss_cls: 0.0186, decode.d8.loss_mask: 0.4092, decode.d8.loss_dice: 0.3931, loss: 8.9881, grad_norm: 481.5396
2023-08-29 03:06:24,466 - mmseg - INFO - Iter [11700/160000]	lr: 1.560e-06, eta: 1 day, 6:07:30, time: 0.740, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0130, decode.loss_mask: 0.4126, decode.loss_dice: 0.4107, decode.d0.loss_cls: 0.6462, decode.d0.loss_mask: 0.4302, decode.d0.loss_dice: 0.4435, decode.d1.loss_cls: 0.0107, decode.d1.loss_mask: 0.4211, decode.d1.loss_dice: 0.4235, decode.d2.loss_cls: 0.0031, decode.d2.loss_mask: 0.4283, decode.d2.loss_dice: 0.4159, decode.d3.loss_cls: 0.0157, decode.d3.loss_mask: 0.4089, decode.d3.loss_dice: 0.4074, decode.d4.loss_cls: 0.0119, decode.d4.loss_mask: 0.4094, decode.d4.loss_dice: 0.4064, decode.d5.loss_cls: 0.0061, decode.d5.loss_mask: 0.4214, decode.d5.loss_dice: 0.4078, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.4266, decode.d6.loss_dice: 0.4142, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.4229, decode.d7.loss_dice: 0.4121, decode.d8.loss_cls: 0.0047, decode.d8.loss_mask: 0.4250, decode.d8.loss_dice: 0.4154, loss: 9.0825, grad_norm: 426.6151
2023-08-29 03:07:01,991 - mmseg - INFO - Iter [11750/160000]	lr: 1.560e-06, eta: 1 day, 6:07:05, time: 0.751, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.3724, decode.loss_dice: 0.3711, decode.d0.loss_cls: 0.6349, decode.d0.loss_mask: 0.3849, decode.d0.loss_dice: 0.4184, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3634, decode.d1.loss_dice: 0.3744, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3607, decode.d2.loss_dice: 0.3677, decode.d3.loss_cls: 0.0018, decode.d3.loss_mask: 0.3658, decode.d3.loss_dice: 0.3695, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3683, decode.d4.loss_dice: 0.3729, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3676, decode.d5.loss_dice: 0.3727, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.3713, decode.d6.loss_dice: 0.3710, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.3684, decode.d7.loss_dice: 0.3725, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3668, decode.d8.loss_dice: 0.3705, loss: 8.1021, grad_norm: 395.3943
2023-08-29 03:07:36,777 - mmseg - INFO - Iter [11800/160000]	lr: 1.559e-06, eta: 1 day, 6:06:06, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0087, decode.loss_mask: 0.4144, decode.loss_dice: 0.4107, decode.d0.loss_cls: 0.6330, decode.d0.loss_mask: 0.4331, decode.d0.loss_dice: 0.4498, decode.d1.loss_cls: 0.0085, decode.d1.loss_mask: 0.4149, decode.d1.loss_dice: 0.4166, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.4068, decode.d2.loss_dice: 0.4096, decode.d3.loss_cls: 0.0076, decode.d3.loss_mask: 0.4098, decode.d3.loss_dice: 0.4058, decode.d4.loss_cls: 0.0056, decode.d4.loss_mask: 0.4113, decode.d4.loss_dice: 0.4076, decode.d5.loss_cls: 0.0058, decode.d5.loss_mask: 0.4104, decode.d5.loss_dice: 0.4088, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.4240, decode.d6.loss_dice: 0.4157, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.4113, decode.d7.loss_dice: 0.4136, decode.d8.loss_cls: 0.0081, decode.d8.loss_mask: 0.4136, decode.d8.loss_dice: 0.4154, loss: 8.9952, grad_norm: 501.9649
2023-08-29 03:08:13,378 - mmseg - INFO - Iter [11850/160000]	lr: 1.559e-06, eta: 1 day, 6:05:30, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.4129, decode.loss_dice: 0.4005, decode.d0.loss_cls: 0.6270, decode.d0.loss_mask: 0.4262, decode.d0.loss_dice: 0.4451, decode.d1.loss_cls: 0.0017, decode.d1.loss_mask: 0.4201, decode.d1.loss_dice: 0.4129, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.4173, decode.d2.loss_dice: 0.4063, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.4157, decode.d3.loss_dice: 0.4024, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.4082, decode.d4.loss_dice: 0.4029, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.4159, decode.d5.loss_dice: 0.4037, decode.d6.loss_cls: 0.0007, decode.d6.loss_mask: 0.4185, decode.d6.loss_dice: 0.4035, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.4134, decode.d7.loss_dice: 0.4028, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.4144, decode.d8.loss_dice: 0.4031, loss: 8.8875, grad_norm: 388.6717
2023-08-29 03:08:50,431 - mmseg - INFO - Iter [11900/160000]	lr: 1.558e-06, eta: 1 day, 6:05:00, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0188, decode.loss_mask: 0.3798, decode.loss_dice: 0.3743, decode.d0.loss_cls: 0.6228, decode.d0.loss_mask: 0.3990, decode.d0.loss_dice: 0.4034, decode.d1.loss_cls: 0.0214, decode.d1.loss_mask: 0.3868, decode.d1.loss_dice: 0.3711, decode.d2.loss_cls: 0.0221, decode.d2.loss_mask: 0.3810, decode.d2.loss_dice: 0.3718, decode.d3.loss_cls: 0.0229, decode.d3.loss_mask: 0.3835, decode.d3.loss_dice: 0.3690, decode.d4.loss_cls: 0.0223, decode.d4.loss_mask: 0.3810, decode.d4.loss_dice: 0.3675, decode.d5.loss_cls: 0.0118, decode.d5.loss_mask: 0.4013, decode.d5.loss_dice: 0.3719, decode.d6.loss_cls: 0.0105, decode.d6.loss_mask: 0.4018, decode.d6.loss_dice: 0.3707, decode.d7.loss_cls: 0.0224, decode.d7.loss_mask: 0.3791, decode.d7.loss_dice: 0.3684, decode.d8.loss_cls: 0.0119, decode.d8.loss_mask: 0.4025, decode.d8.loss_dice: 0.3795, loss: 8.4300, grad_norm: 362.2385
2023-08-29 03:09:27,656 - mmseg - INFO - Iter [11950/160000]	lr: 1.558e-06, eta: 1 day, 6:04:31, time: 0.745, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0075, decode.loss_mask: 0.3804, decode.loss_dice: 0.3756, decode.d0.loss_cls: 0.6165, decode.d0.loss_mask: 0.4009, decode.d0.loss_dice: 0.4064, decode.d1.loss_cls: 0.0015, decode.d1.loss_mask: 0.3906, decode.d1.loss_dice: 0.3854, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.3935, decode.d2.loss_dice: 0.3829, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3959, decode.d3.loss_dice: 0.3796, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.3949, decode.d4.loss_dice: 0.3813, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.3958, decode.d5.loss_dice: 0.3854, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.3964, decode.d6.loss_dice: 0.3848, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.3826, decode.d7.loss_dice: 0.3796, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.3919, decode.d8.loss_dice: 0.3850, loss: 8.4057, grad_norm: 464.6676
2023-08-29 03:10:02,258 - mmseg - INFO - Saving checkpoint at 12000 iterations
2023-08-29 03:10:04,885 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 03:10:04,885 - mmseg - INFO - Iter [12000/160000]	lr: 1.557e-06, eta: 1 day, 6:04:03, time: 0.745, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0007, decode.loss_mask: 0.3825, decode.loss_dice: 0.3817, decode.d0.loss_cls: 0.6097, decode.d0.loss_mask: 0.4108, decode.d0.loss_dice: 0.4257, decode.d1.loss_cls: 0.0016, decode.d1.loss_mask: 0.3825, decode.d1.loss_dice: 0.3846, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.3789, decode.d2.loss_dice: 0.3791, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3814, decode.d3.loss_dice: 0.3799, decode.d4.loss_cls: 0.0007, decode.d4.loss_mask: 0.3804, decode.d4.loss_dice: 0.3806, decode.d5.loss_cls: 0.0006, decode.d5.loss_mask: 0.3800, decode.d5.loss_dice: 0.3827, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.3813, decode.d6.loss_dice: 0.3851, decode.d7.loss_cls: 0.0007, decode.d7.loss_mask: 0.3816, decode.d7.loss_dice: 0.3837, decode.d8.loss_cls: 0.0006, decode.d8.loss_mask: 0.3802, decode.d8.loss_dice: 0.3847, loss: 8.3250, grad_norm: 409.6352
2023-08-29 03:10:41,582 - mmseg - INFO - Iter [12050/160000]	lr: 1.556e-06, eta: 1 day, 6:03:28, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0011, decode.loss_mask: 0.3795, decode.loss_dice: 0.3974, decode.d0.loss_cls: 0.6065, decode.d0.loss_mask: 0.3953, decode.d0.loss_dice: 0.4271, decode.d1.loss_cls: 0.0019, decode.d1.loss_mask: 0.3791, decode.d1.loss_dice: 0.3977, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.3785, decode.d2.loss_dice: 0.3928, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.3779, decode.d3.loss_dice: 0.3897, decode.d4.loss_cls: 0.0011, decode.d4.loss_mask: 0.3764, decode.d4.loss_dice: 0.3896, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.3779, decode.d5.loss_dice: 0.3905, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.3803, decode.d6.loss_dice: 0.3932, decode.d7.loss_cls: 0.0011, decode.d7.loss_mask: 0.3781, decode.d7.loss_dice: 0.3897, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3805, decode.d8.loss_dice: 0.3957, loss: 8.3845, grad_norm: 344.5816
2023-08-29 03:11:18,737 - mmseg - INFO - Iter [12100/160000]	lr: 1.556e-06, eta: 1 day, 6:02:58, time: 0.743, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0090, decode.loss_mask: 0.3531, decode.loss_dice: 0.3551, decode.d0.loss_cls: 0.6009, decode.d0.loss_mask: 0.3626, decode.d0.loss_dice: 0.3847, decode.d1.loss_cls: 0.0018, decode.d1.loss_mask: 0.3580, decode.d1.loss_dice: 0.3615, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.3611, decode.d2.loss_dice: 0.3583, decode.d3.loss_cls: 0.0012, decode.d3.loss_mask: 0.3647, decode.d3.loss_dice: 0.3582, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.3631, decode.d4.loss_dice: 0.3588, decode.d5.loss_cls: 0.0010, decode.d5.loss_mask: 0.3643, decode.d5.loss_dice: 0.3620, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.3671, decode.d6.loss_dice: 0.3620, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.3518, decode.d7.loss_dice: 0.3559, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3667, decode.d8.loss_dice: 0.3589, loss: 7.8526, grad_norm: 382.4555
2023-08-29 03:11:56,059 - mmseg - INFO - Iter [12150/160000]	lr: 1.555e-06, eta: 1 day, 6:02:31, time: 0.747, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0016, decode.loss_mask: 0.3842, decode.loss_dice: 0.3603, decode.d0.loss_cls: 0.5964, decode.d0.loss_mask: 0.4028, decode.d0.loss_dice: 0.4003, decode.d1.loss_cls: 0.0025, decode.d1.loss_mask: 0.3818, decode.d1.loss_dice: 0.3670, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3807, decode.d2.loss_dice: 0.3632, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.3818, decode.d3.loss_dice: 0.3616, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3839, decode.d4.loss_dice: 0.3617, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3829, decode.d5.loss_dice: 0.3619, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3849, decode.d6.loss_dice: 0.3622, decode.d7.loss_cls: 0.0016, decode.d7.loss_mask: 0.3857, decode.d7.loss_dice: 0.3618, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3859, decode.d8.loss_dice: 0.3626, loss: 8.1295, grad_norm: 453.6290
2023-08-29 03:12:30,854 - mmseg - INFO - Iter [12200/160000]	lr: 1.555e-06, eta: 1 day, 6:01:33, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0083, decode.loss_mask: 0.3893, decode.loss_dice: 0.3912, decode.d0.loss_cls: 0.5904, decode.d0.loss_mask: 0.4098, decode.d0.loss_dice: 0.4283, decode.d1.loss_cls: 0.0015, decode.d1.loss_mask: 0.3962, decode.d1.loss_dice: 0.3977, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.3945, decode.d2.loss_dice: 0.3936, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.3972, decode.d3.loss_dice: 0.3940, decode.d4.loss_cls: 0.0006, decode.d4.loss_mask: 0.3965, decode.d4.loss_dice: 0.3964, decode.d5.loss_cls: 0.0005, decode.d5.loss_mask: 0.3939, decode.d5.loss_dice: 0.3967, decode.d6.loss_cls: 0.0006, decode.d6.loss_mask: 0.3934, decode.d6.loss_dice: 0.3940, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.3885, decode.d7.loss_dice: 0.3916, decode.d8.loss_cls: 0.0005, decode.d8.loss_mask: 0.3935, decode.d8.loss_dice: 0.3934, loss: 8.5396, grad_norm: 475.5031
2023-08-29 03:13:07,309 - mmseg - INFO - Iter [12250/160000]	lr: 1.554e-06, eta: 1 day, 6:00:55, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.3528, decode.loss_dice: 0.3512, decode.d0.loss_cls: 0.5868, decode.d0.loss_mask: 0.3697, decode.d0.loss_dice: 0.3843, decode.d1.loss_cls: 0.0024, decode.d1.loss_mask: 0.3531, decode.d1.loss_dice: 0.3503, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3541, decode.d2.loss_dice: 0.3517, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3553, decode.d3.loss_dice: 0.3508, decode.d4.loss_cls: 0.0018, decode.d4.loss_mask: 0.3533, decode.d4.loss_dice: 0.3507, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.3514, decode.d5.loss_dice: 0.3469, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3518, decode.d6.loss_dice: 0.3505, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3512, decode.d7.loss_dice: 0.3497, decode.d8.loss_cls: 0.0019, decode.d8.loss_mask: 0.3551, decode.d8.loss_dice: 0.3513, loss: 7.6897, grad_norm: 384.2846
2023-08-29 03:13:44,142 - mmseg - INFO - Iter [12300/160000]	lr: 1.554e-06, eta: 1 day, 6:00:22, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0068, decode.loss_mask: 0.3905, decode.loss_dice: 0.3843, decode.d0.loss_cls: 0.5834, decode.d0.loss_mask: 0.3971, decode.d0.loss_dice: 0.4106, decode.d1.loss_cls: 0.0082, decode.d1.loss_mask: 0.3890, decode.d1.loss_dice: 0.3832, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.3932, decode.d2.loss_dice: 0.3806, decode.d3.loss_cls: 0.0016, decode.d3.loss_mask: 0.3955, decode.d3.loss_dice: 0.3827, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.3928, decode.d4.loss_dice: 0.3811, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3921, decode.d5.loss_dice: 0.3795, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3974, decode.d6.loss_dice: 0.3828, decode.d7.loss_cls: 0.0062, decode.d7.loss_mask: 0.3904, decode.d7.loss_dice: 0.3844, decode.d8.loss_cls: 0.0072, decode.d8.loss_mask: 0.3862, decode.d8.loss_dice: 0.3815, loss: 8.3946, grad_norm: 390.9164
2023-08-29 03:14:21,424 - mmseg - INFO - Iter [12350/160000]	lr: 1.553e-06, eta: 1 day, 5:59:54, time: 0.746, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0096, decode.loss_mask: 0.3889, decode.loss_dice: 0.3987, decode.d0.loss_cls: 0.5782, decode.d0.loss_mask: 0.4104, decode.d0.loss_dice: 0.4321, decode.d1.loss_cls: 0.0024, decode.d1.loss_mask: 0.4026, decode.d1.loss_dice: 0.4052, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.4006, decode.d2.loss_dice: 0.4009, decode.d3.loss_cls: 0.0100, decode.d3.loss_mask: 0.3918, decode.d3.loss_dice: 0.3976, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.4007, decode.d4.loss_dice: 0.3991, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3983, decode.d5.loss_dice: 0.3983, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3991, decode.d6.loss_dice: 0.3984, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.3988, decode.d7.loss_dice: 0.3987, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.4010, decode.d8.loss_dice: 0.4024, loss: 8.6333, grad_norm: 445.2752
2023-08-29 03:14:56,420 - mmseg - INFO - Iter [12400/160000]	lr: 1.553e-06, eta: 1 day, 5:58:58, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0251, decode.loss_mask: 0.4111, decode.loss_dice: 0.4040, decode.d0.loss_cls: 0.5775, decode.d0.loss_mask: 0.4339, decode.d0.loss_dice: 0.4317, decode.d1.loss_cls: 0.0158, decode.d1.loss_mask: 0.4456, decode.d1.loss_dice: 0.4168, decode.d2.loss_cls: 0.0059, decode.d2.loss_mask: 0.4696, decode.d2.loss_dice: 0.4136, decode.d3.loss_cls: 0.0143, decode.d3.loss_mask: 0.4431, decode.d3.loss_dice: 0.4102, decode.d4.loss_cls: 0.0086, decode.d4.loss_mask: 0.4698, decode.d4.loss_dice: 0.4100, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.4682, decode.d5.loss_dice: 0.4125, decode.d6.loss_cls: 0.0082, decode.d6.loss_mask: 0.4631, decode.d6.loss_dice: 0.4141, decode.d7.loss_cls: 0.0194, decode.d7.loss_mask: 0.4276, decode.d7.loss_dice: 0.4077, decode.d8.loss_cls: 0.0119, decode.d8.loss_mask: 0.4440, decode.d8.loss_dice: 0.4171, loss: 9.3074, grad_norm: 430.7421
2023-08-29 03:15:33,093 - mmseg - INFO - Iter [12450/160000]	lr: 1.552e-06, eta: 1 day, 5:58:23, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0019, decode.loss_mask: 0.3800, decode.loss_dice: 0.3836, decode.d0.loss_cls: 0.5698, decode.d0.loss_mask: 0.3967, decode.d0.loss_dice: 0.4117, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3784, decode.d1.loss_dice: 0.3914, decode.d2.loss_cls: 0.0015, decode.d2.loss_mask: 0.3755, decode.d2.loss_dice: 0.3886, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.3752, decode.d3.loss_dice: 0.3837, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.3755, decode.d4.loss_dice: 0.3826, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.3762, decode.d5.loss_dice: 0.3849, decode.d6.loss_cls: 0.0014, decode.d6.loss_mask: 0.3756, decode.d6.loss_dice: 0.3850, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3777, decode.d7.loss_dice: 0.3821, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.3799, decode.d8.loss_dice: 0.3845, loss: 8.2521, grad_norm: 488.3073
2023-08-29 03:16:09,817 - mmseg - INFO - Iter [12500/160000]	lr: 1.552e-06, eta: 1 day, 5:57:48, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0024, decode.loss_mask: 0.3678, decode.loss_dice: 0.3677, decode.d0.loss_cls: 0.5644, decode.d0.loss_mask: 0.3920, decode.d0.loss_dice: 0.3984, decode.d1.loss_cls: 0.0028, decode.d1.loss_mask: 0.3714, decode.d1.loss_dice: 0.3737, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.3671, decode.d2.loss_dice: 0.3700, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.3692, decode.d3.loss_dice: 0.3693, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.3683, decode.d4.loss_dice: 0.3702, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.3692, decode.d5.loss_dice: 0.3717, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.3661, decode.d6.loss_dice: 0.3699, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.3687, decode.d7.loss_dice: 0.3671, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.3689, decode.d8.loss_dice: 0.3679, loss: 8.0210, grad_norm: 361.6392
2023-08-29 03:16:47,026 - mmseg - INFO - Iter [12550/160000]	lr: 1.551e-06, eta: 1 day, 5:57:19, time: 0.744, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0095, decode.loss_mask: 0.3505, decode.loss_dice: 0.3634, decode.d0.loss_cls: 0.5606, decode.d0.loss_mask: 0.3831, decode.d0.loss_dice: 0.4073, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3682, decode.d1.loss_dice: 0.3745, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.3675, decode.d2.loss_dice: 0.3702, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.3539, decode.d3.loss_dice: 0.3619, decode.d4.loss_cls: 0.0082, decode.d4.loss_mask: 0.3540, decode.d4.loss_dice: 0.3663, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.3683, decode.d5.loss_dice: 0.3686, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.3664, decode.d6.loss_dice: 0.3693, decode.d7.loss_cls: 0.0060, decode.d7.loss_mask: 0.3519, decode.d7.loss_dice: 0.3638, decode.d8.loss_cls: 0.0067, decode.d8.loss_mask: 0.3558, decode.d8.loss_dice: 0.3676, loss: 7.9395, grad_norm: 420.9197
2023-08-29 03:17:22,025 - mmseg - INFO - Iter [12600/160000]	lr: 1.551e-06, eta: 1 day, 5:56:24, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0120, decode.loss_mask: 0.3931, decode.loss_dice: 0.3687, decode.d0.loss_cls: 0.5606, decode.d0.loss_mask: 0.3943, decode.d0.loss_dice: 0.4021, decode.d1.loss_cls: 0.0148, decode.d1.loss_mask: 0.3979, decode.d1.loss_dice: 0.3796, decode.d2.loss_cls: 0.0025, decode.d2.loss_mask: 0.4095, decode.d2.loss_dice: 0.3762, decode.d3.loss_cls: 0.0074, decode.d3.loss_mask: 0.4019, decode.d3.loss_dice: 0.3737, decode.d4.loss_cls: 0.0060, decode.d4.loss_mask: 0.4018, decode.d4.loss_dice: 0.3711, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.4110, decode.d5.loss_dice: 0.3754, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.4065, decode.d6.loss_dice: 0.3755, decode.d7.loss_cls: 0.0046, decode.d7.loss_mask: 0.4032, decode.d7.loss_dice: 0.3705, decode.d8.loss_cls: 0.0056, decode.d8.loss_mask: 0.4052, decode.d8.loss_dice: 0.3730, loss: 8.4090, grad_norm: 487.8443
2023-08-29 03:17:58,634 - mmseg - INFO - Iter [12650/160000]	lr: 1.550e-06, eta: 1 day, 5:55:48, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0037, decode.loss_mask: 0.3834, decode.loss_dice: 0.3676, decode.d0.loss_cls: 0.5531, decode.d0.loss_mask: 0.3898, decode.d0.loss_dice: 0.4038, decode.d1.loss_cls: 0.0134, decode.d1.loss_mask: 0.3725, decode.d1.loss_dice: 0.3728, decode.d2.loss_cls: 0.0094, decode.d2.loss_mask: 0.3677, decode.d2.loss_dice: 0.3720, decode.d3.loss_cls: 0.0130, decode.d3.loss_mask: 0.3678, decode.d3.loss_dice: 0.3689, decode.d4.loss_cls: 0.0127, decode.d4.loss_mask: 0.3687, decode.d4.loss_dice: 0.3684, decode.d5.loss_cls: 0.0124, decode.d5.loss_mask: 0.3755, decode.d5.loss_dice: 0.3694, decode.d6.loss_cls: 0.0126, decode.d6.loss_mask: 0.3758, decode.d6.loss_dice: 0.3705, decode.d7.loss_cls: 0.0130, decode.d7.loss_mask: 0.3683, decode.d7.loss_dice: 0.3697, decode.d8.loss_cls: 0.0126, decode.d8.loss_mask: 0.3685, decode.d8.loss_dice: 0.3710, loss: 8.1280, grad_norm: 398.5884
2023-08-29 03:18:35,291 - mmseg - INFO - Iter [12700/160000]	lr: 1.550e-06, eta: 1 day, 5:55:13, time: 0.733, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0067, decode.loss_mask: 0.3927, decode.loss_dice: 0.3905, decode.d0.loss_cls: 0.5539, decode.d0.loss_mask: 0.4055, decode.d0.loss_dice: 0.4114, decode.d1.loss_cls: 0.0137, decode.d1.loss_mask: 0.4023, decode.d1.loss_dice: 0.3930, decode.d2.loss_cls: 0.0118, decode.d2.loss_mask: 0.3928, decode.d2.loss_dice: 0.3898, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.3920, decode.d3.loss_dice: 0.3899, decode.d4.loss_cls: 0.0085, decode.d4.loss_mask: 0.3920, decode.d4.loss_dice: 0.3895, decode.d5.loss_cls: 0.0108, decode.d5.loss_mask: 0.3928, decode.d5.loss_dice: 0.3879, decode.d6.loss_cls: 0.0109, decode.d6.loss_mask: 0.3942, decode.d6.loss_dice: 0.3904, decode.d7.loss_cls: 0.0082, decode.d7.loss_mask: 0.3926, decode.d7.loss_dice: 0.3881, decode.d8.loss_cls: 0.0131, decode.d8.loss_mask: 0.3908, decode.d8.loss_dice: 0.3903, loss: 8.5154, grad_norm: 444.2109
2023-08-29 03:19:12,367 - mmseg - INFO - Iter [12750/160000]	lr: 1.549e-06, eta: 1 day, 5:54:42, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0054, decode.loss_mask: 0.3732, decode.loss_dice: 0.3629, decode.d0.loss_cls: 0.5452, decode.d0.loss_mask: 0.3766, decode.d0.loss_dice: 0.3971, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.3641, decode.d1.loss_dice: 0.3641, decode.d2.loss_cls: 0.0084, decode.d2.loss_mask: 0.3694, decode.d2.loss_dice: 0.3608, decode.d3.loss_cls: 0.0095, decode.d3.loss_mask: 0.3704, decode.d3.loss_dice: 0.3644, decode.d4.loss_cls: 0.0085, decode.d4.loss_mask: 0.3694, decode.d4.loss_dice: 0.3641, decode.d5.loss_cls: 0.0094, decode.d5.loss_mask: 0.3714, decode.d5.loss_dice: 0.3670, decode.d6.loss_cls: 0.0081, decode.d6.loss_mask: 0.3716, decode.d6.loss_dice: 0.3669, decode.d7.loss_cls: 0.0108, decode.d7.loss_mask: 0.3710, decode.d7.loss_dice: 0.3652, decode.d8.loss_cls: 0.0092, decode.d8.loss_mask: 0.3747, decode.d8.loss_dice: 0.3666, loss: 8.0201, grad_norm: 414.4122
2023-08-29 03:19:47,164 - mmseg - INFO - Iter [12800/160000]	lr: 1.549e-06, eta: 1 day, 5:53:45, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0041, decode.loss_mask: 0.3451, decode.loss_dice: 0.3247, decode.d0.loss_cls: 0.5405, decode.d0.loss_mask: 0.3538, decode.d0.loss_dice: 0.3592, decode.d1.loss_cls: 0.0136, decode.d1.loss_mask: 0.3398, decode.d1.loss_dice: 0.3309, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.3382, decode.d2.loss_dice: 0.3299, decode.d3.loss_cls: 0.0100, decode.d3.loss_mask: 0.3382, decode.d3.loss_dice: 0.3290, decode.d4.loss_cls: 0.0065, decode.d4.loss_mask: 0.3370, decode.d4.loss_dice: 0.3279, decode.d5.loss_cls: 0.0070, decode.d5.loss_mask: 0.3397, decode.d5.loss_dice: 0.3251, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.3423, decode.d6.loss_dice: 0.3254, decode.d7.loss_cls: 0.0067, decode.d7.loss_mask: 0.3418, decode.d7.loss_dice: 0.3284, decode.d8.loss_cls: 0.0085, decode.d8.loss_mask: 0.3425, decode.d8.loss_dice: 0.3277, loss: 7.3372, grad_norm: 348.3836
2023-08-29 03:20:23,999 - mmseg - INFO - Iter [12850/160000]	lr: 1.548e-06, eta: 1 day, 5:53:12, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0109, decode.loss_mask: 0.3761, decode.loss_dice: 0.3654, decode.d0.loss_cls: 0.5357, decode.d0.loss_mask: 0.4034, decode.d0.loss_dice: 0.4091, decode.d1.loss_cls: 0.0098, decode.d1.loss_mask: 0.3838, decode.d1.loss_dice: 0.3720, decode.d2.loss_cls: 0.0044, decode.d2.loss_mask: 0.3810, decode.d2.loss_dice: 0.3672, decode.d3.loss_cls: 0.0099, decode.d3.loss_mask: 0.3794, decode.d3.loss_dice: 0.3646, decode.d4.loss_cls: 0.0094, decode.d4.loss_mask: 0.3828, decode.d4.loss_dice: 0.3648, decode.d5.loss_cls: 0.0028, decode.d5.loss_mask: 0.3922, decode.d5.loss_dice: 0.3671, decode.d6.loss_cls: 0.0034, decode.d6.loss_mask: 0.3876, decode.d6.loss_dice: 0.3658, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.3814, decode.d7.loss_dice: 0.3668, decode.d8.loss_cls: 0.0080, decode.d8.loss_mask: 0.3826, decode.d8.loss_dice: 0.3670, loss: 8.1618, grad_norm: 395.3244
2023-08-29 03:21:00,455 - mmseg - INFO - Iter [12900/160000]	lr: 1.548e-06, eta: 1 day, 5:52:34, time: 0.729, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0018, decode.loss_mask: 0.3210, decode.loss_dice: 0.3250, decode.d0.loss_cls: 0.5282, decode.d0.loss_mask: 0.3336, decode.d0.loss_dice: 0.3549, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3192, decode.d1.loss_dice: 0.3264, decode.d2.loss_cls: 0.0019, decode.d2.loss_mask: 0.3217, decode.d2.loss_dice: 0.3232, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.3204, decode.d3.loss_dice: 0.3219, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3198, decode.d4.loss_dice: 0.3253, decode.d5.loss_cls: 0.0017, decode.d5.loss_mask: 0.3181, decode.d5.loss_dice: 0.3227, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3191, decode.d6.loss_dice: 0.3275, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.3194, decode.d7.loss_dice: 0.3259, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.3212, decode.d8.loss_dice: 0.3253, loss: 7.0363, grad_norm: 391.3265
2023-08-29 03:21:37,652 - mmseg - INFO - Iter [12950/160000]	lr: 1.547e-06, eta: 1 day, 5:52:05, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0014, decode.loss_mask: 0.4081, decode.loss_dice: 0.4073, decode.d0.loss_cls: 0.5238, decode.d0.loss_mask: 0.4181, decode.d0.loss_dice: 0.4345, decode.d1.loss_cls: 0.0019, decode.d1.loss_mask: 0.4026, decode.d1.loss_dice: 0.4047, decode.d2.loss_cls: 0.0014, decode.d2.loss_mask: 0.4087, decode.d2.loss_dice: 0.4058, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.4056, decode.d3.loss_dice: 0.4061, decode.d4.loss_cls: 0.0012, decode.d4.loss_mask: 0.4080, decode.d4.loss_dice: 0.4087, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.4053, decode.d5.loss_dice: 0.4066, decode.d6.loss_cls: 0.0012, decode.d6.loss_mask: 0.4073, decode.d6.loss_dice: 0.4075, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.4029, decode.d7.loss_dice: 0.4048, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.4070, decode.d8.loss_dice: 0.4090, loss: 8.7049, grad_norm: 388.8307
2023-08-29 03:22:12,858 - mmseg - INFO - Saving checkpoint at 13000 iterations
2023-08-29 03:22:15,345 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 03:22:15,345 - mmseg - INFO - Iter [13000/160000]	lr: 1.546e-06, eta: 1 day, 5:51:41, time: 0.754, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0128, decode.loss_mask: 0.4157, decode.loss_dice: 0.3861, decode.d0.loss_cls: 0.5267, decode.d0.loss_mask: 0.4370, decode.d0.loss_dice: 0.4172, decode.d1.loss_cls: 0.0125, decode.d1.loss_mask: 0.4159, decode.d1.loss_dice: 0.3905, decode.d2.loss_cls: 0.0119, decode.d2.loss_mask: 0.4075, decode.d2.loss_dice: 0.3823, decode.d3.loss_cls: 0.0119, decode.d3.loss_mask: 0.4108, decode.d3.loss_dice: 0.3796, decode.d4.loss_cls: 0.0141, decode.d4.loss_mask: 0.4133, decode.d4.loss_dice: 0.3826, decode.d5.loss_cls: 0.0151, decode.d5.loss_mask: 0.4151, decode.d5.loss_dice: 0.3814, decode.d6.loss_cls: 0.0143, decode.d6.loss_mask: 0.4142, decode.d6.loss_dice: 0.3821, decode.d7.loss_cls: 0.0175, decode.d7.loss_mask: 0.4136, decode.d7.loss_dice: 0.3801, decode.d8.loss_cls: 0.0159, decode.d8.loss_mask: 0.4149, decode.d8.loss_dice: 0.3805, loss: 8.6729, grad_norm: 385.1797
2023-08-29 03:22:52,226 - mmseg - INFO - Iter [13050/160000]	lr: 1.546e-06, eta: 1 day, 5:51:08, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0080, decode.loss_mask: 0.3976, decode.loss_dice: 0.3846, decode.d0.loss_cls: 0.5171, decode.d0.loss_mask: 0.4190, decode.d0.loss_dice: 0.4103, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.4040, decode.d1.loss_dice: 0.3950, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.4041, decode.d2.loss_dice: 0.3933, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.4005, decode.d3.loss_dice: 0.3880, decode.d4.loss_cls: 0.0013, decode.d4.loss_mask: 0.4041, decode.d4.loss_dice: 0.3895, decode.d5.loss_cls: 0.0012, decode.d5.loss_mask: 0.4015, decode.d5.loss_dice: 0.3888, decode.d6.loss_cls: 0.0013, decode.d6.loss_mask: 0.4024, decode.d6.loss_dice: 0.3903, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.3966, decode.d7.loss_dice: 0.3848, decode.d8.loss_cls: 0.0058, decode.d8.loss_mask: 0.3983, decode.d8.loss_dice: 0.3829, loss: 8.4810, grad_norm: 428.0075
2023-08-29 03:23:28,673 - mmseg - INFO - Iter [13100/160000]	lr: 1.545e-06, eta: 1 day, 5:50:30, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0087, decode.loss_mask: 0.3754, decode.loss_dice: 0.3856, decode.d0.loss_cls: 0.5123, decode.d0.loss_mask: 0.3969, decode.d0.loss_dice: 0.4184, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.3880, decode.d1.loss_dice: 0.3955, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.3842, decode.d2.loss_dice: 0.3926, decode.d3.loss_cls: 0.0088, decode.d3.loss_mask: 0.3762, decode.d3.loss_dice: 0.3863, decode.d4.loss_cls: 0.0082, decode.d4.loss_mask: 0.3740, decode.d4.loss_dice: 0.3877, decode.d5.loss_cls: 0.0027, decode.d5.loss_mask: 0.3841, decode.d5.loss_dice: 0.3907, decode.d6.loss_cls: 0.0028, decode.d6.loss_mask: 0.3846, decode.d6.loss_dice: 0.3876, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.3832, decode.d7.loss_dice: 0.3892, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.3830, decode.d8.loss_dice: 0.3890, loss: 8.3067, grad_norm: 492.6104
2023-08-29 03:24:06,020 - mmseg - INFO - Iter [13150/160000]	lr: 1.545e-06, eta: 1 day, 5:50:02, time: 0.747, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0104, decode.loss_mask: 0.3701, decode.loss_dice: 0.3617, decode.d0.loss_cls: 0.5095, decode.d0.loss_mask: 0.3852, decode.d0.loss_dice: 0.3930, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.3802, decode.d1.loss_dice: 0.3689, decode.d2.loss_cls: 0.0023, decode.d2.loss_mask: 0.3805, decode.d2.loss_dice: 0.3694, decode.d3.loss_cls: 0.0091, decode.d3.loss_mask: 0.3702, decode.d3.loss_dice: 0.3613, decode.d4.loss_cls: 0.0096, decode.d4.loss_mask: 0.3707, decode.d4.loss_dice: 0.3620, decode.d5.loss_cls: 0.0102, decode.d5.loss_mask: 0.3711, decode.d5.loss_dice: 0.3631, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.3830, decode.d6.loss_dice: 0.3673, decode.d7.loss_cls: 0.0074, decode.d7.loss_mask: 0.3718, decode.d7.loss_dice: 0.3649, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.3872, decode.d8.loss_dice: 0.3640, loss: 8.0110, grad_norm: 363.7549
2023-08-29 03:24:41,075 - mmseg - INFO - Iter [13200/160000]	lr: 1.544e-06, eta: 1 day, 5:49:09, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0127, decode.loss_mask: 0.3689, decode.loss_dice: 0.3471, decode.d0.loss_cls: 0.5068, decode.d0.loss_mask: 0.3846, decode.d0.loss_dice: 0.3799, decode.d1.loss_cls: 0.0168, decode.d1.loss_mask: 0.3661, decode.d1.loss_dice: 0.3497, decode.d2.loss_cls: 0.0108, decode.d2.loss_mask: 0.3657, decode.d2.loss_dice: 0.3499, decode.d3.loss_cls: 0.0129, decode.d3.loss_mask: 0.3689, decode.d3.loss_dice: 0.3469, decode.d4.loss_cls: 0.0125, decode.d4.loss_mask: 0.3700, decode.d4.loss_dice: 0.3524, decode.d5.loss_cls: 0.0134, decode.d5.loss_mask: 0.3691, decode.d5.loss_dice: 0.3463, decode.d6.loss_cls: 0.0114, decode.d6.loss_mask: 0.3714, decode.d6.loss_dice: 0.3509, decode.d7.loss_cls: 0.0101, decode.d7.loss_mask: 0.3656, decode.d7.loss_dice: 0.3438, decode.d8.loss_cls: 0.0092, decode.d8.loss_mask: 0.3757, decode.d8.loss_dice: 0.3510, loss: 7.8403, grad_norm: 367.5553
2023-08-29 03:25:17,714 - mmseg - INFO - Iter [13250/160000]	lr: 1.544e-06, eta: 1 day, 5:48:33, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0088, decode.loss_mask: 0.3999, decode.loss_dice: 0.3629, decode.d0.loss_cls: 0.5025, decode.d0.loss_mask: 0.4168, decode.d0.loss_dice: 0.3992, decode.d1.loss_cls: 0.0144, decode.d1.loss_mask: 0.3875, decode.d1.loss_dice: 0.3654, decode.d2.loss_cls: 0.0105, decode.d2.loss_mask: 0.3884, decode.d2.loss_dice: 0.3674, decode.d3.loss_cls: 0.0061, decode.d3.loss_mask: 0.3883, decode.d3.loss_dice: 0.3656, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.3929, decode.d4.loss_dice: 0.3670, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.3939, decode.d5.loss_dice: 0.3707, decode.d6.loss_cls: 0.0052, decode.d6.loss_mask: 0.3919, decode.d6.loss_dice: 0.3710, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.4007, decode.d7.loss_dice: 0.3711, decode.d8.loss_cls: 0.0095, decode.d8.loss_mask: 0.3908, decode.d8.loss_dice: 0.3680, loss: 8.2325, grad_norm: 446.3524
2023-08-29 03:25:54,272 - mmseg - INFO - Iter [13300/160000]	lr: 1.543e-06, eta: 1 day, 5:47:57, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0012, decode.loss_mask: 0.3680, decode.loss_dice: 0.3608, decode.d0.loss_cls: 0.4951, decode.d0.loss_mask: 0.3829, decode.d0.loss_dice: 0.3814, decode.d1.loss_cls: 0.0019, decode.d1.loss_mask: 0.3730, decode.d1.loss_dice: 0.3657, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.3701, decode.d2.loss_dice: 0.3652, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.3710, decode.d3.loss_dice: 0.3631, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.3716, decode.d4.loss_dice: 0.3616, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.3703, decode.d5.loss_dice: 0.3590, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.3699, decode.d6.loss_dice: 0.3616, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.3709, decode.d7.loss_dice: 0.3619, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3687, decode.d8.loss_dice: 0.3613, loss: 7.8635, grad_norm: 417.2438
2023-08-29 03:26:31,329 - mmseg - INFO - Iter [13350/160000]	lr: 1.543e-06, eta: 1 day, 5:47:25, time: 0.741, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3873, decode.loss_dice: 0.4160, decode.d0.loss_cls: 0.4925, decode.d0.loss_mask: 0.4040, decode.d0.loss_dice: 0.4479, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.3942, decode.d1.loss_dice: 0.4189, decode.d2.loss_cls: 0.0020, decode.d2.loss_mask: 0.3868, decode.d2.loss_dice: 0.4175, decode.d3.loss_cls: 0.0017, decode.d3.loss_mask: 0.3875, decode.d3.loss_dice: 0.4130, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3887, decode.d4.loss_dice: 0.4185, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3888, decode.d5.loss_dice: 0.4138, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.3883, decode.d6.loss_dice: 0.4164, decode.d7.loss_cls: 0.0014, decode.d7.loss_mask: 0.3865, decode.d7.loss_dice: 0.4143, decode.d8.loss_cls: 0.0014, decode.d8.loss_mask: 0.3876, decode.d8.loss_dice: 0.4151, loss: 8.5983, grad_norm: 413.9597
2023-08-29 03:27:08,476 - mmseg - INFO - Iter [13400/160000]	lr: 1.542e-06, eta: 1 day, 5:46:55, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0180, decode.loss_mask: 0.4065, decode.loss_dice: 0.3950, decode.d0.loss_cls: 0.4910, decode.d0.loss_mask: 0.4219, decode.d0.loss_dice: 0.4261, decode.d1.loss_cls: 0.0174, decode.d1.loss_mask: 0.4110, decode.d1.loss_dice: 0.3993, decode.d2.loss_cls: 0.0029, decode.d2.loss_mask: 0.4239, decode.d2.loss_dice: 0.4047, decode.d3.loss_cls: 0.0101, decode.d3.loss_mask: 0.4183, decode.d3.loss_dice: 0.4012, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.4125, decode.d4.loss_dice: 0.4051, decode.d5.loss_cls: 0.0071, decode.d5.loss_mask: 0.4181, decode.d5.loss_dice: 0.4039, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.4339, decode.d6.loss_dice: 0.4060, decode.d7.loss_cls: 0.0054, decode.d7.loss_mask: 0.4149, decode.d7.loss_dice: 0.3992, decode.d8.loss_cls: 0.0164, decode.d8.loss_mask: 0.4063, decode.d8.loss_dice: 0.3976, loss: 8.7839, grad_norm: 377.8064
2023-08-29 03:27:43,063 - mmseg - INFO - Iter [13450/160000]	lr: 1.542e-06, eta: 1 day, 5:45:57, time: 0.692, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0103, decode.loss_mask: 0.3868, decode.loss_dice: 0.3917, decode.d0.loss_cls: 0.4840, decode.d0.loss_mask: 0.4010, decode.d0.loss_dice: 0.4185, decode.d1.loss_cls: 0.0094, decode.d1.loss_mask: 0.3908, decode.d1.loss_dice: 0.3977, decode.d2.loss_cls: 0.0107, decode.d2.loss_mask: 0.3897, decode.d2.loss_dice: 0.3958, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.3909, decode.d3.loss_dice: 0.3857, decode.d4.loss_cls: 0.0084, decode.d4.loss_mask: 0.3912, decode.d4.loss_dice: 0.3899, decode.d5.loss_cls: 0.0091, decode.d5.loss_mask: 0.3929, decode.d5.loss_dice: 0.3903, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.4088, decode.d6.loss_dice: 0.3947, decode.d7.loss_cls: 0.0064, decode.d7.loss_mask: 0.3875, decode.d7.loss_dice: 0.3932, decode.d8.loss_cls: 0.0108, decode.d8.loss_mask: 0.3872, decode.d8.loss_dice: 0.3964, loss: 8.4408, grad_norm: 397.3598
2023-08-29 03:28:19,508 - mmseg - INFO - Iter [13500/160000]	lr: 1.541e-06, eta: 1 day, 5:45:19, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0163, decode.loss_mask: 0.3966, decode.loss_dice: 0.3794, decode.d0.loss_cls: 0.4807, decode.d0.loss_mask: 0.4025, decode.d0.loss_dice: 0.3985, decode.d1.loss_cls: 0.0138, decode.d1.loss_mask: 0.3889, decode.d1.loss_dice: 0.3779, decode.d2.loss_cls: 0.0100, decode.d2.loss_mask: 0.3873, decode.d2.loss_dice: 0.3767, decode.d3.loss_cls: 0.0085, decode.d3.loss_mask: 0.3899, decode.d3.loss_dice: 0.3762, decode.d4.loss_cls: 0.0093, decode.d4.loss_mask: 0.3871, decode.d4.loss_dice: 0.3767, decode.d5.loss_cls: 0.0108, decode.d5.loss_mask: 0.3885, decode.d5.loss_dice: 0.3761, decode.d6.loss_cls: 0.0072, decode.d6.loss_mask: 0.3938, decode.d6.loss_dice: 0.3803, decode.d7.loss_cls: 0.0117, decode.d7.loss_mask: 0.3907, decode.d7.loss_dice: 0.3788, decode.d8.loss_cls: 0.0120, decode.d8.loss_mask: 0.3903, decode.d8.loss_dice: 0.3801, loss: 8.2965, grad_norm: 333.3173
2023-08-29 03:28:56,711 - mmseg - INFO - Iter [13550/160000]	lr: 1.541e-06, eta: 1 day, 5:44:50, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3838, decode.loss_dice: 0.3801, decode.d0.loss_cls: 0.4747, decode.d0.loss_mask: 0.4062, decode.d0.loss_dice: 0.4111, decode.d1.loss_cls: 0.0021, decode.d1.loss_mask: 0.3846, decode.d1.loss_dice: 0.3861, decode.d2.loss_cls: 0.0018, decode.d2.loss_mask: 0.3875, decode.d2.loss_dice: 0.3797, decode.d3.loss_cls: 0.0097, decode.d3.loss_mask: 0.3792, decode.d3.loss_dice: 0.3761, decode.d4.loss_cls: 0.0101, decode.d4.loss_mask: 0.3772, decode.d4.loss_dice: 0.3792, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3864, decode.d5.loss_dice: 0.3814, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.3893, decode.d6.loss_dice: 0.3790, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.3894, decode.d7.loss_dice: 0.3803, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.3843, decode.d8.loss_dice: 0.3825, loss: 8.2098, grad_norm: 414.4171
2023-08-29 03:29:33,958 - mmseg - INFO - Iter [13600/160000]	lr: 1.540e-06, eta: 1 day, 5:44:21, time: 0.745, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0124, decode.loss_mask: 0.3705, decode.loss_dice: 0.3781, decode.d0.loss_cls: 0.4735, decode.d0.loss_mask: 0.3800, decode.d0.loss_dice: 0.3956, decode.d1.loss_cls: 0.0160, decode.d1.loss_mask: 0.3667, decode.d1.loss_dice: 0.3755, decode.d2.loss_cls: 0.0124, decode.d2.loss_mask: 0.3663, decode.d2.loss_dice: 0.3735, decode.d3.loss_cls: 0.0121, decode.d3.loss_mask: 0.3678, decode.d3.loss_dice: 0.3731, decode.d4.loss_cls: 0.0109, decode.d4.loss_mask: 0.3680, decode.d4.loss_dice: 0.3745, decode.d5.loss_cls: 0.0051, decode.d5.loss_mask: 0.3727, decode.d5.loss_dice: 0.3765, decode.d6.loss_cls: 0.0094, decode.d6.loss_mask: 0.3678, decode.d6.loss_dice: 0.3751, decode.d7.loss_cls: 0.0123, decode.d7.loss_mask: 0.3669, decode.d7.loss_dice: 0.3761, decode.d8.loss_cls: 0.0127, decode.d8.loss_mask: 0.3738, decode.d8.loss_dice: 0.3748, loss: 8.0503, grad_norm: 399.1081
2023-08-29 03:30:08,900 - mmseg - INFO - Iter [13650/160000]	lr: 1.540e-06, eta: 1 day, 5:43:26, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0335, decode.loss_mask: 0.4108, decode.loss_dice: 0.3912, decode.d0.loss_cls: 0.4800, decode.d0.loss_mask: 0.4123, decode.d0.loss_dice: 0.4211, decode.d1.loss_cls: 0.0234, decode.d1.loss_mask: 0.4183, decode.d1.loss_dice: 0.3956, decode.d2.loss_cls: 0.0228, decode.d2.loss_mask: 0.4079, decode.d2.loss_dice: 0.3947, decode.d3.loss_cls: 0.0324, decode.d3.loss_mask: 0.3955, decode.d3.loss_dice: 0.3912, decode.d4.loss_cls: 0.0315, decode.d4.loss_mask: 0.3988, decode.d4.loss_dice: 0.3873, decode.d5.loss_cls: 0.0258, decode.d5.loss_mask: 0.4105, decode.d5.loss_dice: 0.3939, decode.d6.loss_cls: 0.0184, decode.d6.loss_mask: 0.4283, decode.d6.loss_dice: 0.4001, decode.d7.loss_cls: 0.0291, decode.d7.loss_mask: 0.4164, decode.d7.loss_dice: 0.3997, decode.d8.loss_cls: 0.0143, decode.d8.loss_mask: 0.4605, decode.d8.loss_dice: 0.4052, loss: 8.8507, grad_norm: 358.2513
2023-08-29 03:30:45,441 - mmseg - INFO - Iter [13700/160000]	lr: 1.539e-06, eta: 1 day, 5:42:50, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.3561, decode.loss_dice: 0.3478, decode.d0.loss_cls: 0.4646, decode.d0.loss_mask: 0.3683, decode.d0.loss_dice: 0.3837, decode.d1.loss_cls: 0.0018, decode.d1.loss_mask: 0.3491, decode.d1.loss_dice: 0.3568, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.3489, decode.d2.loss_dice: 0.3488, decode.d3.loss_cls: 0.0013, decode.d3.loss_mask: 0.3499, decode.d3.loss_dice: 0.3478, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.3519, decode.d4.loss_dice: 0.3474, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3519, decode.d5.loss_dice: 0.3485, decode.d6.loss_cls: 0.0016, decode.d6.loss_mask: 0.3508, decode.d6.loss_dice: 0.3538, decode.d7.loss_cls: 0.0022, decode.d7.loss_mask: 0.3515, decode.d7.loss_dice: 0.3461, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.3518, decode.d8.loss_dice: 0.3519, loss: 7.5426, grad_norm: 399.2927
2023-08-29 03:31:22,413 - mmseg - INFO - Iter [13750/160000]	lr: 1.539e-06, eta: 1 day, 5:42:18, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0098, decode.loss_mask: 0.3495, decode.loss_dice: 0.3495, decode.d0.loss_cls: 0.4600, decode.d0.loss_mask: 0.3620, decode.d0.loss_dice: 0.3895, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3488, decode.d1.loss_dice: 0.3650, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.3491, decode.d2.loss_dice: 0.3547, decode.d3.loss_cls: 0.0079, decode.d3.loss_mask: 0.3475, decode.d3.loss_dice: 0.3506, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.3471, decode.d4.loss_dice: 0.3501, decode.d5.loss_cls: 0.0078, decode.d5.loss_mask: 0.3476, decode.d5.loss_dice: 0.3510, decode.d6.loss_cls: 0.0097, decode.d6.loss_mask: 0.3485, decode.d6.loss_dice: 0.3534, decode.d7.loss_cls: 0.0087, decode.d7.loss_mask: 0.3560, decode.d7.loss_dice: 0.3557, decode.d8.loss_cls: 0.0016, decode.d8.loss_mask: 0.3595, decode.d8.loss_dice: 0.3624, loss: 7.6141, grad_norm: 387.7715
2023-08-29 03:31:59,701 - mmseg - INFO - Iter [13800/160000]	lr: 1.538e-06, eta: 1 day, 5:41:49, time: 0.746, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.3379, decode.loss_dice: 0.3430, decode.d0.loss_cls: 0.4556, decode.d0.loss_mask: 0.3462, decode.d0.loss_dice: 0.3744, decode.d1.loss_cls: 0.0026, decode.d1.loss_mask: 0.3343, decode.d1.loss_dice: 0.3483, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3322, decode.d2.loss_dice: 0.3423, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3332, decode.d3.loss_dice: 0.3461, decode.d4.loss_cls: 0.0027, decode.d4.loss_mask: 0.3332, decode.d4.loss_dice: 0.3436, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.3331, decode.d5.loss_dice: 0.3413, decode.d6.loss_cls: 0.0025, decode.d6.loss_mask: 0.3353, decode.d6.loss_dice: 0.3437, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.3390, decode.d7.loss_dice: 0.3447, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.3336, decode.d8.loss_dice: 0.3450, loss: 7.3090, grad_norm: 355.9686
2023-08-29 03:32:34,735 - mmseg - INFO - Iter [13850/160000]	lr: 1.538e-06, eta: 1 day, 5:40:56, time: 0.701, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0008, decode.loss_mask: 0.3556, decode.loss_dice: 0.3500, decode.d0.loss_cls: 0.4517, decode.d0.loss_mask: 0.3636, decode.d0.loss_dice: 0.3779, decode.d1.loss_cls: 0.0018, decode.d1.loss_mask: 0.3591, decode.d1.loss_dice: 0.3522, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.3551, decode.d2.loss_dice: 0.3495, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3531, decode.d3.loss_dice: 0.3499, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.3528, decode.d4.loss_dice: 0.3507, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3551, decode.d5.loss_dice: 0.3510, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.3522, decode.d6.loss_dice: 0.3513, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.3542, decode.d7.loss_dice: 0.3500, decode.d8.loss_cls: 0.0008, decode.d8.loss_mask: 0.3535, decode.d8.loss_dice: 0.3508, loss: 7.5482, grad_norm: 368.5025
2023-08-29 03:33:11,178 - mmseg - INFO - Iter [13900/160000]	lr: 1.537e-06, eta: 1 day, 5:40:18, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0090, decode.loss_mask: 0.3410, decode.loss_dice: 0.3325, decode.d0.loss_cls: 0.4505, decode.d0.loss_mask: 0.3500, decode.d0.loss_dice: 0.3690, decode.d1.loss_cls: 0.0022, decode.d1.loss_mask: 0.3501, decode.d1.loss_dice: 0.3483, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.3501, decode.d2.loss_dice: 0.3420, decode.d3.loss_cls: 0.0087, decode.d3.loss_mask: 0.3402, decode.d3.loss_dice: 0.3335, decode.d4.loss_cls: 0.0074, decode.d4.loss_mask: 0.3425, decode.d4.loss_dice: 0.3343, decode.d5.loss_cls: 0.0095, decode.d5.loss_mask: 0.3425, decode.d5.loss_dice: 0.3341, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3492, decode.d6.loss_dice: 0.3364, decode.d7.loss_cls: 0.0061, decode.d7.loss_mask: 0.3412, decode.d7.loss_dice: 0.3356, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3503, decode.d8.loss_dice: 0.3361, loss: 7.3572, grad_norm: 457.8299
2023-08-29 03:33:47,980 - mmseg - INFO - Iter [13950/160000]	lr: 1.536e-06, eta: 1 day, 5:39:44, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0156, decode.loss_mask: 0.4337, decode.loss_dice: 0.3841, decode.d0.loss_cls: 0.4488, decode.d0.loss_mask: 0.4399, decode.d0.loss_dice: 0.4140, decode.d1.loss_cls: 0.0215, decode.d1.loss_mask: 0.4324, decode.d1.loss_dice: 0.3918, decode.d2.loss_cls: 0.0189, decode.d2.loss_mask: 0.4290, decode.d2.loss_dice: 0.3876, decode.d3.loss_cls: 0.0204, decode.d3.loss_mask: 0.4299, decode.d3.loss_dice: 0.3857, decode.d4.loss_cls: 0.0214, decode.d4.loss_mask: 0.4328, decode.d4.loss_dice: 0.3893, decode.d5.loss_cls: 0.0218, decode.d5.loss_mask: 0.4306, decode.d5.loss_dice: 0.3867, decode.d6.loss_cls: 0.0245, decode.d6.loss_mask: 0.4280, decode.d6.loss_dice: 0.3892, decode.d7.loss_cls: 0.0140, decode.d7.loss_mask: 0.4390, decode.d7.loss_dice: 0.3907, decode.d8.loss_cls: 0.0108, decode.d8.loss_mask: 0.4393, decode.d8.loss_dice: 0.3914, loss: 8.8630, grad_norm: 417.4219
2023-08-29 03:34:25,183 - mmseg - INFO - Saving checkpoint at 14000 iterations
2023-08-29 03:34:27,448 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 03:34:27,448 - mmseg - INFO - Iter [14000/160000]	lr: 1.536e-06, eta: 1 day, 5:39:38, time: 0.789, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0158, decode.loss_mask: 0.3815, decode.loss_dice: 0.3888, decode.d0.loss_cls: 0.4467, decode.d0.loss_mask: 0.3896, decode.d0.loss_dice: 0.4283, decode.d1.loss_cls: 0.0129, decode.d1.loss_mask: 0.3784, decode.d1.loss_dice: 0.3972, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 0.3747, decode.d2.loss_dice: 0.3923, decode.d3.loss_cls: 0.0081, decode.d3.loss_mask: 0.3737, decode.d3.loss_dice: 0.3944, decode.d4.loss_cls: 0.0085, decode.d4.loss_mask: 0.3833, decode.d4.loss_dice: 0.4018, decode.d5.loss_cls: 0.0086, decode.d5.loss_mask: 0.3949, decode.d5.loss_dice: 0.4012, decode.d6.loss_cls: 0.0090, decode.d6.loss_mask: 0.3946, decode.d6.loss_dice: 0.4014, decode.d7.loss_cls: 0.0138, decode.d7.loss_mask: 0.3877, decode.d7.loss_dice: 0.3911, decode.d8.loss_cls: 0.0102, decode.d8.loss_mask: 0.3786, decode.d8.loss_dice: 0.3964, loss: 8.3732, grad_norm: 387.9642
2023-08-29 03:35:02,768 - mmseg - INFO - Iter [14050/160000]	lr: 1.535e-06, eta: 1 day, 5:38:48, time: 0.706, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.3650, decode.loss_dice: 0.3725, decode.d0.loss_cls: 0.4372, decode.d0.loss_mask: 0.3889, decode.d0.loss_dice: 0.4027, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3695, decode.d1.loss_dice: 0.3740, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.3674, decode.d2.loss_dice: 0.3714, decode.d3.loss_cls: 0.0019, decode.d3.loss_mask: 0.3685, decode.d3.loss_dice: 0.3709, decode.d4.loss_cls: 0.0017, decode.d4.loss_mask: 0.3697, decode.d4.loss_dice: 0.3717, decode.d5.loss_cls: 0.0016, decode.d5.loss_mask: 0.3661, decode.d5.loss_dice: 0.3731, decode.d6.loss_cls: 0.0019, decode.d6.loss_mask: 0.3677, decode.d6.loss_dice: 0.3722, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.3674, decode.d7.loss_dice: 0.3706, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3677, decode.d8.loss_dice: 0.3692, loss: 7.8990, grad_norm: 441.1122
2023-08-29 03:35:39,268 - mmseg - INFO - Iter [14100/160000]	lr: 1.535e-06, eta: 1 day, 5:38:11, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0098, decode.loss_mask: 0.3536, decode.loss_dice: 0.3534, decode.d0.loss_cls: 0.4364, decode.d0.loss_mask: 0.3780, decode.d0.loss_dice: 0.3824, decode.d1.loss_cls: 0.0033, decode.d1.loss_mask: 0.3725, decode.d1.loss_dice: 0.3615, decode.d2.loss_cls: 0.0027, decode.d2.loss_mask: 0.3661, decode.d2.loss_dice: 0.3579, decode.d3.loss_cls: 0.0026, decode.d3.loss_mask: 0.3696, decode.d3.loss_dice: 0.3568, decode.d4.loss_cls: 0.0025, decode.d4.loss_mask: 0.3674, decode.d4.loss_dice: 0.3590, decode.d5.loss_cls: 0.0026, decode.d5.loss_mask: 0.3665, decode.d5.loss_dice: 0.3569, decode.d6.loss_cls: 0.0029, decode.d6.loss_mask: 0.3691, decode.d6.loss_dice: 0.3592, decode.d7.loss_cls: 0.0094, decode.d7.loss_mask: 0.3555, decode.d7.loss_dice: 0.3547, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.3699, decode.d8.loss_dice: 0.3558, loss: 7.7408, grad_norm: 396.0746
2023-08-29 03:36:16,273 - mmseg - INFO - Iter [14150/160000]	lr: 1.534e-06, eta: 1 day, 5:37:39, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0113, decode.loss_mask: 0.3883, decode.loss_dice: 0.3835, decode.d0.loss_cls: 0.4380, decode.d0.loss_mask: 0.3844, decode.d0.loss_dice: 0.3992, decode.d1.loss_cls: 0.0126, decode.d1.loss_mask: 0.3760, decode.d1.loss_dice: 0.3862, decode.d2.loss_cls: 0.0086, decode.d2.loss_mask: 0.3911, decode.d2.loss_dice: 0.3862, decode.d3.loss_cls: 0.0079, decode.d3.loss_mask: 0.3810, decode.d3.loss_dice: 0.3839, decode.d4.loss_cls: 0.0072, decode.d4.loss_mask: 0.3775, decode.d4.loss_dice: 0.3845, decode.d5.loss_cls: 0.0077, decode.d5.loss_mask: 0.3816, decode.d5.loss_dice: 0.3901, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.3919, decode.d6.loss_dice: 0.3887, decode.d7.loss_cls: 0.0047, decode.d7.loss_mask: 0.3856, decode.d7.loss_dice: 0.3842, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.3874, decode.d8.loss_dice: 0.3867, loss: 8.2245, grad_norm: 398.6316
2023-08-29 03:36:53,582 - mmseg - INFO - Iter [14200/160000]	lr: 1.534e-06, eta: 1 day, 5:37:10, time: 0.746, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0168, decode.loss_mask: 0.4137, decode.loss_dice: 0.3864, decode.d0.loss_cls: 0.4324, decode.d0.loss_mask: 0.4315, decode.d0.loss_dice: 0.4135, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.4258, decode.d1.loss_dice: 0.3964, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.4313, decode.d2.loss_dice: 0.4005, decode.d3.loss_cls: 0.0092, decode.d3.loss_mask: 0.4273, decode.d3.loss_dice: 0.3924, decode.d4.loss_cls: 0.0157, decode.d4.loss_mask: 0.4197, decode.d4.loss_dice: 0.3896, decode.d5.loss_cls: 0.0100, decode.d5.loss_mask: 0.4252, decode.d5.loss_dice: 0.3905, decode.d6.loss_cls: 0.0102, decode.d6.loss_mask: 0.4219, decode.d6.loss_dice: 0.3933, decode.d7.loss_cls: 0.0132, decode.d7.loss_mask: 0.4164, decode.d7.loss_dice: 0.3860, decode.d8.loss_cls: 0.0089, decode.d8.loss_mask: 0.4159, decode.d8.loss_dice: 0.3887, loss: 8.6984, grad_norm: 408.9413
2023-08-29 03:37:28,302 - mmseg - INFO - Iter [14250/160000]	lr: 1.533e-06, eta: 1 day, 5:36:15, time: 0.694, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0147, decode.loss_mask: 0.3331, decode.loss_dice: 0.3343, decode.d0.loss_cls: 0.4276, decode.d0.loss_mask: 0.3619, decode.d0.loss_dice: 0.3825, decode.d1.loss_cls: 0.0145, decode.d1.loss_mask: 0.3451, decode.d1.loss_dice: 0.3513, decode.d2.loss_cls: 0.0080, decode.d2.loss_mask: 0.3430, decode.d2.loss_dice: 0.3488, decode.d3.loss_cls: 0.0129, decode.d3.loss_mask: 0.3356, decode.d3.loss_dice: 0.3373, decode.d4.loss_cls: 0.0087, decode.d4.loss_mask: 0.3341, decode.d4.loss_dice: 0.3339, decode.d5.loss_cls: 0.0097, decode.d5.loss_mask: 0.3369, decode.d5.loss_dice: 0.3355, decode.d6.loss_cls: 0.0109, decode.d6.loss_mask: 0.3394, decode.d6.loss_dice: 0.3446, decode.d7.loss_cls: 0.0155, decode.d7.loss_mask: 0.3357, decode.d7.loss_dice: 0.3347, decode.d8.loss_cls: 0.0132, decode.d8.loss_mask: 0.3364, decode.d8.loss_dice: 0.3384, loss: 7.3783, grad_norm: 393.6985
2023-08-29 03:38:04,932 - mmseg - INFO - Iter [14300/160000]	lr: 1.533e-06, eta: 1 day, 5:35:39, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0107, decode.loss_mask: 0.3454, decode.loss_dice: 0.3544, decode.d0.loss_cls: 0.4248, decode.d0.loss_mask: 0.3609, decode.d0.loss_dice: 0.3954, decode.d1.loss_cls: 0.0095, decode.d1.loss_mask: 0.3476, decode.d1.loss_dice: 0.3614, decode.d2.loss_cls: 0.0095, decode.d2.loss_mask: 0.3424, decode.d2.loss_dice: 0.3572, decode.d3.loss_cls: 0.0111, decode.d3.loss_mask: 0.3424, decode.d3.loss_dice: 0.3533, decode.d4.loss_cls: 0.0077, decode.d4.loss_mask: 0.3446, decode.d4.loss_dice: 0.3535, decode.d5.loss_cls: 0.0114, decode.d5.loss_mask: 0.3422, decode.d5.loss_dice: 0.3554, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3567, decode.d6.loss_dice: 0.3591, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.3437, decode.d7.loss_dice: 0.3554, decode.d8.loss_cls: 0.0075, decode.d8.loss_mask: 0.3475, decode.d8.loss_dice: 0.3551, loss: 7.5750, grad_norm: 431.0323
2023-08-29 03:38:41,673 - mmseg - INFO - Iter [14350/160000]	lr: 1.532e-06, eta: 1 day, 5:35:04, time: 0.735, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0157, decode.loss_mask: 0.3719, decode.loss_dice: 0.3597, decode.d0.loss_cls: 0.4221, decode.d0.loss_mask: 0.3793, decode.d0.loss_dice: 0.3995, decode.d1.loss_cls: 0.0086, decode.d1.loss_mask: 0.3883, decode.d1.loss_dice: 0.3725, decode.d2.loss_cls: 0.0142, decode.d2.loss_mask: 0.3724, decode.d2.loss_dice: 0.3646, decode.d3.loss_cls: 0.0166, decode.d3.loss_mask: 0.3687, decode.d3.loss_dice: 0.3601, decode.d4.loss_cls: 0.0119, decode.d4.loss_mask: 0.3719, decode.d4.loss_dice: 0.3628, decode.d5.loss_cls: 0.0121, decode.d5.loss_mask: 0.3694, decode.d5.loss_dice: 0.3596, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.3920, decode.d6.loss_dice: 0.3678, decode.d7.loss_cls: 0.0107, decode.d7.loss_mask: 0.3715, decode.d7.loss_dice: 0.3632, decode.d8.loss_cls: 0.0191, decode.d8.loss_mask: 0.3717, decode.d8.loss_dice: 0.3642, loss: 7.9687, grad_norm: 398.3167
2023-08-29 03:39:18,767 - mmseg - INFO - Iter [14400/160000]	lr: 1.532e-06, eta: 1 day, 5:34:33, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0106, decode.loss_mask: 0.3704, decode.loss_dice: 0.3880, decode.d0.loss_cls: 0.4179, decode.d0.loss_mask: 0.3980, decode.d0.loss_dice: 0.4247, decode.d1.loss_cls: 0.0042, decode.d1.loss_mask: 0.3806, decode.d1.loss_dice: 0.3945, decode.d2.loss_cls: 0.0035, decode.d2.loss_mask: 0.3736, decode.d2.loss_dice: 0.3891, decode.d3.loss_cls: 0.0037, decode.d3.loss_mask: 0.3732, decode.d3.loss_dice: 0.3920, decode.d4.loss_cls: 0.0038, decode.d4.loss_mask: 0.3763, decode.d4.loss_dice: 0.3946, decode.d5.loss_cls: 0.0038, decode.d5.loss_mask: 0.3767, decode.d5.loss_dice: 0.3940, decode.d6.loss_cls: 0.0037, decode.d6.loss_mask: 0.3759, decode.d6.loss_dice: 0.3925, decode.d7.loss_cls: 0.0071, decode.d7.loss_mask: 0.3711, decode.d7.loss_dice: 0.3920, decode.d8.loss_cls: 0.0072, decode.d8.loss_mask: 0.3712, decode.d8.loss_dice: 0.3916, loss: 8.1854, grad_norm: 433.9574
2023-08-29 03:39:53,899 - mmseg - INFO - Iter [14450/160000]	lr: 1.531e-06, eta: 1 day, 5:33:42, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0032, decode.loss_mask: 0.4124, decode.loss_dice: 0.3705, decode.d0.loss_cls: 0.4147, decode.d0.loss_mask: 0.3748, decode.d0.loss_dice: 0.3920, decode.d1.loss_cls: 0.0147, decode.d1.loss_mask: 0.3581, decode.d1.loss_dice: 0.3659, decode.d2.loss_cls: 0.0175, decode.d2.loss_mask: 0.3592, decode.d2.loss_dice: 0.3656, decode.d3.loss_cls: 0.0143, decode.d3.loss_mask: 0.3571, decode.d3.loss_dice: 0.3692, decode.d4.loss_cls: 0.0168, decode.d4.loss_mask: 0.3567, decode.d4.loss_dice: 0.3658, decode.d5.loss_cls: 0.0148, decode.d5.loss_mask: 0.3604, decode.d5.loss_dice: 0.3680, decode.d6.loss_cls: 0.0154, decode.d6.loss_mask: 0.3592, decode.d6.loss_dice: 0.3719, decode.d7.loss_cls: 0.0160, decode.d7.loss_mask: 0.3596, decode.d7.loss_dice: 0.3700, decode.d8.loss_cls: 0.0177, decode.d8.loss_mask: 0.3643, decode.d8.loss_dice: 0.3725, loss: 7.9181, grad_norm: 427.4373
2023-08-29 03:40:30,675 - mmseg - INFO - Iter [14500/160000]	lr: 1.531e-06, eta: 1 day, 5:33:08, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0016, decode.loss_mask: 0.2956, decode.loss_dice: 0.3036, decode.d0.loss_cls: 0.4082, decode.d0.loss_mask: 0.3139, decode.d0.loss_dice: 0.3286, decode.d1.loss_cls: 0.0014, decode.d1.loss_mask: 0.3025, decode.d1.loss_dice: 0.3056, decode.d2.loss_cls: 0.0010, decode.d2.loss_mask: 0.3008, decode.d2.loss_dice: 0.3014, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3009, decode.d3.loss_dice: 0.2990, decode.d4.loss_cls: 0.0014, decode.d4.loss_mask: 0.3015, decode.d4.loss_dice: 0.2979, decode.d5.loss_cls: 0.0011, decode.d5.loss_mask: 0.2974, decode.d5.loss_dice: 0.2982, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.2992, decode.d6.loss_dice: 0.2999, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.2997, decode.d7.loss_dice: 0.3034, decode.d8.loss_cls: 0.0013, decode.d8.loss_mask: 0.2996, decode.d8.loss_dice: 0.3022, loss: 6.4709, grad_norm: 295.0720
2023-08-29 03:41:07,173 - mmseg - INFO - Iter [14550/160000]	lr: 1.530e-06, eta: 1 day, 5:32:31, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0168, decode.loss_mask: 0.3900, decode.loss_dice: 0.3649, decode.d0.loss_cls: 0.4102, decode.d0.loss_mask: 0.3973, decode.d0.loss_dice: 0.3835, decode.d1.loss_cls: 0.0100, decode.d1.loss_mask: 0.4004, decode.d1.loss_dice: 0.3615, decode.d2.loss_cls: 0.0129, decode.d2.loss_mask: 0.3901, decode.d2.loss_dice: 0.3567, decode.d3.loss_cls: 0.0122, decode.d3.loss_mask: 0.3932, decode.d3.loss_dice: 0.3542, decode.d4.loss_cls: 0.0161, decode.d4.loss_mask: 0.3937, decode.d4.loss_dice: 0.3552, decode.d5.loss_cls: 0.0149, decode.d5.loss_mask: 0.3923, decode.d5.loss_dice: 0.3535, decode.d6.loss_cls: 0.0088, decode.d6.loss_mask: 0.4001, decode.d6.loss_dice: 0.3593, decode.d7.loss_cls: 0.0082, decode.d7.loss_mask: 0.4001, decode.d7.loss_dice: 0.3621, decode.d8.loss_cls: 0.0083, decode.d8.loss_mask: 0.4029, decode.d8.loss_dice: 0.3597, loss: 8.0893, grad_norm: 431.0014
2023-08-29 03:41:44,252 - mmseg - INFO - Iter [14600/160000]	lr: 1.530e-06, eta: 1 day, 5:31:59, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0090, decode.loss_mask: 0.3423, decode.loss_dice: 0.3408, decode.d0.loss_cls: 0.4018, decode.d0.loss_mask: 0.3625, decode.d0.loss_dice: 0.3738, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.3460, decode.d1.loss_dice: 0.3470, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3494, decode.d2.loss_dice: 0.3480, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3475, decode.d3.loss_dice: 0.3475, decode.d4.loss_cls: 0.0087, decode.d4.loss_mask: 0.3428, decode.d4.loss_dice: 0.3448, decode.d5.loss_cls: 0.0020, decode.d5.loss_mask: 0.3454, decode.d5.loss_dice: 0.3497, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3476, decode.d6.loss_dice: 0.3484, decode.d7.loss_cls: 0.0019, decode.d7.loss_mask: 0.3481, decode.d7.loss_dice: 0.3455, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.3505, decode.d8.loss_dice: 0.3445, loss: 7.4120, grad_norm: 404.3897
2023-08-29 03:42:19,612 - mmseg - INFO - Iter [14650/160000]	lr: 1.529e-06, eta: 1 day, 5:31:11, time: 0.707, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0057, decode.loss_mask: 0.3771, decode.loss_dice: 0.3624, decode.d0.loss_cls: 0.3994, decode.d0.loss_mask: 0.3965, decode.d0.loss_dice: 0.3894, decode.d1.loss_cls: 0.0029, decode.d1.loss_mask: 0.3753, decode.d1.loss_dice: 0.3637, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3737, decode.d2.loss_dice: 0.3626, decode.d3.loss_cls: 0.0024, decode.d3.loss_mask: 0.3743, decode.d3.loss_dice: 0.3643, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.3774, decode.d4.loss_dice: 0.3619, decode.d5.loss_cls: 0.0024, decode.d5.loss_mask: 0.3778, decode.d5.loss_dice: 0.3634, decode.d6.loss_cls: 0.0024, decode.d6.loss_mask: 0.3776, decode.d6.loss_dice: 0.3639, decode.d7.loss_cls: 0.0082, decode.d7.loss_mask: 0.3749, decode.d7.loss_dice: 0.3639, decode.d8.loss_cls: 0.0055, decode.d8.loss_mask: 0.3754, decode.d8.loss_dice: 0.3616, loss: 7.8708, grad_norm: 349.5755
2023-08-29 03:42:56,267 - mmseg - INFO - Iter [14700/160000]	lr: 1.529e-06, eta: 1 day, 5:30:35, time: 0.733, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0083, decode.loss_mask: 0.4244, decode.loss_dice: 0.3925, decode.d0.loss_cls: 0.4009, decode.d0.loss_mask: 0.4242, decode.d0.loss_dice: 0.4084, decode.d1.loss_cls: 0.0132, decode.d1.loss_mask: 0.4054, decode.d1.loss_dice: 0.3959, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 0.3978, decode.d2.loss_dice: 0.3919, decode.d3.loss_cls: 0.0112, decode.d3.loss_mask: 0.4040, decode.d3.loss_dice: 0.3947, decode.d4.loss_cls: 0.0099, decode.d4.loss_mask: 0.4021, decode.d4.loss_dice: 0.3950, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.4039, decode.d5.loss_dice: 0.3938, decode.d6.loss_cls: 0.0088, decode.d6.loss_mask: 0.4000, decode.d6.loss_dice: 0.3924, decode.d7.loss_cls: 0.0053, decode.d7.loss_mask: 0.4090, decode.d7.loss_dice: 0.3973, decode.d8.loss_cls: 0.0085, decode.d8.loss_mask: 0.4066, decode.d8.loss_dice: 0.3941, loss: 8.5166, grad_norm: 424.3484
2023-08-29 03:43:32,813 - mmseg - INFO - Iter [14750/160000]	lr: 1.528e-06, eta: 1 day, 5:29:58, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0157, decode.loss_mask: 0.3445, decode.loss_dice: 0.3296, decode.d0.loss_cls: 0.3967, decode.d0.loss_mask: 0.3608, decode.d0.loss_dice: 0.3650, decode.d1.loss_cls: 0.0153, decode.d1.loss_mask: 0.3474, decode.d1.loss_dice: 0.3479, decode.d2.loss_cls: 0.0111, decode.d2.loss_mask: 0.3579, decode.d2.loss_dice: 0.3469, decode.d3.loss_cls: 0.0163, decode.d3.loss_mask: 0.3480, decode.d3.loss_dice: 0.3357, decode.d4.loss_cls: 0.0144, decode.d4.loss_mask: 0.3505, decode.d4.loss_dice: 0.3388, decode.d5.loss_cls: 0.0084, decode.d5.loss_mask: 0.3594, decode.d5.loss_dice: 0.3464, decode.d6.loss_cls: 0.0027, decode.d6.loss_mask: 0.3645, decode.d6.loss_dice: 0.3491, decode.d7.loss_cls: 0.0094, decode.d7.loss_mask: 0.3454, decode.d7.loss_dice: 0.3376, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 0.3453, decode.d8.loss_dice: 0.3335, loss: 7.4536, grad_norm: 434.7034
2023-08-29 03:44:09,938 - mmseg - INFO - Iter [14800/160000]	lr: 1.528e-06, eta: 1 day, 5:29:27, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0260, decode.loss_mask: 0.4248, decode.loss_dice: 0.4082, decode.d0.loss_cls: 0.4041, decode.d0.loss_mask: 0.4282, decode.d0.loss_dice: 0.4309, decode.d1.loss_cls: 0.0365, decode.d1.loss_mask: 0.4136, decode.d1.loss_dice: 0.4171, decode.d2.loss_cls: 0.0360, decode.d2.loss_mask: 0.4059, decode.d2.loss_dice: 0.4110, decode.d3.loss_cls: 0.0236, decode.d3.loss_mask: 0.4101, decode.d3.loss_dice: 0.4090, decode.d4.loss_cls: 0.0212, decode.d4.loss_mask: 0.4064, decode.d4.loss_dice: 0.4086, decode.d5.loss_cls: 0.0144, decode.d5.loss_mask: 0.4101, decode.d5.loss_dice: 0.4134, decode.d6.loss_cls: 0.0134, decode.d6.loss_mask: 0.4121, decode.d6.loss_dice: 0.4130, decode.d7.loss_cls: 0.0221, decode.d7.loss_mask: 0.4152, decode.d7.loss_dice: 0.4127, decode.d8.loss_cls: 0.0223, decode.d8.loss_mask: 0.4277, decode.d8.loss_dice: 0.4089, loss: 8.9064, grad_norm: 410.5697
2023-08-29 03:44:45,103 - mmseg - INFO - Iter [14850/160000]	lr: 1.527e-06, eta: 1 day, 5:28:37, time: 0.703, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0152, decode.loss_mask: 0.3942, decode.loss_dice: 0.3931, decode.d0.loss_cls: 0.3916, decode.d0.loss_mask: 0.4280, decode.d0.loss_dice: 0.4335, decode.d1.loss_cls: 0.0180, decode.d1.loss_mask: 0.3934, decode.d1.loss_dice: 0.3924, decode.d2.loss_cls: 0.0156, decode.d2.loss_mask: 0.3918, decode.d2.loss_dice: 0.3900, decode.d3.loss_cls: 0.0127, decode.d3.loss_mask: 0.3885, decode.d3.loss_dice: 0.3885, decode.d4.loss_cls: 0.0132, decode.d4.loss_mask: 0.3913, decode.d4.loss_dice: 0.3931, decode.d5.loss_cls: 0.0130, decode.d5.loss_mask: 0.3907, decode.d5.loss_dice: 0.3998, decode.d6.loss_cls: 0.0121, decode.d6.loss_mask: 0.3982, decode.d6.loss_dice: 0.4049, decode.d7.loss_cls: 0.0135, decode.d7.loss_mask: 0.3922, decode.d7.loss_dice: 0.4007, decode.d8.loss_cls: 0.0149, decode.d8.loss_mask: 0.3884, decode.d8.loss_dice: 0.4018, loss: 8.4743, grad_norm: 371.3826
2023-08-29 03:45:21,892 - mmseg - INFO - Iter [14900/160000]	lr: 1.526e-06, eta: 1 day, 5:28:03, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0020, decode.loss_mask: 0.3382, decode.loss_dice: 0.3363, decode.d0.loss_cls: 0.3853, decode.d0.loss_mask: 0.3531, decode.d0.loss_dice: 0.3622, decode.d1.loss_cls: 0.0073, decode.d1.loss_mask: 0.3375, decode.d1.loss_dice: 0.3405, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.3432, decode.d2.loss_dice: 0.3388, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.3420, decode.d3.loss_dice: 0.3387, decode.d4.loss_cls: 0.0016, decode.d4.loss_mask: 0.3389, decode.d4.loss_dice: 0.3368, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3384, decode.d5.loss_dice: 0.3347, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.3428, decode.d6.loss_dice: 0.3389, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3413, decode.d7.loss_dice: 0.3344, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3378, decode.d8.loss_dice: 0.3347, loss: 7.2143, grad_norm: 358.9424
2023-08-29 03:45:58,145 - mmseg - INFO - Iter [14950/160000]	lr: 1.526e-06, eta: 1 day, 5:27:24, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0089, decode.loss_mask: 0.3579, decode.loss_dice: 0.3481, decode.d0.loss_cls: 0.3811, decode.d0.loss_mask: 0.3766, decode.d0.loss_dice: 0.3761, decode.d1.loss_cls: 0.0100, decode.d1.loss_mask: 0.3600, decode.d1.loss_dice: 0.3506, decode.d2.loss_cls: 0.0072, decode.d2.loss_mask: 0.3556, decode.d2.loss_dice: 0.3487, decode.d3.loss_cls: 0.0089, decode.d3.loss_mask: 0.3566, decode.d3.loss_dice: 0.3479, decode.d4.loss_cls: 0.0081, decode.d4.loss_mask: 0.3570, decode.d4.loss_dice: 0.3483, decode.d5.loss_cls: 0.0091, decode.d5.loss_mask: 0.3564, decode.d5.loss_dice: 0.3490, decode.d6.loss_cls: 0.0021, decode.d6.loss_mask: 0.3613, decode.d6.loss_dice: 0.3494, decode.d7.loss_cls: 0.0089, decode.d7.loss_mask: 0.3551, decode.d7.loss_dice: 0.3482, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.3560, decode.d8.loss_dice: 0.3485, loss: 7.5574, grad_norm: 358.9057
2023-08-29 03:46:35,113 - mmseg - INFO - Saving checkpoint at 15000 iterations
2023-08-29 03:46:37,449 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 03:46:37,449 - mmseg - INFO - Iter [15000/160000]	lr: 1.525e-06, eta: 1 day, 5:27:14, time: 0.786, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.3396, decode.loss_dice: 0.3466, decode.d0.loss_cls: 0.3773, decode.d0.loss_mask: 0.3562, decode.d0.loss_dice: 0.3723, decode.d1.loss_cls: 0.0027, decode.d1.loss_mask: 0.3392, decode.d1.loss_dice: 0.3508, decode.d2.loss_cls: 0.0024, decode.d2.loss_mask: 0.3362, decode.d2.loss_dice: 0.3494, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3396, decode.d3.loss_dice: 0.3488, decode.d4.loss_cls: 0.0024, decode.d4.loss_mask: 0.3399, decode.d4.loss_dice: 0.3463, decode.d5.loss_cls: 0.0023, decode.d5.loss_mask: 0.3422, decode.d5.loss_dice: 0.3464, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.3438, decode.d6.loss_dice: 0.3508, decode.d7.loss_cls: 0.0023, decode.d7.loss_mask: 0.3408, decode.d7.loss_dice: 0.3494, decode.d8.loss_cls: 0.0021, decode.d8.loss_mask: 0.3398, decode.d8.loss_dice: 0.3477, loss: 7.3238, grad_norm: 396.0658
2023-08-29 03:47:15,005 - mmseg - INFO - Iter [15050/160000]	lr: 1.525e-06, eta: 1 day, 5:26:47, time: 0.751, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0017, decode.loss_mask: 0.3268, decode.loss_dice: 0.3264, decode.d0.loss_cls: 0.3741, decode.d0.loss_mask: 0.3441, decode.d0.loss_dice: 0.3485, decode.d1.loss_cls: 0.0025, decode.d1.loss_mask: 0.3264, decode.d1.loss_dice: 0.3282, decode.d2.loss_cls: 0.0022, decode.d2.loss_mask: 0.3250, decode.d2.loss_dice: 0.3257, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3232, decode.d3.loss_dice: 0.3245, decode.d4.loss_cls: 0.0020, decode.d4.loss_mask: 0.3244, decode.d4.loss_dice: 0.3227, decode.d5.loss_cls: 0.0018, decode.d5.loss_mask: 0.3238, decode.d5.loss_dice: 0.3279, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.3234, decode.d6.loss_dice: 0.3239, decode.d7.loss_cls: 0.0017, decode.d7.loss_mask: 0.3207, decode.d7.loss_dice: 0.3241, decode.d8.loss_cls: 0.0017, decode.d8.loss_mask: 0.3254, decode.d8.loss_dice: 0.3278, loss: 6.9345, grad_norm: 368.9899
2023-08-29 03:47:49,798 - mmseg - INFO - Iter [15100/160000]	lr: 1.524e-06, eta: 1 day, 5:25:53, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0276, decode.loss_mask: 0.3391, decode.loss_dice: 0.3251, decode.d0.loss_cls: 0.3793, decode.d0.loss_mask: 0.3566, decode.d0.loss_dice: 0.3642, decode.d1.loss_cls: 0.0286, decode.d1.loss_mask: 0.3418, decode.d1.loss_dice: 0.3368, decode.d2.loss_cls: 0.0199, decode.d2.loss_mask: 0.3453, decode.d2.loss_dice: 0.3284, decode.d3.loss_cls: 0.0177, decode.d3.loss_mask: 0.3430, decode.d3.loss_dice: 0.3254, decode.d4.loss_cls: 0.0206, decode.d4.loss_mask: 0.3445, decode.d4.loss_dice: 0.3248, decode.d5.loss_cls: 0.0219, decode.d5.loss_mask: 0.3434, decode.d5.loss_dice: 0.3222, decode.d6.loss_cls: 0.0241, decode.d6.loss_mask: 0.3441, decode.d6.loss_dice: 0.3288, decode.d7.loss_cls: 0.0229, decode.d7.loss_mask: 0.3406, decode.d7.loss_dice: 0.3255, decode.d8.loss_cls: 0.0215, decode.d8.loss_mask: 0.3442, decode.d8.loss_dice: 0.3256, loss: 7.3334, grad_norm: 359.1140
2023-08-29 03:48:26,374 - mmseg - INFO - Iter [15150/160000]	lr: 1.524e-06, eta: 1 day, 5:25:16, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0022, decode.loss_mask: 0.3317, decode.loss_dice: 0.3390, decode.d0.loss_cls: 0.3678, decode.d0.loss_mask: 0.3437, decode.d0.loss_dice: 0.3686, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3284, decode.d1.loss_dice: 0.3423, decode.d2.loss_cls: 0.0017, decode.d2.loss_mask: 0.3324, decode.d2.loss_dice: 0.3413, decode.d3.loss_cls: 0.0014, decode.d3.loss_mask: 0.3329, decode.d3.loss_dice: 0.3402, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.3320, decode.d4.loss_dice: 0.3382, decode.d5.loss_cls: 0.0015, decode.d5.loss_mask: 0.3344, decode.d5.loss_dice: 0.3432, decode.d6.loss_cls: 0.0017, decode.d6.loss_mask: 0.3296, decode.d6.loss_dice: 0.3399, decode.d7.loss_cls: 0.0018, decode.d7.loss_mask: 0.3315, decode.d7.loss_dice: 0.3393, decode.d8.loss_cls: 0.0018, decode.d8.loss_mask: 0.3343, decode.d8.loss_dice: 0.3443, loss: 7.1504, grad_norm: 375.1182
2023-08-29 03:49:03,482 - mmseg - INFO - Iter [15200/160000]	lr: 1.523e-06, eta: 1 day, 5:24:45, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0173, decode.loss_mask: 0.3153, decode.loss_dice: 0.3183, decode.d0.loss_cls: 0.3697, decode.d0.loss_mask: 0.3268, decode.d0.loss_dice: 0.3437, decode.d1.loss_cls: 0.0124, decode.d1.loss_mask: 0.3179, decode.d1.loss_dice: 0.3245, decode.d2.loss_cls: 0.0139, decode.d2.loss_mask: 0.3142, decode.d2.loss_dice: 0.3211, decode.d3.loss_cls: 0.0107, decode.d3.loss_mask: 0.3161, decode.d3.loss_dice: 0.3218, decode.d4.loss_cls: 0.0106, decode.d4.loss_mask: 0.3165, decode.d4.loss_dice: 0.3178, decode.d5.loss_cls: 0.0100, decode.d5.loss_mask: 0.3148, decode.d5.loss_dice: 0.3224, decode.d6.loss_cls: 0.0105, decode.d6.loss_mask: 0.3149, decode.d6.loss_dice: 0.3208, decode.d7.loss_cls: 0.0143, decode.d7.loss_mask: 0.3176, decode.d7.loss_dice: 0.3223, decode.d8.loss_cls: 0.0154, decode.d8.loss_mask: 0.3157, decode.d8.loss_dice: 0.3181, loss: 6.8858, grad_norm: 320.6316
2023-08-29 03:49:40,769 - mmseg - INFO - Iter [15250/160000]	lr: 1.523e-06, eta: 1 day, 5:24:16, time: 0.746, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0192, decode.loss_mask: 0.3817, decode.loss_dice: 0.3758, decode.d0.loss_cls: 0.3722, decode.d0.loss_mask: 0.4000, decode.d0.loss_dice: 0.4118, decode.d1.loss_cls: 0.0161, decode.d1.loss_mask: 0.3945, decode.d1.loss_dice: 0.3913, decode.d2.loss_cls: 0.0186, decode.d2.loss_mask: 0.3798, decode.d2.loss_dice: 0.3802, decode.d3.loss_cls: 0.0183, decode.d3.loss_mask: 0.3806, decode.d3.loss_dice: 0.3798, decode.d4.loss_cls: 0.0188, decode.d4.loss_mask: 0.3825, decode.d4.loss_dice: 0.3786, decode.d5.loss_cls: 0.0211, decode.d5.loss_mask: 0.3780, decode.d5.loss_dice: 0.3796, decode.d6.loss_cls: 0.0130, decode.d6.loss_mask: 0.3906, decode.d6.loss_dice: 0.3851, decode.d7.loss_cls: 0.0201, decode.d7.loss_mask: 0.3851, decode.d7.loss_dice: 0.3830, decode.d8.loss_cls: 0.0180, decode.d8.loss_mask: 0.3818, decode.d8.loss_dice: 0.3857, loss: 8.2411, grad_norm: 413.4549
2023-08-29 03:50:15,455 - mmseg - INFO - Iter [15300/160000]	lr: 1.522e-06, eta: 1 day, 5:23:21, time: 0.694, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0023, decode.loss_mask: 0.3447, decode.loss_dice: 0.3385, decode.d0.loss_cls: 0.3592, decode.d0.loss_mask: 0.3602, decode.d0.loss_dice: 0.3630, decode.d1.loss_cls: 0.0024, decode.d1.loss_mask: 0.3449, decode.d1.loss_dice: 0.3369, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3427, decode.d2.loss_dice: 0.3351, decode.d3.loss_cls: 0.0020, decode.d3.loss_mask: 0.3418, decode.d3.loss_dice: 0.3337, decode.d4.loss_cls: 0.0019, decode.d4.loss_mask: 0.3447, decode.d4.loss_dice: 0.3347, decode.d5.loss_cls: 0.0019, decode.d5.loss_mask: 0.3438, decode.d5.loss_dice: 0.3353, decode.d6.loss_cls: 0.0018, decode.d6.loss_mask: 0.3431, decode.d6.loss_dice: 0.3340, decode.d7.loss_cls: 0.0065, decode.d7.loss_mask: 0.3392, decode.d7.loss_dice: 0.3301, decode.d8.loss_cls: 0.0063, decode.d8.loss_mask: 0.3373, decode.d8.loss_dice: 0.3331, loss: 7.2037, grad_norm: 413.1690
2023-08-29 03:50:51,711 - mmseg - INFO - Iter [15350/160000]	lr: 1.522e-06, eta: 1 day, 5:22:42, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0010, decode.loss_mask: 0.3286, decode.loss_dice: 0.3122, decode.d0.loss_cls: 0.3582, decode.d0.loss_mask: 0.3419, decode.d0.loss_dice: 0.3425, decode.d1.loss_cls: 0.0017, decode.d1.loss_mask: 0.3306, decode.d1.loss_dice: 0.3168, decode.d2.loss_cls: 0.0012, decode.d2.loss_mask: 0.3301, decode.d2.loss_dice: 0.3134, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.3306, decode.d3.loss_dice: 0.3088, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.3301, decode.d4.loss_dice: 0.3083, decode.d5.loss_cls: 0.0008, decode.d5.loss_mask: 0.3280, decode.d5.loss_dice: 0.3085, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.3288, decode.d6.loss_dice: 0.3098, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.3300, decode.d7.loss_dice: 0.3119, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.3296, decode.d8.loss_dice: 0.3116, loss: 6.8197, grad_norm: 370.8625
2023-08-29 03:51:28,782 - mmseg - INFO - Iter [15400/160000]	lr: 1.521e-06, eta: 1 day, 5:22:10, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0072, decode.loss_mask: 0.3458, decode.loss_dice: 0.3735, decode.d0.loss_cls: 0.3570, decode.d0.loss_mask: 0.3601, decode.d0.loss_dice: 0.3969, decode.d1.loss_cls: 0.0068, decode.d1.loss_mask: 0.3451, decode.d1.loss_dice: 0.3771, decode.d2.loss_cls: 0.0052, decode.d2.loss_mask: 0.3435, decode.d2.loss_dice: 0.3732, decode.d3.loss_cls: 0.0067, decode.d3.loss_mask: 0.3406, decode.d3.loss_dice: 0.3701, decode.d4.loss_cls: 0.0065, decode.d4.loss_mask: 0.3463, decode.d4.loss_dice: 0.3733, decode.d5.loss_cls: 0.0070, decode.d5.loss_mask: 0.3453, decode.d5.loss_dice: 0.3759, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.3443, decode.d6.loss_dice: 0.3752, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.3446, decode.d7.loss_dice: 0.3760, decode.d8.loss_cls: 0.0046, decode.d8.loss_mask: 0.3463, decode.d8.loss_dice: 0.3755, loss: 7.6387, grad_norm: 397.0076
2023-08-29 03:52:05,791 - mmseg - INFO - Iter [15450/160000]	lr: 1.521e-06, eta: 1 day, 5:21:38, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0025, decode.loss_mask: 0.3225, decode.loss_dice: 0.3198, decode.d0.loss_cls: 0.3510, decode.d0.loss_mask: 0.3335, decode.d0.loss_dice: 0.3485, decode.d1.loss_cls: 0.0023, decode.d1.loss_mask: 0.3251, decode.d1.loss_dice: 0.3229, decode.d2.loss_cls: 0.0021, decode.d2.loss_mask: 0.3219, decode.d2.loss_dice: 0.3197, decode.d3.loss_cls: 0.0021, decode.d3.loss_mask: 0.3197, decode.d3.loss_dice: 0.3202, decode.d4.loss_cls: 0.0021, decode.d4.loss_mask: 0.3220, decode.d4.loss_dice: 0.3197, decode.d5.loss_cls: 0.0021, decode.d5.loss_mask: 0.3230, decode.d5.loss_dice: 0.3218, decode.d6.loss_cls: 0.0020, decode.d6.loss_mask: 0.3218, decode.d6.loss_dice: 0.3218, decode.d7.loss_cls: 0.0021, decode.d7.loss_mask: 0.3227, decode.d7.loss_dice: 0.3222, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.3224, decode.d8.loss_dice: 0.3211, loss: 6.8429, grad_norm: 422.1009
2023-08-29 03:52:40,752 - mmseg - INFO - Iter [15500/160000]	lr: 1.520e-06, eta: 1 day, 5:20:46, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0066, decode.loss_mask: 0.3739, decode.loss_dice: 0.3664, decode.d0.loss_cls: 0.3523, decode.d0.loss_mask: 0.3883, decode.d0.loss_dice: 0.3853, decode.d1.loss_cls: 0.0054, decode.d1.loss_mask: 0.3725, decode.d1.loss_dice: 0.3696, decode.d2.loss_cls: 0.0032, decode.d2.loss_mask: 0.3730, decode.d2.loss_dice: 0.3653, decode.d3.loss_cls: 0.0046, decode.d3.loss_mask: 0.3731, decode.d3.loss_dice: 0.3678, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.3741, decode.d4.loss_dice: 0.3658, decode.d5.loss_cls: 0.0050, decode.d5.loss_mask: 0.3737, decode.d5.loss_dice: 0.3662, decode.d6.loss_cls: 0.0031, decode.d6.loss_mask: 0.3693, decode.d6.loss_dice: 0.3665, decode.d7.loss_cls: 0.0041, decode.d7.loss_mask: 0.3712, decode.d7.loss_dice: 0.3633, decode.d8.loss_cls: 0.0022, decode.d8.loss_mask: 0.3742, decode.d8.loss_dice: 0.3692, loss: 7.8200, grad_norm: 435.8570
2023-08-29 03:53:16,949 - mmseg - INFO - Iter [15550/160000]	lr: 1.520e-06, eta: 1 day, 5:20:06, time: 0.724, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.3413, decode.loss_dice: 0.3467, decode.d0.loss_cls: 0.3500, decode.d0.loss_mask: 0.3633, decode.d0.loss_dice: 0.3728, decode.d1.loss_cls: 0.0015, decode.d1.loss_mask: 0.3478, decode.d1.loss_dice: 0.3616, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.3386, decode.d2.loss_dice: 0.3455, decode.d3.loss_cls: 0.0010, decode.d3.loss_mask: 0.3384, decode.d3.loss_dice: 0.3421, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.3399, decode.d4.loss_dice: 0.3468, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3392, decode.d5.loss_dice: 0.3430, decode.d6.loss_cls: 0.0010, decode.d6.loss_mask: 0.3401, decode.d6.loss_dice: 0.3424, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.3379, decode.d7.loss_dice: 0.3436, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3396, decode.d8.loss_dice: 0.3473, loss: 7.2779, grad_norm: 385.5304
2023-08-29 03:53:53,872 - mmseg - INFO - Iter [15600/160000]	lr: 1.519e-06, eta: 1 day, 5:19:33, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0015, decode.loss_mask: 0.3804, decode.loss_dice: 0.3766, decode.d0.loss_cls: 0.3433, decode.d0.loss_mask: 0.4026, decode.d0.loss_dice: 0.3980, decode.d1.loss_cls: 0.0020, decode.d1.loss_mask: 0.3847, decode.d1.loss_dice: 0.3825, decode.d2.loss_cls: 0.0016, decode.d2.loss_mask: 0.3850, decode.d2.loss_dice: 0.3804, decode.d3.loss_cls: 0.0015, decode.d3.loss_mask: 0.3810, decode.d3.loss_dice: 0.3761, decode.d4.loss_cls: 0.0015, decode.d4.loss_mask: 0.3838, decode.d4.loss_dice: 0.3785, decode.d5.loss_cls: 0.0014, decode.d5.loss_mask: 0.3805, decode.d5.loss_dice: 0.3782, decode.d6.loss_cls: 0.0015, decode.d6.loss_mask: 0.3812, decode.d6.loss_dice: 0.3760, decode.d7.loss_cls: 0.0015, decode.d7.loss_mask: 0.3830, decode.d7.loss_dice: 0.3784, decode.d8.loss_cls: 0.0015, decode.d8.loss_mask: 0.3828, decode.d8.loss_dice: 0.3782, loss: 8.0054, grad_norm: 443.1171
2023-08-29 03:54:31,099 - mmseg - INFO - Iter [15650/160000]	lr: 1.519e-06, eta: 1 day, 5:19:03, time: 0.745, data_time: 0.049, memory: 6584, decode.loss_cls: 0.0008, decode.loss_mask: 0.3573, decode.loss_dice: 0.3494, decode.d0.loss_cls: 0.3404, decode.d0.loss_mask: 0.3724, decode.d0.loss_dice: 0.3717, decode.d1.loss_cls: 0.0013, decode.d1.loss_mask: 0.3550, decode.d1.loss_dice: 0.3468, decode.d2.loss_cls: 0.0009, decode.d2.loss_mask: 0.3557, decode.d2.loss_dice: 0.3474, decode.d3.loss_cls: 0.0008, decode.d3.loss_mask: 0.3577, decode.d3.loss_dice: 0.3486, decode.d4.loss_cls: 0.0008, decode.d4.loss_mask: 0.3580, decode.d4.loss_dice: 0.3475, decode.d5.loss_cls: 0.0007, decode.d5.loss_mask: 0.3557, decode.d5.loss_dice: 0.3456, decode.d6.loss_cls: 0.0008, decode.d6.loss_mask: 0.3569, decode.d6.loss_dice: 0.3479, decode.d7.loss_cls: 0.0008, decode.d7.loss_mask: 0.3570, decode.d7.loss_dice: 0.3484, decode.d8.loss_cls: 0.0007, decode.d8.loss_mask: 0.3559, decode.d8.loss_dice: 0.3487, loss: 7.4317, grad_norm: 400.9551
2023-08-29 03:55:05,944 - mmseg - INFO - Iter [15700/160000]	lr: 1.518e-06, eta: 1 day, 5:18:10, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0009, decode.loss_mask: 0.3441, decode.loss_dice: 0.3396, decode.d0.loss_cls: 0.3415, decode.d0.loss_mask: 0.3610, decode.d0.loss_dice: 0.3642, decode.d1.loss_cls: 0.0016, decode.d1.loss_mask: 0.3464, decode.d1.loss_dice: 0.3421, decode.d2.loss_cls: 0.0011, decode.d2.loss_mask: 0.3451, decode.d2.loss_dice: 0.3417, decode.d3.loss_cls: 0.0009, decode.d3.loss_mask: 0.3440, decode.d3.loss_dice: 0.3380, decode.d4.loss_cls: 0.0009, decode.d4.loss_mask: 0.3445, decode.d4.loss_dice: 0.3408, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3427, decode.d5.loss_dice: 0.3389, decode.d6.loss_cls: 0.0009, decode.d6.loss_mask: 0.3432, decode.d6.loss_dice: 0.3376, decode.d7.loss_cls: 0.0009, decode.d7.loss_mask: 0.3417, decode.d7.loss_dice: 0.3381, decode.d8.loss_cls: 0.0009, decode.d8.loss_mask: 0.3449, decode.d8.loss_dice: 0.3394, loss: 7.2285, grad_norm: 410.1486
2023-08-29 03:55:42,642 - mmseg - INFO - Iter [15750/160000]	lr: 1.518e-06, eta: 1 day, 5:17:35, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0062, decode.loss_mask: 0.3392, decode.loss_dice: 0.3488, decode.d0.loss_cls: 0.3383, decode.d0.loss_mask: 0.3532, decode.d0.loss_dice: 0.3732, decode.d1.loss_cls: 0.0083, decode.d1.loss_mask: 0.3419, decode.d1.loss_dice: 0.3554, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.3398, decode.d2.loss_dice: 0.3519, decode.d3.loss_cls: 0.0093, decode.d3.loss_mask: 0.3401, decode.d3.loss_dice: 0.3484, decode.d4.loss_cls: 0.0063, decode.d4.loss_mask: 0.3406, decode.d4.loss_dice: 0.3497, decode.d5.loss_cls: 0.0069, decode.d5.loss_mask: 0.3405, decode.d5.loss_dice: 0.3493, decode.d6.loss_cls: 0.0084, decode.d6.loss_mask: 0.3404, decode.d6.loss_dice: 0.3488, decode.d7.loss_cls: 0.0067, decode.d7.loss_mask: 0.3403, decode.d7.loss_dice: 0.3489, decode.d8.loss_cls: 0.0071, decode.d8.loss_mask: 0.3433, decode.d8.loss_dice: 0.3491, loss: 7.3472, grad_norm: 402.0031
2023-08-29 03:56:19,461 - mmseg - INFO - Iter [15800/160000]	lr: 1.517e-06, eta: 1 day, 5:17:01, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0042, decode.loss_mask: 0.3259, decode.loss_dice: 0.3301, decode.d0.loss_cls: 0.3345, decode.d0.loss_mask: 0.3436, decode.d0.loss_dice: 0.3524, decode.d1.loss_cls: 0.0081, decode.d1.loss_mask: 0.3262, decode.d1.loss_dice: 0.3361, decode.d2.loss_cls: 0.0065, decode.d2.loss_mask: 0.3249, decode.d2.loss_dice: 0.3310, decode.d3.loss_cls: 0.0060, decode.d3.loss_mask: 0.3251, decode.d3.loss_dice: 0.3335, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.3241, decode.d4.loss_dice: 0.3316, decode.d5.loss_cls: 0.0066, decode.d5.loss_mask: 0.3257, decode.d5.loss_dice: 0.3345, decode.d6.loss_cls: 0.0070, decode.d6.loss_mask: 0.3251, decode.d6.loss_dice: 0.3321, decode.d7.loss_cls: 0.0064, decode.d7.loss_mask: 0.3251, decode.d7.loss_dice: 0.3328, decode.d8.loss_cls: 0.0054, decode.d8.loss_mask: 0.3264, decode.d8.loss_dice: 0.3322, loss: 7.0087, grad_norm: 339.7999
2023-08-29 03:56:56,528 - mmseg - INFO - Iter [15850/160000]	lr: 1.516e-06, eta: 1 day, 5:16:29, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0205, decode.loss_mask: 0.3561, decode.loss_dice: 0.3517, decode.d0.loss_cls: 0.3336, decode.d0.loss_mask: 0.3666, decode.d0.loss_dice: 0.3716, decode.d1.loss_cls: 0.0176, decode.d1.loss_mask: 0.3539, decode.d1.loss_dice: 0.3545, decode.d2.loss_cls: 0.0187, decode.d2.loss_mask: 0.3509, decode.d2.loss_dice: 0.3540, decode.d3.loss_cls: 0.0169, decode.d3.loss_mask: 0.3532, decode.d3.loss_dice: 0.3483, decode.d4.loss_cls: 0.0198, decode.d4.loss_mask: 0.3546, decode.d4.loss_dice: 0.3507, decode.d5.loss_cls: 0.0173, decode.d5.loss_mask: 0.3534, decode.d5.loss_dice: 0.3511, decode.d6.loss_cls: 0.0161, decode.d6.loss_mask: 0.3529, decode.d6.loss_dice: 0.3503, decode.d7.loss_cls: 0.0176, decode.d7.loss_mask: 0.3556, decode.d7.loss_dice: 0.3501, decode.d8.loss_cls: 0.0162, decode.d8.loss_mask: 0.3551, decode.d8.loss_dice: 0.3526, loss: 7.5816, grad_norm: 360.7919
2023-08-29 03:57:31,337 - mmseg - INFO - Iter [15900/160000]	lr: 1.516e-06, eta: 1 day, 5:15:37, time: 0.696, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0013, decode.loss_mask: 0.3628, decode.loss_dice: 0.3649, decode.d0.loss_cls: 0.3292, decode.d0.loss_mask: 0.3823, decode.d0.loss_dice: 0.3903, decode.d1.loss_cls: 0.0018, decode.d1.loss_mask: 0.3638, decode.d1.loss_dice: 0.3685, decode.d2.loss_cls: 0.0013, decode.d2.loss_mask: 0.3594, decode.d2.loss_dice: 0.3638, decode.d3.loss_cls: 0.0011, decode.d3.loss_mask: 0.3599, decode.d3.loss_dice: 0.3609, decode.d4.loss_cls: 0.0010, decode.d4.loss_mask: 0.3593, decode.d4.loss_dice: 0.3627, decode.d5.loss_cls: 0.0009, decode.d5.loss_mask: 0.3613, decode.d5.loss_dice: 0.3666, decode.d6.loss_cls: 0.0011, decode.d6.loss_mask: 0.3617, decode.d6.loss_dice: 0.3669, decode.d7.loss_cls: 0.0010, decode.d7.loss_mask: 0.3607, decode.d7.loss_dice: 0.3645, decode.d8.loss_cls: 0.0010, decode.d8.loss_mask: 0.3604, decode.d8.loss_dice: 0.3656, loss: 7.6460, grad_norm: 391.7283
2023-08-29 03:58:08,255 - mmseg - INFO - Iter [15950/160000]	lr: 1.515e-06, eta: 1 day, 5:15:03, time: 0.738, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0135, decode.loss_mask: 0.3666, decode.loss_dice: 0.3550, decode.d0.loss_cls: 0.3328, decode.d0.loss_mask: 0.3691, decode.d0.loss_dice: 0.3907, decode.d1.loss_cls: 0.0224, decode.d1.loss_mask: 0.3541, decode.d1.loss_dice: 0.3568, decode.d2.loss_cls: 0.0169, decode.d2.loss_mask: 0.3560, decode.d2.loss_dice: 0.3586, decode.d3.loss_cls: 0.0155, decode.d3.loss_mask: 0.3514, decode.d3.loss_dice: 0.3552, decode.d4.loss_cls: 0.0203, decode.d4.loss_mask: 0.3511, decode.d4.loss_dice: 0.3539, decode.d5.loss_cls: 0.0193, decode.d5.loss_mask: 0.3517, decode.d5.loss_dice: 0.3560, decode.d6.loss_cls: 0.0182, decode.d6.loss_mask: 0.3597, decode.d6.loss_dice: 0.3568, decode.d7.loss_cls: 0.0108, decode.d7.loss_mask: 0.3666, decode.d7.loss_dice: 0.3547, decode.d8.loss_cls: 0.0139, decode.d8.loss_mask: 0.3591, decode.d8.loss_dice: 0.3553, loss: 7.6619, grad_norm: 374.2766
2023-08-29 03:58:44,797 - mmseg - INFO - Saving checkpoint at 16000 iterations
2023-08-29 03:58:47,139 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 03:58:47,139 - mmseg - INFO - Iter [16000/160000]	lr: 1.515e-06, eta: 1 day, 5:14:48, time: 0.778, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0075, decode.loss_mask: 0.3112, decode.loss_dice: 0.3306, decode.d0.loss_cls: 0.3218, decode.d0.loss_mask: 0.3278, decode.d0.loss_dice: 0.3561, decode.d1.loss_cls: 0.0076, decode.d1.loss_mask: 0.3102, decode.d1.loss_dice: 0.3297, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.3091, decode.d2.loss_dice: 0.3294, decode.d3.loss_cls: 0.0074, decode.d3.loss_mask: 0.3078, decode.d3.loss_dice: 0.3315, decode.d4.loss_cls: 0.0058, decode.d4.loss_mask: 0.3099, decode.d4.loss_dice: 0.3250, decode.d5.loss_cls: 0.0069, decode.d5.loss_mask: 0.3108, decode.d5.loss_dice: 0.3240, decode.d6.loss_cls: 0.0085, decode.d6.loss_mask: 0.3113, decode.d6.loss_dice: 0.3293, decode.d7.loss_cls: 0.0070, decode.d7.loss_mask: 0.3101, decode.d7.loss_dice: 0.3280, decode.d8.loss_cls: 0.0071, decode.d8.loss_mask: 0.3120, decode.d8.loss_dice: 0.3269, loss: 6.8173, grad_norm: 370.5366
