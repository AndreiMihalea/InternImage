2023-08-29 09:54:29,182 - mmseg - INFO - Multi-processing start method is `None`
2023-08-29 09:54:29,183 - mmseg - INFO - OpenCV num_threads is `12
2023-08-29 09:54:29,183 - mmseg - INFO - OMP num threads is 1
2023-08-29 09:54:29,210 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce GTX 1080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 12.1, V12.1.66
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.8.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+cefb275
------------------------------------------------------------

2023-08-29 09:54:29,211 - mmseg - INFO - Distributed training: True
2023-08-29 09:54:30,149 - mmseg - INFO - Config:
num_things_classes = 0
num_stuff_classes = 2
num_classes = 2
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoderMask2Former',
    pretrained=None,
    backbone=dict(
        type='InternImage',
        core_op='DCNv3',
        channels=112,
        depths=[4, 4, 21, 4],
        groups=[7, 14, 28, 56],
        mlp_ratio=4.0,
        drop_path_rate=0.4,
        norm_layer='LN',
        layer_scale=1.0,
        offset_scale=1.0,
        post_norm=True,
        with_cp=False,
        out_indices=(0, 1, 2, 3),
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
        )),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[112, 224, 448, 896],
        feat_channels=256,
        out_channels=256,
        in_index=[0, 1, 2, 3],
        num_things_classes=0,
        num_stuff_classes=2,
        num_queries=100,
        num_transformer_feat_level=3,
        pixel_decoder=dict(
            type='MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        num_heads=8,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=False,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True),
                        with_cp=True),
                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),
                init_cfg=None),
            positional_encoding=dict(
                type='SinePositionalEncoding', num_feats=128, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(
            type='SinePositionalEncoding', num_feats=128, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=256,
                    num_heads=8,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=256,
                    feedforward_channels=2048,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True,
                    with_cp=True),
                feedforward_channels=2048,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[1.0, 1.0, 0.1]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0)),
    train_cfg=dict(
        num_points=12544,
        oversample_ratio=3.0,
        importance_sample_ratio=0.75,
        assigner=dict(
            type='MaskHungarianAssigner',
            cls_cost=dict(type='ClassificationCost', weight=2.0),
            mask_cost=dict(
                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
            dice_cost=dict(
                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
        sampler=dict(type='MaskPseudoSampler')),
    test_cfg=dict(
        panoptic_on=True,
        semantic_on=False,
        instance_on=True,
        max_per_image=100,
        iou_thr=0.8,
        filter_low_score=True,
        mode='slide',
        crop_size=(200, 664),
        stride=(341, 341)),
    init_cfg=None)
dataset_type = 'UPBDataset'
data_root = '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation'
img_norm_cfg = dict(
    mean=[89.497, 93.675, 92.645], std=[76.422, 78.611, 80.487], to_rgb=True)
crop_size = (200, 664)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=False),
    dict(type='LoadCategory'),
    dict(type='Resize', img_scale=(664, 200), ratio_range=None),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[89.497, 93.675, 92.645],
        std=[76.422, 78.611, 80.487],
        to_rgb=True),
    dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
    dict(type='ToMask'),
    dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels', 'category'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(200, 664),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir='self_supervised_labels_30',
        split='splits/val_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=False),
            dict(type='LoadCategory'),
            dict(type='Resize', img_scale=(664, 200), ratio_range=None),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[89.497, 93.675, 92.645],
                std=[76.422, 78.611, 80.487],
                to_rgb=True),
            dict(type='Pad', size=(200, 664), pad_val=0, seg_pad_val=0),
            dict(type='ToMask'),
            dict(type='ToSoft', num_iter=12, kernel_size=(11, 11), std_dev=5),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=[
                    'img', 'gt_semantic_seg', 'gt_masks', 'gt_labels',
                    'category'
                ])
        ]),
    val=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='UPBDataset',
        data_root=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation',
        img_dir='images',
        ann_dir=
        '/mnt/storage/workspace/andreim/kitti/data_odometry_color/segmentation_gt/self_supervised_labels_30',
        split='splits/test_30.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(200, 664),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[89.497, 93.675, 92.645],
                        std=[76.422, 78.611, 80.487],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=2e-05,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    constructor='CustomLayerDecayOptimizerConstructor',
    paramwise_cfg=dict(
        num_layers=39,
        layer_decay_rate=0.94,
        depths=[5, 5, 24, 5],
        offset_lr_scale=1.0))
optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
evaluation = dict(
    interval=16000, metric='mIoU', pre_eval=True, save_best='mIoU')
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth'
work_dir = 'work_dirs/mask2former_internimage_b_kitti'
gpu_ids = range(0, 2)
auto_resume = False

2023-08-29 09:54:32,037 - mmseg - INFO - Set random seed to 814400958, deterministic: False
2023-08-29 09:54:32,038 - mmseg - INFO - using core type: DCNv3
2023-08-29 09:54:32,038 - mmseg - INFO - using activation layer: GELU
2023-08-29 09:54:32,038 - mmseg - INFO - using main norm layer: LN
2023-08-29 09:54:32,038 - mmseg - INFO - using dpr: linear, 0.4
2023-08-29 09:54:32,038 - mmseg - INFO - level2_post_norm: False
2023-08-29 09:54:32,038 - mmseg - INFO - level2_post_norm_block_ids: None
2023-08-29 09:54:32,038 - mmseg - INFO - res_post_norm: False
2023-08-29 09:54:33,321 - mmseg - INFO - load checkpoint from http path: https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth
2023-08-29 09:54:33,583 - mmseg - INFO - _IncompatibleKeys(missing_keys=[], unexpected_keys=['conv_head.0.weight', 'conv_head.1.0.weight', 'conv_head.1.0.bias', 'conv_head.1.0.running_mean', 'conv_head.1.0.running_var', 'conv_head.1.0.num_batches_tracked', 'head.weight', 'head.bias'])
Name of parameter - Initialization information

backbone.patch_embed.conv1.weight - torch.Size([56, 3, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.weight - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm1.1.bias - torch.Size([56]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.weight - torch.Size([112, 56, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.conv2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.patch_embed.norm2.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.0.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.1.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.2.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma1 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.gamma2 - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm1.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.weight - torch.Size([112, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.weight - torch.Size([126, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.offset.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.weight - torch.Size([63, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.mask.bias - torch.Size([63]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.input_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.weight - torch.Size([112, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.dcn.output_proj.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.weight - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.norm2.0.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.weight - torch.Size([448, 112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.weight - torch.Size([112, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.blocks.3.mlp.fc2.bias - torch.Size([112]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.conv.weight - torch.Size([224, 112, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.0.downsample.norm.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.0.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.1.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.2.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma1 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.gamma2 - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm1.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.weight - torch.Size([224, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.weight - torch.Size([252, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.offset.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.weight - torch.Size([126, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.mask.bias - torch.Size([126]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.input_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.weight - torch.Size([224, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.dcn.output_proj.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.weight - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.norm2.0.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.weight - torch.Size([896, 224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.weight - torch.Size([224, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.blocks.3.mlp.fc2.bias - torch.Size([224]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.conv.weight - torch.Size([448, 224, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.1.downsample.norm.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.7.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.8.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.9.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.10.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.11.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.12.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.13.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.14.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.15.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.16.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.17.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.18.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.19.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma1 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.gamma2 - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm1.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.weight - torch.Size([448, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.weight - torch.Size([504, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.offset.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.weight - torch.Size([252, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.mask.bias - torch.Size([252]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.input_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.weight - torch.Size([448, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.dcn.output_proj.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.weight - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.norm2.0.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.weight - torch.Size([1792, 448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc1.bias - torch.Size([1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.weight - torch.Size([448, 1792]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.blocks.20.mlp.fc2.bias - torch.Size([448]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.conv.weight - torch.Size([896, 448, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.2.downsample.norm.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma1 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.gamma2 - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm1.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.weight - torch.Size([896, 1, 3, 3]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.weight - torch.Size([1008, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.offset.bias - torch.Size([1008]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.weight - torch.Size([504, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.mask.bias - torch.Size([504]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.input_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.weight - torch.Size([896, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.dcn.output_proj.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.weight - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.norm2.0.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([3584, 896]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([896, 3584]): 
Initialized by user-defined `init_weights` in InternImage  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([896]): 
Initialized by user-defined `init_weights` in InternImage  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 896, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 448, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 224, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 112, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.cls_embed.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2Former  
2023-08-29 09:54:33,811 - mmseg - INFO - Loaded 20598 images
2023-08-29 09:54:45,118 - mmseg - INFO - {'num_layers': 39, 'layer_decay_rate': 0.94, 'depths': [5, 5, 24, 5], 'offset_lr_scale': 1.0}
2023-08-29 09:54:45,118 - mmseg - INFO - Build CustomLayerDecayOptimizerConstructor 0.940000 - 41
2023-08-29 09:54:45,123 - mmseg - INFO - Param groups = {
  "layer_0_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.weight",
      "backbone.patch_embed.conv2.weight",
      "decode_head.query_embed.weight",
      "decode_head.query_feat.weight",
      "decode_head.level_embed.weight",
      "decode_head.cls_embed.weight",
      "decode_head.mask_embed.0.weight",
      "decode_head.mask_embed.2.weight",
      "decode_head.mask_embed.4.weight"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.05
  },
  "layer_0_no_decay": {
    "param_names": [
      "backbone.patch_embed.conv1.bias",
      "backbone.patch_embed.norm1.1.weight",
      "backbone.patch_embed.norm1.1.bias",
      "backbone.patch_embed.conv2.bias",
      "backbone.patch_embed.norm2.1.weight",
      "backbone.patch_embed.norm2.1.bias",
      "decode_head.cls_embed.bias",
      "decode_head.mask_embed.0.bias",
      "decode_head.mask_embed.2.bias",
      "decode_head.mask_embed.4.bias"
    ],
    "lr_scale": 0.08416163114342567,
    "lr": 1.6832326228685137e-06,
    "weight_decay": 0.0
  },
  "layer_1_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.gamma1",
      "backbone.levels.0.blocks.0.gamma2",
      "backbone.levels.0.blocks.0.norm1.0.weight",
      "backbone.levels.0.blocks.0.norm1.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.0.dcn.offset.bias",
      "backbone.levels.0.blocks.0.dcn.mask.bias",
      "backbone.levels.0.blocks.0.dcn.input_proj.bias",
      "backbone.levels.0.blocks.0.dcn.output_proj.bias",
      "backbone.levels.0.blocks.0.norm2.0.weight",
      "backbone.levels.0.blocks.0.norm2.0.bias",
      "backbone.levels.0.blocks.0.mlp.fc1.bias",
      "backbone.levels.0.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.0
  },
  "layer_1_decay": {
    "param_names": [
      "backbone.levels.0.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.0.dcn.offset.weight",
      "backbone.levels.0.blocks.0.dcn.mask.weight",
      "backbone.levels.0.blocks.0.dcn.input_proj.weight",
      "backbone.levels.0.blocks.0.dcn.output_proj.weight",
      "backbone.levels.0.blocks.0.mlp.fc1.weight",
      "backbone.levels.0.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.08953365015258051,
    "lr": 1.7906730030516104e-06,
    "weight_decay": 0.05
  },
  "layer_2_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.gamma1",
      "backbone.levels.0.blocks.1.gamma2",
      "backbone.levels.0.blocks.1.norm1.0.weight",
      "backbone.levels.0.blocks.1.norm1.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.1.dcn.offset.bias",
      "backbone.levels.0.blocks.1.dcn.mask.bias",
      "backbone.levels.0.blocks.1.dcn.input_proj.bias",
      "backbone.levels.0.blocks.1.dcn.output_proj.bias",
      "backbone.levels.0.blocks.1.norm2.0.weight",
      "backbone.levels.0.blocks.1.norm2.0.bias",
      "backbone.levels.0.blocks.1.mlp.fc1.bias",
      "backbone.levels.0.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.0
  },
  "layer_2_decay": {
    "param_names": [
      "backbone.levels.0.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.1.dcn.offset.weight",
      "backbone.levels.0.blocks.1.dcn.mask.weight",
      "backbone.levels.0.blocks.1.dcn.input_proj.weight",
      "backbone.levels.0.blocks.1.dcn.output_proj.weight",
      "backbone.levels.0.blocks.1.mlp.fc1.weight",
      "backbone.levels.0.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.09524856399210693,
    "lr": 1.9049712798421389e-06,
    "weight_decay": 0.05
  },
  "layer_3_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.gamma1",
      "backbone.levels.0.blocks.2.gamma2",
      "backbone.levels.0.blocks.2.norm1.0.weight",
      "backbone.levels.0.blocks.2.norm1.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.2.dcn.offset.bias",
      "backbone.levels.0.blocks.2.dcn.mask.bias",
      "backbone.levels.0.blocks.2.dcn.input_proj.bias",
      "backbone.levels.0.blocks.2.dcn.output_proj.bias",
      "backbone.levels.0.blocks.2.norm2.0.weight",
      "backbone.levels.0.blocks.2.norm2.0.bias",
      "backbone.levels.0.blocks.2.mlp.fc1.bias",
      "backbone.levels.0.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.0
  },
  "layer_3_decay": {
    "param_names": [
      "backbone.levels.0.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.2.dcn.offset.weight",
      "backbone.levels.0.blocks.2.dcn.mask.weight",
      "backbone.levels.0.blocks.2.dcn.input_proj.weight",
      "backbone.levels.0.blocks.2.dcn.output_proj.weight",
      "backbone.levels.0.blocks.2.mlp.fc1.weight",
      "backbone.levels.0.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.10132825956607122,
    "lr": 2.0265651913214247e-06,
    "weight_decay": 0.05
  },
  "layer_4_no_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.gamma1",
      "backbone.levels.0.blocks.3.gamma2",
      "backbone.levels.0.blocks.3.norm1.0.weight",
      "backbone.levels.0.blocks.3.norm1.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.0.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.0.blocks.3.dcn.offset.bias",
      "backbone.levels.0.blocks.3.dcn.mask.bias",
      "backbone.levels.0.blocks.3.dcn.input_proj.bias",
      "backbone.levels.0.blocks.3.dcn.output_proj.bias",
      "backbone.levels.0.blocks.3.norm2.0.weight",
      "backbone.levels.0.blocks.3.norm2.0.bias",
      "backbone.levels.0.blocks.3.mlp.fc1.bias",
      "backbone.levels.0.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.0
  },
  "layer_4_decay": {
    "param_names": [
      "backbone.levels.0.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.0.blocks.3.dcn.offset.weight",
      "backbone.levels.0.blocks.3.dcn.mask.weight",
      "backbone.levels.0.blocks.3.dcn.input_proj.weight",
      "backbone.levels.0.blocks.3.dcn.output_proj.weight",
      "backbone.levels.0.blocks.3.mlp.fc1.weight",
      "backbone.levels.0.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.10779602081496939,
    "lr": 2.155920416299388e-06,
    "weight_decay": 0.05
  },
  "layer_6_decay": {
    "param_names": [
      "backbone.levels.0.downsample.conv.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.0.dcn.offset.weight",
      "backbone.levels.1.blocks.0.dcn.mask.weight",
      "backbone.levels.1.blocks.0.dcn.input_proj.weight",
      "backbone.levels.1.blocks.0.dcn.output_proj.weight",
      "backbone.levels.1.blocks.0.mlp.fc1.weight",
      "backbone.levels.1.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.05
  },
  "layer_6_no_decay": {
    "param_names": [
      "backbone.levels.0.downsample.norm.1.weight",
      "backbone.levels.0.downsample.norm.1.bias",
      "backbone.levels.1.blocks.0.gamma1",
      "backbone.levels.1.blocks.0.gamma2",
      "backbone.levels.1.blocks.0.norm1.0.weight",
      "backbone.levels.1.blocks.0.norm1.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.0.dcn.offset.bias",
      "backbone.levels.1.blocks.0.dcn.mask.bias",
      "backbone.levels.1.blocks.0.dcn.input_proj.bias",
      "backbone.levels.1.blocks.0.dcn.output_proj.bias",
      "backbone.levels.1.blocks.0.norm2.0.weight",
      "backbone.levels.1.blocks.0.norm2.0.bias",
      "backbone.levels.1.blocks.0.mlp.fc1.bias",
      "backbone.levels.1.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.12199640200879289,
    "lr": 2.439928040175858e-06,
    "weight_decay": 0.0
  },
  "layer_7_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.gamma1",
      "backbone.levels.1.blocks.1.gamma2",
      "backbone.levels.1.blocks.1.norm1.0.weight",
      "backbone.levels.1.blocks.1.norm1.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.1.dcn.offset.bias",
      "backbone.levels.1.blocks.1.dcn.mask.bias",
      "backbone.levels.1.blocks.1.dcn.input_proj.bias",
      "backbone.levels.1.blocks.1.dcn.output_proj.bias",
      "backbone.levels.1.blocks.1.norm2.0.weight",
      "backbone.levels.1.blocks.1.norm2.0.bias",
      "backbone.levels.1.blocks.1.mlp.fc1.bias",
      "backbone.levels.1.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.0
  },
  "layer_7_decay": {
    "param_names": [
      "backbone.levels.1.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.1.dcn.offset.weight",
      "backbone.levels.1.blocks.1.dcn.mask.weight",
      "backbone.levels.1.blocks.1.dcn.input_proj.weight",
      "backbone.levels.1.blocks.1.dcn.output_proj.weight",
      "backbone.levels.1.blocks.1.mlp.fc1.weight",
      "backbone.levels.1.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.12978340639233288,
    "lr": 2.595668127846658e-06,
    "weight_decay": 0.05
  },
  "layer_8_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.gamma1",
      "backbone.levels.1.blocks.2.gamma2",
      "backbone.levels.1.blocks.2.norm1.0.weight",
      "backbone.levels.1.blocks.2.norm1.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.2.dcn.offset.bias",
      "backbone.levels.1.blocks.2.dcn.mask.bias",
      "backbone.levels.1.blocks.2.dcn.input_proj.bias",
      "backbone.levels.1.blocks.2.dcn.output_proj.bias",
      "backbone.levels.1.blocks.2.norm2.0.weight",
      "backbone.levels.1.blocks.2.norm2.0.bias",
      "backbone.levels.1.blocks.2.mlp.fc1.bias",
      "backbone.levels.1.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.0
  },
  "layer_8_decay": {
    "param_names": [
      "backbone.levels.1.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.2.dcn.offset.weight",
      "backbone.levels.1.blocks.2.dcn.mask.weight",
      "backbone.levels.1.blocks.2.dcn.input_proj.weight",
      "backbone.levels.1.blocks.2.dcn.output_proj.weight",
      "backbone.levels.1.blocks.2.mlp.fc1.weight",
      "backbone.levels.1.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.13806745360886477,
    "lr": 2.7613490721772957e-06,
    "weight_decay": 0.05
  },
  "layer_9_no_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.gamma1",
      "backbone.levels.1.blocks.3.gamma2",
      "backbone.levels.1.blocks.3.norm1.0.weight",
      "backbone.levels.1.blocks.3.norm1.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.1.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.1.blocks.3.dcn.offset.bias",
      "backbone.levels.1.blocks.3.dcn.mask.bias",
      "backbone.levels.1.blocks.3.dcn.input_proj.bias",
      "backbone.levels.1.blocks.3.dcn.output_proj.bias",
      "backbone.levels.1.blocks.3.norm2.0.weight",
      "backbone.levels.1.blocks.3.norm2.0.bias",
      "backbone.levels.1.blocks.3.mlp.fc1.bias",
      "backbone.levels.1.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.0
  },
  "layer_9_decay": {
    "param_names": [
      "backbone.levels.1.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.1.blocks.3.dcn.offset.weight",
      "backbone.levels.1.blocks.3.dcn.mask.weight",
      "backbone.levels.1.blocks.3.dcn.input_proj.weight",
      "backbone.levels.1.blocks.3.dcn.output_proj.weight",
      "backbone.levels.1.blocks.3.mlp.fc1.weight",
      "backbone.levels.1.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.14688026979666466,
    "lr": 2.9376053959332933e-06,
    "weight_decay": 0.05
  },
  "layer_11_decay": {
    "param_names": [
      "backbone.levels.1.downsample.conv.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.0.dcn.offset.weight",
      "backbone.levels.2.blocks.0.dcn.mask.weight",
      "backbone.levels.2.blocks.0.dcn.input_proj.weight",
      "backbone.levels.2.blocks.0.dcn.output_proj.weight",
      "backbone.levels.2.blocks.0.mlp.fc1.weight",
      "backbone.levels.2.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.05
  },
  "layer_11_no_decay": {
    "param_names": [
      "backbone.levels.1.downsample.norm.1.weight",
      "backbone.levels.1.downsample.norm.1.bias",
      "backbone.levels.2.blocks.0.gamma1",
      "backbone.levels.2.blocks.0.gamma2",
      "backbone.levels.2.blocks.0.norm1.0.weight",
      "backbone.levels.2.blocks.0.norm1.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.0.dcn.offset.bias",
      "backbone.levels.2.blocks.0.dcn.mask.bias",
      "backbone.levels.2.blocks.0.dcn.input_proj.bias",
      "backbone.levels.2.blocks.0.dcn.output_proj.bias",
      "backbone.levels.2.blocks.0.norm2.0.weight",
      "backbone.levels.2.blocks.0.norm2.0.bias",
      "backbone.levels.2.blocks.0.mlp.fc1.bias",
      "backbone.levels.2.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.16622936826240908,
    "lr": 3.324587365248182e-06,
    "weight_decay": 0.0
  },
  "layer_12_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.gamma1",
      "backbone.levels.2.blocks.1.gamma2",
      "backbone.levels.2.blocks.1.norm1.0.weight",
      "backbone.levels.2.blocks.1.norm1.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.1.dcn.offset.bias",
      "backbone.levels.2.blocks.1.dcn.mask.bias",
      "backbone.levels.2.blocks.1.dcn.input_proj.bias",
      "backbone.levels.2.blocks.1.dcn.output_proj.bias",
      "backbone.levels.2.blocks.1.norm2.0.weight",
      "backbone.levels.2.blocks.1.norm2.0.bias",
      "backbone.levels.2.blocks.1.mlp.fc1.bias",
      "backbone.levels.2.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.0
  },
  "layer_12_decay": {
    "param_names": [
      "backbone.levels.2.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.1.dcn.offset.weight",
      "backbone.levels.2.blocks.1.dcn.mask.weight",
      "backbone.levels.2.blocks.1.dcn.input_proj.weight",
      "backbone.levels.2.blocks.1.dcn.output_proj.weight",
      "backbone.levels.2.blocks.1.mlp.fc1.weight",
      "backbone.levels.2.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.17683975347064798,
    "lr": 3.53679506941296e-06,
    "weight_decay": 0.05
  },
  "layer_13_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.gamma1",
      "backbone.levels.2.blocks.2.gamma2",
      "backbone.levels.2.blocks.2.norm1.0.weight",
      "backbone.levels.2.blocks.2.norm1.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.2.dcn.offset.bias",
      "backbone.levels.2.blocks.2.dcn.mask.bias",
      "backbone.levels.2.blocks.2.dcn.input_proj.bias",
      "backbone.levels.2.blocks.2.dcn.output_proj.bias",
      "backbone.levels.2.blocks.2.norm2.0.weight",
      "backbone.levels.2.blocks.2.norm2.0.bias",
      "backbone.levels.2.blocks.2.mlp.fc1.bias",
      "backbone.levels.2.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.0
  },
  "layer_13_decay": {
    "param_names": [
      "backbone.levels.2.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.2.dcn.offset.weight",
      "backbone.levels.2.blocks.2.dcn.mask.weight",
      "backbone.levels.2.blocks.2.dcn.input_proj.weight",
      "backbone.levels.2.blocks.2.dcn.output_proj.weight",
      "backbone.levels.2.blocks.2.mlp.fc1.weight",
      "backbone.levels.2.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.18812739730919997,
    "lr": 3.7625479461839997e-06,
    "weight_decay": 0.05
  },
  "layer_14_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.gamma1",
      "backbone.levels.2.blocks.3.gamma2",
      "backbone.levels.2.blocks.3.norm1.0.weight",
      "backbone.levels.2.blocks.3.norm1.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.3.dcn.offset.bias",
      "backbone.levels.2.blocks.3.dcn.mask.bias",
      "backbone.levels.2.blocks.3.dcn.input_proj.bias",
      "backbone.levels.2.blocks.3.dcn.output_proj.bias",
      "backbone.levels.2.blocks.3.norm2.0.weight",
      "backbone.levels.2.blocks.3.norm2.0.bias",
      "backbone.levels.2.blocks.3.mlp.fc1.bias",
      "backbone.levels.2.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.0
  },
  "layer_14_decay": {
    "param_names": [
      "backbone.levels.2.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.3.dcn.offset.weight",
      "backbone.levels.2.blocks.3.dcn.mask.weight",
      "backbone.levels.2.blocks.3.dcn.input_proj.weight",
      "backbone.levels.2.blocks.3.dcn.output_proj.weight",
      "backbone.levels.2.blocks.3.mlp.fc1.weight",
      "backbone.levels.2.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.20013552905234042,
    "lr": 4.002710581046809e-06,
    "weight_decay": 0.05
  },
  "layer_15_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.gamma1",
      "backbone.levels.2.blocks.4.gamma2",
      "backbone.levels.2.blocks.4.norm1.0.weight",
      "backbone.levels.2.blocks.4.norm1.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.4.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.4.dcn.offset.bias",
      "backbone.levels.2.blocks.4.dcn.mask.bias",
      "backbone.levels.2.blocks.4.dcn.input_proj.bias",
      "backbone.levels.2.blocks.4.dcn.output_proj.bias",
      "backbone.levels.2.blocks.4.norm2.0.weight",
      "backbone.levels.2.blocks.4.norm2.0.bias",
      "backbone.levels.2.blocks.4.mlp.fc1.bias",
      "backbone.levels.2.blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.0
  },
  "layer_15_decay": {
    "param_names": [
      "backbone.levels.2.blocks.4.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.4.dcn.offset.weight",
      "backbone.levels.2.blocks.4.dcn.mask.weight",
      "backbone.levels.2.blocks.4.dcn.input_proj.weight",
      "backbone.levels.2.blocks.4.dcn.output_proj.weight",
      "backbone.levels.2.blocks.4.mlp.fc1.weight",
      "backbone.levels.2.blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.21291013728972386,
    "lr": 4.258202745794477e-06,
    "weight_decay": 0.05
  },
  "layer_16_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.gamma1",
      "backbone.levels.2.blocks.5.gamma2",
      "backbone.levels.2.blocks.5.norm1.0.weight",
      "backbone.levels.2.blocks.5.norm1.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.5.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.5.dcn.offset.bias",
      "backbone.levels.2.blocks.5.dcn.mask.bias",
      "backbone.levels.2.blocks.5.dcn.input_proj.bias",
      "backbone.levels.2.blocks.5.dcn.output_proj.bias",
      "backbone.levels.2.blocks.5.norm2.0.weight",
      "backbone.levels.2.blocks.5.norm2.0.bias",
      "backbone.levels.2.blocks.5.mlp.fc1.bias",
      "backbone.levels.2.blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.0
  },
  "layer_16_decay": {
    "param_names": [
      "backbone.levels.2.blocks.5.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.5.dcn.offset.weight",
      "backbone.levels.2.blocks.5.dcn.mask.weight",
      "backbone.levels.2.blocks.5.dcn.input_proj.weight",
      "backbone.levels.2.blocks.5.dcn.output_proj.weight",
      "backbone.levels.2.blocks.5.mlp.fc1.weight",
      "backbone.levels.2.blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.22650014605289773,
    "lr": 4.5300029210579546e-06,
    "weight_decay": 0.05
  },
  "layer_17_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.gamma1",
      "backbone.levels.2.blocks.6.gamma2",
      "backbone.levels.2.blocks.6.norm1.0.weight",
      "backbone.levels.2.blocks.6.norm1.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.6.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.6.dcn.offset.bias",
      "backbone.levels.2.blocks.6.dcn.mask.bias",
      "backbone.levels.2.blocks.6.dcn.input_proj.bias",
      "backbone.levels.2.blocks.6.dcn.output_proj.bias",
      "backbone.levels.2.blocks.6.norm2.0.weight",
      "backbone.levels.2.blocks.6.norm2.0.bias",
      "backbone.levels.2.blocks.6.mlp.fc1.bias",
      "backbone.levels.2.blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.0
  },
  "layer_17_decay": {
    "param_names": [
      "backbone.levels.2.blocks.6.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.6.dcn.offset.weight",
      "backbone.levels.2.blocks.6.dcn.mask.weight",
      "backbone.levels.2.blocks.6.dcn.input_proj.weight",
      "backbone.levels.2.blocks.6.dcn.output_proj.weight",
      "backbone.levels.2.blocks.6.mlp.fc1.weight",
      "backbone.levels.2.blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.24095760218393378,
    "lr": 4.819152043678676e-06,
    "weight_decay": 0.05
  },
  "layer_18_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.gamma1",
      "backbone.levels.2.blocks.7.gamma2",
      "backbone.levels.2.blocks.7.norm1.0.weight",
      "backbone.levels.2.blocks.7.norm1.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.7.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.7.dcn.offset.bias",
      "backbone.levels.2.blocks.7.dcn.mask.bias",
      "backbone.levels.2.blocks.7.dcn.input_proj.bias",
      "backbone.levels.2.blocks.7.dcn.output_proj.bias",
      "backbone.levels.2.blocks.7.norm2.0.weight",
      "backbone.levels.2.blocks.7.norm2.0.bias",
      "backbone.levels.2.blocks.7.mlp.fc1.bias",
      "backbone.levels.2.blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.0
  },
  "layer_18_decay": {
    "param_names": [
      "backbone.levels.2.blocks.7.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.7.dcn.offset.weight",
      "backbone.levels.2.blocks.7.dcn.mask.weight",
      "backbone.levels.2.blocks.7.dcn.input_proj.weight",
      "backbone.levels.2.blocks.7.dcn.output_proj.weight",
      "backbone.levels.2.blocks.7.mlp.fc1.weight",
      "backbone.levels.2.blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.25633787466375935,
    "lr": 5.126757493275187e-06,
    "weight_decay": 0.05
  },
  "layer_19_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.gamma1",
      "backbone.levels.2.blocks.8.gamma2",
      "backbone.levels.2.blocks.8.norm1.0.weight",
      "backbone.levels.2.blocks.8.norm1.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.8.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.8.dcn.offset.bias",
      "backbone.levels.2.blocks.8.dcn.mask.bias",
      "backbone.levels.2.blocks.8.dcn.input_proj.bias",
      "backbone.levels.2.blocks.8.dcn.output_proj.bias",
      "backbone.levels.2.blocks.8.norm2.0.weight",
      "backbone.levels.2.blocks.8.norm2.0.bias",
      "backbone.levels.2.blocks.8.mlp.fc1.bias",
      "backbone.levels.2.blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.0
  },
  "layer_19_decay": {
    "param_names": [
      "backbone.levels.2.blocks.8.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.8.dcn.offset.weight",
      "backbone.levels.2.blocks.8.dcn.mask.weight",
      "backbone.levels.2.blocks.8.dcn.input_proj.weight",
      "backbone.levels.2.blocks.8.dcn.output_proj.weight",
      "backbone.levels.2.blocks.8.mlp.fc1.weight",
      "backbone.levels.2.blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.27269986666357376,
    "lr": 5.453997333271476e-06,
    "weight_decay": 0.05
  },
  "layer_20_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.gamma1",
      "backbone.levels.2.blocks.9.gamma2",
      "backbone.levels.2.blocks.9.norm1.0.weight",
      "backbone.levels.2.blocks.9.norm1.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.9.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.9.dcn.offset.bias",
      "backbone.levels.2.blocks.9.dcn.mask.bias",
      "backbone.levels.2.blocks.9.dcn.input_proj.bias",
      "backbone.levels.2.blocks.9.dcn.output_proj.bias",
      "backbone.levels.2.blocks.9.norm2.0.weight",
      "backbone.levels.2.blocks.9.norm2.0.bias",
      "backbone.levels.2.blocks.9.mlp.fc1.bias",
      "backbone.levels.2.blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.0
  },
  "layer_20_decay": {
    "param_names": [
      "backbone.levels.2.blocks.9.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.9.dcn.offset.weight",
      "backbone.levels.2.blocks.9.dcn.mask.weight",
      "backbone.levels.2.blocks.9.dcn.input_proj.weight",
      "backbone.levels.2.blocks.9.dcn.output_proj.weight",
      "backbone.levels.2.blocks.9.mlp.fc1.weight",
      "backbone.levels.2.blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.2901062411314615,
    "lr": 5.802124822629231e-06,
    "weight_decay": 0.05
  },
  "layer_21_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.gamma1",
      "backbone.levels.2.blocks.10.gamma2",
      "backbone.levels.2.blocks.10.norm1.0.weight",
      "backbone.levels.2.blocks.10.norm1.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.10.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.10.dcn.offset.bias",
      "backbone.levels.2.blocks.10.dcn.mask.bias",
      "backbone.levels.2.blocks.10.dcn.input_proj.bias",
      "backbone.levels.2.blocks.10.dcn.output_proj.bias",
      "backbone.levels.2.blocks.10.norm2.0.weight",
      "backbone.levels.2.blocks.10.norm2.0.bias",
      "backbone.levels.2.blocks.10.mlp.fc1.bias",
      "backbone.levels.2.blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.0
  },
  "layer_21_decay": {
    "param_names": [
      "backbone.levels.2.blocks.10.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.10.dcn.offset.weight",
      "backbone.levels.2.blocks.10.dcn.mask.weight",
      "backbone.levels.2.blocks.10.dcn.input_proj.weight",
      "backbone.levels.2.blocks.10.dcn.output_proj.weight",
      "backbone.levels.2.blocks.10.mlp.fc1.weight",
      "backbone.levels.2.blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.30862366077815057,
    "lr": 6.1724732155630115e-06,
    "weight_decay": 0.05
  },
  "layer_22_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.gamma1",
      "backbone.levels.2.blocks.11.gamma2",
      "backbone.levels.2.blocks.11.norm1.0.weight",
      "backbone.levels.2.blocks.11.norm1.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.11.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.11.dcn.offset.bias",
      "backbone.levels.2.blocks.11.dcn.mask.bias",
      "backbone.levels.2.blocks.11.dcn.input_proj.bias",
      "backbone.levels.2.blocks.11.dcn.output_proj.bias",
      "backbone.levels.2.blocks.11.norm2.0.weight",
      "backbone.levels.2.blocks.11.norm2.0.bias",
      "backbone.levels.2.blocks.11.mlp.fc1.bias",
      "backbone.levels.2.blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.0
  },
  "layer_22_decay": {
    "param_names": [
      "backbone.levels.2.blocks.11.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.11.dcn.offset.weight",
      "backbone.levels.2.blocks.11.dcn.mask.weight",
      "backbone.levels.2.blocks.11.dcn.input_proj.weight",
      "backbone.levels.2.blocks.11.dcn.output_proj.weight",
      "backbone.levels.2.blocks.11.mlp.fc1.weight",
      "backbone.levels.2.blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.32832304338101126,
    "lr": 6.566460867620226e-06,
    "weight_decay": 0.05
  },
  "layer_23_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.gamma1",
      "backbone.levels.2.blocks.12.gamma2",
      "backbone.levels.2.blocks.12.norm1.0.weight",
      "backbone.levels.2.blocks.12.norm1.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.12.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.12.dcn.offset.bias",
      "backbone.levels.2.blocks.12.dcn.mask.bias",
      "backbone.levels.2.blocks.12.dcn.input_proj.bias",
      "backbone.levels.2.blocks.12.dcn.output_proj.bias",
      "backbone.levels.2.blocks.12.norm2.0.weight",
      "backbone.levels.2.blocks.12.norm2.0.bias",
      "backbone.levels.2.blocks.12.mlp.fc1.bias",
      "backbone.levels.2.blocks.12.mlp.fc2.bias"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.0
  },
  "layer_23_decay": {
    "param_names": [
      "backbone.levels.2.blocks.12.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.12.dcn.offset.weight",
      "backbone.levels.2.blocks.12.dcn.mask.weight",
      "backbone.levels.2.blocks.12.dcn.input_proj.weight",
      "backbone.levels.2.blocks.12.dcn.output_proj.weight",
      "backbone.levels.2.blocks.12.mlp.fc1.weight",
      "backbone.levels.2.blocks.12.mlp.fc2.weight"
    ],
    "lr_scale": 0.34927983338405455,
    "lr": 6.985596667681092e-06,
    "weight_decay": 0.05
  },
  "layer_24_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.gamma1",
      "backbone.levels.2.blocks.13.gamma2",
      "backbone.levels.2.blocks.13.norm1.0.weight",
      "backbone.levels.2.blocks.13.norm1.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.13.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.13.dcn.offset.bias",
      "backbone.levels.2.blocks.13.dcn.mask.bias",
      "backbone.levels.2.blocks.13.dcn.input_proj.bias",
      "backbone.levels.2.blocks.13.dcn.output_proj.bias",
      "backbone.levels.2.blocks.13.norm2.0.weight",
      "backbone.levels.2.blocks.13.norm2.0.bias",
      "backbone.levels.2.blocks.13.mlp.fc1.bias",
      "backbone.levels.2.blocks.13.mlp.fc2.bias"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.0
  },
  "layer_24_decay": {
    "param_names": [
      "backbone.levels.2.blocks.13.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.13.dcn.offset.weight",
      "backbone.levels.2.blocks.13.dcn.mask.weight",
      "backbone.levels.2.blocks.13.dcn.input_proj.weight",
      "backbone.levels.2.blocks.13.dcn.output_proj.weight",
      "backbone.levels.2.blocks.13.mlp.fc1.weight",
      "backbone.levels.2.blocks.13.mlp.fc2.weight"
    ],
    "lr_scale": 0.3715742908341006,
    "lr": 7.4314858166820124e-06,
    "weight_decay": 0.05
  },
  "layer_25_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.gamma1",
      "backbone.levels.2.blocks.14.gamma2",
      "backbone.levels.2.blocks.14.norm1.0.weight",
      "backbone.levels.2.blocks.14.norm1.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.14.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.14.dcn.offset.bias",
      "backbone.levels.2.blocks.14.dcn.mask.bias",
      "backbone.levels.2.blocks.14.dcn.input_proj.bias",
      "backbone.levels.2.blocks.14.dcn.output_proj.bias",
      "backbone.levels.2.blocks.14.norm2.0.weight",
      "backbone.levels.2.blocks.14.norm2.0.bias",
      "backbone.levels.2.blocks.14.mlp.fc1.bias",
      "backbone.levels.2.blocks.14.mlp.fc2.bias"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.0
  },
  "layer_25_decay": {
    "param_names": [
      "backbone.levels.2.blocks.14.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.14.dcn.offset.weight",
      "backbone.levels.2.blocks.14.dcn.mask.weight",
      "backbone.levels.2.blocks.14.dcn.input_proj.weight",
      "backbone.levels.2.blocks.14.dcn.output_proj.weight",
      "backbone.levels.2.blocks.14.mlp.fc1.weight",
      "backbone.levels.2.blocks.14.mlp.fc2.weight"
    ],
    "lr_scale": 0.3952917987596815,
    "lr": 7.90583597519363e-06,
    "weight_decay": 0.05
  },
  "layer_26_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.gamma1",
      "backbone.levels.2.blocks.15.gamma2",
      "backbone.levels.2.blocks.15.norm1.0.weight",
      "backbone.levels.2.blocks.15.norm1.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.15.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.15.dcn.offset.bias",
      "backbone.levels.2.blocks.15.dcn.mask.bias",
      "backbone.levels.2.blocks.15.dcn.input_proj.bias",
      "backbone.levels.2.blocks.15.dcn.output_proj.bias",
      "backbone.levels.2.blocks.15.norm2.0.weight",
      "backbone.levels.2.blocks.15.norm2.0.bias",
      "backbone.levels.2.blocks.15.mlp.fc1.bias",
      "backbone.levels.2.blocks.15.mlp.fc2.bias"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.0
  },
  "layer_26_decay": {
    "param_names": [
      "backbone.levels.2.blocks.15.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.15.dcn.offset.weight",
      "backbone.levels.2.blocks.15.dcn.mask.weight",
      "backbone.levels.2.blocks.15.dcn.input_proj.weight",
      "backbone.levels.2.blocks.15.dcn.output_proj.weight",
      "backbone.levels.2.blocks.15.mlp.fc1.weight",
      "backbone.levels.2.blocks.15.mlp.fc2.weight"
    ],
    "lr_scale": 0.42052319016987394,
    "lr": 8.41046380339748e-06,
    "weight_decay": 0.05
  },
  "layer_27_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.gamma1",
      "backbone.levels.2.blocks.16.gamma2",
      "backbone.levels.2.blocks.16.norm1.0.weight",
      "backbone.levels.2.blocks.16.norm1.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.16.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.16.dcn.offset.bias",
      "backbone.levels.2.blocks.16.dcn.mask.bias",
      "backbone.levels.2.blocks.16.dcn.input_proj.bias",
      "backbone.levels.2.blocks.16.dcn.output_proj.bias",
      "backbone.levels.2.blocks.16.norm2.0.weight",
      "backbone.levels.2.blocks.16.norm2.0.bias",
      "backbone.levels.2.blocks.16.mlp.fc1.bias",
      "backbone.levels.2.blocks.16.mlp.fc2.bias"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.0
  },
  "layer_27_decay": {
    "param_names": [
      "backbone.levels.2.blocks.16.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.16.dcn.offset.weight",
      "backbone.levels.2.blocks.16.dcn.mask.weight",
      "backbone.levels.2.blocks.16.dcn.input_proj.weight",
      "backbone.levels.2.blocks.16.dcn.output_proj.weight",
      "backbone.levels.2.blocks.16.mlp.fc1.weight",
      "backbone.levels.2.blocks.16.mlp.fc2.weight"
    ],
    "lr_scale": 0.44736509592539786,
    "lr": 8.947301918507958e-06,
    "weight_decay": 0.05
  },
  "layer_28_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.gamma1",
      "backbone.levels.2.blocks.17.gamma2",
      "backbone.levels.2.blocks.17.norm1.0.weight",
      "backbone.levels.2.blocks.17.norm1.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.17.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.17.dcn.offset.bias",
      "backbone.levels.2.blocks.17.dcn.mask.bias",
      "backbone.levels.2.blocks.17.dcn.input_proj.bias",
      "backbone.levels.2.blocks.17.dcn.output_proj.bias",
      "backbone.levels.2.blocks.17.norm2.0.weight",
      "backbone.levels.2.blocks.17.norm2.0.bias",
      "backbone.levels.2.blocks.17.mlp.fc1.bias",
      "backbone.levels.2.blocks.17.mlp.fc2.bias"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.0
  },
  "layer_28_decay": {
    "param_names": [
      "backbone.levels.2.blocks.17.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.17.dcn.offset.weight",
      "backbone.levels.2.blocks.17.dcn.mask.weight",
      "backbone.levels.2.blocks.17.dcn.input_proj.weight",
      "backbone.levels.2.blocks.17.dcn.output_proj.weight",
      "backbone.levels.2.blocks.17.mlp.fc1.weight",
      "backbone.levels.2.blocks.17.mlp.fc2.weight"
    ],
    "lr_scale": 0.47592031481425306,
    "lr": 9.518406296285062e-06,
    "weight_decay": 0.05
  },
  "layer_29_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.gamma1",
      "backbone.levels.2.blocks.18.gamma2",
      "backbone.levels.2.blocks.18.norm1.0.weight",
      "backbone.levels.2.blocks.18.norm1.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.18.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.18.dcn.offset.bias",
      "backbone.levels.2.blocks.18.dcn.mask.bias",
      "backbone.levels.2.blocks.18.dcn.input_proj.bias",
      "backbone.levels.2.blocks.18.dcn.output_proj.bias",
      "backbone.levels.2.blocks.18.norm2.0.weight",
      "backbone.levels.2.blocks.18.norm2.0.bias",
      "backbone.levels.2.blocks.18.mlp.fc1.bias",
      "backbone.levels.2.blocks.18.mlp.fc2.bias"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.0
  },
  "layer_29_decay": {
    "param_names": [
      "backbone.levels.2.blocks.18.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.18.dcn.offset.weight",
      "backbone.levels.2.blocks.18.dcn.mask.weight",
      "backbone.levels.2.blocks.18.dcn.input_proj.weight",
      "backbone.levels.2.blocks.18.dcn.output_proj.weight",
      "backbone.levels.2.blocks.18.mlp.fc1.weight",
      "backbone.levels.2.blocks.18.mlp.fc2.weight"
    ],
    "lr_scale": 0.5062982072492054,
    "lr": 1.0125964144984108e-05,
    "weight_decay": 0.05
  },
  "layer_30_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.gamma1",
      "backbone.levels.2.blocks.19.gamma2",
      "backbone.levels.2.blocks.19.norm1.0.weight",
      "backbone.levels.2.blocks.19.norm1.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.19.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.19.dcn.offset.bias",
      "backbone.levels.2.blocks.19.dcn.mask.bias",
      "backbone.levels.2.blocks.19.dcn.input_proj.bias",
      "backbone.levels.2.blocks.19.dcn.output_proj.bias",
      "backbone.levels.2.blocks.19.norm2.0.weight",
      "backbone.levels.2.blocks.19.norm2.0.bias",
      "backbone.levels.2.blocks.19.mlp.fc1.bias",
      "backbone.levels.2.blocks.19.mlp.fc2.bias"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.0
  },
  "layer_30_decay": {
    "param_names": [
      "backbone.levels.2.blocks.19.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.19.dcn.offset.weight",
      "backbone.levels.2.blocks.19.dcn.mask.weight",
      "backbone.levels.2.blocks.19.dcn.input_proj.weight",
      "backbone.levels.2.blocks.19.dcn.output_proj.weight",
      "backbone.levels.2.blocks.19.mlp.fc1.weight",
      "backbone.levels.2.blocks.19.mlp.fc2.weight"
    ],
    "lr_scale": 0.5386151140948994,
    "lr": 1.0772302281897988e-05,
    "weight_decay": 0.05
  },
  "layer_31_no_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.gamma1",
      "backbone.levels.2.blocks.20.gamma2",
      "backbone.levels.2.blocks.20.norm1.0.weight",
      "backbone.levels.2.blocks.20.norm1.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.bias",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.weight",
      "backbone.levels.2.blocks.20.dcn.dw_conv.1.1.bias",
      "backbone.levels.2.blocks.20.dcn.offset.bias",
      "backbone.levels.2.blocks.20.dcn.mask.bias",
      "backbone.levels.2.blocks.20.dcn.input_proj.bias",
      "backbone.levels.2.blocks.20.dcn.output_proj.bias",
      "backbone.levels.2.blocks.20.norm2.0.weight",
      "backbone.levels.2.blocks.20.norm2.0.bias",
      "backbone.levels.2.blocks.20.mlp.fc1.bias",
      "backbone.levels.2.blocks.20.mlp.fc2.bias"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.0
  },
  "layer_31_decay": {
    "param_names": [
      "backbone.levels.2.blocks.20.dcn.dw_conv.0.weight",
      "backbone.levels.2.blocks.20.dcn.offset.weight",
      "backbone.levels.2.blocks.20.dcn.mask.weight",
      "backbone.levels.2.blocks.20.dcn.input_proj.weight",
      "backbone.levels.2.blocks.20.dcn.output_proj.weight",
      "backbone.levels.2.blocks.20.mlp.fc1.weight",
      "backbone.levels.2.blocks.20.mlp.fc2.weight"
    ],
    "lr_scale": 0.5729948022286164,
    "lr": 1.145989604457233e-05,
    "weight_decay": 0.05
  },
  "layer_35_decay": {
    "param_names": [
      "backbone.levels.2.downsample.conv.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.0.dcn.offset.weight",
      "backbone.levels.3.blocks.0.dcn.mask.weight",
      "backbone.levels.3.blocks.0.dcn.input_proj.weight",
      "backbone.levels.3.blocks.0.dcn.output_proj.weight",
      "backbone.levels.3.blocks.0.mlp.fc1.weight",
      "backbone.levels.3.blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.05
  },
  "layer_35_no_decay": {
    "param_names": [
      "backbone.levels.2.downsample.norm.1.weight",
      "backbone.levels.2.downsample.norm.1.bias",
      "backbone.levels.3.blocks.0.gamma1",
      "backbone.levels.3.blocks.0.gamma2",
      "backbone.levels.3.blocks.0.norm1.0.weight",
      "backbone.levels.3.blocks.0.norm1.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.0.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.0.dcn.offset.bias",
      "backbone.levels.3.blocks.0.dcn.mask.bias",
      "backbone.levels.3.blocks.0.dcn.input_proj.bias",
      "backbone.levels.3.blocks.0.dcn.output_proj.bias",
      "backbone.levels.3.blocks.0.norm2.0.weight",
      "backbone.levels.3.blocks.0.norm2.0.bias",
      "backbone.levels.3.blocks.0.mlp.fc1.bias",
      "backbone.levels.3.blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.7339040223999997,
    "lr": 1.4678080447999996e-05,
    "weight_decay": 0.0
  },
  "layer_36_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.gamma1",
      "backbone.levels.3.blocks.1.gamma2",
      "backbone.levels.3.blocks.1.norm1.0.weight",
      "backbone.levels.3.blocks.1.norm1.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.1.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.1.dcn.offset.bias",
      "backbone.levels.3.blocks.1.dcn.mask.bias",
      "backbone.levels.3.blocks.1.dcn.input_proj.bias",
      "backbone.levels.3.blocks.1.dcn.output_proj.bias",
      "backbone.levels.3.blocks.1.norm2.0.weight",
      "backbone.levels.3.blocks.1.norm2.0.bias",
      "backbone.levels.3.blocks.1.mlp.fc1.bias",
      "backbone.levels.3.blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.0
  },
  "layer_36_decay": {
    "param_names": [
      "backbone.levels.3.blocks.1.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.1.dcn.offset.weight",
      "backbone.levels.3.blocks.1.dcn.mask.weight",
      "backbone.levels.3.blocks.1.dcn.input_proj.weight",
      "backbone.levels.3.blocks.1.dcn.output_proj.weight",
      "backbone.levels.3.blocks.1.mlp.fc1.weight",
      "backbone.levels.3.blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.7807489599999998,
    "lr": 1.5614979199999998e-05,
    "weight_decay": 0.05
  },
  "layer_37_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.gamma1",
      "backbone.levels.3.blocks.2.gamma2",
      "backbone.levels.3.blocks.2.norm1.0.weight",
      "backbone.levels.3.blocks.2.norm1.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.2.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.2.dcn.offset.bias",
      "backbone.levels.3.blocks.2.dcn.mask.bias",
      "backbone.levels.3.blocks.2.dcn.input_proj.bias",
      "backbone.levels.3.blocks.2.dcn.output_proj.bias",
      "backbone.levels.3.blocks.2.norm2.0.weight",
      "backbone.levels.3.blocks.2.norm2.0.bias",
      "backbone.levels.3.blocks.2.mlp.fc1.bias",
      "backbone.levels.3.blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.0
  },
  "layer_37_decay": {
    "param_names": [
      "backbone.levels.3.blocks.2.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.2.dcn.offset.weight",
      "backbone.levels.3.blocks.2.dcn.mask.weight",
      "backbone.levels.3.blocks.2.dcn.input_proj.weight",
      "backbone.levels.3.blocks.2.dcn.output_proj.weight",
      "backbone.levels.3.blocks.2.mlp.fc1.weight",
      "backbone.levels.3.blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.8305839999999999,
    "lr": 1.6611679999999997e-05,
    "weight_decay": 0.05
  },
  "layer_38_no_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.gamma1",
      "backbone.levels.3.blocks.3.gamma2",
      "backbone.levels.3.blocks.3.norm1.0.weight",
      "backbone.levels.3.blocks.3.norm1.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.bias",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.weight",
      "backbone.levels.3.blocks.3.dcn.dw_conv.1.1.bias",
      "backbone.levels.3.blocks.3.dcn.offset.bias",
      "backbone.levels.3.blocks.3.dcn.mask.bias",
      "backbone.levels.3.blocks.3.dcn.input_proj.bias",
      "backbone.levels.3.blocks.3.dcn.output_proj.bias",
      "backbone.levels.3.blocks.3.norm2.0.weight",
      "backbone.levels.3.blocks.3.norm2.0.bias",
      "backbone.levels.3.blocks.3.mlp.fc1.bias",
      "backbone.levels.3.blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.0
  },
  "layer_38_decay": {
    "param_names": [
      "backbone.levels.3.blocks.3.dcn.dw_conv.0.weight",
      "backbone.levels.3.blocks.3.dcn.offset.weight",
      "backbone.levels.3.blocks.3.dcn.mask.weight",
      "backbone.levels.3.blocks.3.dcn.input_proj.weight",
      "backbone.levels.3.blocks.3.dcn.output_proj.weight",
      "backbone.levels.3.blocks.3.mlp.fc1.weight",
      "backbone.levels.3.blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.8835999999999999,
    "lr": 1.7672e-05,
    "weight_decay": 0.05
  },
  "layer_40_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.weight",
      "decode_head.pixel_decoder.input_convs.1.conv.weight",
      "decode_head.pixel_decoder.input_convs.2.conv.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.pixel_decoder.level_encoding.weight",
      "decode_head.pixel_decoder.lateral_convs.0.conv.weight",
      "decode_head.pixel_decoder.output_convs.0.conv.weight",
      "decode_head.pixel_decoder.mask_feature.weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.05
  },
  "layer_40_no_decay": {
    "param_names": [
      "decode_head.pixel_decoder.input_convs.0.conv.bias",
      "decode_head.pixel_decoder.input_convs.0.gn.weight",
      "decode_head.pixel_decoder.input_convs.0.gn.bias",
      "decode_head.pixel_decoder.input_convs.1.conv.bias",
      "decode_head.pixel_decoder.input_convs.1.gn.weight",
      "decode_head.pixel_decoder.input_convs.1.gn.bias",
      "decode_head.pixel_decoder.input_convs.2.conv.bias",
      "decode_head.pixel_decoder.input_convs.2.gn.weight",
      "decode_head.pixel_decoder.input_convs.2.gn.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.0.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.1.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.2.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.3.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.4.norms.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.0.bias",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.weight",
      "decode_head.pixel_decoder.encoder.layers.5.norms.1.bias",
      "decode_head.pixel_decoder.lateral_convs.0.gn.weight",
      "decode_head.pixel_decoder.lateral_convs.0.gn.bias",
      "decode_head.pixel_decoder.output_convs.0.gn.weight",
      "decode_head.pixel_decoder.output_convs.0.gn.bias",
      "decode_head.pixel_decoder.mask_feature.bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.0.weight",
      "decode_head.transformer_decoder.layers.0.norms.0.bias",
      "decode_head.transformer_decoder.layers.0.norms.1.weight",
      "decode_head.transformer_decoder.layers.0.norms.1.bias",
      "decode_head.transformer_decoder.layers.0.norms.2.weight",
      "decode_head.transformer_decoder.layers.0.norms.2.bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.0.weight",
      "decode_head.transformer_decoder.layers.1.norms.0.bias",
      "decode_head.transformer_decoder.layers.1.norms.1.weight",
      "decode_head.transformer_decoder.layers.1.norms.1.bias",
      "decode_head.transformer_decoder.layers.1.norms.2.weight",
      "decode_head.transformer_decoder.layers.1.norms.2.bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.0.weight",
      "decode_head.transformer_decoder.layers.2.norms.0.bias",
      "decode_head.transformer_decoder.layers.2.norms.1.weight",
      "decode_head.transformer_decoder.layers.2.norms.1.bias",
      "decode_head.transformer_decoder.layers.2.norms.2.weight",
      "decode_head.transformer_decoder.layers.2.norms.2.bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.0.weight",
      "decode_head.transformer_decoder.layers.3.norms.0.bias",
      "decode_head.transformer_decoder.layers.3.norms.1.weight",
      "decode_head.transformer_decoder.layers.3.norms.1.bias",
      "decode_head.transformer_decoder.layers.3.norms.2.weight",
      "decode_head.transformer_decoder.layers.3.norms.2.bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.0.weight",
      "decode_head.transformer_decoder.layers.4.norms.0.bias",
      "decode_head.transformer_decoder.layers.4.norms.1.weight",
      "decode_head.transformer_decoder.layers.4.norms.1.bias",
      "decode_head.transformer_decoder.layers.4.norms.2.weight",
      "decode_head.transformer_decoder.layers.4.norms.2.bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.0.weight",
      "decode_head.transformer_decoder.layers.5.norms.0.bias",
      "decode_head.transformer_decoder.layers.5.norms.1.weight",
      "decode_head.transformer_decoder.layers.5.norms.1.bias",
      "decode_head.transformer_decoder.layers.5.norms.2.weight",
      "decode_head.transformer_decoder.layers.5.norms.2.bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.0.weight",
      "decode_head.transformer_decoder.layers.6.norms.0.bias",
      "decode_head.transformer_decoder.layers.6.norms.1.weight",
      "decode_head.transformer_decoder.layers.6.norms.1.bias",
      "decode_head.transformer_decoder.layers.6.norms.2.weight",
      "decode_head.transformer_decoder.layers.6.norms.2.bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.0.weight",
      "decode_head.transformer_decoder.layers.7.norms.0.bias",
      "decode_head.transformer_decoder.layers.7.norms.1.weight",
      "decode_head.transformer_decoder.layers.7.norms.1.bias",
      "decode_head.transformer_decoder.layers.7.norms.2.weight",
      "decode_head.transformer_decoder.layers.7.norms.2.bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias",
      "decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias",
      "decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.0.weight",
      "decode_head.transformer_decoder.layers.8.norms.0.bias",
      "decode_head.transformer_decoder.layers.8.norms.1.weight",
      "decode_head.transformer_decoder.layers.8.norms.1.bias",
      "decode_head.transformer_decoder.layers.8.norms.2.weight",
      "decode_head.transformer_decoder.layers.8.norms.2.bias",
      "decode_head.transformer_decoder.post_norm.weight",
      "decode_head.transformer_decoder.post_norm.bias"
    ],
    "lr_scale": 1.0,
    "lr": 2e-05,
    "weight_decay": 0.0
  }
}
2023-08-29 09:54:45,148 - mmseg - INFO - Loaded 6861 images
2023-08-29 09:54:45,178 - mmseg - INFO - Start running, host: nemodrive@nemodrive0, work_dir: /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti
2023-08-29 09:54:45,178 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-08-29 09:54:45,178 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-08-29 09:54:45,178 - mmseg - INFO - Checkpoints will be saved to /home/nemodrive/workspace/andreim/InternImage/segmentation/work_dirs/mask2former_internimage_b_kitti by HardDiskBackend.
2023-08-29 09:55:19,357 - mmseg - INFO - Iter [50/160000]	lr: 5.497e-08, eta: 1 day, 6:21:40, time: 0.683, data_time: 0.007, memory: 6584, decode.loss_cls: 1.3769, decode.loss_mask: 3.6381, decode.loss_dice: 2.9524, decode.d0.loss_cls: 2.1767, decode.d0.loss_mask: 2.7009, decode.d0.loss_dice: 2.8536, decode.d1.loss_cls: 2.4026, decode.d1.loss_mask: 2.6500, decode.d1.loss_dice: 2.7513, decode.d2.loss_cls: 2.3675, decode.d2.loss_mask: 3.1095, decode.d2.loss_dice: 3.0243, decode.d3.loss_cls: 2.0865, decode.d3.loss_mask: 3.2562, decode.d3.loss_dice: 3.0330, decode.d4.loss_cls: 2.3685, decode.d4.loss_mask: 3.2661, decode.d4.loss_dice: 3.0378, decode.d5.loss_cls: 1.4726, decode.d5.loss_mask: 3.3991, decode.d5.loss_dice: 3.1128, decode.d6.loss_cls: 1.8832, decode.d6.loss_mask: 3.6191, decode.d6.loss_dice: 2.9333, decode.d7.loss_cls: 1.5181, decode.d7.loss_mask: 3.4841, decode.d7.loss_dice: 3.0828, decode.d8.loss_cls: 1.6987, decode.d8.loss_mask: 3.5293, decode.d8.loss_dice: 3.1271, loss: 81.9123, grad_norm: 241.6118
2023-08-29 09:55:54,780 - mmseg - INFO - Iter [100/160000]	lr: 1.110e-07, eta: 1 day, 6:54:37, time: 0.708, data_time: 0.046, memory: 6584, decode.loss_cls: 1.1827, decode.loss_mask: 3.6042, decode.loss_dice: 2.9755, decode.d0.loss_cls: 2.1847, decode.d0.loss_mask: 2.4432, decode.d0.loss_dice: 2.6896, decode.d1.loss_cls: 1.9727, decode.d1.loss_mask: 2.4921, decode.d1.loss_dice: 2.6696, decode.d2.loss_cls: 1.8219, decode.d2.loss_mask: 2.6281, decode.d2.loss_dice: 2.7754, decode.d3.loss_cls: 1.4509, decode.d3.loss_mask: 2.8567, decode.d3.loss_dice: 2.8290, decode.d4.loss_cls: 1.5845, decode.d4.loss_mask: 2.9749, decode.d4.loss_dice: 2.8910, decode.d5.loss_cls: 1.2052, decode.d5.loss_mask: 3.2865, decode.d5.loss_dice: 2.9923, decode.d6.loss_cls: 1.3204, decode.d6.loss_mask: 3.5139, decode.d6.loss_dice: 2.9008, decode.d7.loss_cls: 1.2012, decode.d7.loss_mask: 3.4507, decode.d7.loss_dice: 3.0232, decode.d8.loss_cls: 1.2918, decode.d8.loss_mask: 3.5441, decode.d8.loss_dice: 3.0190, loss: 74.7757, grad_norm: 188.5387
2023-08-29 09:56:30,591 - mmseg - INFO - Iter [150/160000]	lr: 1.670e-07, eta: 1 day, 7:12:04, time: 0.716, data_time: 0.046, memory: 6584, decode.loss_cls: 1.1438, decode.loss_mask: 3.4676, decode.loss_dice: 2.9977, decode.d0.loss_cls: 2.1110, decode.d0.loss_mask: 1.9337, decode.d0.loss_dice: 2.5318, decode.d1.loss_cls: 1.4370, decode.d1.loss_mask: 1.8092, decode.d1.loss_dice: 2.5398, decode.d2.loss_cls: 1.3130, decode.d2.loss_mask: 1.6170, decode.d2.loss_dice: 2.4896, decode.d3.loss_cls: 1.1449, decode.d3.loss_mask: 1.7450, decode.d3.loss_dice: 2.5314, decode.d4.loss_cls: 1.2269, decode.d4.loss_mask: 1.8892, decode.d4.loss_dice: 2.5862, decode.d5.loss_cls: 1.1312, decode.d5.loss_mask: 2.7182, decode.d5.loss_dice: 2.8271, decode.d6.loss_cls: 1.1439, decode.d6.loss_mask: 2.9567, decode.d6.loss_dice: 2.9052, decode.d7.loss_cls: 1.1466, decode.d7.loss_mask: 3.1546, decode.d7.loss_dice: 2.9330, decode.d8.loss_cls: 1.1567, decode.d8.loss_mask: 3.3388, decode.d8.loss_dice: 2.9486, loss: 64.8752, grad_norm: 168.5430
2023-08-29 09:57:06,611 - mmseg - INFO - Iter [200/160000]	lr: 2.230e-07, eta: 1 day, 7:23:16, time: 0.720, data_time: 0.047, memory: 6584, decode.loss_cls: 1.1166, decode.loss_mask: 2.5809, decode.loss_dice: 2.7234, decode.d0.loss_cls: 2.1042, decode.d0.loss_mask: 1.3940, decode.d0.loss_dice: 2.3479, decode.d1.loss_cls: 1.1343, decode.d1.loss_mask: 1.2880, decode.d1.loss_dice: 2.3648, decode.d2.loss_cls: 1.0685, decode.d2.loss_mask: 1.2128, decode.d2.loss_dice: 2.2968, decode.d3.loss_cls: 0.9975, decode.d3.loss_mask: 1.2557, decode.d3.loss_dice: 2.2994, decode.d4.loss_cls: 1.0524, decode.d4.loss_mask: 1.2155, decode.d4.loss_dice: 2.2908, decode.d5.loss_cls: 1.0198, decode.d5.loss_mask: 1.4180, decode.d5.loss_dice: 2.3689, decode.d6.loss_cls: 1.0350, decode.d6.loss_mask: 1.4395, decode.d6.loss_dice: 2.4634, decode.d7.loss_cls: 1.0904, decode.d7.loss_mask: 1.9049, decode.d7.loss_dice: 2.5135, decode.d8.loss_cls: 1.1078, decode.d8.loss_mask: 2.1561, decode.d8.loss_dice: 2.6375, loss: 51.8985, grad_norm: 165.4258
2023-08-29 09:57:40,524 - mmseg - INFO - Iter [250/160000]	lr: 2.790e-07, eta: 1 day, 7:07:17, time: 0.678, data_time: 0.004, memory: 6584, decode.loss_cls: 0.9808, decode.loss_mask: 1.5191, decode.loss_dice: 2.2277, decode.d0.loss_cls: 2.1034, decode.d0.loss_mask: 1.4758, decode.d0.loss_dice: 2.1859, decode.d1.loss_cls: 0.9018, decode.d1.loss_mask: 1.5131, decode.d1.loss_dice: 2.2165, decode.d2.loss_cls: 0.8713, decode.d2.loss_mask: 1.4204, decode.d2.loss_dice: 2.1590, decode.d3.loss_cls: 0.7332, decode.d3.loss_mask: 1.5248, decode.d3.loss_dice: 2.1523, decode.d4.loss_cls: 0.7449, decode.d4.loss_mask: 1.5409, decode.d4.loss_dice: 2.1281, decode.d5.loss_cls: 0.7086, decode.d5.loss_mask: 1.5715, decode.d5.loss_dice: 2.1707, decode.d6.loss_cls: 0.7353, decode.d6.loss_mask: 1.5516, decode.d6.loss_dice: 2.1948, decode.d7.loss_cls: 0.8345, decode.d7.loss_mask: 1.4929, decode.d7.loss_dice: 2.1826, decode.d8.loss_cls: 0.8927, decode.d8.loss_mask: 1.5637, decode.d8.loss_dice: 2.2409, loss: 46.5388, grad_norm: 133.3030
2023-08-29 09:58:16,239 - mmseg - INFO - Iter [300/160000]	lr: 3.349e-07, eta: 1 day, 7:12:26, time: 0.714, data_time: 0.047, memory: 6584, decode.loss_cls: 0.6443, decode.loss_mask: 1.5942, decode.loss_dice: 2.1674, decode.d0.loss_cls: 2.1020, decode.d0.loss_mask: 1.5198, decode.d0.loss_dice: 2.2015, decode.d1.loss_cls: 0.7686, decode.d1.loss_mask: 1.5765, decode.d1.loss_dice: 2.1916, decode.d2.loss_cls: 0.6733, decode.d2.loss_mask: 1.5735, decode.d2.loss_dice: 2.1545, decode.d3.loss_cls: 0.4148, decode.d3.loss_mask: 1.6013, decode.d3.loss_dice: 2.1367, decode.d4.loss_cls: 0.3755, decode.d4.loss_mask: 1.6418, decode.d4.loss_dice: 2.1080, decode.d5.loss_cls: 0.3346, decode.d5.loss_mask: 1.6059, decode.d5.loss_dice: 2.1265, decode.d6.loss_cls: 0.3264, decode.d6.loss_mask: 1.6255, decode.d6.loss_dice: 2.1116, decode.d7.loss_cls: 0.4128, decode.d7.loss_mask: 1.6127, decode.d7.loss_dice: 2.1339, decode.d8.loss_cls: 0.4966, decode.d8.loss_mask: 1.6165, decode.d8.loss_dice: 2.1672, loss: 44.0155, grad_norm: 151.3170
2023-08-29 09:58:52,480 - mmseg - INFO - Iter [350/160000]	lr: 3.908e-07, eta: 1 day, 7:19:58, time: 0.725, data_time: 0.048, memory: 6584, decode.loss_cls: 0.3374, decode.loss_mask: 1.6082, decode.loss_dice: 2.0773, decode.d0.loss_cls: 2.1000, decode.d0.loss_mask: 1.5600, decode.d0.loss_dice: 2.1552, decode.d1.loss_cls: 0.6792, decode.d1.loss_mask: 1.6114, decode.d1.loss_dice: 2.1148, decode.d2.loss_cls: 0.5347, decode.d2.loss_mask: 1.6238, decode.d2.loss_dice: 2.0717, decode.d3.loss_cls: 0.2384, decode.d3.loss_mask: 1.6037, decode.d3.loss_dice: 2.0636, decode.d4.loss_cls: 0.1893, decode.d4.loss_mask: 1.6295, decode.d4.loss_dice: 2.0407, decode.d5.loss_cls: 0.1528, decode.d5.loss_mask: 1.6188, decode.d5.loss_dice: 2.0448, decode.d6.loss_cls: 0.1337, decode.d6.loss_mask: 1.6333, decode.d6.loss_dice: 2.0231, decode.d7.loss_cls: 0.1704, decode.d7.loss_mask: 1.6207, decode.d7.loss_dice: 2.0578, decode.d8.loss_cls: 0.2207, decode.d8.loss_mask: 1.6280, decode.d8.loss_dice: 2.0733, loss: 41.6164, grad_norm: 202.4506
2023-08-29 09:59:29,069 - mmseg - INFO - Iter [400/160000]	lr: 4.466e-07, eta: 1 day, 7:27:47, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.1854, decode.loss_mask: 1.6055, decode.loss_dice: 2.0488, decode.d0.loss_cls: 2.0995, decode.d0.loss_mask: 1.5534, decode.d0.loss_dice: 2.1480, decode.d1.loss_cls: 0.6069, decode.d1.loss_mask: 1.6029, decode.d1.loss_dice: 2.0951, decode.d2.loss_cls: 0.4261, decode.d2.loss_mask: 1.6265, decode.d2.loss_dice: 2.0506, decode.d3.loss_cls: 0.1644, decode.d3.loss_mask: 1.6034, decode.d3.loss_dice: 2.0523, decode.d4.loss_cls: 0.1200, decode.d4.loss_mask: 1.6267, decode.d4.loss_dice: 2.0335, decode.d5.loss_cls: 0.0939, decode.d5.loss_mask: 1.6164, decode.d5.loss_dice: 2.0307, decode.d6.loss_cls: 0.0788, decode.d6.loss_mask: 1.6310, decode.d6.loss_dice: 2.0098, decode.d7.loss_cls: 0.0934, decode.d7.loss_mask: 1.6249, decode.d7.loss_dice: 2.0273, decode.d8.loss_cls: 0.1165, decode.d8.loss_mask: 1.6233, decode.d8.loss_dice: 2.0361, loss: 40.6311, grad_norm: 235.2428
2023-08-29 10:00:03,134 - mmseg - INFO - Iter [450/160000]	lr: 5.024e-07, eta: 1 day, 7:18:48, time: 0.681, data_time: 0.004, memory: 6584, decode.loss_cls: 0.1265, decode.loss_mask: 1.6341, decode.loss_dice: 2.0304, decode.d0.loss_cls: 2.0981, decode.d0.loss_mask: 1.5712, decode.d0.loss_dice: 2.1339, decode.d1.loss_cls: 0.5415, decode.d1.loss_mask: 1.6317, decode.d1.loss_dice: 2.0672, decode.d2.loss_cls: 0.3329, decode.d2.loss_mask: 1.6315, decode.d2.loss_dice: 2.0333, decode.d3.loss_cls: 0.1201, decode.d3.loss_mask: 1.6256, decode.d3.loss_dice: 2.0333, decode.d4.loss_cls: 0.0877, decode.d4.loss_mask: 1.6374, decode.d4.loss_dice: 2.0202, decode.d5.loss_cls: 0.0700, decode.d5.loss_mask: 1.6283, decode.d5.loss_dice: 2.0213, decode.d6.loss_cls: 0.0600, decode.d6.loss_mask: 1.6476, decode.d6.loss_dice: 1.9951, decode.d7.loss_cls: 0.0687, decode.d7.loss_mask: 1.6276, decode.d7.loss_dice: 2.0224, decode.d8.loss_cls: 0.0849, decode.d8.loss_mask: 1.6331, decode.d8.loss_dice: 2.0273, loss: 40.2432, grad_norm: 270.0826
2023-08-29 10:00:39,296 - mmseg - INFO - Iter [500/160000]	lr: 5.582e-07, eta: 1 day, 7:22:36, time: 0.723, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0745, decode.loss_mask: 1.5511, decode.loss_dice: 1.9714, decode.d0.loss_cls: 2.0972, decode.d0.loss_mask: 1.5328, decode.d0.loss_dice: 2.0812, decode.d1.loss_cls: 0.4817, decode.d1.loss_mask: 1.5664, decode.d1.loss_dice: 2.0230, decode.d2.loss_cls: 0.2646, decode.d2.loss_mask: 1.5637, decode.d2.loss_dice: 1.9815, decode.d3.loss_cls: 0.0842, decode.d3.loss_mask: 1.5616, decode.d3.loss_dice: 1.9721, decode.d4.loss_cls: 0.0571, decode.d4.loss_mask: 1.5691, decode.d4.loss_dice: 1.9507, decode.d5.loss_cls: 0.0423, decode.d5.loss_mask: 1.5580, decode.d5.loss_dice: 1.9585, decode.d6.loss_cls: 0.0345, decode.d6.loss_mask: 1.5680, decode.d6.loss_dice: 1.9391, decode.d7.loss_cls: 0.0399, decode.d7.loss_mask: 1.5551, decode.d7.loss_dice: 1.9648, decode.d8.loss_cls: 0.0477, decode.d8.loss_mask: 1.5519, decode.d8.loss_dice: 1.9584, loss: 38.6020, grad_norm: 306.3123
2023-08-29 10:01:15,825 - mmseg - INFO - Iter [550/160000]	lr: 6.140e-07, eta: 1 day, 7:27:28, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0657, decode.loss_mask: 1.5669, decode.loss_dice: 1.8991, decode.d0.loss_cls: 2.0975, decode.d0.loss_mask: 1.5563, decode.d0.loss_dice: 2.0327, decode.d1.loss_cls: 0.4351, decode.d1.loss_mask: 1.5873, decode.d1.loss_dice: 1.9685, decode.d2.loss_cls: 0.2226, decode.d2.loss_mask: 1.5683, decode.d2.loss_dice: 1.9268, decode.d3.loss_cls: 0.0754, decode.d3.loss_mask: 1.5667, decode.d3.loss_dice: 1.9139, decode.d4.loss_cls: 0.0545, decode.d4.loss_mask: 1.5756, decode.d4.loss_dice: 1.8958, decode.d5.loss_cls: 0.0445, decode.d5.loss_mask: 1.5793, decode.d5.loss_dice: 1.8995, decode.d6.loss_cls: 0.0399, decode.d6.loss_mask: 1.5900, decode.d6.loss_dice: 1.8813, decode.d7.loss_cls: 0.0421, decode.d7.loss_mask: 1.5584, decode.d7.loss_dice: 1.9060, decode.d8.loss_cls: 0.0474, decode.d8.loss_mask: 1.5754, decode.d8.loss_dice: 1.8861, loss: 38.0586, grad_norm: 367.6533
2023-08-29 10:01:52,535 - mmseg - INFO - Iter [600/160000]	lr: 6.697e-07, eta: 1 day, 7:32:11, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0439, decode.loss_mask: 1.4788, decode.loss_dice: 1.8694, decode.d0.loss_cls: 2.0947, decode.d0.loss_mask: 1.5128, decode.d0.loss_dice: 2.0046, decode.d1.loss_cls: 0.3871, decode.d1.loss_mask: 1.5295, decode.d1.loss_dice: 1.9347, decode.d2.loss_cls: 0.1835, decode.d2.loss_mask: 1.5064, decode.d2.loss_dice: 1.8860, decode.d3.loss_cls: 0.0566, decode.d3.loss_mask: 1.4909, decode.d3.loss_dice: 1.8738, decode.d4.loss_cls: 0.0382, decode.d4.loss_mask: 1.5060, decode.d4.loss_dice: 1.8499, decode.d5.loss_cls: 0.0300, decode.d5.loss_mask: 1.4909, decode.d5.loss_dice: 1.8537, decode.d6.loss_cls: 0.0251, decode.d6.loss_mask: 1.4921, decode.d6.loss_dice: 1.8325, decode.d7.loss_cls: 0.0281, decode.d7.loss_mask: 1.4786, decode.d7.loss_dice: 1.8585, decode.d8.loss_cls: 0.0309, decode.d8.loss_mask: 1.4792, decode.d8.loss_dice: 1.8492, loss: 36.6954, grad_norm: 350.5588
2023-08-29 10:02:26,529 - mmseg - INFO - Iter [650/160000]	lr: 7.253e-07, eta: 1 day, 7:24:58, time: 0.680, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0365, decode.loss_mask: 1.4601, decode.loss_dice: 1.8255, decode.d0.loss_cls: 2.0951, decode.d0.loss_mask: 1.4934, decode.d0.loss_dice: 1.9794, decode.d1.loss_cls: 0.3478, decode.d1.loss_mask: 1.5047, decode.d1.loss_dice: 1.9116, decode.d2.loss_cls: 0.1604, decode.d2.loss_mask: 1.4862, decode.d2.loss_dice: 1.8510, decode.d3.loss_cls: 0.0500, decode.d3.loss_mask: 1.4767, decode.d3.loss_dice: 1.8369, decode.d4.loss_cls: 0.0347, decode.d4.loss_mask: 1.4861, decode.d4.loss_dice: 1.8185, decode.d5.loss_cls: 0.0272, decode.d5.loss_mask: 1.4674, decode.d5.loss_dice: 1.8220, decode.d6.loss_cls: 0.0229, decode.d6.loss_mask: 1.4891, decode.d6.loss_dice: 1.8119, decode.d7.loss_cls: 0.0260, decode.d7.loss_mask: 1.4613, decode.d7.loss_dice: 1.8186, decode.d8.loss_cls: 0.0278, decode.d8.loss_mask: 1.4602, decode.d8.loss_dice: 1.8106, loss: 36.0998, grad_norm: 451.1199
2023-08-29 10:03:02,636 - mmseg - INFO - Iter [700/160000]	lr: 7.810e-07, eta: 1 day, 7:26:42, time: 0.722, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0496, decode.loss_mask: 1.4716, decode.loss_dice: 1.7918, decode.d0.loss_cls: 2.0931, decode.d0.loss_mask: 1.4999, decode.d0.loss_dice: 1.9504, decode.d1.loss_cls: 0.3231, decode.d1.loss_mask: 1.5115, decode.d1.loss_dice: 1.8686, decode.d2.loss_cls: 0.1499, decode.d2.loss_mask: 1.4803, decode.d2.loss_dice: 1.8238, decode.d3.loss_cls: 0.0575, decode.d3.loss_mask: 1.4782, decode.d3.loss_dice: 1.8077, decode.d4.loss_cls: 0.0446, decode.d4.loss_mask: 1.4816, decode.d4.loss_dice: 1.7850, decode.d5.loss_cls: 0.0394, decode.d5.loss_mask: 1.4715, decode.d5.loss_dice: 1.7847, decode.d6.loss_cls: 0.0399, decode.d6.loss_mask: 1.4813, decode.d6.loss_dice: 1.7771, decode.d7.loss_cls: 0.0400, decode.d7.loss_mask: 1.4749, decode.d7.loss_dice: 1.7982, decode.d8.loss_cls: 0.0424, decode.d8.loss_mask: 1.4764, decode.d8.loss_dice: 1.7823, loss: 35.8764, grad_norm: 444.8514
2023-08-29 10:03:39,175 - mmseg - INFO - Iter [750/160000]	lr: 8.366e-07, eta: 1 day, 7:29:42, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0304, decode.loss_mask: 1.4635, decode.loss_dice: 1.7633, decode.d0.loss_cls: 2.0908, decode.d0.loss_mask: 1.4855, decode.d0.loss_dice: 1.9338, decode.d1.loss_cls: 0.2864, decode.d1.loss_mask: 1.4988, decode.d1.loss_dice: 1.8574, decode.d2.loss_cls: 0.1249, decode.d2.loss_mask: 1.4742, decode.d2.loss_dice: 1.8061, decode.d3.loss_cls: 0.0399, decode.d3.loss_mask: 1.4629, decode.d3.loss_dice: 1.7954, decode.d4.loss_cls: 0.0282, decode.d4.loss_mask: 1.4837, decode.d4.loss_dice: 1.7741, decode.d5.loss_cls: 0.0220, decode.d5.loss_mask: 1.4655, decode.d5.loss_dice: 1.7779, decode.d6.loss_cls: 0.0189, decode.d6.loss_mask: 1.4766, decode.d6.loss_dice: 1.7599, decode.d7.loss_cls: 0.0201, decode.d7.loss_mask: 1.4522, decode.d7.loss_dice: 1.7733, decode.d8.loss_cls: 0.0220, decode.d8.loss_mask: 1.4617, decode.d8.loss_dice: 1.7661, loss: 35.4156, grad_norm: 488.8846
2023-08-29 10:04:15,739 - mmseg - INFO - Iter [800/160000]	lr: 8.921e-07, eta: 1 day, 7:32:19, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0418, decode.loss_mask: 1.4099, decode.loss_dice: 1.6976, decode.d0.loss_cls: 2.0888, decode.d0.loss_mask: 1.4564, decode.d0.loss_dice: 1.8494, decode.d1.loss_cls: 0.2671, decode.d1.loss_mask: 1.4589, decode.d1.loss_dice: 1.7660, decode.d2.loss_cls: 0.1189, decode.d2.loss_mask: 1.4333, decode.d2.loss_dice: 1.7127, decode.d3.loss_cls: 0.0455, decode.d3.loss_mask: 1.4175, decode.d3.loss_dice: 1.7002, decode.d4.loss_cls: 0.0356, decode.d4.loss_mask: 1.4255, decode.d4.loss_dice: 1.6828, decode.d5.loss_cls: 0.0315, decode.d5.loss_mask: 1.4010, decode.d5.loss_dice: 1.6875, decode.d6.loss_cls: 0.0286, decode.d6.loss_mask: 1.4191, decode.d6.loss_dice: 1.6722, decode.d7.loss_cls: 0.0317, decode.d7.loss_mask: 1.4110, decode.d7.loss_dice: 1.6801, decode.d8.loss_cls: 0.0342, decode.d8.loss_mask: 1.4049, decode.d8.loss_dice: 1.6890, loss: 34.0989, grad_norm: 486.5288
2023-08-29 10:04:50,187 - mmseg - INFO - Iter [850/160000]	lr: 9.477e-07, eta: 1 day, 7:27:55, time: 0.689, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0515, decode.loss_mask: 1.4345, decode.loss_dice: 1.7223, decode.d0.loss_cls: 2.0879, decode.d0.loss_mask: 1.4923, decode.d0.loss_dice: 1.8754, decode.d1.loss_cls: 0.2433, decode.d1.loss_mask: 1.5051, decode.d1.loss_dice: 1.8015, decode.d2.loss_cls: 0.1135, decode.d2.loss_mask: 1.4783, decode.d2.loss_dice: 1.7467, decode.d3.loss_cls: 0.0506, decode.d3.loss_mask: 1.4578, decode.d3.loss_dice: 1.7376, decode.d4.loss_cls: 0.0441, decode.d4.loss_mask: 1.4736, decode.d4.loss_dice: 1.7216, decode.d5.loss_cls: 0.0408, decode.d5.loss_mask: 1.4538, decode.d5.loss_dice: 1.7174, decode.d6.loss_cls: 0.0407, decode.d6.loss_mask: 1.4598, decode.d6.loss_dice: 1.7061, decode.d7.loss_cls: 0.0434, decode.d7.loss_mask: 1.4442, decode.d7.loss_dice: 1.7177, decode.d8.loss_cls: 0.0442, decode.d8.loss_mask: 1.4439, decode.d8.loss_dice: 1.7091, loss: 34.8588, grad_norm: 438.3123
2023-08-29 10:05:26,156 - mmseg - INFO - Iter [900/160000]	lr: 1.003e-06, eta: 1 day, 7:28:27, time: 0.719, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0223, decode.loss_mask: 1.3539, decode.loss_dice: 1.6653, decode.d0.loss_cls: 2.0844, decode.d0.loss_mask: 1.4017, decode.d0.loss_dice: 1.8410, decode.d1.loss_cls: 0.2150, decode.d1.loss_mask: 1.4005, decode.d1.loss_dice: 1.7541, decode.d2.loss_cls: 0.0889, decode.d2.loss_mask: 1.3752, decode.d2.loss_dice: 1.6946, decode.d3.loss_cls: 0.0291, decode.d3.loss_mask: 1.3615, decode.d3.loss_dice: 1.6801, decode.d4.loss_cls: 0.0209, decode.d4.loss_mask: 1.3639, decode.d4.loss_dice: 1.6604, decode.d5.loss_cls: 0.0177, decode.d5.loss_mask: 1.3524, decode.d5.loss_dice: 1.6650, decode.d6.loss_cls: 0.0152, decode.d6.loss_mask: 1.3608, decode.d6.loss_dice: 1.6591, decode.d7.loss_cls: 0.0160, decode.d7.loss_mask: 1.3523, decode.d7.loss_dice: 1.6696, decode.d8.loss_cls: 0.0164, decode.d8.loss_mask: 1.3631, decode.d8.loss_dice: 1.6568, loss: 33.1572, grad_norm: 443.9790
2023-08-29 10:06:03,168 - mmseg - INFO - Iter [950/160000]	lr: 1.059e-06, eta: 1 day, 7:31:47, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0307, decode.loss_mask: 1.3774, decode.loss_dice: 1.6211, decode.d0.loss_cls: 2.0842, decode.d0.loss_mask: 1.4425, decode.d0.loss_dice: 1.7864, decode.d1.loss_cls: 0.1978, decode.d1.loss_mask: 1.4474, decode.d1.loss_dice: 1.7010, decode.d2.loss_cls: 0.0872, decode.d2.loss_mask: 1.4170, decode.d2.loss_dice: 1.6432, decode.d3.loss_cls: 0.0354, decode.d3.loss_mask: 1.4040, decode.d3.loss_dice: 1.6374, decode.d4.loss_cls: 0.0302, decode.d4.loss_mask: 1.4077, decode.d4.loss_dice: 1.6172, decode.d5.loss_cls: 0.0265, decode.d5.loss_mask: 1.3874, decode.d5.loss_dice: 1.6212, decode.d6.loss_cls: 0.0251, decode.d6.loss_mask: 1.4012, decode.d6.loss_dice: 1.6135, decode.d7.loss_cls: 0.0264, decode.d7.loss_mask: 1.3926, decode.d7.loss_dice: 1.6152, decode.d8.loss_cls: 0.0284, decode.d8.loss_mask: 1.3979, decode.d8.loss_dice: 1.6136, loss: 33.1169, grad_norm: 577.3324
2023-08-29 10:06:40,175 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-08-29 10:06:42,465 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 10:06:42,465 - mmseg - INFO - Iter [1000/160000]	lr: 1.114e-06, eta: 1 day, 7:40:47, time: 0.786, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0346, decode.loss_mask: 1.3088, decode.loss_dice: 1.5673, decode.d0.loss_cls: 2.0792, decode.d0.loss_mask: 1.3536, decode.d0.loss_dice: 1.7545, decode.d1.loss_cls: 0.1866, decode.d1.loss_mask: 1.3566, decode.d1.loss_dice: 1.6685, decode.d2.loss_cls: 0.0792, decode.d2.loss_mask: 1.3074, decode.d2.loss_dice: 1.5915, decode.d3.loss_cls: 0.0338, decode.d3.loss_mask: 1.3006, decode.d3.loss_dice: 1.5831, decode.d4.loss_cls: 0.0295, decode.d4.loss_mask: 1.3044, decode.d4.loss_dice: 1.5657, decode.d5.loss_cls: 0.0282, decode.d5.loss_mask: 1.2917, decode.d5.loss_dice: 1.5678, decode.d6.loss_cls: 0.0266, decode.d6.loss_mask: 1.3053, decode.d6.loss_dice: 1.5584, decode.d7.loss_cls: 0.0285, decode.d7.loss_mask: 1.2986, decode.d7.loss_dice: 1.5703, decode.d8.loss_cls: 0.0310, decode.d8.loss_mask: 1.3107, decode.d8.loss_dice: 1.5605, loss: 31.6823, grad_norm: 488.0079
2023-08-29 10:07:17,214 - mmseg - INFO - Iter [1050/160000]	lr: 1.169e-06, eta: 1 day, 7:37:20, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0191, decode.loss_mask: 1.2755, decode.loss_dice: 1.4583, decode.d0.loss_cls: 2.0790, decode.d0.loss_mask: 1.3287, decode.d0.loss_dice: 1.6288, decode.d1.loss_cls: 0.1653, decode.d1.loss_mask: 1.3220, decode.d1.loss_dice: 1.5419, decode.d2.loss_cls: 0.0673, decode.d2.loss_mask: 1.2801, decode.d2.loss_dice: 1.4790, decode.d3.loss_cls: 0.0232, decode.d3.loss_mask: 1.2682, decode.d3.loss_dice: 1.4671, decode.d4.loss_cls: 0.0179, decode.d4.loss_mask: 1.2794, decode.d4.loss_dice: 1.4490, decode.d5.loss_cls: 0.0154, decode.d5.loss_mask: 1.2631, decode.d5.loss_dice: 1.4499, decode.d6.loss_cls: 0.0133, decode.d6.loss_mask: 1.2681, decode.d6.loss_dice: 1.4494, decode.d7.loss_cls: 0.0138, decode.d7.loss_mask: 1.2666, decode.d7.loss_dice: 1.4506, decode.d8.loss_cls: 0.0164, decode.d8.loss_mask: 1.2718, decode.d8.loss_dice: 1.4506, loss: 30.0790, grad_norm: 517.7659
2023-08-29 10:07:53,360 - mmseg - INFO - Iter [1100/160000]	lr: 1.225e-06, eta: 1 day, 7:37:32, time: 0.723, data_time: 0.046, memory: 6584, decode.loss_cls: 0.0402, decode.loss_mask: 1.2308, decode.loss_dice: 1.4877, decode.d0.loss_cls: 2.0760, decode.d0.loss_mask: 1.2868, decode.d0.loss_dice: 1.6602, decode.d1.loss_cls: 0.1631, decode.d1.loss_mask: 1.2767, decode.d1.loss_dice: 1.5672, decode.d2.loss_cls: 0.0791, decode.d2.loss_mask: 1.2354, decode.d2.loss_dice: 1.5023, decode.d3.loss_cls: 0.0420, decode.d3.loss_mask: 1.2361, decode.d3.loss_dice: 1.4875, decode.d4.loss_cls: 0.0380, decode.d4.loss_mask: 1.2350, decode.d4.loss_dice: 1.4762, decode.d5.loss_cls: 0.0372, decode.d5.loss_mask: 1.2367, decode.d5.loss_dice: 1.4747, decode.d6.loss_cls: 0.0377, decode.d6.loss_mask: 1.2443, decode.d6.loss_dice: 1.4712, decode.d7.loss_cls: 0.0369, decode.d7.loss_mask: 1.2309, decode.d7.loss_dice: 1.4796, decode.d8.loss_cls: 0.0365, decode.d8.loss_mask: 1.2424, decode.d8.loss_dice: 1.4783, loss: 30.1267, grad_norm: 505.4741
2023-08-29 10:08:29,927 - mmseg - INFO - Iter [1150/160000]	lr: 1.280e-06, eta: 1 day, 7:38:40, time: 0.732, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0162, decode.loss_mask: 1.2938, decode.loss_dice: 1.4780, decode.d0.loss_cls: 2.0728, decode.d0.loss_mask: 1.3360, decode.d0.loss_dice: 1.6136, decode.d1.loss_cls: 0.1378, decode.d1.loss_mask: 1.3408, decode.d1.loss_dice: 1.5456, decode.d2.loss_cls: 0.0559, decode.d2.loss_mask: 1.3061, decode.d2.loss_dice: 1.4935, decode.d3.loss_cls: 0.0200, decode.d3.loss_mask: 1.3038, decode.d3.loss_dice: 1.4876, decode.d4.loss_cls: 0.0162, decode.d4.loss_mask: 1.3023, decode.d4.loss_dice: 1.4708, decode.d5.loss_cls: 0.0144, decode.d5.loss_mask: 1.2927, decode.d5.loss_dice: 1.4778, decode.d6.loss_cls: 0.0127, decode.d6.loss_mask: 1.2963, decode.d6.loss_dice: 1.4712, decode.d7.loss_cls: 0.0131, decode.d7.loss_mask: 1.2910, decode.d7.loss_dice: 1.4867, decode.d8.loss_cls: 0.0145, decode.d8.loss_mask: 1.2915, decode.d8.loss_dice: 1.4773, loss: 30.4301, grad_norm: 502.4991
2023-08-29 10:09:06,730 - mmseg - INFO - Iter [1200/160000]	lr: 1.335e-06, eta: 1 day, 7:40:10, time: 0.736, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0139, decode.loss_mask: 1.2996, decode.loss_dice: 1.4752, decode.d0.loss_cls: 2.0697, decode.d0.loss_mask: 1.3362, decode.d0.loss_dice: 1.6198, decode.d1.loss_cls: 0.1270, decode.d1.loss_mask: 1.3476, decode.d1.loss_dice: 1.5510, decode.d2.loss_cls: 0.0512, decode.d2.loss_mask: 1.3071, decode.d2.loss_dice: 1.4889, decode.d3.loss_cls: 0.0179, decode.d3.loss_mask: 1.3055, decode.d3.loss_dice: 1.4761, decode.d4.loss_cls: 0.0147, decode.d4.loss_mask: 1.3127, decode.d4.loss_dice: 1.4616, decode.d5.loss_cls: 0.0135, decode.d5.loss_mask: 1.2960, decode.d5.loss_dice: 1.4716, decode.d6.loss_cls: 0.0117, decode.d6.loss_mask: 1.3020, decode.d6.loss_dice: 1.4643, decode.d7.loss_cls: 0.0115, decode.d7.loss_mask: 1.3041, decode.d7.loss_dice: 1.4700, decode.d8.loss_cls: 0.0121, decode.d8.loss_mask: 1.3098, decode.d8.loss_dice: 1.4683, loss: 30.4107, grad_norm: 516.7158
2023-08-29 10:09:41,510 - mmseg - INFO - Iter [1250/160000]	lr: 1.391e-06, eta: 1 day, 7:37:11, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0119, decode.loss_mask: 1.2202, decode.loss_dice: 1.4088, decode.d0.loss_cls: 2.0667, decode.d0.loss_mask: 1.2833, decode.d0.loss_dice: 1.5738, decode.d1.loss_cls: 0.1145, decode.d1.loss_mask: 1.2483, decode.d1.loss_dice: 1.4765, decode.d2.loss_cls: 0.0457, decode.d2.loss_mask: 1.2176, decode.d2.loss_dice: 1.4184, decode.d3.loss_cls: 0.0155, decode.d3.loss_mask: 1.2242, decode.d3.loss_dice: 1.3983, decode.d4.loss_cls: 0.0124, decode.d4.loss_mask: 1.2217, decode.d4.loss_dice: 1.3981, decode.d5.loss_cls: 0.0110, decode.d5.loss_mask: 1.2233, decode.d5.loss_dice: 1.3960, decode.d6.loss_cls: 0.0091, decode.d6.loss_mask: 1.2256, decode.d6.loss_dice: 1.3958, decode.d7.loss_cls: 0.0092, decode.d7.loss_mask: 1.2228, decode.d7.loss_dice: 1.4007, decode.d8.loss_cls: 0.0098, decode.d8.loss_mask: 1.2186, decode.d8.loss_dice: 1.4005, loss: 28.8780, grad_norm: 610.8286
2023-08-29 10:10:17,868 - mmseg - INFO - Iter [1300/160000]	lr: 1.446e-06, eta: 1 day, 7:37:37, time: 0.727, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0378, decode.loss_mask: 1.2385, decode.loss_dice: 1.4410, decode.d0.loss_cls: 2.0628, decode.d0.loss_mask: 1.2910, decode.d0.loss_dice: 1.5798, decode.d1.loss_cls: 0.1197, decode.d1.loss_mask: 1.2871, decode.d1.loss_dice: 1.5081, decode.d2.loss_cls: 0.0621, decode.d2.loss_mask: 1.2547, decode.d2.loss_dice: 1.4550, decode.d3.loss_cls: 0.0369, decode.d3.loss_mask: 1.2468, decode.d3.loss_dice: 1.4520, decode.d4.loss_cls: 0.0349, decode.d4.loss_mask: 1.2396, decode.d4.loss_dice: 1.4431, decode.d5.loss_cls: 0.0352, decode.d5.loss_mask: 1.2411, decode.d5.loss_dice: 1.4388, decode.d6.loss_cls: 0.0346, decode.d6.loss_mask: 1.2387, decode.d6.loss_dice: 1.4361, decode.d7.loss_cls: 0.0339, decode.d7.loss_mask: 1.2308, decode.d7.loss_dice: 1.4467, decode.d8.loss_cls: 0.0360, decode.d8.loss_mask: 1.2333, decode.d8.loss_dice: 1.4454, loss: 29.6416, grad_norm: 500.8766
2023-08-29 10:10:54,336 - mmseg - INFO - Iter [1350/160000]	lr: 1.501e-06, eta: 1 day, 7:38:11, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0226, decode.loss_mask: 1.1335, decode.loss_dice: 1.3704, decode.d0.loss_cls: 2.0618, decode.d0.loss_mask: 1.1901, decode.d0.loss_dice: 1.5222, decode.d1.loss_cls: 0.1091, decode.d1.loss_mask: 1.1572, decode.d1.loss_dice: 1.4379, decode.d2.loss_cls: 0.0522, decode.d2.loss_mask: 1.1460, decode.d2.loss_dice: 1.3816, decode.d3.loss_cls: 0.0248, decode.d3.loss_mask: 1.1338, decode.d3.loss_dice: 1.3695, decode.d4.loss_cls: 0.0242, decode.d4.loss_mask: 1.1302, decode.d4.loss_dice: 1.3728, decode.d5.loss_cls: 0.0222, decode.d5.loss_mask: 1.1255, decode.d5.loss_dice: 1.3682, decode.d6.loss_cls: 0.0202, decode.d6.loss_mask: 1.1281, decode.d6.loss_dice: 1.3641, decode.d7.loss_cls: 0.0200, decode.d7.loss_mask: 1.1329, decode.d7.loss_dice: 1.3684, decode.d8.loss_cls: 0.0208, decode.d8.loss_mask: 1.1368, decode.d8.loss_dice: 1.3715, loss: 27.7187, grad_norm: 572.6894
2023-08-29 10:11:31,413 - mmseg - INFO - Iter [1400/160000]	lr: 1.556e-06, eta: 1 day, 7:39:49, time: 0.742, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0103, decode.loss_mask: 1.1392, decode.loss_dice: 1.3451, decode.d0.loss_cls: 2.0559, decode.d0.loss_mask: 1.1632, decode.d0.loss_dice: 1.5051, decode.d1.loss_cls: 0.0927, decode.d1.loss_mask: 1.1422, decode.d1.loss_dice: 1.4159, decode.d2.loss_cls: 0.0397, decode.d2.loss_mask: 1.1304, decode.d2.loss_dice: 1.3592, decode.d3.loss_cls: 0.0143, decode.d3.loss_mask: 1.1322, decode.d3.loss_dice: 1.3526, decode.d4.loss_cls: 0.0124, decode.d4.loss_mask: 1.1282, decode.d4.loss_dice: 1.3467, decode.d5.loss_cls: 0.0105, decode.d5.loss_mask: 1.1342, decode.d5.loss_dice: 1.3477, decode.d6.loss_cls: 0.0086, decode.d6.loss_mask: 1.1402, decode.d6.loss_dice: 1.3408, decode.d7.loss_cls: 0.0092, decode.d7.loss_mask: 1.1403, decode.d7.loss_dice: 1.3520, decode.d8.loss_cls: 0.0088, decode.d8.loss_mask: 1.1403, decode.d8.loss_dice: 1.3481, loss: 27.3658, grad_norm: 578.7206
2023-08-29 10:12:06,350 - mmseg - INFO - Iter [1450/160000]	lr: 1.611e-06, eta: 1 day, 7:37:24, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0094, decode.loss_mask: 1.1827, decode.loss_dice: 1.3487, decode.d0.loss_cls: 2.0522, decode.d0.loss_mask: 1.2340, decode.d0.loss_dice: 1.4773, decode.d1.loss_cls: 0.0864, decode.d1.loss_mask: 1.2193, decode.d1.loss_dice: 1.4018, decode.d2.loss_cls: 0.0345, decode.d2.loss_mask: 1.1946, decode.d2.loss_dice: 1.3604, decode.d3.loss_cls: 0.0124, decode.d3.loss_mask: 1.1916, decode.d3.loss_dice: 1.3591, decode.d4.loss_cls: 0.0106, decode.d4.loss_mask: 1.1864, decode.d4.loss_dice: 1.3525, decode.d5.loss_cls: 0.0092, decode.d5.loss_mask: 1.1809, decode.d5.loss_dice: 1.3513, decode.d6.loss_cls: 0.0071, decode.d6.loss_mask: 1.1837, decode.d6.loss_dice: 1.3510, decode.d7.loss_cls: 0.0074, decode.d7.loss_mask: 1.1803, decode.d7.loss_dice: 1.3502, decode.d8.loss_cls: 0.0080, decode.d8.loss_mask: 1.1816, decode.d8.loss_dice: 1.3489, loss: 27.8736, grad_norm: 613.2328
2023-08-29 10:12:42,861 - mmseg - INFO - Iter [1500/160000]	lr: 1.666e-06, eta: 1 day, 7:37:52, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0113, decode.loss_mask: 1.1176, decode.loss_dice: 1.3285, decode.d0.loss_cls: 2.0479, decode.d0.loss_mask: 1.1751, decode.d0.loss_dice: 1.4841, decode.d1.loss_cls: 0.0809, decode.d1.loss_mask: 1.1466, decode.d1.loss_dice: 1.3878, decode.d2.loss_cls: 0.0344, decode.d2.loss_mask: 1.0998, decode.d2.loss_dice: 1.3322, decode.d3.loss_cls: 0.0127, decode.d3.loss_mask: 1.1033, decode.d3.loss_dice: 1.3235, decode.d4.loss_cls: 0.0112, decode.d4.loss_mask: 1.1014, decode.d4.loss_dice: 1.3148, decode.d5.loss_cls: 0.0099, decode.d5.loss_mask: 1.1068, decode.d5.loss_dice: 1.3170, decode.d6.loss_cls: 0.0084, decode.d6.loss_mask: 1.1135, decode.d6.loss_dice: 1.3123, decode.d7.loss_cls: 0.0094, decode.d7.loss_mask: 1.1137, decode.d7.loss_dice: 1.3170, decode.d8.loss_cls: 0.0096, decode.d8.loss_mask: 1.1170, decode.d8.loss_dice: 1.3204, loss: 26.8681, grad_norm: 538.2127
2023-08-29 10:13:19,188 - mmseg - INFO - Iter [1550/160000]	lr: 1.667e-06, eta: 1 day, 7:37:58, time: 0.727, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0098, decode.loss_mask: 1.1154, decode.loss_dice: 1.2715, decode.d0.loss_cls: 2.0432, decode.d0.loss_mask: 1.1639, decode.d0.loss_dice: 1.4109, decode.d1.loss_cls: 0.0752, decode.d1.loss_mask: 1.1121, decode.d1.loss_dice: 1.3194, decode.d2.loss_cls: 0.0336, decode.d2.loss_mask: 1.1100, decode.d2.loss_dice: 1.2769, decode.d3.loss_cls: 0.0118, decode.d3.loss_mask: 1.1128, decode.d3.loss_dice: 1.2673, decode.d4.loss_cls: 0.0105, decode.d4.loss_mask: 1.1073, decode.d4.loss_dice: 1.2631, decode.d5.loss_cls: 0.0090, decode.d5.loss_mask: 1.1155, decode.d5.loss_dice: 1.2641, decode.d6.loss_cls: 0.0073, decode.d6.loss_mask: 1.1198, decode.d6.loss_dice: 1.2621, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 1.1078, decode.d7.loss_dice: 1.2690, decode.d8.loss_cls: 0.0082, decode.d8.loss_mask: 1.1077, decode.d8.loss_dice: 1.2675, loss: 26.2603, grad_norm: 514.0746
2023-08-29 10:13:55,951 - mmseg - INFO - Iter [1600/160000]	lr: 1.666e-06, eta: 1 day, 7:38:44, time: 0.735, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0223, decode.loss_mask: 1.1414, decode.loss_dice: 1.3071, decode.d0.loss_cls: 2.0406, decode.d0.loss_mask: 1.2195, decode.d0.loss_dice: 1.4487, decode.d1.loss_cls: 0.0790, decode.d1.loss_mask: 1.1762, decode.d1.loss_dice: 1.3591, decode.d2.loss_cls: 0.0397, decode.d2.loss_mask: 1.1444, decode.d2.loss_dice: 1.3168, decode.d3.loss_cls: 0.0242, decode.d3.loss_mask: 1.1414, decode.d3.loss_dice: 1.3128, decode.d4.loss_cls: 0.0229, decode.d4.loss_mask: 1.1353, decode.d4.loss_dice: 1.3047, decode.d5.loss_cls: 0.0228, decode.d5.loss_mask: 1.1409, decode.d5.loss_dice: 1.3028, decode.d6.loss_cls: 0.0224, decode.d6.loss_mask: 1.1392, decode.d6.loss_dice: 1.3009, decode.d7.loss_cls: 0.0219, decode.d7.loss_mask: 1.1350, decode.d7.loss_dice: 1.3033, decode.d8.loss_cls: 0.0213, decode.d8.loss_mask: 1.1345, decode.d8.loss_dice: 1.3116, loss: 27.0927, grad_norm: 557.0391
2023-08-29 10:14:30,728 - mmseg - INFO - Iter [1650/160000]	lr: 1.666e-06, eta: 1 day, 7:36:14, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0100, decode.loss_mask: 1.0289, decode.loss_dice: 1.1687, decode.d0.loss_cls: 2.0356, decode.d0.loss_mask: 1.0875, decode.d0.loss_dice: 1.3413, decode.d1.loss_cls: 0.0685, decode.d1.loss_mask: 1.0528, decode.d1.loss_dice: 1.2331, decode.d2.loss_cls: 0.0309, decode.d2.loss_mask: 1.0390, decode.d2.loss_dice: 1.1818, decode.d3.loss_cls: 0.0123, decode.d3.loss_mask: 1.0283, decode.d3.loss_dice: 1.1656, decode.d4.loss_cls: 0.0112, decode.d4.loss_mask: 1.0319, decode.d4.loss_dice: 1.1600, decode.d5.loss_cls: 0.0101, decode.d5.loss_mask: 1.0281, decode.d5.loss_dice: 1.1667, decode.d6.loss_cls: 0.0085, decode.d6.loss_mask: 1.0321, decode.d6.loss_dice: 1.1678, decode.d7.loss_cls: 0.0086, decode.d7.loss_mask: 1.0362, decode.d7.loss_dice: 1.1615, decode.d8.loss_cls: 0.0089, decode.d8.loss_mask: 1.0348, decode.d8.loss_dice: 1.1647, loss: 24.5152, grad_norm: 563.2641
2023-08-29 10:15:07,270 - mmseg - INFO - Iter [1700/160000]	lr: 1.665e-06, eta: 1 day, 7:36:36, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0229, decode.loss_mask: 1.1072, decode.loss_dice: 1.2312, decode.d0.loss_cls: 2.0321, decode.d0.loss_mask: 1.1240, decode.d0.loss_dice: 1.3382, decode.d1.loss_cls: 0.0706, decode.d1.loss_mask: 1.1099, decode.d1.loss_dice: 1.2681, decode.d2.loss_cls: 0.0382, decode.d2.loss_mask: 1.1096, decode.d2.loss_dice: 1.2350, decode.d3.loss_cls: 0.0235, decode.d3.loss_mask: 1.1124, decode.d3.loss_dice: 1.2232, decode.d4.loss_cls: 0.0214, decode.d4.loss_mask: 1.1170, decode.d4.loss_dice: 1.2194, decode.d5.loss_cls: 0.0220, decode.d5.loss_mask: 1.1052, decode.d5.loss_dice: 1.2348, decode.d6.loss_cls: 0.0217, decode.d6.loss_mask: 1.1013, decode.d6.loss_dice: 1.2278, decode.d7.loss_cls: 0.0202, decode.d7.loss_mask: 1.1008, decode.d7.loss_dice: 1.2302, decode.d8.loss_cls: 0.0217, decode.d8.loss_mask: 1.1053, decode.d8.loss_dice: 1.2292, loss: 25.8242, grad_norm: 554.3261
2023-08-29 10:15:43,431 - mmseg - INFO - Iter [1750/160000]	lr: 1.665e-06, eta: 1 day, 7:36:20, time: 0.723, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0199, decode.loss_mask: 1.0559, decode.loss_dice: 1.2085, decode.d0.loss_cls: 2.0258, decode.d0.loss_mask: 1.1282, decode.d0.loss_dice: 1.3419, decode.d1.loss_cls: 0.0679, decode.d1.loss_mask: 1.0600, decode.d1.loss_dice: 1.2349, decode.d2.loss_cls: 0.0370, decode.d2.loss_mask: 1.0520, decode.d2.loss_dice: 1.2007, decode.d3.loss_cls: 0.0222, decode.d3.loss_mask: 1.0529, decode.d3.loss_dice: 1.1988, decode.d4.loss_cls: 0.0209, decode.d4.loss_mask: 1.0510, decode.d4.loss_dice: 1.1994, decode.d5.loss_cls: 0.0206, decode.d5.loss_mask: 1.0476, decode.d5.loss_dice: 1.1956, decode.d6.loss_cls: 0.0187, decode.d6.loss_mask: 1.0487, decode.d6.loss_dice: 1.1974, decode.d7.loss_cls: 0.0183, decode.d7.loss_mask: 1.0450, decode.d7.loss_dice: 1.2009, decode.d8.loss_cls: 0.0185, decode.d8.loss_mask: 1.0511, decode.d8.loss_dice: 1.2024, loss: 25.0430, grad_norm: 523.3251
2023-08-29 10:16:20,426 - mmseg - INFO - Iter [1800/160000]	lr: 1.664e-06, eta: 1 day, 7:37:16, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0161, decode.loss_mask: 1.0494, decode.loss_dice: 1.2048, decode.d0.loss_cls: 2.0216, decode.d0.loss_mask: 1.1101, decode.d0.loss_dice: 1.3466, decode.d1.loss_cls: 0.0636, decode.d1.loss_mask: 1.0633, decode.d1.loss_dice: 1.2539, decode.d2.loss_cls: 0.0323, decode.d2.loss_mask: 1.0464, decode.d2.loss_dice: 1.2165, decode.d3.loss_cls: 0.0179, decode.d3.loss_mask: 1.0368, decode.d3.loss_dice: 1.2070, decode.d4.loss_cls: 0.0155, decode.d4.loss_mask: 1.0406, decode.d4.loss_dice: 1.2090, decode.d5.loss_cls: 0.0150, decode.d5.loss_mask: 1.0470, decode.d5.loss_dice: 1.1956, decode.d6.loss_cls: 0.0143, decode.d6.loss_mask: 1.0503, decode.d6.loss_dice: 1.2026, decode.d7.loss_cls: 0.0142, decode.d7.loss_mask: 1.0575, decode.d7.loss_dice: 1.2026, decode.d8.loss_cls: 0.0141, decode.d8.loss_mask: 1.0543, decode.d8.loss_dice: 1.2018, loss: 25.0208, grad_norm: 530.3805
2023-08-29 10:16:57,462 - mmseg - INFO - Iter [1850/160000]	lr: 1.664e-06, eta: 1 day, 7:38:10, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0203, decode.loss_mask: 1.1067, decode.loss_dice: 1.2063, decode.d0.loss_cls: 2.0160, decode.d0.loss_mask: 1.1487, decode.d0.loss_dice: 1.3314, decode.d1.loss_cls: 0.0567, decode.d1.loss_mask: 1.1000, decode.d1.loss_dice: 1.2385, decode.d2.loss_cls: 0.0303, decode.d2.loss_mask: 1.1005, decode.d2.loss_dice: 1.2106, decode.d3.loss_cls: 0.0154, decode.d3.loss_mask: 1.1071, decode.d3.loss_dice: 1.2046, decode.d4.loss_cls: 0.0201, decode.d4.loss_mask: 1.1060, decode.d4.loss_dice: 1.2053, decode.d5.loss_cls: 0.0195, decode.d5.loss_mask: 1.1013, decode.d5.loss_dice: 1.2085, decode.d6.loss_cls: 0.0185, decode.d6.loss_mask: 1.1047, decode.d6.loss_dice: 1.2064, decode.d7.loss_cls: 0.0187, decode.d7.loss_mask: 1.1028, decode.d7.loss_dice: 1.2016, decode.d8.loss_cls: 0.0198, decode.d8.loss_mask: 1.1022, decode.d8.loss_dice: 1.2109, loss: 25.5394, grad_norm: 553.8034
2023-08-29 10:17:31,958 - mmseg - INFO - Iter [1900/160000]	lr: 1.663e-06, eta: 1 day, 7:35:28, time: 0.690, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0093, decode.loss_mask: 1.0324, decode.loss_dice: 1.1617, decode.d0.loss_cls: 2.0113, decode.d0.loss_mask: 1.0694, decode.d0.loss_dice: 1.2959, decode.d1.loss_cls: 0.0507, decode.d1.loss_mask: 1.0263, decode.d1.loss_dice: 1.1904, decode.d2.loss_cls: 0.0238, decode.d2.loss_mask: 1.0194, decode.d2.loss_dice: 1.1662, decode.d3.loss_cls: 0.0102, decode.d3.loss_mask: 1.0183, decode.d3.loss_dice: 1.1629, decode.d4.loss_cls: 0.0089, decode.d4.loss_mask: 1.0256, decode.d4.loss_dice: 1.1524, decode.d5.loss_cls: 0.0081, decode.d5.loss_mask: 1.0253, decode.d5.loss_dice: 1.1517, decode.d6.loss_cls: 0.0075, decode.d6.loss_mask: 1.0240, decode.d6.loss_dice: 1.1543, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 1.0187, decode.d7.loss_dice: 1.1628, decode.d8.loss_cls: 0.0080, decode.d8.loss_mask: 1.0229, decode.d8.loss_dice: 1.1581, loss: 24.1837, grad_norm: 544.6081
2023-08-29 10:18:08,172 - mmseg - INFO - Iter [1950/160000]	lr: 1.663e-06, eta: 1 day, 7:35:12, time: 0.724, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0217, decode.loss_mask: 1.0374, decode.loss_dice: 1.1740, decode.d0.loss_cls: 2.0063, decode.d0.loss_mask: 1.0824, decode.d0.loss_dice: 1.2952, decode.d1.loss_cls: 0.0569, decode.d1.loss_mask: 1.0488, decode.d1.loss_dice: 1.1963, decode.d2.loss_cls: 0.0329, decode.d2.loss_mask: 1.0544, decode.d2.loss_dice: 1.1765, decode.d3.loss_cls: 0.0219, decode.d3.loss_mask: 1.0394, decode.d3.loss_dice: 1.1729, decode.d4.loss_cls: 0.0210, decode.d4.loss_mask: 1.0436, decode.d4.loss_dice: 1.1650, decode.d5.loss_cls: 0.0209, decode.d5.loss_mask: 1.0397, decode.d5.loss_dice: 1.1652, decode.d6.loss_cls: 0.0194, decode.d6.loss_mask: 1.0333, decode.d6.loss_dice: 1.1742, decode.d7.loss_cls: 0.0197, decode.d7.loss_mask: 1.0354, decode.d7.loss_dice: 1.1684, decode.d8.loss_cls: 0.0205, decode.d8.loss_mask: 1.0400, decode.d8.loss_dice: 1.1722, loss: 24.5554, grad_norm: 649.7337
2023-08-29 10:18:45,217 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-08-29 10:18:47,576 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 10:18:47,576 - mmseg - INFO - Iter [2000/160000]	lr: 1.662e-06, eta: 1 day, 7:39:08, time: 0.788, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0198, decode.loss_mask: 1.0753, decode.loss_dice: 1.1777, decode.d0.loss_cls: 2.0009, decode.d0.loss_mask: 1.1336, decode.d0.loss_dice: 1.3219, decode.d1.loss_cls: 0.0540, decode.d1.loss_mask: 1.0760, decode.d1.loss_dice: 1.2127, decode.d2.loss_cls: 0.0326, decode.d2.loss_mask: 1.0681, decode.d2.loss_dice: 1.1839, decode.d3.loss_cls: 0.0212, decode.d3.loss_mask: 1.0567, decode.d3.loss_dice: 1.1805, decode.d4.loss_cls: 0.0213, decode.d4.loss_mask: 1.0663, decode.d4.loss_dice: 1.1802, decode.d5.loss_cls: 0.0204, decode.d5.loss_mask: 1.0701, decode.d5.loss_dice: 1.1764, decode.d6.loss_cls: 0.0195, decode.d6.loss_mask: 1.0610, decode.d6.loss_dice: 1.1834, decode.d7.loss_cls: 0.0178, decode.d7.loss_mask: 1.0666, decode.d7.loss_dice: 1.1822, decode.d8.loss_cls: 0.0178, decode.d8.loss_mask: 1.0674, decode.d8.loss_dice: 1.1765, loss: 24.9415, grad_norm: 513.6449
2023-08-29 10:19:24,754 - mmseg - INFO - Iter [2050/160000]	lr: 1.662e-06, eta: 1 day, 7:39:58, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0077, decode.loss_mask: 0.9922, decode.loss_dice: 1.0910, decode.d0.loss_cls: 1.9944, decode.d0.loss_mask: 1.0266, decode.d0.loss_dice: 1.2069, decode.d1.loss_cls: 0.0425, decode.d1.loss_mask: 0.9912, decode.d1.loss_dice: 1.1124, decode.d2.loss_cls: 0.0203, decode.d2.loss_mask: 0.9888, decode.d2.loss_dice: 1.0821, decode.d3.loss_cls: 0.0088, decode.d3.loss_mask: 0.9852, decode.d3.loss_dice: 1.0776, decode.d4.loss_cls: 0.0080, decode.d4.loss_mask: 0.9802, decode.d4.loss_dice: 1.0786, decode.d5.loss_cls: 0.0075, decode.d5.loss_mask: 0.9777, decode.d5.loss_dice: 1.0775, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.9774, decode.d6.loss_dice: 1.0785, decode.d7.loss_cls: 0.0060, decode.d7.loss_mask: 0.9813, decode.d7.loss_dice: 1.0826, decode.d8.loss_cls: 0.0065, decode.d8.loss_mask: 0.9906, decode.d8.loss_dice: 1.0828, loss: 22.9694, grad_norm: 451.2187
2023-08-29 10:19:59,412 - mmseg - INFO - Iter [2100/160000]	lr: 1.661e-06, eta: 1 day, 7:37:34, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0067, decode.loss_mask: 1.0178, decode.loss_dice: 1.1181, decode.d0.loss_cls: 1.9879, decode.d0.loss_mask: 1.0641, decode.d0.loss_dice: 1.2574, decode.d1.loss_cls: 0.0411, decode.d1.loss_mask: 1.0047, decode.d1.loss_dice: 1.1567, decode.d2.loss_cls: 0.0201, decode.d2.loss_mask: 1.0149, decode.d2.loss_dice: 1.1271, decode.d3.loss_cls: 0.0085, decode.d3.loss_mask: 1.0073, decode.d3.loss_dice: 1.1174, decode.d4.loss_cls: 0.0078, decode.d4.loss_mask: 1.0107, decode.d4.loss_dice: 1.1139, decode.d5.loss_cls: 0.0067, decode.d5.loss_mask: 1.0130, decode.d5.loss_dice: 1.1125, decode.d6.loss_cls: 0.0058, decode.d6.loss_mask: 1.0120, decode.d6.loss_dice: 1.1161, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 1.0188, decode.d7.loss_dice: 1.1083, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 1.0153, decode.d8.loss_dice: 1.1166, loss: 23.6189, grad_norm: 561.2867
2023-08-29 10:20:35,676 - mmseg - INFO - Iter [2150/160000]	lr: 1.661e-06, eta: 1 day, 7:37:12, time: 0.725, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0193, decode.loss_mask: 1.0280, decode.loss_dice: 1.1126, decode.d0.loss_cls: 1.9832, decode.d0.loss_mask: 1.0511, decode.d0.loss_dice: 1.2347, decode.d1.loss_cls: 0.0601, decode.d1.loss_mask: 1.0139, decode.d1.loss_dice: 1.1344, decode.d2.loss_cls: 0.0317, decode.d2.loss_mask: 1.0303, decode.d2.loss_dice: 1.1180, decode.d3.loss_cls: 0.0213, decode.d3.loss_mask: 1.0256, decode.d3.loss_dice: 1.1074, decode.d4.loss_cls: 0.0282, decode.d4.loss_mask: 1.0173, decode.d4.loss_dice: 1.1087, decode.d5.loss_cls: 0.0270, decode.d5.loss_mask: 1.0199, decode.d5.loss_dice: 1.1034, decode.d6.loss_cls: 0.0198, decode.d6.loss_mask: 1.0198, decode.d6.loss_dice: 1.1089, decode.d7.loss_cls: 0.0208, decode.d7.loss_mask: 1.0164, decode.d7.loss_dice: 1.1078, decode.d8.loss_cls: 0.0190, decode.d8.loss_mask: 1.0214, decode.d8.loss_dice: 1.1088, loss: 23.7188, grad_norm: 578.5535
2023-08-29 10:21:12,632 - mmseg - INFO - Iter [2200/160000]	lr: 1.660e-06, eta: 1 day, 7:37:42, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0062, decode.loss_mask: 0.9658, decode.loss_dice: 1.0806, decode.d0.loss_cls: 1.9772, decode.d0.loss_mask: 0.9901, decode.d0.loss_dice: 1.1949, decode.d1.loss_cls: 0.0377, decode.d1.loss_mask: 0.9846, decode.d1.loss_dice: 1.1085, decode.d2.loss_cls: 0.0183, decode.d2.loss_mask: 0.9749, decode.d2.loss_dice: 1.0905, decode.d3.loss_cls: 0.0078, decode.d3.loss_mask: 0.9677, decode.d3.loss_dice: 1.0840, decode.d4.loss_cls: 0.0072, decode.d4.loss_mask: 0.9722, decode.d4.loss_dice: 1.0766, decode.d5.loss_cls: 0.0064, decode.d5.loss_mask: 0.9669, decode.d5.loss_dice: 1.0781, decode.d6.loss_cls: 0.0056, decode.d6.loss_mask: 0.9644, decode.d6.loss_dice: 1.0794, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.9658, decode.d7.loss_dice: 1.0806, decode.d8.loss_cls: 0.0055, decode.d8.loss_mask: 0.9730, decode.d8.loss_dice: 1.0841, loss: 22.7602, grad_norm: 655.9813
2023-08-29 10:21:49,373 - mmseg - INFO - Iter [2250/160000]	lr: 1.660e-06, eta: 1 day, 7:37:52, time: 0.735, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0059, decode.loss_mask: 0.9344, decode.loss_dice: 1.0254, decode.d0.loss_cls: 1.9732, decode.d0.loss_mask: 0.9713, decode.d0.loss_dice: 1.1610, decode.d1.loss_cls: 0.0400, decode.d1.loss_mask: 0.9351, decode.d1.loss_dice: 1.0590, decode.d2.loss_cls: 0.0178, decode.d2.loss_mask: 0.9339, decode.d2.loss_dice: 1.0435, decode.d3.loss_cls: 0.0078, decode.d3.loss_mask: 0.9292, decode.d3.loss_dice: 1.0326, decode.d4.loss_cls: 0.0071, decode.d4.loss_mask: 0.9316, decode.d4.loss_dice: 1.0274, decode.d5.loss_cls: 0.0064, decode.d5.loss_mask: 0.9344, decode.d5.loss_dice: 1.0271, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.9313, decode.d6.loss_dice: 1.0270, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.9388, decode.d7.loss_dice: 1.0306, decode.d8.loss_cls: 0.0055, decode.d8.loss_mask: 0.9401, decode.d8.loss_dice: 1.0211, loss: 21.9103, grad_norm: 576.0738
2023-08-29 10:22:24,087 - mmseg - INFO - Iter [2300/160000]	lr: 1.659e-06, eta: 1 day, 7:35:41, time: 0.694, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0063, decode.loss_mask: 0.9620, decode.loss_dice: 1.0929, decode.d0.loss_cls: 1.9664, decode.d0.loss_mask: 0.9880, decode.d0.loss_dice: 1.1970, decode.d1.loss_cls: 0.0356, decode.d1.loss_mask: 0.9656, decode.d1.loss_dice: 1.1125, decode.d2.loss_cls: 0.0185, decode.d2.loss_mask: 0.9636, decode.d2.loss_dice: 1.0833, decode.d3.loss_cls: 0.0077, decode.d3.loss_mask: 0.9611, decode.d3.loss_dice: 1.0808, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.9588, decode.d4.loss_dice: 1.0804, decode.d5.loss_cls: 0.0061, decode.d5.loss_mask: 0.9645, decode.d5.loss_dice: 1.0755, decode.d6.loss_cls: 0.0052, decode.d6.loss_mask: 0.9618, decode.d6.loss_dice: 1.0835, decode.d7.loss_cls: 0.0054, decode.d7.loss_mask: 0.9646, decode.d7.loss_dice: 1.0867, decode.d8.loss_cls: 0.0055, decode.d8.loss_mask: 0.9623, decode.d8.loss_dice: 1.0877, loss: 22.6961, grad_norm: 589.0838
2023-08-29 10:23:00,246 - mmseg - INFO - Iter [2350/160000]	lr: 1.659e-06, eta: 1 day, 7:35:11, time: 0.723, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0089, decode.loss_mask: 0.9655, decode.loss_dice: 1.0260, decode.d0.loss_cls: 1.9627, decode.d0.loss_mask: 1.0351, decode.d0.loss_dice: 1.1325, decode.d1.loss_cls: 0.0338, decode.d1.loss_mask: 0.9725, decode.d1.loss_dice: 1.0550, decode.d2.loss_cls: 0.0184, decode.d2.loss_mask: 0.9613, decode.d2.loss_dice: 1.0367, decode.d3.loss_cls: 0.0095, decode.d3.loss_mask: 0.9594, decode.d3.loss_dice: 1.0273, decode.d4.loss_cls: 0.0089, decode.d4.loss_mask: 0.9701, decode.d4.loss_dice: 1.0205, decode.d5.loss_cls: 0.0085, decode.d5.loss_mask: 0.9636, decode.d5.loss_dice: 1.0201, decode.d6.loss_cls: 0.0081, decode.d6.loss_mask: 0.9661, decode.d6.loss_dice: 1.0194, decode.d7.loss_cls: 0.0085, decode.d7.loss_mask: 0.9661, decode.d7.loss_dice: 1.0248, decode.d8.loss_cls: 0.0083, decode.d8.loss_mask: 0.9647, decode.d8.loss_dice: 1.0234, loss: 22.1857, grad_norm: 599.9970
2023-08-29 10:23:36,963 - mmseg - INFO - Iter [2400/160000]	lr: 1.658e-06, eta: 1 day, 7:35:18, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0190, decode.loss_mask: 0.9253, decode.loss_dice: 1.0255, decode.d0.loss_cls: 1.9555, decode.d0.loss_mask: 0.9635, decode.d0.loss_dice: 1.1291, decode.d1.loss_cls: 0.0410, decode.d1.loss_mask: 0.9208, decode.d1.loss_dice: 1.0336, decode.d2.loss_cls: 0.0348, decode.d2.loss_mask: 0.9233, decode.d2.loss_dice: 1.0203, decode.d3.loss_cls: 0.0206, decode.d3.loss_mask: 0.9209, decode.d3.loss_dice: 1.0177, decode.d4.loss_cls: 0.0209, decode.d4.loss_mask: 0.9170, decode.d4.loss_dice: 1.0243, decode.d5.loss_cls: 0.0206, decode.d5.loss_mask: 0.9297, decode.d5.loss_dice: 1.0097, decode.d6.loss_cls: 0.0200, decode.d6.loss_mask: 0.9203, decode.d6.loss_dice: 1.0164, decode.d7.loss_cls: 0.0197, decode.d7.loss_mask: 0.9220, decode.d7.loss_dice: 1.0215, decode.d8.loss_cls: 0.0185, decode.d8.loss_mask: 0.9273, decode.d8.loss_dice: 1.0236, loss: 21.7622, grad_norm: 517.2372
2023-08-29 10:24:13,740 - mmseg - INFO - Iter [2450/160000]	lr: 1.657e-06, eta: 1 day, 7:35:27, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0072, decode.loss_mask: 0.9855, decode.loss_dice: 1.1187, decode.d0.loss_cls: 1.9511, decode.d0.loss_mask: 1.0026, decode.d0.loss_dice: 1.2061, decode.d1.loss_cls: 0.0373, decode.d1.loss_mask: 0.9825, decode.d1.loss_dice: 1.1299, decode.d2.loss_cls: 0.0161, decode.d2.loss_mask: 0.9913, decode.d2.loss_dice: 1.1149, decode.d3.loss_cls: 0.0082, decode.d3.loss_mask: 0.9852, decode.d3.loss_dice: 1.1098, decode.d4.loss_cls: 0.0079, decode.d4.loss_mask: 0.9812, decode.d4.loss_dice: 1.1083, decode.d5.loss_cls: 0.0073, decode.d5.loss_mask: 0.9836, decode.d5.loss_dice: 1.1129, decode.d6.loss_cls: 0.0071, decode.d6.loss_mask: 0.9861, decode.d6.loss_dice: 1.1121, decode.d7.loss_cls: 0.0068, decode.d7.loss_mask: 0.9864, decode.d7.loss_dice: 1.1228, decode.d8.loss_cls: 0.0070, decode.d8.loss_mask: 0.9837, decode.d8.loss_dice: 1.1179, loss: 23.1775, grad_norm: 556.1903
2023-08-29 10:24:48,498 - mmseg - INFO - Iter [2500/160000]	lr: 1.657e-06, eta: 1 day, 7:33:27, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0051, decode.loss_mask: 0.8383, decode.loss_dice: 0.9506, decode.d0.loss_cls: 1.9422, decode.d0.loss_mask: 0.9011, decode.d0.loss_dice: 1.0700, decode.d1.loss_cls: 0.0294, decode.d1.loss_mask: 0.8462, decode.d1.loss_dice: 0.9727, decode.d2.loss_cls: 0.0143, decode.d2.loss_mask: 0.8389, decode.d2.loss_dice: 0.9535, decode.d3.loss_cls: 0.0065, decode.d3.loss_mask: 0.8351, decode.d3.loss_dice: 0.9455, decode.d4.loss_cls: 0.0064, decode.d4.loss_mask: 0.8350, decode.d4.loss_dice: 0.9487, decode.d5.loss_cls: 0.0058, decode.d5.loss_mask: 0.8342, decode.d5.loss_dice: 0.9492, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.8315, decode.d6.loss_dice: 0.9485, decode.d7.loss_cls: 0.0050, decode.d7.loss_mask: 0.8317, decode.d7.loss_dice: 0.9469, decode.d8.loss_cls: 0.0052, decode.d8.loss_mask: 0.8316, decode.d8.loss_dice: 0.9480, loss: 20.0822, grad_norm: 511.7864
2023-08-29 10:25:25,199 - mmseg - INFO - Iter [2550/160000]	lr: 1.656e-06, eta: 1 day, 7:33:30, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0050, decode.loss_mask: 0.8570, decode.loss_dice: 0.9676, decode.d0.loss_cls: 1.9364, decode.d0.loss_mask: 0.8957, decode.d0.loss_dice: 1.0787, decode.d1.loss_cls: 0.0294, decode.d1.loss_mask: 0.8728, decode.d1.loss_dice: 0.9945, decode.d2.loss_cls: 0.0143, decode.d2.loss_mask: 0.8698, decode.d2.loss_dice: 0.9743, decode.d3.loss_cls: 0.0063, decode.d3.loss_mask: 0.8577, decode.d3.loss_dice: 0.9697, decode.d4.loss_cls: 0.0064, decode.d4.loss_mask: 0.8663, decode.d4.loss_dice: 0.9673, decode.d5.loss_cls: 0.0056, decode.d5.loss_mask: 0.8655, decode.d5.loss_dice: 0.9630, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.8686, decode.d6.loss_dice: 0.9629, decode.d7.loss_cls: 0.0049, decode.d7.loss_mask: 0.8685, decode.d7.loss_dice: 0.9645, decode.d8.loss_cls: 0.0047, decode.d8.loss_mask: 0.8658, decode.d8.loss_dice: 0.9672, loss: 20.5153, grad_norm: 570.6697
2023-08-29 10:26:01,781 - mmseg - INFO - Iter [2600/160000]	lr: 1.656e-06, eta: 1 day, 7:33:25, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0061, decode.loss_mask: 0.8785, decode.loss_dice: 1.0089, decode.d0.loss_cls: 1.9299, decode.d0.loss_mask: 0.9251, decode.d0.loss_dice: 1.1307, decode.d1.loss_cls: 0.0283, decode.d1.loss_mask: 0.8956, decode.d1.loss_dice: 1.0552, decode.d2.loss_cls: 0.0146, decode.d2.loss_mask: 0.8803, decode.d2.loss_dice: 1.0204, decode.d3.loss_cls: 0.0073, decode.d3.loss_mask: 0.8755, decode.d3.loss_dice: 1.0098, decode.d4.loss_cls: 0.0071, decode.d4.loss_mask: 0.8706, decode.d4.loss_dice: 1.0063, decode.d5.loss_cls: 0.0067, decode.d5.loss_mask: 0.8664, decode.d5.loss_dice: 1.0066, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.8734, decode.d6.loss_dice: 1.0084, decode.d7.loss_cls: 0.0059, decode.d7.loss_mask: 0.8756, decode.d7.loss_dice: 1.0023, decode.d8.loss_cls: 0.0057, decode.d8.loss_mask: 0.8745, decode.d8.loss_dice: 1.0081, loss: 21.0896, grad_norm: 593.3646
2023-08-29 10:26:38,763 - mmseg - INFO - Iter [2650/160000]	lr: 1.655e-06, eta: 1 day, 7:33:42, time: 0.740, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0055, decode.loss_mask: 0.8750, decode.loss_dice: 0.9307, decode.d0.loss_cls: 1.9250, decode.d0.loss_mask: 0.9387, decode.d0.loss_dice: 1.0385, decode.d1.loss_cls: 0.0265, decode.d1.loss_mask: 0.8973, decode.d1.loss_dice: 0.9533, decode.d2.loss_cls: 0.0141, decode.d2.loss_mask: 0.8818, decode.d2.loss_dice: 0.9305, decode.d3.loss_cls: 0.0072, decode.d3.loss_mask: 0.8697, decode.d3.loss_dice: 0.9220, decode.d4.loss_cls: 0.0066, decode.d4.loss_mask: 0.8809, decode.d4.loss_dice: 0.9237, decode.d5.loss_cls: 0.0065, decode.d5.loss_mask: 0.8701, decode.d5.loss_dice: 0.9231, decode.d6.loss_cls: 0.0059, decode.d6.loss_mask: 0.8730, decode.d6.loss_dice: 0.9268, decode.d7.loss_cls: 0.0058, decode.d7.loss_mask: 0.8726, decode.d7.loss_dice: 0.9290, decode.d8.loss_cls: 0.0056, decode.d8.loss_mask: 0.8714, decode.d8.loss_dice: 0.9303, loss: 20.2466, grad_norm: 539.2670
2023-08-29 10:27:13,186 - mmseg - INFO - Iter [2700/160000]	lr: 1.655e-06, eta: 1 day, 7:31:27, time: 0.688, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0068, decode.loss_mask: 0.8911, decode.loss_dice: 0.9568, decode.d0.loss_cls: 1.9190, decode.d0.loss_mask: 0.9427, decode.d0.loss_dice: 1.0839, decode.d1.loss_cls: 0.0267, decode.d1.loss_mask: 0.9037, decode.d1.loss_dice: 0.9927, decode.d2.loss_cls: 0.0165, decode.d2.loss_mask: 0.8980, decode.d2.loss_dice: 0.9743, decode.d3.loss_cls: 0.0083, decode.d3.loss_mask: 0.8850, decode.d3.loss_dice: 0.9628, decode.d4.loss_cls: 0.0076, decode.d4.loss_mask: 0.8829, decode.d4.loss_dice: 0.9597, decode.d5.loss_cls: 0.0072, decode.d5.loss_mask: 0.8889, decode.d5.loss_dice: 0.9541, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.8929, decode.d6.loss_dice: 0.9600, decode.d7.loss_cls: 0.0067, decode.d7.loss_mask: 0.8943, decode.d7.loss_dice: 0.9652, decode.d8.loss_cls: 0.0065, decode.d8.loss_mask: 0.8945, decode.d8.loss_dice: 0.9632, loss: 20.7585, grad_norm: 676.5370
2023-08-29 10:27:49,639 - mmseg - INFO - Iter [2750/160000]	lr: 1.654e-06, eta: 1 day, 7:31:13, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0058, decode.loss_mask: 0.7789, decode.loss_dice: 0.9104, decode.d0.loss_cls: 1.9118, decode.d0.loss_mask: 0.8308, decode.d0.loss_dice: 1.0122, decode.d1.loss_cls: 0.0249, decode.d1.loss_mask: 0.7864, decode.d1.loss_dice: 0.9438, decode.d2.loss_cls: 0.0150, decode.d2.loss_mask: 0.7747, decode.d2.loss_dice: 0.9172, decode.d3.loss_cls: 0.0072, decode.d3.loss_mask: 0.7667, decode.d3.loss_dice: 0.9117, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.7721, decode.d4.loss_dice: 0.9169, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.7718, decode.d5.loss_dice: 0.9036, decode.d6.loss_cls: 0.0063, decode.d6.loss_mask: 0.7709, decode.d6.loss_dice: 0.9128, decode.d7.loss_cls: 0.0061, decode.d7.loss_mask: 0.7734, decode.d7.loss_dice: 0.9108, decode.d8.loss_cls: 0.0059, decode.d8.loss_mask: 0.7733, decode.d8.loss_dice: 0.9129, loss: 19.0480, grad_norm: 588.8530
2023-08-29 10:28:26,245 - mmseg - INFO - Iter [2800/160000]	lr: 1.654e-06, eta: 1 day, 7:31:07, time: 0.732, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0077, decode.loss_mask: 0.8715, decode.loss_dice: 0.9726, decode.d0.loss_cls: 1.9072, decode.d0.loss_mask: 0.9358, decode.d0.loss_dice: 1.0789, decode.d1.loss_cls: 0.0251, decode.d1.loss_mask: 0.8741, decode.d1.loss_dice: 0.9927, decode.d2.loss_cls: 0.0152, decode.d2.loss_mask: 0.8704, decode.d2.loss_dice: 0.9726, decode.d3.loss_cls: 0.0088, decode.d3.loss_mask: 0.8573, decode.d3.loss_dice: 0.9673, decode.d4.loss_cls: 0.0082, decode.d4.loss_mask: 0.8645, decode.d4.loss_dice: 0.9639, decode.d5.loss_cls: 0.0080, decode.d5.loss_mask: 0.8636, decode.d5.loss_dice: 0.9596, decode.d6.loss_cls: 0.0076, decode.d6.loss_mask: 0.8700, decode.d6.loss_dice: 0.9565, decode.d7.loss_cls: 0.0073, decode.d7.loss_mask: 0.8742, decode.d7.loss_dice: 0.9705, decode.d8.loss_cls: 0.0072, decode.d8.loss_mask: 0.8731, decode.d8.loss_dice: 0.9653, loss: 20.5565, grad_norm: 606.3049
2023-08-29 10:29:03,206 - mmseg - INFO - Iter [2850/160000]	lr: 1.653e-06, eta: 1 day, 7:31:19, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0053, decode.loss_mask: 0.8084, decode.loss_dice: 0.8852, decode.d0.loss_cls: 1.8990, decode.d0.loss_mask: 0.8780, decode.d0.loss_dice: 1.0112, decode.d1.loss_cls: 0.0229, decode.d1.loss_mask: 0.8295, decode.d1.loss_dice: 0.9220, decode.d2.loss_cls: 0.0139, decode.d2.loss_mask: 0.8279, decode.d2.loss_dice: 0.8934, decode.d3.loss_cls: 0.0073, decode.d3.loss_mask: 0.8141, decode.d3.loss_dice: 0.8927, decode.d4.loss_cls: 0.0068, decode.d4.loss_mask: 0.8144, decode.d4.loss_dice: 0.8864, decode.d5.loss_cls: 0.0068, decode.d5.loss_mask: 0.8149, decode.d5.loss_dice: 0.8811, decode.d6.loss_cls: 0.0060, decode.d6.loss_mask: 0.8135, decode.d6.loss_dice: 0.8782, decode.d7.loss_cls: 0.0056, decode.d7.loss_mask: 0.8056, decode.d7.loss_dice: 0.8799, decode.d8.loss_cls: 0.0056, decode.d8.loss_mask: 0.8087, decode.d8.loss_dice: 0.8790, loss: 19.2033, grad_norm: 595.2171
2023-08-29 10:29:38,059 - mmseg - INFO - Iter [2900/160000]	lr: 1.653e-06, eta: 1 day, 7:29:34, time: 0.697, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0045, decode.loss_mask: 0.8038, decode.loss_dice: 0.8884, decode.d0.loss_cls: 1.8913, decode.d0.loss_mask: 0.8420, decode.d0.loss_dice: 1.0028, decode.d1.loss_cls: 0.0221, decode.d1.loss_mask: 0.8135, decode.d1.loss_dice: 0.9199, decode.d2.loss_cls: 0.0127, decode.d2.loss_mask: 0.8078, decode.d2.loss_dice: 0.8946, decode.d3.loss_cls: 0.0064, decode.d3.loss_mask: 0.7979, decode.d3.loss_dice: 0.8872, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.8039, decode.d4.loss_dice: 0.8855, decode.d5.loss_cls: 0.0056, decode.d5.loss_mask: 0.7985, decode.d5.loss_dice: 0.8797, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.8018, decode.d6.loss_dice: 0.8790, decode.d7.loss_cls: 0.0045, decode.d7.loss_mask: 0.8064, decode.d7.loss_dice: 0.8884, decode.d8.loss_cls: 0.0044, decode.d8.loss_mask: 0.8033, decode.d8.loss_dice: 0.8877, loss: 19.0544, grad_norm: 599.8198
2023-08-29 10:30:14,606 - mmseg - INFO - Iter [2950/160000]	lr: 1.652e-06, eta: 1 day, 7:29:23, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0049, decode.loss_mask: 0.8035, decode.loss_dice: 0.8936, decode.d0.loss_cls: 1.8847, decode.d0.loss_mask: 0.8451, decode.d0.loss_dice: 0.9924, decode.d1.loss_cls: 0.0215, decode.d1.loss_mask: 0.8050, decode.d1.loss_dice: 0.9129, decode.d2.loss_cls: 0.0133, decode.d2.loss_mask: 0.8017, decode.d2.loss_dice: 0.9089, decode.d3.loss_cls: 0.0069, decode.d3.loss_mask: 0.7969, decode.d3.loss_dice: 0.8939, decode.d4.loss_cls: 0.0065, decode.d4.loss_mask: 0.8011, decode.d4.loss_dice: 0.8922, decode.d5.loss_cls: 0.0058, decode.d5.loss_mask: 0.7932, decode.d5.loss_dice: 0.8954, decode.d6.loss_cls: 0.0051, decode.d6.loss_mask: 0.7975, decode.d6.loss_dice: 0.8951, decode.d7.loss_cls: 0.0049, decode.d7.loss_mask: 0.7939, decode.d7.loss_dice: 0.8952, decode.d8.loss_cls: 0.0049, decode.d8.loss_mask: 0.8005, decode.d8.loss_dice: 0.8859, loss: 19.0623, grad_norm: 549.9415
2023-08-29 10:30:50,916 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-08-29 10:30:53,257 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 10:30:53,258 - mmseg - INFO - Iter [3000/160000]	lr: 1.652e-06, eta: 1 day, 7:31:01, time: 0.773, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0109, decode.loss_mask: 0.8091, decode.loss_dice: 0.8873, decode.d0.loss_cls: 1.8769, decode.d0.loss_mask: 0.8815, decode.d0.loss_dice: 1.0068, decode.d1.loss_cls: 0.0260, decode.d1.loss_mask: 0.8276, decode.d1.loss_dice: 0.9333, decode.d2.loss_cls: 0.0189, decode.d2.loss_mask: 0.8256, decode.d2.loss_dice: 0.9108, decode.d3.loss_cls: 0.0126, decode.d3.loss_mask: 0.8098, decode.d3.loss_dice: 0.8970, decode.d4.loss_cls: 0.0120, decode.d4.loss_mask: 0.8033, decode.d4.loss_dice: 0.8930, decode.d5.loss_cls: 0.0116, decode.d5.loss_mask: 0.8060, decode.d5.loss_dice: 0.8932, decode.d6.loss_cls: 0.0107, decode.d6.loss_mask: 0.8001, decode.d6.loss_dice: 0.8891, decode.d7.loss_cls: 0.0102, decode.d7.loss_mask: 0.8089, decode.d7.loss_dice: 0.8947, decode.d8.loss_cls: 0.0105, decode.d8.loss_mask: 0.8112, decode.d8.loss_dice: 0.8852, loss: 19.2739, grad_norm: 570.6350
2023-08-29 10:31:30,189 - mmseg - INFO - Iter [3050/160000]	lr: 1.651e-06, eta: 1 day, 7:31:06, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0120, decode.loss_mask: 0.7881, decode.loss_dice: 0.8806, decode.d0.loss_cls: 1.8698, decode.d0.loss_mask: 0.8269, decode.d0.loss_dice: 0.9835, decode.d1.loss_cls: 0.0266, decode.d1.loss_mask: 0.7938, decode.d1.loss_dice: 0.9035, decode.d2.loss_cls: 0.0125, decode.d2.loss_mask: 0.7950, decode.d2.loss_dice: 0.8887, decode.d3.loss_cls: 0.0063, decode.d3.loss_mask: 0.7871, decode.d3.loss_dice: 0.8786, decode.d4.loss_cls: 0.0061, decode.d4.loss_mask: 0.7920, decode.d4.loss_dice: 0.8802, decode.d5.loss_cls: 0.0117, decode.d5.loss_mask: 0.7839, decode.d5.loss_dice: 0.8657, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.7870, decode.d6.loss_dice: 0.8768, decode.d7.loss_cls: 0.0049, decode.d7.loss_mask: 0.7837, decode.d7.loss_dice: 0.8781, decode.d8.loss_cls: 0.0106, decode.d8.loss_mask: 0.7846, decode.d8.loss_dice: 0.8748, loss: 18.7980, grad_norm: 552.1030
2023-08-29 10:32:04,843 - mmseg - INFO - Iter [3100/160000]	lr: 1.651e-06, eta: 1 day, 7:29:14, time: 0.693, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0061, decode.loss_mask: 0.7856, decode.loss_dice: 0.8363, decode.d0.loss_cls: 1.8643, decode.d0.loss_mask: 0.8509, decode.d0.loss_dice: 0.9502, decode.d1.loss_cls: 0.0203, decode.d1.loss_mask: 0.7942, decode.d1.loss_dice: 0.8728, decode.d2.loss_cls: 0.0119, decode.d2.loss_mask: 0.7927, decode.d2.loss_dice: 0.8517, decode.d3.loss_cls: 0.0070, decode.d3.loss_mask: 0.7857, decode.d3.loss_dice: 0.8426, decode.d4.loss_cls: 0.0069, decode.d4.loss_mask: 0.7887, decode.d4.loss_dice: 0.8367, decode.d5.loss_cls: 0.0066, decode.d5.loss_mask: 0.7816, decode.d5.loss_dice: 0.8360, decode.d6.loss_cls: 0.0060, decode.d6.loss_mask: 0.7862, decode.d6.loss_dice: 0.8354, decode.d7.loss_cls: 0.0062, decode.d7.loss_mask: 0.7802, decode.d7.loss_dice: 0.8357, decode.d8.loss_cls: 0.0062, decode.d8.loss_mask: 0.7765, decode.d8.loss_dice: 0.8330, loss: 18.3941, grad_norm: 502.4460
2023-08-29 10:32:41,328 - mmseg - INFO - Iter [3150/160000]	lr: 1.650e-06, eta: 1 day, 7:28:55, time: 0.729, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0193, decode.loss_mask: 0.8127, decode.loss_dice: 0.8373, decode.d0.loss_cls: 1.8551, decode.d0.loss_mask: 0.8129, decode.d0.loss_dice: 0.9357, decode.d1.loss_cls: 0.0268, decode.d1.loss_mask: 0.8029, decode.d1.loss_dice: 0.8522, decode.d2.loss_cls: 0.0237, decode.d2.loss_mask: 0.7948, decode.d2.loss_dice: 0.8303, decode.d3.loss_cls: 0.0195, decode.d3.loss_mask: 0.7888, decode.d3.loss_dice: 0.8267, decode.d4.loss_cls: 0.0259, decode.d4.loss_mask: 0.7875, decode.d4.loss_dice: 0.8226, decode.d5.loss_cls: 0.0189, decode.d5.loss_mask: 0.7989, decode.d5.loss_dice: 0.8239, decode.d6.loss_cls: 0.0176, decode.d6.loss_mask: 0.8032, decode.d6.loss_dice: 0.8288, decode.d7.loss_cls: 0.0173, decode.d7.loss_mask: 0.7997, decode.d7.loss_dice: 0.8414, decode.d8.loss_cls: 0.0175, decode.d8.loss_mask: 0.8087, decode.d8.loss_dice: 0.8337, loss: 18.4845, grad_norm: 532.9437
2023-08-29 10:33:17,776 - mmseg - INFO - Iter [3200/160000]	lr: 1.650e-06, eta: 1 day, 7:28:36, time: 0.729, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0065, decode.loss_mask: 0.7886, decode.loss_dice: 0.8736, decode.d0.loss_cls: 1.8498, decode.d0.loss_mask: 0.8283, decode.d0.loss_dice: 0.9827, decode.d1.loss_cls: 0.0199, decode.d1.loss_mask: 0.8072, decode.d1.loss_dice: 0.8991, decode.d2.loss_cls: 0.0120, decode.d2.loss_mask: 0.7871, decode.d2.loss_dice: 0.8705, decode.d3.loss_cls: 0.0076, decode.d3.loss_mask: 0.7813, decode.d3.loss_dice: 0.8689, decode.d4.loss_cls: 0.0075, decode.d4.loss_mask: 0.7778, decode.d4.loss_dice: 0.8703, decode.d5.loss_cls: 0.0071, decode.d5.loss_mask: 0.7819, decode.d5.loss_dice: 0.8697, decode.d6.loss_cls: 0.0068, decode.d6.loss_mask: 0.7789, decode.d6.loss_dice: 0.8680, decode.d7.loss_cls: 0.0060, decode.d7.loss_mask: 0.7773, decode.d7.loss_dice: 0.8714, decode.d8.loss_cls: 0.0066, decode.d8.loss_mask: 0.7822, decode.d8.loss_dice: 0.8761, loss: 18.6707, grad_norm: 623.6660
2023-08-29 10:33:54,860 - mmseg - INFO - Iter [3250/160000]	lr: 1.649e-06, eta: 1 day, 7:28:45, time: 0.742, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0036, decode.loss_mask: 0.7905, decode.loss_dice: 0.8308, decode.d0.loss_cls: 1.8405, decode.d0.loss_mask: 0.8297, decode.d0.loss_dice: 0.9275, decode.d1.loss_cls: 0.0175, decode.d1.loss_mask: 0.8031, decode.d1.loss_dice: 0.8600, decode.d2.loss_cls: 0.0102, decode.d2.loss_mask: 0.8021, decode.d2.loss_dice: 0.8379, decode.d3.loss_cls: 0.0054, decode.d3.loss_mask: 0.8001, decode.d3.loss_dice: 0.8292, decode.d4.loss_cls: 0.0051, decode.d4.loss_mask: 0.7940, decode.d4.loss_dice: 0.8252, decode.d5.loss_cls: 0.0044, decode.d5.loss_mask: 0.7956, decode.d5.loss_dice: 0.8264, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.7999, decode.d6.loss_dice: 0.8274, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.7995, decode.d7.loss_dice: 0.8328, decode.d8.loss_cls: 0.0037, decode.d8.loss_mask: 0.7950, decode.d8.loss_dice: 0.8337, loss: 18.3383, grad_norm: 554.4836
2023-08-29 10:34:29,867 - mmseg - INFO - Iter [3300/160000]	lr: 1.649e-06, eta: 1 day, 7:27:14, time: 0.700, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0251, decode.loss_mask: 0.7884, decode.loss_dice: 0.8389, decode.d0.loss_cls: 1.8365, decode.d0.loss_mask: 0.8425, decode.d0.loss_dice: 0.9466, decode.d1.loss_cls: 0.0328, decode.d1.loss_mask: 0.8068, decode.d1.loss_dice: 0.8611, decode.d2.loss_cls: 0.0292, decode.d2.loss_mask: 0.7976, decode.d2.loss_dice: 0.8445, decode.d3.loss_cls: 0.0265, decode.d3.loss_mask: 0.7950, decode.d3.loss_dice: 0.8327, decode.d4.loss_cls: 0.0237, decode.d4.loss_mask: 0.7908, decode.d4.loss_dice: 0.8337, decode.d5.loss_cls: 0.0245, decode.d5.loss_mask: 0.7913, decode.d5.loss_dice: 0.8331, decode.d6.loss_cls: 0.0251, decode.d6.loss_mask: 0.7968, decode.d6.loss_dice: 0.8309, decode.d7.loss_cls: 0.0245, decode.d7.loss_mask: 0.7897, decode.d7.loss_dice: 0.8378, decode.d8.loss_cls: 0.0248, decode.d8.loss_mask: 0.7936, decode.d8.loss_dice: 0.8345, loss: 18.5590, grad_norm: 542.9299
2023-08-29 10:35:06,549 - mmseg - INFO - Iter [3350/160000]	lr: 1.648e-06, eta: 1 day, 7:27:04, time: 0.734, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.7327, decode.loss_dice: 0.7687, decode.d0.loss_cls: 1.8253, decode.d0.loss_mask: 0.8017, decode.d0.loss_dice: 0.8845, decode.d1.loss_cls: 0.0165, decode.d1.loss_mask: 0.7341, decode.d1.loss_dice: 0.7989, decode.d2.loss_cls: 0.0094, decode.d2.loss_mask: 0.7285, decode.d2.loss_dice: 0.7810, decode.d3.loss_cls: 0.0049, decode.d3.loss_mask: 0.7256, decode.d3.loss_dice: 0.7706, decode.d4.loss_cls: 0.0049, decode.d4.loss_mask: 0.7234, decode.d4.loss_dice: 0.7657, decode.d5.loss_cls: 0.0043, decode.d5.loss_mask: 0.7276, decode.d5.loss_dice: 0.7633, decode.d6.loss_cls: 0.0037, decode.d6.loss_mask: 0.7266, decode.d6.loss_dice: 0.7618, decode.d7.loss_cls: 0.0033, decode.d7.loss_mask: 0.7279, decode.d7.loss_dice: 0.7652, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.7322, decode.d8.loss_dice: 0.7698, loss: 17.0691, grad_norm: 451.1562
2023-08-29 10:35:42,848 - mmseg - INFO - Iter [3400/160000]	lr: 1.647e-06, eta: 1 day, 7:26:36, time: 0.726, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0046, decode.loss_mask: 0.8006, decode.loss_dice: 0.8210, decode.d0.loss_cls: 1.8188, decode.d0.loss_mask: 0.8267, decode.d0.loss_dice: 0.9007, decode.d1.loss_cls: 0.0233, decode.d1.loss_mask: 0.7911, decode.d1.loss_dice: 0.8322, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 0.7920, decode.d2.loss_dice: 0.8248, decode.d3.loss_cls: 0.0060, decode.d3.loss_mask: 0.7985, decode.d3.loss_dice: 0.8146, decode.d4.loss_cls: 0.0058, decode.d4.loss_mask: 0.7993, decode.d4.loss_dice: 0.8127, decode.d5.loss_cls: 0.0122, decode.d5.loss_mask: 0.7968, decode.d5.loss_dice: 0.8145, decode.d6.loss_cls: 0.0115, decode.d6.loss_mask: 0.7971, decode.d6.loss_dice: 0.8160, decode.d7.loss_cls: 0.0092, decode.d7.loss_mask: 0.8004, decode.d7.loss_dice: 0.8100, decode.d8.loss_cls: 0.0148, decode.d8.loss_mask: 0.7883, decode.d8.loss_dice: 0.8124, loss: 18.1655, grad_norm: 527.6330
2023-08-29 10:36:19,774 - mmseg - INFO - Iter [3450/160000]	lr: 1.647e-06, eta: 1 day, 7:26:35, time: 0.738, data_time: 0.050, memory: 6584, decode.loss_cls: 0.0070, decode.loss_mask: 0.7729, decode.loss_dice: 0.8077, decode.d0.loss_cls: 1.8136, decode.d0.loss_mask: 0.8029, decode.d0.loss_dice: 0.9068, decode.d1.loss_cls: 0.0175, decode.d1.loss_mask: 0.7917, decode.d1.loss_dice: 0.8469, decode.d2.loss_cls: 0.0110, decode.d2.loss_mask: 0.7717, decode.d2.loss_dice: 0.8250, decode.d3.loss_cls: 0.0072, decode.d3.loss_mask: 0.7677, decode.d3.loss_dice: 0.8083, decode.d4.loss_cls: 0.0072, decode.d4.loss_mask: 0.7683, decode.d4.loss_dice: 0.8068, decode.d5.loss_cls: 0.0070, decode.d5.loss_mask: 0.7666, decode.d5.loss_dice: 0.8114, decode.d6.loss_cls: 0.0066, decode.d6.loss_mask: 0.7662, decode.d6.loss_dice: 0.8088, decode.d7.loss_cls: 0.0063, decode.d7.loss_mask: 0.7657, decode.d7.loss_dice: 0.8065, decode.d8.loss_cls: 0.0066, decode.d8.loss_mask: 0.7664, decode.d8.loss_dice: 0.8025, loss: 17.8606, grad_norm: 566.3047
2023-08-29 10:36:56,921 - mmseg - INFO - Iter [3500/160000]	lr: 1.646e-06, eta: 1 day, 7:26:43, time: 0.743, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0049, decode.loss_mask: 0.7366, decode.loss_dice: 0.7609, decode.d0.loss_cls: 1.8035, decode.d0.loss_mask: 0.7827, decode.d0.loss_dice: 0.8563, decode.d1.loss_cls: 0.0222, decode.d1.loss_mask: 0.7312, decode.d1.loss_dice: 0.7772, decode.d2.loss_cls: 0.0093, decode.d2.loss_mask: 0.7219, decode.d2.loss_dice: 0.7666, decode.d3.loss_cls: 0.0057, decode.d3.loss_mask: 0.7245, decode.d3.loss_dice: 0.7591, decode.d4.loss_cls: 0.0057, decode.d4.loss_mask: 0.7334, decode.d4.loss_dice: 0.7577, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.7306, decode.d5.loss_dice: 0.7594, decode.d6.loss_cls: 0.0050, decode.d6.loss_mask: 0.7327, decode.d6.loss_dice: 0.7563, decode.d7.loss_cls: 0.0048, decode.d7.loss_mask: 0.7311, decode.d7.loss_dice: 0.7580, decode.d8.loss_cls: 0.0049, decode.d8.loss_mask: 0.7345, decode.d8.loss_dice: 0.7563, loss: 16.9384, grad_norm: 512.5355
2023-08-29 10:37:31,493 - mmseg - INFO - Iter [3550/160000]	lr: 1.646e-06, eta: 1 day, 7:24:57, time: 0.691, data_time: 0.004, memory: 6584, decode.loss_cls: 0.0340, decode.loss_mask: 0.7831, decode.loss_dice: 0.8281, decode.d0.loss_cls: 1.7974, decode.d0.loss_mask: 0.8096, decode.d0.loss_dice: 0.9270, decode.d1.loss_cls: 0.0364, decode.d1.loss_mask: 0.7762, decode.d1.loss_dice: 0.8468, decode.d2.loss_cls: 0.0342, decode.d2.loss_mask: 0.7627, decode.d2.loss_dice: 0.8327, decode.d3.loss_cls: 0.0329, decode.d3.loss_mask: 0.7607, decode.d3.loss_dice: 0.8186, decode.d4.loss_cls: 0.0333, decode.d4.loss_mask: 0.7572, decode.d4.loss_dice: 0.8149, decode.d5.loss_cls: 0.0332, decode.d5.loss_mask: 0.7592, decode.d5.loss_dice: 0.8185, decode.d6.loss_cls: 0.0316, decode.d6.loss_mask: 0.7669, decode.d6.loss_dice: 0.8177, decode.d7.loss_cls: 0.0315, decode.d7.loss_mask: 0.7642, decode.d7.loss_dice: 0.8307, decode.d8.loss_cls: 0.0328, decode.d8.loss_mask: 0.7783, decode.d8.loss_dice: 0.8264, loss: 18.1767, grad_norm: 560.0083
2023-08-29 10:38:07,994 - mmseg - INFO - Iter [3600/160000]	lr: 1.645e-06, eta: 1 day, 7:24:36, time: 0.730, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0197, decode.loss_mask: 0.7889, decode.loss_dice: 0.8571, decode.d0.loss_cls: 1.7892, decode.d0.loss_mask: 0.8217, decode.d0.loss_dice: 0.9477, decode.d1.loss_cls: 0.0340, decode.d1.loss_mask: 0.7809, decode.d1.loss_dice: 0.8768, decode.d2.loss_cls: 0.0290, decode.d2.loss_mask: 0.7681, decode.d2.loss_dice: 0.8600, decode.d3.loss_cls: 0.0262, decode.d3.loss_mask: 0.7653, decode.d3.loss_dice: 0.8553, decode.d4.loss_cls: 0.0190, decode.d4.loss_mask: 0.7788, decode.d4.loss_dice: 0.8617, decode.d5.loss_cls: 0.0194, decode.d5.loss_mask: 0.7856, decode.d5.loss_dice: 0.8548, decode.d6.loss_cls: 0.0183, decode.d6.loss_mask: 0.7857, decode.d6.loss_dice: 0.8524, decode.d7.loss_cls: 0.0184, decode.d7.loss_mask: 0.7793, decode.d7.loss_dice: 0.8566, decode.d8.loss_cls: 0.0198, decode.d8.loss_mask: 0.7870, decode.d8.loss_dice: 0.8529, loss: 18.5094, grad_norm: 576.5348
2023-08-29 10:38:44,907 - mmseg - INFO - Iter [3650/160000]	lr: 1.645e-06, eta: 1 day, 7:24:33, time: 0.738, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0056, decode.loss_mask: 0.7767, decode.loss_dice: 0.8348, decode.d0.loss_cls: 1.7811, decode.d0.loss_mask: 0.8081, decode.d0.loss_dice: 0.9196, decode.d1.loss_cls: 0.0164, decode.d1.loss_mask: 0.7778, decode.d1.loss_dice: 0.8514, decode.d2.loss_cls: 0.0098, decode.d2.loss_mask: 0.7614, decode.d2.loss_dice: 0.8364, decode.d3.loss_cls: 0.0063, decode.d3.loss_mask: 0.7620, decode.d3.loss_dice: 0.8240, decode.d4.loss_cls: 0.0059, decode.d4.loss_mask: 0.7680, decode.d4.loss_dice: 0.8279, decode.d5.loss_cls: 0.0053, decode.d5.loss_mask: 0.7685, decode.d5.loss_dice: 0.8262, decode.d6.loss_cls: 0.0053, decode.d6.loss_mask: 0.7679, decode.d6.loss_dice: 0.8246, decode.d7.loss_cls: 0.0049, decode.d7.loss_mask: 0.7681, decode.d7.loss_dice: 0.8338, decode.d8.loss_cls: 0.0054, decode.d8.loss_mask: 0.7686, decode.d8.loss_dice: 0.8325, loss: 17.9846, grad_norm: 525.3943
2023-08-29 10:39:21,946 - mmseg - INFO - Iter [3700/160000]	lr: 1.644e-06, eta: 1 day, 7:24:34, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0090, decode.loss_mask: 0.7289, decode.loss_dice: 0.8011, decode.d0.loss_cls: 1.7724, decode.d0.loss_mask: 0.7609, decode.d0.loss_dice: 0.8892, decode.d1.loss_cls: 0.0210, decode.d1.loss_mask: 0.7466, decode.d1.loss_dice: 0.8278, decode.d2.loss_cls: 0.0083, decode.d2.loss_mask: 0.7381, decode.d2.loss_dice: 0.8059, decode.d3.loss_cls: 0.0118, decode.d3.loss_mask: 0.7221, decode.d3.loss_dice: 0.7906, decode.d4.loss_cls: 0.0102, decode.d4.loss_mask: 0.7232, decode.d4.loss_dice: 0.8000, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.7336, decode.d5.loss_dice: 0.8053, decode.d6.loss_cls: 0.0034, decode.d6.loss_mask: 0.7374, decode.d6.loss_dice: 0.8020, decode.d7.loss_cls: 0.0029, decode.d7.loss_mask: 0.7369, decode.d7.loss_dice: 0.8099, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.7420, decode.d8.loss_dice: 0.8020, loss: 17.3495, grad_norm: 526.5096
2023-08-29 10:39:56,662 - mmseg - INFO - Iter [3750/160000]	lr: 1.644e-06, eta: 1 day, 7:22:57, time: 0.694, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0042, decode.loss_mask: 0.7204, decode.loss_dice: 0.7876, decode.d0.loss_cls: 1.7674, decode.d0.loss_mask: 0.7371, decode.d0.loss_dice: 0.8725, decode.d1.loss_cls: 0.0215, decode.d1.loss_mask: 0.7235, decode.d1.loss_dice: 0.8147, decode.d2.loss_cls: 0.0087, decode.d2.loss_mask: 0.7250, decode.d2.loss_dice: 0.7964, decode.d3.loss_cls: 0.0055, decode.d3.loss_mask: 0.7222, decode.d3.loss_dice: 0.7884, decode.d4.loss_cls: 0.0051, decode.d4.loss_mask: 0.7144, decode.d4.loss_dice: 0.7839, decode.d5.loss_cls: 0.0048, decode.d5.loss_mask: 0.7193, decode.d5.loss_dice: 0.7813, decode.d6.loss_cls: 0.0046, decode.d6.loss_mask: 0.7203, decode.d6.loss_dice: 0.7848, decode.d7.loss_cls: 0.0042, decode.d7.loss_mask: 0.7198, decode.d7.loss_dice: 0.7857, decode.d8.loss_cls: 0.0042, decode.d8.loss_mask: 0.7174, decode.d8.loss_dice: 0.7839, loss: 17.0288, grad_norm: 571.5018
2023-08-29 10:40:32,933 - mmseg - INFO - Iter [3800/160000]	lr: 1.643e-06, eta: 1 day, 7:22:25, time: 0.725, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.6999, decode.loss_dice: 0.7539, decode.d0.loss_cls: 1.7578, decode.d0.loss_mask: 0.7262, decode.d0.loss_dice: 0.8433, decode.d1.loss_cls: 0.0144, decode.d1.loss_mask: 0.7021, decode.d1.loss_dice: 0.7720, decode.d2.loss_cls: 0.0079, decode.d2.loss_mask: 0.6981, decode.d2.loss_dice: 0.7564, decode.d3.loss_cls: 0.0050, decode.d3.loss_mask: 0.6948, decode.d3.loss_dice: 0.7482, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.6954, decode.d4.loss_dice: 0.7473, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.6970, decode.d5.loss_dice: 0.7464, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.7001, decode.d6.loss_dice: 0.7516, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.6993, decode.d7.loss_dice: 0.7534, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.6977, decode.d8.loss_dice: 0.7534, loss: 16.4445, grad_norm: 530.8446
2023-08-29 10:41:09,781 - mmseg - INFO - Iter [3850/160000]	lr: 1.643e-06, eta: 1 day, 7:22:17, time: 0.737, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0184, decode.loss_mask: 0.6774, decode.loss_dice: 0.7504, decode.d0.loss_cls: 1.7489, decode.d0.loss_mask: 0.7296, decode.d0.loss_dice: 0.8566, decode.d1.loss_cls: 0.0258, decode.d1.loss_mask: 0.6773, decode.d1.loss_dice: 0.7771, decode.d2.loss_cls: 0.0218, decode.d2.loss_mask: 0.6666, decode.d2.loss_dice: 0.7583, decode.d3.loss_cls: 0.0193, decode.d3.loss_mask: 0.6639, decode.d3.loss_dice: 0.7505, decode.d4.loss_cls: 0.0175, decode.d4.loss_mask: 0.6659, decode.d4.loss_dice: 0.7518, decode.d5.loss_cls: 0.0177, decode.d5.loss_mask: 0.6764, decode.d5.loss_dice: 0.7585, decode.d6.loss_cls: 0.0164, decode.d6.loss_mask: 0.6744, decode.d6.loss_dice: 0.7506, decode.d7.loss_cls: 0.0151, decode.d7.loss_mask: 0.6729, decode.d7.loss_dice: 0.7553, decode.d8.loss_cls: 0.0159, decode.d8.loss_mask: 0.6725, decode.d8.loss_dice: 0.7494, loss: 16.3521, grad_norm: 498.0514
2023-08-29 10:41:46,942 - mmseg - INFO - Iter [3900/160000]	lr: 1.642e-06, eta: 1 day, 7:22:21, time: 0.743, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0038, decode.loss_mask: 0.7587, decode.loss_dice: 0.8264, decode.d0.loss_cls: 1.7420, decode.d0.loss_mask: 0.7970, decode.d0.loss_dice: 0.9020, decode.d1.loss_cls: 0.0133, decode.d1.loss_mask: 0.7627, decode.d1.loss_dice: 0.8288, decode.d2.loss_cls: 0.0075, decode.d2.loss_mask: 0.7509, decode.d2.loss_dice: 0.8172, decode.d3.loss_cls: 0.0046, decode.d3.loss_mask: 0.7543, decode.d3.loss_dice: 0.8138, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.7496, decode.d4.loss_dice: 0.8152, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.7504, decode.d5.loss_dice: 0.8146, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.7556, decode.d6.loss_dice: 0.8184, decode.d7.loss_cls: 0.0032, decode.d7.loss_mask: 0.7537, decode.d7.loss_dice: 0.8206, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.7564, decode.d8.loss_dice: 0.8194, loss: 17.6553, grad_norm: 519.4757
2023-08-29 10:42:21,705 - mmseg - INFO - Iter [3950/160000]	lr: 1.642e-06, eta: 1 day, 7:20:49, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0200, decode.loss_mask: 0.7232, decode.loss_dice: 0.7359, decode.d0.loss_cls: 1.7344, decode.d0.loss_mask: 0.7521, decode.d0.loss_dice: 0.8249, decode.d1.loss_cls: 0.0256, decode.d1.loss_mask: 0.7258, decode.d1.loss_dice: 0.7610, decode.d2.loss_cls: 0.0204, decode.d2.loss_mask: 0.7117, decode.d2.loss_dice: 0.7392, decode.d3.loss_cls: 0.0182, decode.d3.loss_mask: 0.7158, decode.d3.loss_dice: 0.7325, decode.d4.loss_cls: 0.0185, decode.d4.loss_mask: 0.7129, decode.d4.loss_dice: 0.7309, decode.d5.loss_cls: 0.0166, decode.d5.loss_mask: 0.7146, decode.d5.loss_dice: 0.7380, decode.d6.loss_cls: 0.0111, decode.d6.loss_mask: 0.7405, decode.d6.loss_dice: 0.7336, decode.d7.loss_cls: 0.0189, decode.d7.loss_mask: 0.7216, decode.d7.loss_dice: 0.7379, decode.d8.loss_cls: 0.0190, decode.d8.loss_mask: 0.7209, decode.d8.loss_dice: 0.7369, loss: 16.6126, grad_norm: 617.8063
2023-08-29 10:42:58,076 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-08-29 10:43:01,148 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 10:43:01,149 - mmseg - INFO - Iter [4000/160000]	lr: 1.641e-06, eta: 1 day, 7:22:21, time: 0.789, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0045, decode.loss_mask: 0.6664, decode.loss_dice: 0.7224, decode.d0.loss_cls: 1.7266, decode.d0.loss_mask: 0.6793, decode.d0.loss_dice: 0.8032, decode.d1.loss_cls: 0.0136, decode.d1.loss_mask: 0.6512, decode.d1.loss_dice: 0.7357, decode.d2.loss_cls: 0.0089, decode.d2.loss_mask: 0.6501, decode.d2.loss_dice: 0.7255, decode.d3.loss_cls: 0.0059, decode.d3.loss_mask: 0.6512, decode.d3.loss_dice: 0.7233, decode.d4.loss_cls: 0.0055, decode.d4.loss_mask: 0.6566, decode.d4.loss_dice: 0.7199, decode.d5.loss_cls: 0.0049, decode.d5.loss_mask: 0.6590, decode.d5.loss_dice: 0.7198, decode.d6.loss_cls: 0.0048, decode.d6.loss_mask: 0.6626, decode.d6.loss_dice: 0.7220, decode.d7.loss_cls: 0.0043, decode.d7.loss_mask: 0.6653, decode.d7.loss_dice: 0.7146, decode.d8.loss_cls: 0.0043, decode.d8.loss_mask: 0.6680, decode.d8.loss_dice: 0.7182, loss: 15.6975, grad_norm: 520.2285
2023-08-29 10:43:37,865 - mmseg - INFO - Iter [4050/160000]	lr: 1.641e-06, eta: 1 day, 7:22:05, time: 0.734, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.7508, decode.loss_dice: 0.7781, decode.d0.loss_cls: 1.7178, decode.d0.loss_mask: 0.7858, decode.d0.loss_dice: 0.8584, decode.d1.loss_cls: 0.0183, decode.d1.loss_mask: 0.7447, decode.d1.loss_dice: 0.7920, decode.d2.loss_cls: 0.0074, decode.d2.loss_mask: 0.7476, decode.d2.loss_dice: 0.7768, decode.d3.loss_cls: 0.0043, decode.d3.loss_mask: 0.7481, decode.d3.loss_dice: 0.7696, decode.d4.loss_cls: 0.0040, decode.d4.loss_mask: 0.7418, decode.d4.loss_dice: 0.7642, decode.d5.loss_cls: 0.0034, decode.d5.loss_mask: 0.7409, decode.d5.loss_dice: 0.7695, decode.d6.loss_cls: 0.0036, decode.d6.loss_mask: 0.7416, decode.d6.loss_dice: 0.7710, decode.d7.loss_cls: 0.0030, decode.d7.loss_mask: 0.7394, decode.d7.loss_dice: 0.7710, decode.d8.loss_cls: 0.0030, decode.d8.loss_mask: 0.7495, decode.d8.loss_dice: 0.7717, loss: 17.0803, grad_norm: 576.2447
2023-08-29 10:44:14,822 - mmseg - INFO - Iter [4100/160000]	lr: 1.640e-06, eta: 1 day, 7:21:57, time: 0.739, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.6709, decode.loss_dice: 0.7039, decode.d0.loss_cls: 1.7103, decode.d0.loss_mask: 0.7015, decode.d0.loss_dice: 0.7987, decode.d1.loss_cls: 0.0120, decode.d1.loss_mask: 0.6817, decode.d1.loss_dice: 0.7235, decode.d2.loss_cls: 0.0073, decode.d2.loss_mask: 0.6751, decode.d2.loss_dice: 0.7132, decode.d3.loss_cls: 0.0045, decode.d3.loss_mask: 0.6687, decode.d3.loss_dice: 0.7010, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.6707, decode.d4.loss_dice: 0.6982, decode.d5.loss_cls: 0.0037, decode.d5.loss_mask: 0.6722, decode.d5.loss_dice: 0.7009, decode.d6.loss_cls: 0.0035, decode.d6.loss_mask: 0.6753, decode.d6.loss_dice: 0.6960, decode.d7.loss_cls: 0.0031, decode.d7.loss_mask: 0.6701, decode.d7.loss_dice: 0.6999, decode.d8.loss_cls: 0.0031, decode.d8.loss_mask: 0.6756, decode.d8.loss_dice: 0.6996, loss: 15.6516, grad_norm: 523.6986
2023-08-29 10:44:49,756 - mmseg - INFO - Iter [4150/160000]	lr: 1.640e-06, eta: 1 day, 7:20:33, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0028, decode.loss_mask: 0.6446, decode.loss_dice: 0.6977, decode.d0.loss_cls: 1.7017, decode.d0.loss_mask: 0.6793, decode.d0.loss_dice: 0.7887, decode.d1.loss_cls: 0.0113, decode.d1.loss_mask: 0.6638, decode.d1.loss_dice: 0.7145, decode.d2.loss_cls: 0.0070, decode.d2.loss_mask: 0.6530, decode.d2.loss_dice: 0.7029, decode.d3.loss_cls: 0.0041, decode.d3.loss_mask: 0.6451, decode.d3.loss_dice: 0.6941, decode.d4.loss_cls: 0.0037, decode.d4.loss_mask: 0.6451, decode.d4.loss_dice: 0.6914, decode.d5.loss_cls: 0.0032, decode.d5.loss_mask: 0.6458, decode.d5.loss_dice: 0.6901, decode.d6.loss_cls: 0.0030, decode.d6.loss_mask: 0.6484, decode.d6.loss_dice: 0.6888, decode.d7.loss_cls: 0.0027, decode.d7.loss_mask: 0.6462, decode.d7.loss_dice: 0.6870, decode.d8.loss_cls: 0.0027, decode.d8.loss_mask: 0.6471, decode.d8.loss_dice: 0.6888, loss: 15.3047, grad_norm: 584.2724
2023-08-29 10:45:26,021 - mmseg - INFO - Iter [4200/160000]	lr: 1.639e-06, eta: 1 day, 7:19:59, time: 0.725, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0172, decode.loss_mask: 0.7087, decode.loss_dice: 0.7284, decode.d0.loss_cls: 1.6943, decode.d0.loss_mask: 0.7240, decode.d0.loss_dice: 0.8228, decode.d1.loss_cls: 0.0276, decode.d1.loss_mask: 0.6958, decode.d1.loss_dice: 0.7417, decode.d2.loss_cls: 0.0217, decode.d2.loss_mask: 0.6921, decode.d2.loss_dice: 0.7348, decode.d3.loss_cls: 0.0206, decode.d3.loss_mask: 0.6888, decode.d3.loss_dice: 0.7289, decode.d4.loss_cls: 0.0107, decode.d4.loss_mask: 0.7062, decode.d4.loss_dice: 0.7264, decode.d5.loss_cls: 0.0181, decode.d5.loss_mask: 0.7002, decode.d5.loss_dice: 0.7282, decode.d6.loss_cls: 0.0095, decode.d6.loss_mask: 0.7082, decode.d6.loss_dice: 0.7258, decode.d7.loss_cls: 0.0167, decode.d7.loss_mask: 0.7011, decode.d7.loss_dice: 0.7252, decode.d8.loss_cls: 0.0246, decode.d8.loss_mask: 0.7027, decode.d8.loss_dice: 0.7336, loss: 16.2845, grad_norm: 548.2141
2023-08-29 10:46:02,981 - mmseg - INFO - Iter [4250/160000]	lr: 1.639e-06, eta: 1 day, 7:19:51, time: 0.739, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0035, decode.loss_mask: 0.5725, decode.loss_dice: 0.6605, decode.d0.loss_cls: 1.6840, decode.d0.loss_mask: 0.6336, decode.d0.loss_dice: 0.7701, decode.d1.loss_cls: 0.0115, decode.d1.loss_mask: 0.5922, decode.d1.loss_dice: 0.6926, decode.d2.loss_cls: 0.0073, decode.d2.loss_mask: 0.5803, decode.d2.loss_dice: 0.6709, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.5769, decode.d3.loss_dice: 0.6616, decode.d4.loss_cls: 0.0044, decode.d4.loss_mask: 0.5758, decode.d4.loss_dice: 0.6546, decode.d5.loss_cls: 0.0041, decode.d5.loss_mask: 0.5735, decode.d5.loss_dice: 0.6535, decode.d6.loss_cls: 0.0040, decode.d6.loss_mask: 0.5719, decode.d6.loss_dice: 0.6532, decode.d7.loss_cls: 0.0037, decode.d7.loss_mask: 0.5697, decode.d7.loss_dice: 0.6523, decode.d8.loss_cls: 0.0035, decode.d8.loss_mask: 0.5737, decode.d8.loss_dice: 0.6544, loss: 14.2746, grad_norm: 482.4715
2023-08-29 10:46:40,012 - mmseg - INFO - Iter [4300/160000]	lr: 1.638e-06, eta: 1 day, 7:19:44, time: 0.741, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0034, decode.loss_mask: 0.5928, decode.loss_dice: 0.6192, decode.d0.loss_cls: 1.6762, decode.d0.loss_mask: 0.6408, decode.d0.loss_dice: 0.7143, decode.d1.loss_cls: 0.0112, decode.d1.loss_mask: 0.6067, decode.d1.loss_dice: 0.6430, decode.d2.loss_cls: 0.0074, decode.d2.loss_mask: 0.5942, decode.d2.loss_dice: 0.6276, decode.d3.loss_cls: 0.0048, decode.d3.loss_mask: 0.5926, decode.d3.loss_dice: 0.6181, decode.d4.loss_cls: 0.0043, decode.d4.loss_mask: 0.5940, decode.d4.loss_dice: 0.6199, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.5942, decode.d5.loss_dice: 0.6209, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.5912, decode.d6.loss_dice: 0.6149, decode.d7.loss_cls: 0.0036, decode.d7.loss_mask: 0.5899, decode.d7.loss_dice: 0.6188, decode.d8.loss_cls: 0.0033, decode.d8.loss_mask: 0.5911, decode.d8.loss_dice: 0.6128, loss: 14.0190, grad_norm: 575.3252
2023-08-29 10:47:14,627 - mmseg - INFO - Iter [4350/160000]	lr: 1.637e-06, eta: 1 day, 7:18:11, time: 0.692, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.6793, decode.loss_dice: 0.7177, decode.d0.loss_cls: 1.6682, decode.d0.loss_mask: 0.6860, decode.d0.loss_dice: 0.7976, decode.d1.loss_cls: 0.0109, decode.d1.loss_mask: 0.6877, decode.d1.loss_dice: 0.7470, decode.d2.loss_cls: 0.0071, decode.d2.loss_mask: 0.6807, decode.d2.loss_dice: 0.7328, decode.d3.loss_cls: 0.0046, decode.d3.loss_mask: 0.6754, decode.d3.loss_dice: 0.7270, decode.d4.loss_cls: 0.0041, decode.d4.loss_mask: 0.6808, decode.d4.loss_dice: 0.7247, decode.d5.loss_cls: 0.0039, decode.d5.loss_mask: 0.6736, decode.d5.loss_dice: 0.7166, decode.d6.loss_cls: 0.0039, decode.d6.loss_mask: 0.6789, decode.d6.loss_dice: 0.7148, decode.d7.loss_cls: 0.0035, decode.d7.loss_mask: 0.6775, decode.d7.loss_dice: 0.7136, decode.d8.loss_cls: 0.0034, decode.d8.loss_mask: 0.6815, decode.d8.loss_dice: 0.7190, loss: 15.8253, grad_norm: 558.9140
2023-08-29 10:47:50,866 - mmseg - INFO - Iter [4400/160000]	lr: 1.637e-06, eta: 1 day, 7:17:35, time: 0.724, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0021, decode.loss_mask: 0.6690, decode.loss_dice: 0.6907, decode.d0.loss_cls: 1.6590, decode.d0.loss_mask: 0.6944, decode.d0.loss_dice: 0.7547, decode.d1.loss_cls: 0.0231, decode.d1.loss_mask: 0.6552, decode.d1.loss_dice: 0.6933, decode.d2.loss_cls: 0.0059, decode.d2.loss_mask: 0.6652, decode.d2.loss_dice: 0.6936, decode.d3.loss_cls: 0.0033, decode.d3.loss_mask: 0.6624, decode.d3.loss_dice: 0.6855, decode.d4.loss_cls: 0.0029, decode.d4.loss_mask: 0.6660, decode.d4.loss_dice: 0.6849, decode.d5.loss_cls: 0.0025, decode.d5.loss_mask: 0.6632, decode.d5.loss_dice: 0.6869, decode.d6.loss_cls: 0.0023, decode.d6.loss_mask: 0.6659, decode.d6.loss_dice: 0.6848, decode.d7.loss_cls: 0.0020, decode.d7.loss_mask: 0.6659, decode.d7.loss_dice: 0.6902, decode.d8.loss_cls: 0.0020, decode.d8.loss_mask: 0.6717, decode.d8.loss_dice: 0.6890, loss: 15.3377, grad_norm: 527.7466
2023-08-29 10:48:27,426 - mmseg - INFO - Iter [4450/160000]	lr: 1.636e-06, eta: 1 day, 7:17:12, time: 0.731, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0189, decode.loss_mask: 0.5922, decode.loss_dice: 0.6339, decode.d0.loss_cls: 1.6515, decode.d0.loss_mask: 0.6124, decode.d0.loss_dice: 0.7148, decode.d1.loss_cls: 0.0220, decode.d1.loss_mask: 0.5923, decode.d1.loss_dice: 0.6467, decode.d2.loss_cls: 0.0207, decode.d2.loss_mask: 0.5867, decode.d2.loss_dice: 0.6357, decode.d3.loss_cls: 0.0192, decode.d3.loss_mask: 0.5857, decode.d3.loss_dice: 0.6295, decode.d4.loss_cls: 0.0186, decode.d4.loss_mask: 0.5837, decode.d4.loss_dice: 0.6293, decode.d5.loss_cls: 0.0173, decode.d5.loss_mask: 0.5876, decode.d5.loss_dice: 0.6286, decode.d6.loss_cls: 0.0158, decode.d6.loss_mask: 0.5890, decode.d6.loss_dice: 0.6252, decode.d7.loss_cls: 0.0167, decode.d7.loss_mask: 0.5871, decode.d7.loss_dice: 0.6289, decode.d8.loss_cls: 0.0184, decode.d8.loss_mask: 0.5893, decode.d8.loss_dice: 0.6310, loss: 14.1289, grad_norm: 457.2362
2023-08-29 10:49:04,608 - mmseg - INFO - Iter [4500/160000]	lr: 1.636e-06, eta: 1 day, 7:17:10, time: 0.744, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0088, decode.loss_mask: 0.6986, decode.loss_dice: 0.7404, decode.d0.loss_cls: 1.6423, decode.d0.loss_mask: 0.6924, decode.d0.loss_dice: 0.7993, decode.d1.loss_cls: 0.0165, decode.d1.loss_mask: 0.6984, decode.d1.loss_dice: 0.7474, decode.d2.loss_cls: 0.0121, decode.d2.loss_mask: 0.6959, decode.d2.loss_dice: 0.7416, decode.d3.loss_cls: 0.0111, decode.d3.loss_mask: 0.6950, decode.d3.loss_dice: 0.7300, decode.d4.loss_cls: 0.0095, decode.d4.loss_mask: 0.6944, decode.d4.loss_dice: 0.7355, decode.d5.loss_cls: 0.0090, decode.d5.loss_mask: 0.6942, decode.d5.loss_dice: 0.7367, decode.d6.loss_cls: 0.0090, decode.d6.loss_mask: 0.6942, decode.d6.loss_dice: 0.7358, decode.d7.loss_cls: 0.0088, decode.d7.loss_mask: 0.6935, decode.d7.loss_dice: 0.7390, decode.d8.loss_cls: 0.0088, decode.d8.loss_mask: 0.6994, decode.d8.loss_dice: 0.7406, loss: 16.1382, grad_norm: 544.4272
2023-08-29 10:49:39,375 - mmseg - INFO - Iter [4550/160000]	lr: 1.635e-06, eta: 1 day, 7:15:44, time: 0.695, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0185, decode.loss_mask: 0.6800, decode.loss_dice: 0.6583, decode.d0.loss_cls: 1.6368, decode.d0.loss_mask: 0.6798, decode.d0.loss_dice: 0.7128, decode.d1.loss_cls: 0.0294, decode.d1.loss_mask: 0.6622, decode.d1.loss_dice: 0.6610, decode.d2.loss_cls: 0.0271, decode.d2.loss_mask: 0.6543, decode.d2.loss_dice: 0.6557, decode.d3.loss_cls: 0.0189, decode.d3.loss_mask: 0.6682, decode.d3.loss_dice: 0.6523, decode.d4.loss_cls: 0.0186, decode.d4.loss_mask: 0.6709, decode.d4.loss_dice: 0.6529, decode.d5.loss_cls: 0.0183, decode.d5.loss_mask: 0.6753, decode.d5.loss_dice: 0.6521, decode.d6.loss_cls: 0.0173, decode.d6.loss_mask: 0.6756, decode.d6.loss_dice: 0.6530, decode.d7.loss_cls: 0.0171, decode.d7.loss_mask: 0.6737, decode.d7.loss_dice: 0.6544, decode.d8.loss_cls: 0.0182, decode.d8.loss_mask: 0.6750, decode.d8.loss_dice: 0.6556, loss: 15.1432, grad_norm: 564.2434
2023-08-29 10:50:15,923 - mmseg - INFO - Iter [4600/160000]	lr: 1.635e-06, eta: 1 day, 7:15:19, time: 0.731, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0102, decode.loss_mask: 0.6479, decode.loss_dice: 0.6855, decode.d0.loss_cls: 1.6271, decode.d0.loss_mask: 0.6777, decode.d0.loss_dice: 0.7743, decode.d1.loss_cls: 0.0263, decode.d1.loss_mask: 0.6612, decode.d1.loss_dice: 0.7087, decode.d2.loss_cls: 0.0135, decode.d2.loss_mask: 0.6503, decode.d2.loss_dice: 0.7026, decode.d3.loss_cls: 0.0107, decode.d3.loss_mask: 0.6422, decode.d3.loss_dice: 0.6928, decode.d4.loss_cls: 0.0097, decode.d4.loss_mask: 0.6413, decode.d4.loss_dice: 0.6864, decode.d5.loss_cls: 0.0092, decode.d5.loss_mask: 0.6414, decode.d5.loss_dice: 0.6874, decode.d6.loss_cls: 0.0085, decode.d6.loss_mask: 0.6470, decode.d6.loss_dice: 0.6879, decode.d7.loss_cls: 0.0089, decode.d7.loss_mask: 0.6400, decode.d7.loss_dice: 0.6854, decode.d8.loss_cls: 0.0095, decode.d8.loss_mask: 0.6485, decode.d8.loss_dice: 0.6877, loss: 15.2296, grad_norm: 521.4071
2023-08-29 10:50:52,428 - mmseg - INFO - Iter [4650/160000]	lr: 1.634e-06, eta: 1 day, 7:14:53, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0264, decode.loss_mask: 0.5951, decode.loss_dice: 0.6107, decode.d0.loss_cls: 1.6193, decode.d0.loss_mask: 0.6240, decode.d0.loss_dice: 0.6897, decode.d1.loss_cls: 0.0282, decode.d1.loss_mask: 0.5950, decode.d1.loss_dice: 0.6277, decode.d2.loss_cls: 0.0266, decode.d2.loss_mask: 0.5875, decode.d2.loss_dice: 0.6160, decode.d3.loss_cls: 0.0250, decode.d3.loss_mask: 0.5856, decode.d3.loss_dice: 0.6115, decode.d4.loss_cls: 0.0236, decode.d4.loss_mask: 0.5821, decode.d4.loss_dice: 0.6091, decode.d5.loss_cls: 0.0218, decode.d5.loss_mask: 0.5852, decode.d5.loss_dice: 0.6078, decode.d6.loss_cls: 0.0202, decode.d6.loss_mask: 0.5891, decode.d6.loss_dice: 0.6051, decode.d7.loss_cls: 0.0239, decode.d7.loss_mask: 0.5905, decode.d7.loss_dice: 0.6112, decode.d8.loss_cls: 0.0255, decode.d8.loss_mask: 0.5923, decode.d8.loss_dice: 0.6070, loss: 13.9627, grad_norm: 501.2212
2023-08-29 10:51:29,423 - mmseg - INFO - Iter [4700/160000]	lr: 1.634e-06, eta: 1 day, 7:14:43, time: 0.740, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0031, decode.loss_mask: 0.6808, decode.loss_dice: 0.6729, decode.d0.loss_cls: 1.6080, decode.d0.loss_mask: 0.6967, decode.d0.loss_dice: 0.7281, decode.d1.loss_cls: 0.0089, decode.d1.loss_mask: 0.6823, decode.d1.loss_dice: 0.6766, decode.d2.loss_cls: 0.0061, decode.d2.loss_mask: 0.6822, decode.d2.loss_dice: 0.6683, decode.d3.loss_cls: 0.0042, decode.d3.loss_mask: 0.6751, decode.d3.loss_dice: 0.6640, decode.d4.loss_cls: 0.0042, decode.d4.loss_mask: 0.6783, decode.d4.loss_dice: 0.6679, decode.d5.loss_cls: 0.0036, decode.d5.loss_mask: 0.6833, decode.d5.loss_dice: 0.6635, decode.d6.loss_cls: 0.0032, decode.d6.loss_mask: 0.6854, decode.d6.loss_dice: 0.6663, decode.d7.loss_cls: 0.0025, decode.d7.loss_mask: 0.6907, decode.d7.loss_dice: 0.6738, decode.d8.loss_cls: 0.0024, decode.d8.loss_mask: 0.6848, decode.d8.loss_dice: 0.6679, loss: 15.2348, grad_norm: 551.7819
2023-08-29 10:52:04,320 - mmseg - INFO - Iter [4750/160000]	lr: 1.633e-06, eta: 1 day, 7:13:24, time: 0.698, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0030, decode.loss_mask: 0.7419, decode.loss_dice: 0.7561, decode.d0.loss_cls: 1.6018, decode.d0.loss_mask: 0.7179, decode.d0.loss_dice: 0.7926, decode.d1.loss_cls: 0.0283, decode.d1.loss_mask: 0.7043, decode.d1.loss_dice: 0.7421, decode.d2.loss_cls: 0.0196, decode.d2.loss_mask: 0.6901, decode.d2.loss_dice: 0.7387, decode.d3.loss_cls: 0.0231, decode.d3.loss_mask: 0.6899, decode.d3.loss_dice: 0.7326, decode.d4.loss_cls: 0.0154, decode.d4.loss_mask: 0.6998, decode.d4.loss_dice: 0.7440, decode.d5.loss_cls: 0.0103, decode.d5.loss_mask: 0.7202, decode.d5.loss_dice: 0.7452, decode.d6.loss_cls: 0.0099, decode.d6.loss_mask: 0.7318, decode.d6.loss_dice: 0.7540, decode.d7.loss_cls: 0.0102, decode.d7.loss_mask: 0.7274, decode.d7.loss_dice: 0.7521, decode.d8.loss_cls: 0.0104, decode.d8.loss_mask: 0.7379, decode.d8.loss_dice: 0.7524, loss: 16.4031, grad_norm: 571.4842
2023-08-29 10:52:41,144 - mmseg - INFO - Iter [4800/160000]	lr: 1.633e-06, eta: 1 day, 7:13:08, time: 0.736, data_time: 0.048, memory: 6584, decode.loss_cls: 0.0111, decode.loss_mask: 0.6860, decode.loss_dice: 0.6929, decode.d0.loss_cls: 1.5932, decode.d0.loss_mask: 0.6680, decode.d0.loss_dice: 0.7431, decode.d1.loss_cls: 0.0331, decode.d1.loss_mask: 0.6649, decode.d1.loss_dice: 0.7041, decode.d2.loss_cls: 0.0192, decode.d2.loss_mask: 0.6695, decode.d2.loss_dice: 0.6923, decode.d3.loss_cls: 0.0157, decode.d3.loss_mask: 0.6679, decode.d3.loss_dice: 0.6833, decode.d4.loss_cls: 0.0162, decode.d4.loss_mask: 0.6732, decode.d4.loss_dice: 0.6808, decode.d5.loss_cls: 0.0105, decode.d5.loss_mask: 0.6868, decode.d5.loss_dice: 0.6885, decode.d6.loss_cls: 0.0108, decode.d6.loss_mask: 0.6802, decode.d6.loss_dice: 0.6921, decode.d7.loss_cls: 0.0104, decode.d7.loss_mask: 0.6798, decode.d7.loss_dice: 0.6888, decode.d8.loss_cls: 0.0110, decode.d8.loss_mask: 0.6884, decode.d8.loss_dice: 0.6870, loss: 15.4487, grad_norm: 477.4289
2023-08-29 10:53:17,633 - mmseg - INFO - Iter [4850/160000]	lr: 1.632e-06, eta: 1 day, 7:12:40, time: 0.730, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0132, decode.loss_mask: 0.6071, decode.loss_dice: 0.6765, decode.d0.loss_cls: 1.5852, decode.d0.loss_mask: 0.6306, decode.d0.loss_dice: 0.7348, decode.d1.loss_cls: 0.0203, decode.d1.loss_mask: 0.6118, decode.d1.loss_dice: 0.6808, decode.d2.loss_cls: 0.0152, decode.d2.loss_mask: 0.6017, decode.d2.loss_dice: 0.6731, decode.d3.loss_cls: 0.0133, decode.d3.loss_mask: 0.6050, decode.d3.loss_dice: 0.6717, decode.d4.loss_cls: 0.0131, decode.d4.loss_mask: 0.6088, decode.d4.loss_dice: 0.6697, decode.d5.loss_cls: 0.0131, decode.d5.loss_mask: 0.6076, decode.d5.loss_dice: 0.6785, decode.d6.loss_cls: 0.0129, decode.d6.loss_mask: 0.6051, decode.d6.loss_dice: 0.6749, decode.d7.loss_cls: 0.0132, decode.d7.loss_mask: 0.6056, decode.d7.loss_dice: 0.6776, decode.d8.loss_cls: 0.0135, decode.d8.loss_mask: 0.6086, decode.d8.loss_dice: 0.6771, loss: 14.6198, grad_norm: 491.5110
2023-08-29 10:53:54,668 - mmseg - INFO - Iter [4900/160000]	lr: 1.632e-06, eta: 1 day, 7:12:31, time: 0.741, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0033, decode.loss_mask: 0.6476, decode.loss_dice: 0.6564, decode.d0.loss_cls: 1.5747, decode.d0.loss_mask: 0.6872, decode.d0.loss_dice: 0.7264, decode.d1.loss_cls: 0.0093, decode.d1.loss_mask: 0.6455, decode.d1.loss_dice: 0.6546, decode.d2.loss_cls: 0.0064, decode.d2.loss_mask: 0.6345, decode.d2.loss_dice: 0.6482, decode.d3.loss_cls: 0.0095, decode.d3.loss_mask: 0.6360, decode.d3.loss_dice: 0.6370, decode.d4.loss_cls: 0.0096, decode.d4.loss_mask: 0.6375, decode.d4.loss_dice: 0.6376, decode.d5.loss_cls: 0.0098, decode.d5.loss_mask: 0.6371, decode.d5.loss_dice: 0.6472, decode.d6.loss_cls: 0.0034, decode.d6.loss_mask: 0.6456, decode.d6.loss_dice: 0.6430, decode.d7.loss_cls: 0.0093, decode.d7.loss_mask: 0.6386, decode.d7.loss_dice: 0.6403, decode.d8.loss_cls: 0.0094, decode.d8.loss_mask: 0.6387, decode.d8.loss_dice: 0.6390, loss: 14.6226, grad_norm: 508.0062
2023-08-29 10:54:29,602 - mmseg - INFO - Iter [4950/160000]	lr: 1.631e-06, eta: 1 day, 7:11:14, time: 0.699, data_time: 0.005, memory: 6584, decode.loss_cls: 0.0187, decode.loss_mask: 0.6136, decode.loss_dice: 0.6244, decode.d0.loss_cls: 1.5685, decode.d0.loss_mask: 0.6499, decode.d0.loss_dice: 0.6965, decode.d1.loss_cls: 0.0217, decode.d1.loss_mask: 0.6305, decode.d1.loss_dice: 0.6485, decode.d2.loss_cls: 0.0205, decode.d2.loss_mask: 0.6124, decode.d2.loss_dice: 0.6345, decode.d3.loss_cls: 0.0185, decode.d3.loss_mask: 0.6038, decode.d3.loss_dice: 0.6245, decode.d4.loss_cls: 0.0167, decode.d4.loss_mask: 0.6076, decode.d4.loss_dice: 0.6253, decode.d5.loss_cls: 0.0152, decode.d5.loss_mask: 0.6078, decode.d5.loss_dice: 0.6222, decode.d6.loss_cls: 0.0146, decode.d6.loss_mask: 0.6113, decode.d6.loss_dice: 0.6203, decode.d7.loss_cls: 0.0170, decode.d7.loss_mask: 0.6120, decode.d7.loss_dice: 0.6248, decode.d8.loss_cls: 0.0175, decode.d8.loss_mask: 0.6128, decode.d8.loss_dice: 0.6243, loss: 14.2359, grad_norm: 493.3025
2023-08-29 10:55:06,093 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-08-29 10:55:08,919 - mmseg - INFO - Exp name: mask2former_internimage_b_kitti.py
2023-08-29 10:55:08,919 - mmseg - INFO - Iter [5000/160000]	lr: 1.631e-06, eta: 1 day, 7:12:15, time: 0.786, data_time: 0.047, memory: 6584, decode.loss_cls: 0.0086, decode.loss_mask: 0.6022, decode.loss_dice: 0.5871, decode.d0.loss_cls: 1.5592, decode.d0.loss_mask: 0.6407, decode.d0.loss_dice: 0.6769, decode.d1.loss_cls: 0.0149, decode.d1.loss_mask: 0.6056, decode.d1.loss_dice: 0.6086, decode.d2.loss_cls: 0.0069, decode.d2.loss_mask: 0.6081, decode.d2.loss_dice: 0.5974, decode.d3.loss_cls: 0.0051, decode.d3.loss_mask: 0.6061, decode.d3.loss_dice: 0.5868, decode.d4.loss_cls: 0.0048, decode.d4.loss_mask: 0.6113, decode.d4.loss_dice: 0.5892, decode.d5.loss_cls: 0.0046, decode.d5.loss_mask: 0.6133, decode.d5.loss_dice: 0.5882, decode.d6.loss_cls: 0.0104, decode.d6.loss_mask: 0.6048, decode.d6.loss_dice: 0.5872, decode.d7.loss_cls: 0.0090, decode.d7.loss_mask: 0.6015, decode.d7.loss_dice: 0.5855, decode.d8.loss_cls: 0.0088, decode.d8.loss_mask: 0.6027, decode.d8.loss_dice: 0.5874, loss: 13.7228, grad_norm: 473.4327
